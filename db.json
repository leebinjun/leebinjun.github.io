{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/yilia/source/slider.e37972.js","path":"slider.e37972.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.css","path":"main.0cf68a.css","modified":1,"renderable":1},{"_id":"themes/yilia/source/main.0cf68a.js","path":"main.0cf68a.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/mobile.992cbe.js","path":"mobile.992cbe.js","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","path":"fonts/default-skin.b257fa.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","path":"fonts/iconfont.16acc2.ttf","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","path":"fonts/iconfont.8c627f.woff","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","path":"fonts/iconfont.b322fa.eot","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","path":"fonts/tooltip.4004ff.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/default-skin.png","path":"img/default-skin.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/favicon.png","path":"img/favicon.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/preloader.gif","path":"img/preloader.gif","modified":1,"renderable":1},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","path":"fonts/iconfont.45d7ee.svg","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","path":"img/scrollbar_arrow.png","modified":1,"renderable":1},{"_id":"themes/yilia/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1}],"Cache":[{"_id":"themes/yilia/.eslintignore","hash":"ed9d8911ca08c3dd5072c48dd0be4d06f8897730","modified":1561047493399},{"_id":"themes/yilia/.editorconfig","hash":"daaa8757fac18f8735fadd0a37a42c06f421ca14","modified":1561047493398},{"_id":"themes/yilia/.babelrc","hash":"db600d40e93e6d8023737a65d58d3be7370e5e30","modified":1561047493397},{"_id":"themes/yilia/.gitattributes","hash":"758cfbecfa7919e99abddf3297f37cde7e3d8d4e","modified":1561047493402},{"_id":"themes/yilia/.eslintrc.js","hash":"303d25adf02ad65720e537a16a4a137d14bb755f","modified":1561047493400},{"_id":"themes/yilia/README.md","hash":"1bf755806af9d8874bd22e1abbdaaa24328ef4dc","modified":1561047493404},{"_id":"themes/yilia/package.json","hash":"ee6aa61f1cb89fd549e3e087c0232207a9c9ee30","modified":1561047493451},{"_id":"themes/yilia/webpack.config.js","hash":"da7657347109ddb4ab8602b219778117254677fe","modified":1561047493530},{"_id":"themes/yilia/.gitignore","hash":"d5fc575329853ff620b50fc62ad4b18fa09a308a","modified":1561265908755},{"_id":"source/_posts/AI通关超级马里奥.md","hash":"c74024817377e4f608041bb4b2b9749aa3a3a37a","modified":1560347892173},{"_id":"themes/yilia/_config.yml","hash":"d21fc9f9d053db55e28655386947cd8aa5a4809b","modified":1561212562030},{"_id":"source/_posts/Hexo：Hello Hexo.md","hash":"2d45fb36bf5ad9fa6dcc90ad4df4a3e110483db0","modified":1561990804062},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他.md","hash":"d89cc5fe702aaff7cc385289e5698b919e840ebf","modified":1562159236176},{"_id":"source/_posts/Hexo：yilia主题下使用LaTex添加公式.md","hash":"2403376046bc75ae8f0a4076b6a0c12941282a78","modified":1561273779722},{"_id":"source/_posts/Hexo：使用dev分支管理站点源文件，多地同步.md","hash":"d79cdd686c6bc7cfbfe9aac8887e5de70cbaa97e","modified":1561273779725},{"_id":"source/_posts/Hikey970使用记录.md","hash":"f484f535da2f3177450caef1fa40d1cc852ec914","modified":1561273779728},{"_id":"source/_posts/Hikey970使用记录一：ubuntu16-04下烧写lebian系统.md","hash":"dae5dc44d774997f9cd7d2a1f0e6912c92bc3266","modified":1561273779731},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装.md","hash":"fbbd2193e33ad05327442f2cc90b60562f7dbaaf","modified":1561273779734},{"_id":"source/_posts/Jetson-Nano-使用记录.md","hash":"ef01ed0106f6e2c13184813cc02868a1878d5497","modified":1561273779743},{"_id":"source/_posts/OpenCV学习笔记.md","hash":"99757738ab44a133acc98301d426dd65b9517522","modified":1561211945628},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0.md","hash":"14d11d07e4cbd431104d2a83785f718f7dc3268c","modified":1561273779736},{"_id":"source/_posts/Hikey970使用记录四：python加载运行OpenCL.md","hash":"f7d1992cef19ed431c680472708180b347a48ec6","modified":1561273779740},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索.md","hash":"14f1c19469633ac93a3c209ee89677b997e67476","modified":1561355263298},{"_id":"source/_posts/OpenCV学习笔记二：图像处理.md","hash":"e177904cdedfaadf50f2bc91c88e08dd88e31503","modified":1561273779749},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别.md","hash":"47d86170c33ac656065a516cf998ede0765df5a1","modified":1561273779752},{"_id":"source/_posts/RL学习笔记.md","hash":"802ceaf0721ba5b69611a4e4ec54532d9201ff91","modified":1561509471995},{"_id":"source/_posts/Pixar-Lamp.md","hash":"4a43d174a7bae36421d79403cb60c0d12ff57627","modified":1561509383180},{"_id":"source/_posts/golang学习笔记.md","hash":"2186226b3b4ba1b07f1af689776e3c99836611d3","modified":1561461480533},{"_id":"source/_posts/loomo多服务机器人开发.1.md","hash":"6ccb98284a22db4c625285d8255d5d7456a135f3","modified":1561658831185},{"_id":"source/_posts/Scikit-Learn学习笔记.md","hash":"e12ac31b530857004f45748144914c2f4f0dd007","modified":1561273779754},{"_id":"source/_posts/loomo多服务机器人开发.md","hash":"6ccb98284a22db4c625285d8255d5d7456a135f3","modified":1558936510872},{"_id":"source/_posts/TensorFlow-手写数字识别.md","hash":"3d4a2c4f354aeb2316d609d199a12800caa2bc40","modified":1561273779758},{"_id":"source/_posts/tkinter学习笔记.md","hash":"752e4cad89a640969ed5ee49970189202d5299ed","modified":1561273779761},{"_id":"source/_posts/作业检查机器人.md","hash":"c964e04283a9fd54b3dfd9dd92341536bf2b5b7f","modified":1561273779767},{"_id":"source/_posts/人生苦短，我用python.md","hash":"24fbeacea72ee3a8b850db9dabb2f4d5fcf37f9d","modified":1561273779764},{"_id":"source/_posts/天猫精灵，开灯.md","hash":"568a47b84f0c1a0aabd087355018fa534e7fe41f","modified":1561628071912},{"_id":"source/_posts/打磨工具的日常.md","hash":"a76fb368ee4bd0efef1a1e3900ee278b091236ca","modified":1562347823180},{"_id":"source/_posts/天猫精灵：绑定贝壳物联设备.md","hash":"b67ac9c775feaf9a7d74a51502cd7a1af05021a8","modified":1561423464724},{"_id":"source/_posts/好玩的-基于视觉控制的无传感器机械臂.md","hash":"7ad21cd9f0b1cbd8d3389614c2b55b527cfe55c4","modified":1561273779773},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3.md","hash":"96685cd4b33d3c68333460964e359e1c1f7096a3","modified":1561273779778},{"_id":"source/_posts/桌面冰球机器人.md","hash":"a3cde456c14cb14d65a572f6a40167d01fbf158b","modified":1561273779782},{"_id":"source/_posts/简单手势分类器.md","hash":"cd42f3709ff70239df73e5751ab88c10ea2892e7","modified":1561273779785},{"_id":"source/_posts/象棋残局机器人.md","hash":"5dde5c81928964bdb1443cd7f65cab24b09c9548","modified":1561273779787},{"_id":"source/_posts/象棋残局机器人一：摄像头标定.md","hash":"bb302d3afd3b60afc48b02b434d865ee3d3c0aca","modified":1561273779790},{"_id":"source/_posts/象棋残局机器人三：分类模型retrain.md","hash":"c16568ff6251dbf1d3420a429b6b7babafc0a1c4","modified":1561273779793},{"_id":"source/_posts/象棋残局机器人二：透射变换.md","hash":"c3e6d8d0992435f2b82c773ddd7e59fa87c82e48","modified":1561273779796},{"_id":"source/_posts/门禁python多进程练习.md","hash":"c5fbaace869b21b79d7627edf18d79b541ec3b5e","modified":1558265742286},{"_id":"source/_posts/象棋残局机器人五：象棋棋子分类模型.md","hash":"6a9fc6c22e08cfafe393acb44bf9b3d8376b4fa9","modified":1559957529509},{"_id":"source/_posts/象棋残局机器人四：策略.md","hash":"e58fe2b5746a1dab26d255262e55711e377d3baa","modified":1561658734416},{"_id":"source/_posts/门禁ubuntu配置-hadow-ocks-又可以刷脸开门了.md","hash":"abef71bd8c97655385837db79435863223f72be4","modified":1558008076477},{"_id":"source/_posts/门禁人脸检测和识别二：人脸关键点检测.md","hash":"b73dc8ddca75028a53f26c32fe3f87ad9f7e1b10","modified":1561960081312},{"_id":"themes/yilia/languages/fr.yml","hash":"b4be1c1592a72012e48df2b3ec41cc9685573e50","modified":1561047493409},{"_id":"themes/yilia/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1561047493408},{"_id":"themes/yilia/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1561047493411},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图.md","hash":"7835bf7c1392ebede681410a0012b4a8f115fa3c","modified":1561960081231},{"_id":"source/_posts/门禁人脸检测和识别.md","hash":"ad404ab0100f2f66f4f623cdf6383b2968c9d38c","modified":1561688725883},{"_id":"themes/yilia/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1561047493410},{"_id":"themes/yilia/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1561047493414},{"_id":"themes/yilia/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1561047493412},{"_id":"themes/yilia/languages/zh-tw.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1561047493414},{"_id":"themes/yilia/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1561047493446},{"_id":"themes/yilia/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1561047493446},{"_id":"themes/yilia/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1561047493449},{"_id":"themes/yilia/layout/index.ejs","hash":"ec498c6c0606acde997ce195dad97b267418d980","modified":1561047493447},{"_id":"themes/yilia/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1561047493450},{"_id":"themes/yilia/source/slider.e37972.js","hash":"ce5eac88301fe4f2fce0fb6203adfd58eb8313ac","modified":1561047493529},{"_id":"themes/yilia/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1561047493450},{"_id":"themes/yilia/source-src/css.ejs","hash":"cf7eab48d626433120d1ef9697f719a359817018","modified":1561047493453},{"_id":"themes/yilia/source/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1561047493524},{"_id":"themes/yilia/layout/layout.ejs","hash":"b471ab706d48e0be3f783eab1c94bf5878ef5a94","modified":1561047493448},{"_id":"themes/yilia/layout/_partial/toc.ejs","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1561047493443},{"_id":"themes/yilia/source/main.0cf68a.js","hash":"283ae27ea37ac3e0e45b2e05c2482a4c594b9c25","modified":1561047493526},{"_id":"themes/yilia/source/mobile.992cbe.js","hash":"1801ef448909ea23c0a48e9d63b80d0cfd5534ce","modified":1561047493528},{"_id":"themes/yilia/source-src/script.ejs","hash":"28abac2426761d7e715b38aadd86ce6549c8ae77","modified":1561047493510},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/01.jpg","hash":"e74d801194ae1d8a7f742b1100c7941ee0472fa3","modified":1561378370720},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/04.jpg","hash":"9193fd0f0bd0ca765ecdf0414f660c8e97584419","modified":1561378371514},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/05.jpg","hash":"bb4e70195c68d2c20a2bdef3f139875d69d4722e","modified":1561378371782},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/06.jpg","hash":"a8007562b9bf8c521d98a26208f1a5c286a01625","modified":1561378372014},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/08.jpg","hash":"91d1bc553c6a0bc4d135a21c894fdb5b113dbf46","modified":1561378372311},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/09.jpg","hash":"8ea6bc4526895cb14de783493eeb0d8f802a3c3a","modified":1561378372564},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/10.jpg","hash":"d6c0f82ef44ecd06d082ac5c4fdf110da429267a","modified":1561378372853},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/01.png","hash":"7e5314a03c74db15275086e1c13e5e7028f2098b","modified":1558491107436},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/02.png","hash":"7ac3bb89ea653ade2274a55c2df1d840e612925c","modified":1558491107454},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/03.png","hash":"7ac3bb89ea653ade2274a55c2df1d840e612925c","modified":1558491107471},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/05.png","hash":"901c6cdf2df9d6eeb33764075fb8f173de2c2aca","modified":1558598006127},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/04.png","hash":"abe85cacc69856c16f0dde15260a8a1e93acf8e3","modified":1558491107492},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/02.png","hash":"80bd21e079b45ab858392b32db5f4cc9033e80f3","modified":1558490925305},{"_id":"source/_posts/Hikey970使用记录四：python加载运行OpenCL/001.png","hash":"47eacba12e82d7f96d6a08af56b236fa3c753247","modified":1559962108757},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/04.png","hash":"009f3589b63238bced9cfdf0ba06ae4a7f8961bb","modified":1558491004606},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/13.jpg","hash":"35fbbbb8362d8898f3ac25906602292c5daa91f7","modified":1561378373660},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/12.jpg","hash":"d0126b7c29b498174a535bba0d040e3c9470b053","modified":1561378373391},{"_id":"source/_posts/Jetson-Nano-使用记录/001.png","hash":"518664af6d7f8de158242d105c49cd81e9d04a0b","modified":1558969395631},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png","hash":"fb4b5ba9198de9f15c3f53a55b3b8ebeec4625a6","modified":1561219922950},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_11_0.png","hash":"1f7fd7671a8b7684944a70e126cad69d5947f5d9","modified":1561219720449},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_3_2.png","hash":"56fb48ccacf28ed66952e3807992e415c120f7bd","modified":1561219720315},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_5_0.png","hash":"355fbdeabc595dd19c8120949c111315dbfb4fea","modified":1561219720361},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_10_0.png","hash":"9e22eec352a63f34069909b937114ef4b83aef01","modified":1561219248363},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_12_0.png","hash":"b9f35435353c9104206d15f9e1fc0080d9f577da","modified":1561219248385},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_15_0.png","hash":"c04ee8ba457033a91752d943d8ebbeefdbdc4997","modified":1561219248405},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/14.jpg","hash":"aa88fec7b947e1187492e1148705eee57f0f470b","modified":1561378373689},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_4_0.png","hash":"940533f012c8c253da0aeb90842789735387b3fd","modified":1561219248512},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_17_0.png","hash":"cc054900ef529158daa01096f78133cbea8fc373","modified":1561219248425},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg","hash":"f53d4585af600d9a5da0adbda75504af3d509552","modified":1561220826533},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_8_0.png","hash":"9e22eec352a63f34069909b937114ef4b83aef01","modified":1561219248447},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_6_0.png","hash":"63d04ed2f545819d2fc5f07ce688c2d51456d4c8","modified":1561219248487},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg","hash":"de7bbf05c2e0f0c2a3632870fee22c3c97ea2d29","modified":1561220826474},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/output_5_1.png","hash":"1599adad9ed3c8a86b22d8bd8ec2b6a8c58a4031","modified":1561221038530},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/hog01.jpg","hash":"e33929d7053e091469aeb40f9806d02f6796bb18","modified":1561221029594},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/hog02.jpg","hash":"afa2d3a91de70c4665662f7878022db8a8bfd048","modified":1561221029549},{"_id":"source/_posts/Pixar-Lamp/001.jpg","hash":"ff73857dfe4b15be6493ee9cc5d851a454614890","modified":1558427874207},{"_id":"source/_posts/作业检查机器人/000.jpg","hash":"3b5d75ac6526ac25894c1a714e180c48bfc07477","modified":1560446642620},{"_id":"source/_posts/象棋残局机器人四：策略/001.png","hash":"c77e354f7c15e46d93a789d87364937c778083bc","modified":1559737437790},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/P_Trangle.png","hash":"ff6611e104f982244bff6509a839e7ab1539cf3d","modified":1561960081258},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/Trangle.png","hash":"b3cc5c8346fa34f4a63037ecfe2b14f01294286e","modified":1561960081273},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/output_4_0.png","hash":"81ff22ed5dfff551180b84ac68d277d0a2b29bf1","modified":1561960081310},{"_id":"themes/yilia/layout/_partial/archive-post.ejs","hash":"edc0154b30a4127acda10297bec6aacf754b4ac4","modified":1561047493418},{"_id":"themes/yilia/layout/_partial/after-footer.ejs","hash":"c70f367f54064a441e574c913f5e0ea121d0f899","modified":1561047493417},{"_id":"themes/yilia/layout/_partial/aside.ejs","hash":"751e5deab5365348be5243688b419c82d337ab9a","modified":1561047493422},{"_id":"themes/yilia/layout/_partial/footer.ejs","hash":"871f81cacd5d41cb2eb001cd56254217a857dc2f","modified":1561047493425},{"_id":"themes/yilia/layout/_partial/archive.ejs","hash":"a4eacc2bc1278095a0ef99f904b0634c78f980eb","modified":1561047493419},{"_id":"themes/yilia/layout/_partial/baidu-analytics.ejs","hash":"155327c23607f69989b58845f24d842a54e504b8","modified":1561047493423},{"_id":"themes/yilia/layout/_partial/css.ejs","hash":"236f8a377b2e4e35754319c3029bcd4a4115431d","modified":1561047493424},{"_id":"themes/yilia/layout/_partial/header.ejs","hash":"b69855e07b65117769adc515cb64b803932068c9","modified":1561047493427},{"_id":"themes/yilia/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1561047493425},{"_id":"themes/yilia/layout/_partial/head.ejs","hash":"12ca7d8dba56bc767b9309dda9526dcbaffc1614","modified":1561047493426},{"_id":"themes/yilia/layout/_partial/left-col.ejs","hash":"fb1b8457b9eb15b55da1bf7b133e12c375dd26f8","modified":1561047493428},{"_id":"themes/yilia/layout/_partial/mathjax.ejs","hash":"11550a418921d330e6553be0569a94ab5a217967","modified":1561047493429},{"_id":"themes/yilia/layout/_partial/article.ejs","hash":"8dea8f5f93a60185439b330b0f1d1649a6ab4bd0","modified":1561047493421},{"_id":"themes/yilia/layout/_partial/mobile-nav.ejs","hash":"ccec1fc70f021cb50ac85b524e7949878ab93a18","modified":1561047493430},{"_id":"themes/yilia/layout/_partial/viewer.ejs","hash":"cc1c39903aed0a0601d104238d2bbd13ad2a36f3","modified":1561047493445},{"_id":"themes/yilia/source/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1561047493513},{"_id":"themes/yilia/source/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1561047493515},{"_id":"themes/yilia/layout/_partial/tools.ejs","hash":"0ffcb251b79e8a920c9b4cb6bb7a96a808816165","modified":1561047493444},{"_id":"themes/yilia/source/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1561047493518},{"_id":"themes/yilia/source/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1561047493519},{"_id":"themes/yilia/source/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1561047493520},{"_id":"themes/yilia/source/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1561047493521},{"_id":"themes/yilia/source/img/favicon.png","hash":"37e487f5b0d19dfa9bd1e6c2a2014f02d9e4406e","modified":1561079711130},{"_id":"themes/yilia/source/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1561047493522},{"_id":"themes/yilia/source/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1561047493516},{"_id":"themes/yilia/source-src/css/archive.scss","hash":"d6a7dd88404b383b5b94e4c7ec675a410c41f3cc","modified":1561047493457},{"_id":"themes/yilia/source-src/css/_core.scss","hash":"29ba600e98ed55f7af4ade8038272c84cba21188","modified":1561047493455},{"_id":"themes/yilia/source-src/css/_function.scss","hash":"ce227b6f5a9af194fd5d455200630f32c05e151f","modified":1561047493456},{"_id":"themes/yilia/source-src/css/article-main.scss","hash":"1577a2336b3ad122f49f60dff2bc1a97d4e7b18b","modified":1561047493458},{"_id":"themes/yilia/source-src/css/article-inner.scss","hash":"f7388f5c11370ef462f7cb913d8f72edf24ecaf9","modified":1561047493457},{"_id":"themes/yilia/source-src/css/article-nav.scss","hash":"8f82fe898ba1c1bd00c24a7d8270feddc7eba3bc","modified":1561047493459},{"_id":"themes/yilia/source/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1561047493523},{"_id":"themes/yilia/source-src/css/comment.scss","hash":"b85f344f2c66d43d7094746e0a9ccb21d0534201","modified":1561047493462},{"_id":"themes/yilia/source-src/css/aside.scss","hash":"07244c188f58ecfb90bb7c047b8cde977f1dc4b4","modified":1561047493461},{"_id":"themes/yilia/source-src/css/article.scss","hash":"55d082fec4c6bb341725567acaa29ce37d50320a","modified":1561047493460},{"_id":"themes/yilia/source-src/css/footer.scss","hash":"7ca837a4cc34db1c35f01baec85eb10ccc64ea86","modified":1561047493475},{"_id":"themes/yilia/source-src/css/fonts.scss","hash":"96d7eb1d42c06fdcccb8ef969f6ecd30c3194903","modified":1561047493469},{"_id":"themes/yilia/source-src/css/global.scss","hash":"b4cb4f45a55d4250cd9056f76dab2a3c0dabcec4","modified":1561047493476},{"_id":"themes/yilia/source-src/css/highlight.scss","hash":"40e5aa5056dc0b3b9f51c5b387370b612e265d4e","modified":1561047493478},{"_id":"themes/yilia/source-src/css/grid.scss","hash":"f53ea8270752b5919ec5d79224d22af91f2eda12","modified":1561047493477},{"_id":"themes/yilia/source-src/css/main.scss","hash":"9eba1fcf4805256697528fcf3b767cf6dd8d0591","modified":1561047493484},{"_id":"themes/yilia/source-src/css/mobile-slider.scss","hash":"19f10fd2f0c3377aa4b165b3c2291ecf86dd9351","modified":1561047493485},{"_id":"themes/yilia/source-src/css/left.scss","hash":"80dac621e43581a254d0152d5df901e4d0b01c09","modified":1561047493483},{"_id":"themes/yilia/source-src/css/mobile.scss","hash":"d995dcd483a250fe61b426158afb61bf8923a927","modified":1561047493488},{"_id":"themes/yilia/source-src/css/reward.scss","hash":"a557a9ed244c82b8b71e9da9de3339d92783499f","modified":1561047493491},{"_id":"themes/yilia/source-src/css/page.scss","hash":"244c4d75c375978ff9edb74acc68825e63c6b235","modified":1561047493489},{"_id":"themes/yilia/source-src/css/scroll.scss","hash":"2495f7e4e3b055735c531f944b5f40a118a351ec","modified":1561047493491},{"_id":"themes/yilia/source-src/css/social.scss","hash":"a10a038a1dac8953cb4ffc7e04272eff9fac54e4","modified":1561047493493},{"_id":"themes/yilia/source-src/css/tags-cloud.scss","hash":"399744e98e7c67939ed9b23c2670d8baad044eda","modified":1561047493494},{"_id":"themes/yilia/source-src/css/share.scss","hash":"9d6f6884f40c191882e56a1e1e1192400944a515","modified":1561047493492},{"_id":"themes/yilia/source-src/css/tags.scss","hash":"915c93edd67c5326695cc7dc84b14c5f154dbcc8","modified":1561047493495},{"_id":"themes/yilia/source-src/css/tools.scss","hash":"2924fb6f77c4a9973cd928c2c7db0acb848ed483","modified":1561047493497},{"_id":"themes/yilia/source-src/js/anm.js","hash":"d18f6276a352b871390a4112d479b9e58b8cdbbe","modified":1561047493500},{"_id":"themes/yilia/source-src/js/browser.js","hash":"4dc04845cf27f350922b63f1813a9c82e6e33b05","modified":1561047493502},{"_id":"themes/yilia/source-src/js/Q.js","hash":"e56d9710afa79b31ca6b9fbd845f6d1895f5214b","modified":1561047493499},{"_id":"themes/yilia/source-src/js/main.js","hash":"fe98bf90ce61658fe16ae057f8b6a512a845af3b","modified":1561047493504},{"_id":"themes/yilia/source-src/js/aside.js","hash":"5e4c3c3d61f1e1ce2f09688d3aff25fadc851fff","modified":1561047493501},{"_id":"themes/yilia/source-src/js/fix.js","hash":"67b8819abb886c9d066fb3b0624ca15e06f63fe0","modified":1561047493503},{"_id":"themes/yilia/source-src/js/report.js","hash":"57680f9a23bd0a1eaafd64ae08cc33e20627ab15","modified":1561047493505},{"_id":"themes/yilia/source-src/css/tooltip.scss","hash":"b81cedbe31accca82e597801186911a7b5e6841c","modified":1561047493498},{"_id":"themes/yilia/source-src/js/mobile.js","hash":"461c08ffcbc724d74ec7e0ff38e171eefe0f89fd","modified":1561047493505},{"_id":"themes/yilia/source-src/js/share.js","hash":"d4ccff8266c37363b3904226f5d035b7db882c61","modified":1561047493506},{"_id":"themes/yilia/source-src/js/slider.js","hash":"0beaa112657ad57c723d9e773d5b79de60c1dd74","modified":1561047493507},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/02.jpg","hash":"5e61f307ae24e1c4164b78ae37cc282423da78b8","modified":1561378370970},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/00.jpg","hash":"dc88e11eb7381c99c68ee4c8ed9f9e329c5c060a","modified":1561378370477},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/03.jpg","hash":"65a0e5fce6f045a7f50bc8596e0d6d6c8d1ac2b7","modified":1561378371249},{"_id":"themes/yilia/source-src/js/util.js","hash":"3bcdeb95072b85600874424e6929e3e22cfddaa0","modified":1561047493508},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/11.jpg","hash":"794097952326df5d576207922a2e5d2c59435581","modified":1561378373124},{"_id":"source/_posts/Hikey970使用记录/00.png","hash":"9b087e758f4c95a9aecd0f67b9ce8d6c1eeabdb6","modified":1558265959693},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/01.png","hash":"dcd2479451cc27a10576e335e13907a44a818f66","modified":1558490925304},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/03.png","hash":"c560714c834a534e24f8d2b95aa5ff386e38eb28","modified":1558490925386},{"_id":"themes/yilia/source-src/js/viewer.js","hash":"c699cf3c89409ec8f044258e0715a470861b5d5d","modified":1561047493509},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_16_0.png","hash":"e3d8a3208d79e971ccb82decde5ed8095c3694a2","modified":1561219720502},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_7_1.png","hash":"6b4032e90d76706f7418ec3d5b56946b623c5392","modified":1561219720390},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png","hash":"fb7c74d552c33d4a59651e87b8458ca1684d5e16","modified":1561221200057},{"_id":"source/_posts/天猫精灵，开灯/1.png","hash":"cb869e09faacb5bdddf05e3cf1fe8d3974a168b8","modified":1555857675988},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png","hash":"bc31d28c66270fca84a8022ef19600006d9c765e","modified":1555767799051},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png","hash":"65ecf9260630ed39dfdf98b5e50a30854cc0871e","modified":1555767873275},{"_id":"source/_posts/简单手势分类器/01.png","hash":"e2476fb0d7ee4ab4af4f541f35e6ce1c3e0f6a5c","modified":1556121143107},{"_id":"source/_posts/象棋残局机器人二：透射变换/001.jpg","hash":"8a33b44169bf9a2533de8e47b162ab41e7092fa9","modified":1558870656924},{"_id":"source/_posts/天猫精灵，开灯/2.png","hash":"a5477bd6d0ef8c44a412b4d0714592af503a27fb","modified":1555857679134},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png","hash":"456021205e7579b54418b1046f88255c10618687","modified":1555767939944},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/001.jpg","hash":"8d6b4557e149dab52075bacfc4a506a40dd3de67","modified":1558854319967},{"_id":"themes/yilia/layout/_partial/post/changyan.ejs","hash":"086c8a88fd3bcae7ec13258df58e25d6354af2fa","modified":1561047493432},{"_id":"themes/yilia/layout/_partial/post/duoshuo.ejs","hash":"f6b4c4eaafb5ac386273354b5f64a26139b7a3b0","modified":1561047493434},{"_id":"themes/yilia/layout/_partial/post/date.ejs","hash":"aae96de18d48cd3b9b7bf6fed0100e15b53cca97","modified":1561047493433},{"_id":"themes/yilia/layout/_partial/post/category.ejs","hash":"e777cbf959b11c4dfda649c562799899b90ab4a3","modified":1561047493431},{"_id":"themes/yilia/layout/_partial/post/nav.ejs","hash":"b6a97043f9ec37e571aacacfedcda1d4d75e3c7c","modified":1561047493437},{"_id":"themes/yilia/layout/_partial/post/gitment.ejs","hash":"25655016773aa5d0774c56115ae1736a9fc9ea1f","modified":1561047493436},{"_id":"themes/yilia/layout/_partial/post/tag.ejs","hash":"2c4e4ca36c9bb4318506c38aca7127f1f44d827f","modified":1561047493439},{"_id":"themes/yilia/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1561047493440},{"_id":"themes/yilia/layout/_partial/post/wangyiyun.ejs","hash":"fb022502c741b4a26bad6b2ad37245c10ede3f1a","modified":1561047493441},{"_id":"themes/yilia/layout/_partial/post/share.ejs","hash":"345b262e3c3b75c0cd9a93d9ecabcf06e33e54ff","modified":1561047493438},{"_id":"themes/yilia/source-src/css/core/_animation.scss","hash":"1834c3ed8560716e63bb3a50be94cac87fbbeaf3","modified":1561047493463},{"_id":"themes/yilia/source-src/css/core/_media-queries.scss","hash":"262ffcd88775080b7f511db37f58d2bcb1b2bfc7","modified":1561047493464},{"_id":"themes/yilia/source-src/css/core/_reset.scss","hash":"398a49913b4a47d928103562b1ce94520be4026a","modified":1561047493467},{"_id":"themes/yilia/source-src/css/fonts/iconfont.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1561047493473},{"_id":"themes/yilia/source-src/css/core/_variables.scss","hash":"6e75bdaa46de83094ba0873099c6e7d656a22453","modified":1561047493468},{"_id":"themes/yilia/source-src/css/fonts/iconfont.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1561047493470},{"_id":"themes/yilia/source-src/css/img/checkered-pattern.png","hash":"049262fa0886989d750637b264bed34ab51c23c8","modified":1561047493480},{"_id":"themes/yilia/source-src/css/core/_mixin.scss","hash":"91db061c9c17628291a005e5bd4936cf9d35a6c4","modified":1561047493466},{"_id":"themes/yilia/source-src/css/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1561047493481},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_9_0.png","hash":"a1be4aa9d6f54935b1fc146a18776705ecd5a2d3","modified":1561219720420},{"_id":"themes/yilia/source-src/css/fonts/iconfont.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1561047493474},{"_id":"themes/yilia/source-src/css/img/tooltip.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1561047493482},{"_id":"themes/yilia/layout/_partial/script.ejs","hash":"e98ec0b3b56f14d1d79af99ceb42727719a584f3","modified":1561047493442},{"_id":"themes/yilia/source-src/css/fonts/iconfont.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1561047493472},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_13_0.png","hash":"8908b1fcc29a9e737f487c326412af55b8f64b3f","modified":1561219720478},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/output_4_0.png","hash":"eb5ac6f01c03d4700f6b4a626b5b83cce49fb17c","modified":1561221038551},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_17_0.png","hash":"dff181a113824c53d4518df4025bce3ded386731","modified":1561219720527},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_2_0.png","hash":"2891fd9f9cbeab349e62cd6df7a25267aaea08fb","modified":1561219720583},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/002.png","hash":"98fbc1fd416bbf63997859b20c743461c4b85d10","modified":1558854346617},{"_id":"themes/yilia/source/img/avatar.png","hash":"31f8c6a64a3ccaa454d41fc4eb074aeb94e6cbde","modified":1561079711131},{"_id":"source/_posts/tkinter学习笔记/color.png","hash":"fa5ea684f8e40b865b26b0570aed9b1f77c23476","modified":1557556263196},{"_id":"source/_posts/作业检查机器人/001.png","hash":"a9b3b3c94acfcbe16ed186fe21f68f17d34a6653","modified":1560446642623},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/07.jpg","hash":"066d59dd064e6711e980f6656be9a534dc0d778b","modified":1561357596808},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/003.png","hash":"b1d83610933a20115f195762ae33d35b2c9b0e4c","modified":1558856459929},{"_id":"source/_posts/象棋残局机器人五：象棋棋子分类模型/001.jpg","hash":"7b5cba8f52fa147dc605d544c118d0ba97ea89b0","modified":1559721174639},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/opencv-delaunay-vornoi-subdiv-example.png","hash":"beb1b61d8bfda5b652bfffe3f9ccee261c7fbb2f","modified":1561960081293},{"_id":"source/_posts/Pixar-Lamp/设计思路.png","hash":"e8b5b06807fe39599f8cb147f066f9acf82a80f1","modified":1558007516436},{"_id":"source/_posts/loomo多服务机器人开发/设计思路-201905.png","hash":"366254dcca1877af1cb2b32cd8fded961dd6055b","modified":1558875088078},{"_id":"source/_posts/简单手势分类器/02.png","hash":"40f67510cc5d8f6ae6d9b6843ea34ad25a8b9b83","modified":1556123501160},{"_id":"source/_posts/象棋残局机器人三：分类模型retrain/001.png","hash":"0f83b488878e6b7e531c32589fc203efecbb2800","modified":1559387831816},{"_id":"source/_posts/作业检查机器人/002.png","hash":"632c559847a1e07fcd3de5b5e2c5b3300cbee354","modified":1560497769382},{"_id":"source/_posts/象棋残局机器人三：分类模型retrain/002.png","hash":"6e8ec8165732fbbb935cadb8c7d7f3d54b278268","modified":1559624250733},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_18_0.png","hash":"a13c9e30a4b51e98dcef6d5ee647c876001eb4d7","modified":1561219720553},{"_id":"source/_posts/Scikit-Learn学习笔记/machine_learning_map.png","hash":"ea8361d8304d169ecefc073c17c6ecf4567dd0a0","modified":1557038757103},{"_id":"source/_posts/Pixar-Lamp/设计思路-201905.png","hash":"00eeec1e93894f71b7fa20ce07aed2a66bc6561b","modified":1558803335198},{"_id":"source/_posts/桌面冰球机器人/001.gif","hash":"35355a3613efaa40cae5d38f901df25c4ce00ee5","modified":1560324465655},{"_id":"source/_posts/象棋残局机器人/demo2.gif","hash":"108d3b958f4b607d0c78b5014d72af8a0de157ac","modified":1559839468015},{"_id":"source/_posts/象棋残局机器人/demo1.gif","hash":"70ceb50cefc07f5292fbf2373a167d48f573cdb3","modified":1559839467962},{"_id":"source/_posts/象棋残局机器人/demo3.gif","hash":"be104fb9a69c8565a924b852973a3827ce79b6c0","modified":1559839468048},{"_id":"source/_posts/门禁人脸检测和识别/demo.gif","hash":"370d15448ab481ace650d98c16a163cacdee9a0e","modified":1561658980931},{"_id":"public/content.json","hash":"7e2428b2eb564b5e405ccb77c53a5eab1fdd7dfe","modified":1562347928122},{"_id":"public/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/index.html","hash":"97feef9b1201f4b5f02fec2f2f2918c7deb10394","modified":1562347930160},{"_id":"public/2019/06/28/门禁人脸检测和识别二：人脸关键点检测/index.html","hash":"fbd6f20f70b0db571b03a7000ea697062e26d0e0","modified":1562347930160},{"_id":"public/2019/06/25/golang学习笔记/index.html","hash":"9711a4b70ae7fa9fa3b507046be66286ad3029e8","modified":1562347930160},{"_id":"public/2019/06/25/门禁人脸检测和识别/index.html","hash":"afaadc824f995d5f82949a6a4358082e0c11bc56","modified":1562347930161},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/index.html","hash":"7f3fb2c1e8fd4f1e6ea7297e0389de9ef1be108d","modified":1562347930161},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/index.html","hash":"b3ff4a5cad095ae6b710f3e153f7d601d283d445","modified":1562347930161},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/index.html","hash":"87f333df62f20abec29dc8a4c95bece07c67de8b","modified":1562347930161},{"_id":"public/2019/06/22/Hexo：yilia主题下使用LaTex添加公式/index.html","hash":"4790bd53e7e1c1c1f62fd4c13a128601370ba2a4","modified":1562347930161},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/index.html","hash":"7f63724dd954094868e054caf930702f09d96884","modified":1562347930161},{"_id":"public/2019/06/16/好玩的-基于视觉控制的无传感器机械臂/index.html","hash":"0454555f3f3fd43e5bdd81ad82484adf808341e2","modified":1562347930161},{"_id":"public/2019/06/16/Hexo：使用dev分支管理站点源文件，多地同步/index.html","hash":"3dc189cc9b30051695b99f3e9f4d13bda1276caf","modified":1562347930161},{"_id":"public/2019/06/14/OpenCV学习笔记/index.html","hash":"4f7c8d7727b56d156b306efe8fd7b40f8f8c434d","modified":1562347930162},{"_id":"public/2019/06/10/作业检查机器人/index.html","hash":"9110d557fd895d28e8715bc099eec120b0007af7","modified":1562347930162},{"_id":"public/2019/06/08/Hikey970使用记录四：python加载运行OpenCL/index.html","hash":"e429b50a0fba0d3c7f5d36b750bc98f0a5fd43e8","modified":1562347930162},{"_id":"public/2019/06/07/桌面冰球机器人/index.html","hash":"25102c6ccc16bf96653deff800bcf5dcecb442a6","modified":1562347930162},{"_id":"public/2019/06/05/象棋残局机器人五：象棋棋子分类模型/index.html","hash":"fd8995cfe2a286d844c7128bf31463d2f8d30868","modified":1562347930162},{"_id":"public/2019/06/04/象棋残局机器人四：策略/index.html","hash":"b389b6700a73e49dd3f81a289df966cde0aaa5dd","modified":1562347930162},{"_id":"public/2019/05/29/象棋残局机器人三：分类模型retrain/index.html","hash":"46d94ee875dfdd22861494e540e2df45953ece4c","modified":1562347930162},{"_id":"public/2019/05/26/loomo多服务机器人开发.1/index.html","hash":"4ee0dbb10c58a26725a7f3e123d88fa12567b59f","modified":1562347930163},{"_id":"public/2019/05/26/loomo多服务机器人开发/index.html","hash":"4554648e258266e1347cf2a73b0910d30885ecf5","modified":1562347930163},{"_id":"public/2019/05/25/象棋残局机器人二：透射变换/index.html","hash":"f3166d88c81eafdd109903bad9d590c2daf51028","modified":1562347930163},{"_id":"public/2019/05/25/象棋残局机器人一：摄像头标定/index.html","hash":"3ad4189ca45c50ab6fd0ac968967c19362d7b456","modified":1562347930163},{"_id":"public/2019/05/22/RL学习笔记/index.html","hash":"953253931030e0db5eec9b85436992f46e1e8040","modified":1562347930163},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/index.html","hash":"eb083e9943bad14d7dc9e0c7ca7de0508a4d9078","modified":1562347930163},{"_id":"public/2019/05/22/AI通关超级马里奥/index.html","hash":"df527fc61d9c32256406fc151facdca6680d9cec","modified":1562347930163},{"_id":"public/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/index.html","hash":"091dc03d74b332cf6e3902574774a55556289a47","modified":1562347930163},{"_id":"public/2019/05/22/Hikey970使用记录一：ubuntu16-04下烧写lebian系统/index.html","hash":"05376324b7527309adc50fac5972f9bda62ac5a5","modified":1562347930164},{"_id":"public/2019/05/18/Jetson-Nano-使用记录/index.html","hash":"47a01ebf46df874ac5583737b413ccb1a1d04969","modified":1562347930164},{"_id":"public/2019/05/16/人生苦短，我用python/index.html","hash":"332d33519c472d16b8415a884a83179c98506cfe","modified":1562347930164},{"_id":"public/2019/05/16/门禁python多进程练习/index.html","hash":"68ef35be3b62a572902df5ec1f8f4cc9521b75b3","modified":1562347930164},{"_id":"public/2019/05/14/Pixar-Lamp/index.html","hash":"a93e7803a8a658faad9e2b0e79cea578f463a0cb","modified":1562347930164},{"_id":"public/2019/05/12/Hikey970使用记录/index.html","hash":"6a43d8594e0062bb0d420c3ef2d40dce8de52b12","modified":1562347930164},{"_id":"public/2019/05/11/tkinter学习笔记/index.html","hash":"455c8ddf30ddf463c0e43820ad859563ec66a991","modified":1562347930164},{"_id":"public/2019/05/05/象棋残局机器人/index.html","hash":"89a2e24ffef7a291044509ee9e888503ad7de228","modified":1562347930164},{"_id":"public/2019/05/02/Scikit-Learn学习笔记/index.html","hash":"5fda21d16b4a56d8c3973bc771cf44d2dd38d8e0","modified":1562347930165},{"_id":"public/2019/04/28/天猫精灵：绑定贝壳物联设备/index.html","hash":"0699b5fac853e9c2357c2b9e9fa86584d5437c82","modified":1562347930165},{"_id":"public/2019/04/27/门禁ubuntu配置-hadow-ocks-又可以刷脸开门了/index.html","hash":"f6fe970214d15ddf7f3d5c346373ba72c9303003","modified":1562347930165},{"_id":"public/2019/04/26/TensorFlow-手写数字识别/index.html","hash":"14dc756c8d3c20c0b19966202c52cfc8ef24cfe8","modified":1562347930165},{"_id":"public/2019/04/26/打磨工具的日常/index.html","hash":"74986f57efb706ac0c528f7f50c1afe371a2fe75","modified":1562347930165},{"_id":"public/2019/04/24/简单手势分类器/index.html","hash":"9ef1db391650ea49bf2e8fa535c81d5b731674c1","modified":1562347930165},{"_id":"public/2019/04/20/天猫精灵，开灯/index.html","hash":"4ca47c7e825c497654a2236cc6dc3deebbaff40d","modified":1562347930165},{"_id":"public/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/index.html","hash":"15e76d4776493423305c08be4a4824f00354d90e","modified":1562347930165},{"_id":"public/2019/04/19/Hexo：Hello Hexo/index.html","hash":"e6c0779cead89e721e32b318b6686e6ee4f0a30f","modified":1562347930165},{"_id":"public/index.html","hash":"f9e8b610875bea080ba797a32e90dfc34974add5","modified":1562347930166},{"_id":"public/page/2/index.html","hash":"0a48834533acd04dbbb91c4ea743eca858e5fff2","modified":1562347930166},{"_id":"public/page/3/index.html","hash":"cbe7cae99684a777befaa7b6f3bca6c94084a6c1","modified":1562347930166},{"_id":"public/page/4/index.html","hash":"f2ca9e9a043913f37db113677fb2d13bd07f4372","modified":1562347930166},{"_id":"public/page/5/index.html","hash":"f99080d6adf94f765bac4357736add8cfd66df7a","modified":1562347930167},{"_id":"public/archives/index.html","hash":"9dc40e8d807249e77f5a47794ad2bae8e5e0931b","modified":1562347930167},{"_id":"public/archives/page/2/index.html","hash":"e3a629852a5986144c23a13f720c475cfe39c0d5","modified":1562347930167},{"_id":"public/archives/page/3/index.html","hash":"a7c749028571d78266a2a133157d137a263f9cfc","modified":1562347930167},{"_id":"public/archives/page/4/index.html","hash":"01a8d4b518efb32989f782acc9aa5d7fdbc5d663","modified":1562347930167},{"_id":"public/archives/page/5/index.html","hash":"516b22010f02b47746e531a4ae7a3329e0074416","modified":1562347930167},{"_id":"public/archives/2019/index.html","hash":"982db55ab4093f88daf92a0886b4362857f1a68a","modified":1562347930167},{"_id":"public/archives/2019/page/2/index.html","hash":"ff741a97a0f23287c2d1fa9dbe67d1f62bd27c7a","modified":1562347930168},{"_id":"public/archives/2019/page/3/index.html","hash":"6a4b98d953074d8a5c2401a92269135fa2b23a08","modified":1562347930168},{"_id":"public/archives/2019/page/4/index.html","hash":"432ede71e852eb328fe4f71930513bad6b431e96","modified":1562347930169},{"_id":"public/archives/2019/page/5/index.html","hash":"d8b955697aa2f4481c97dbe8300e84c39c645f08","modified":1562347930169},{"_id":"public/archives/2019/04/index.html","hash":"7e6ca490e283fdfef3e17d85a9e850c9d0313644","modified":1562347930169},{"_id":"public/archives/2019/05/index.html","hash":"429fbe92a3befb6449a4526a9accda0a10c3a408","modified":1562347930169},{"_id":"public/archives/2019/05/page/2/index.html","hash":"13d1566e9b09eb083d160ece960a42ca0d172464","modified":1562347930169},{"_id":"public/archives/2019/06/index.html","hash":"c53e369639912175a62f82d59356ae58c22c3346","modified":1562347930169},{"_id":"public/archives/2019/06/page/2/index.html","hash":"73e0038d10db60dce4eb3c6156403922fd776def","modified":1562347930169},{"_id":"public/tags/lua/index.html","hash":"5049fa0eb32a8db8bde907359dac87b48f2b3cf7","modified":1562347930169},{"_id":"public/tags/neat/index.html","hash":"71252f25a30b32641bb8c208f90d0c36f0132a67","modified":1562347930169},{"_id":"public/tags/Mario/index.html","hash":"d060d648b9bd196108168144cf5b7dc5cdcf4e13","modified":1562347930169},{"_id":"public/tags/3D打印/index.html","hash":"954d2fbfc9765f11f7a0612dd030a2b9dde16489","modified":1562347930170},{"_id":"public/tags/hexo/index.html","hash":"4ca5004d4420c8b3bd0109a89b7d34afce2de0c0","modified":1562347930170},{"_id":"public/tags/吉他/index.html","hash":"4a36503591c1453133db5c7618e109e4af231341","modified":1562347930170},{"_id":"public/tags/Hikey970/index.html","hash":"14e79ac552c7e5f01f5d23ef589430b924571f66","modified":1562347930170},{"_id":"public/tags/opencv/index.html","hash":"b87c8a4a46d5cda57ef038a288d5808361666206","modified":1562347930170},{"_id":"public/tags/opencv/page/2/index.html","hash":"fbff1023fa4a85c83f9dd8b0052c48f02811b114","modified":1562347930170},{"_id":"public/tags/pyopencl/index.html","hash":"a42d4242a16c20d7bc65d612ecb66d440ed36c68","modified":1562347930170},{"_id":"public/tags/python/index.html","hash":"7db9bcea34a64e03415a8ec9e49d24bc5e90ee93","modified":1562347930171},{"_id":"public/tags/RL/index.html","hash":"ccca3d50a362717cc3366096c0ab7fc44967acb0","modified":1562347930171},{"_id":"public/tags/loomo/index.html","hash":"66368035d13aa4dee744191455e4ce871dd2f27c","modified":1562347930171},{"_id":"public/tags/go/index.html","hash":"6dc1ea11e7c28739e9a7bd02fc26b8e7a83f4056","modified":1562347930171},{"_id":"public/tags/Android/index.html","hash":"3c7a81fb8cc59c464e3e09981d88132608814455","modified":1562347930171},{"_id":"public/tags/机械手/index.html","hash":"f486066be35418d104b77e91ec96d5b435565ad8","modified":1562347930171},{"_id":"public/tags/sklearn/index.html","hash":"71d96014fdae635489338df432a98cff1f759429","modified":1562347930171},{"_id":"public/tags/tkinter/index.html","hash":"90ade6f9d5b088f72a4100274001365d402f76af","modified":1562347930171},{"_id":"public/tags/tensorflow/index.html","hash":"3e6d703e47caa4083c6fcd3c7f686a13dd3b8635","modified":1562347930171},{"_id":"public/tags/jupyter-notebook/index.html","hash":"c138418de8e66caa9b09c79d258de0214a5efff4","modified":1562347930171},{"_id":"public/tags/天猫精灵/index.html","hash":"f232d97e5676b2a6af247c39cabb0bb05f2eb871","modified":1562347930172},{"_id":"public/tags/raspberry/index.html","hash":"f9f9c1c386b208b2c1a48d5a7c8f92b0937cc5ef","modified":1562347930172},{"_id":"public/tags/esp8266/index.html","hash":"42447c2e1ea1115b75bc79bf9b72ccdd492234ae","modified":1562347930172},{"_id":"public/tags/tf/index.html","hash":"812ff7c870743d4bc5c68361bf5f0a2b74b0e62a","modified":1562347930172},{"_id":"public/tags/arduino/index.html","hash":"5b9d87daacd3a981d00c2989202046565486fe0e","modified":1562347930172},{"_id":"public/tags/AlphaZero/index.html","hash":"73fb5aeae0a51ccaab44ff677c0c33e11b9eb1a8","modified":1562347930172},{"_id":"public/tags/迁移学习/index.html","hash":"ffba66daa1764913fe1f547e5e9219b4b39012d0","modified":1562347930172},{"_id":"public/tags/alphazero/index.html","hash":"f23fb9421dd2fd8e95ba2dab826b660dc6b85372","modified":1562347930172},{"_id":"public/tags/mysql/index.html","hash":"b854fd61487cc47c7e1599ffa4b656ccf29efba5","modified":1562347930172},{"_id":"public/tags/php/index.html","hash":"d2cb1bf62b856f459b8cb171d192777f3f514ec7","modified":1562347930173},{"_id":"public/fonts/default-skin.b257fa.svg","hash":"2ac727c9e092331d35cce95af209ccfac6d4c7c7","modified":1562347930213},{"_id":"public/fonts/iconfont.16acc2.ttf","hash":"f342ac8bf4d937f42a7d6a0032ad267ab47eb7f2","modified":1562347930213},{"_id":"public/fonts/iconfont.8c627f.woff","hash":"aa9672cb097f7fd73ae5a03bcd3d9d726935bc0a","modified":1562347930213},{"_id":"public/fonts/iconfont.b322fa.eot","hash":"bc8c5e88f4994a852041b4d83f126d9c4d419b4a","modified":1562347930222},{"_id":"public/fonts/tooltip.4004ff.svg","hash":"397fe4b1093bf9b62457dac48aa15dac06b54a3c","modified":1562347930222},{"_id":"public/img/default-skin.png","hash":"ed95a8e40a2c3478c5915376acb8e5f33677f24d","modified":1562347930223},{"_id":"public/img/preloader.gif","hash":"6342367c93c82da1b9c620e97c84a389cc43d96d","modified":1562347930223},{"_id":"public/img/favicon.png","hash":"37e487f5b0d19dfa9bd1e6c2a2014f02d9e4406e","modified":1562347930223},{"_id":"public/fonts/iconfont.45d7ee.svg","hash":"75767c904d483d9b93469afb6b92bb6bdface639","modified":1562347930223},{"_id":"public/img/scrollbar_arrow.png","hash":"d64a33c4ddfbdb89deeb6f4e3d36eb84dc4777c0","modified":1562347930223},{"_id":"public/2019/05/18/Jetson-Nano-使用记录/001.png","hash":"518664af6d7f8de158242d105c49cd81e9d04a0b","modified":1562347930223},{"_id":"public/2019/06/08/Hikey970使用记录四：python加载运行OpenCL/001.png","hash":"47eacba12e82d7f96d6a08af56b236fa3c753247","modified":1562347930223},{"_id":"public/2019/06/04/象棋残局机器人四：策略/001.png","hash":"c77e354f7c15e46d93a789d87364937c778083bc","modified":1562347930223},{"_id":"public/2019/04/24/简单手势分类器/01.png","hash":"e2476fb0d7ee4ab4af4f541f35e6ce1c3e0f6a5c","modified":1562347930223},{"_id":"public/2019/05/14/Pixar-Lamp/001.jpg","hash":"ff73857dfe4b15be6493ee9cc5d851a454614890","modified":1562347930223},{"_id":"public/2019/06/10/作业检查机器人/000.jpg","hash":"3b5d75ac6526ac25894c1a714e180c48bfc07477","modified":1562347930224},{"_id":"public/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/02.png","hash":"80bd21e079b45ab858392b32db5f4cc9033e80f3","modified":1562347930225},{"_id":"public/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/01.png","hash":"dcd2479451cc27a10576e335e13907a44a818f66","modified":1562347930225},{"_id":"public/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/04.png","hash":"009f3589b63238bced9cfdf0ba06ae4a7f8961bb","modified":1562347930225},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/01.png","hash":"7e5314a03c74db15275086e1c13e5e7028f2098b","modified":1562347930225},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/02.png","hash":"7ac3bb89ea653ade2274a55c2df1d840e612925c","modified":1562347930225},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/03.png","hash":"7ac3bb89ea653ade2274a55c2df1d840e612925c","modified":1562347930226},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/04.png","hash":"abe85cacc69856c16f0dde15260a8a1e93acf8e3","modified":1562347930226},{"_id":"public/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/05.png","hash":"901c6cdf2df9d6eeb33764075fb8f173de2c2aca","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/01.jpg","hash":"e74d801194ae1d8a7f742b1100c7941ee0472fa3","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/04.jpg","hash":"9193fd0f0bd0ca765ecdf0414f660c8e97584419","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/05.jpg","hash":"bb4e70195c68d2c20a2bdef3f139875d69d4722e","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/06.jpg","hash":"a8007562b9bf8c521d98a26208f1a5c286a01625","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/08.jpg","hash":"91d1bc553c6a0bc4d135a21c894fdb5b113dbf46","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/09.jpg","hash":"8ea6bc4526895cb14de783493eeb0d8f802a3c3a","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/10.jpg","hash":"d6c0f82ef44ecd06d082ac5c4fdf110da429267a","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/12.jpg","hash":"d0126b7c29b498174a535bba0d040e3c9470b053","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/13.jpg","hash":"35fbbbb8362d8898f3ac25906602292c5daa91f7","modified":1562347930226},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/14.jpg","hash":"aa88fec7b947e1187492e1148705eee57f0f470b","modified":1562347930226},{"_id":"public/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/P_Trangle.png","hash":"ff6611e104f982244bff6509a839e7ab1539cf3d","modified":1562347930226},{"_id":"public/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/Trangle.png","hash":"b3cc5c8346fa34f4a63037ecfe2b14f01294286e","modified":1562347930227},{"_id":"public/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/output_4_0.png","hash":"81ff22ed5dfff551180b84ac68d277d0a2b29bf1","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog01.jpg","hash":"e33929d7053e091469aeb40f9806d02f6796bb18","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog02.jpg","hash":"afa2d3a91de70c4665662f7878022db8a8bfd048","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_5_1.png","hash":"1599adad9ed3c8a86b22d8bd8ec2b6a8c58a4031","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_10_0.png","hash":"9e22eec352a63f34069909b937114ef4b83aef01","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_12_0.png","hash":"b9f35435353c9104206d15f9e1fc0080d9f577da","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_15_0.png","hash":"c04ee8ba457033a91752d943d8ebbeefdbdc4997","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_17_0.png","hash":"cc054900ef529158daa01096f78133cbea8fc373","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_4_0.png","hash":"940533f012c8c253da0aeb90842789735387b3fd","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_6_0.png","hash":"63d04ed2f545819d2fc5f07ce688c2d51456d4c8","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg","hash":"f53d4585af600d9a5da0adbda75504af3d509552","modified":1562347930227},{"_id":"public/2019/06/22/OpenCV学习笔记二：图像处理/output_8_0.png","hash":"9e22eec352a63f34069909b937114ef4b83aef01","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png","hash":"fb4b5ba9198de9f15c3f53a55b3b8ebeec4625a6","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_11_0.png","hash":"1f7fd7671a8b7684944a70e126cad69d5947f5d9","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_3_2.png","hash":"56fb48ccacf28ed66952e3807992e415c120f7bd","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_5_0.png","hash":"355fbdeabc595dd19c8120949c111315dbfb4fea","modified":1562347930227},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg","hash":"de7bbf05c2e0f0c2a3632870fee22c3c97ea2d29","modified":1562347930228},{"_id":"public/assets/css/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1562347930228},{"_id":"public/2019/05/12/Hikey970使用记录/00.png","hash":"9b087e758f4c95a9aecd0f67b9ce8d6c1eeabdb6","modified":1562347930238},{"_id":"public/2019/05/25/象棋残局机器人二：透射变换/001.jpg","hash":"8a33b44169bf9a2533de8e47b162ab41e7092fa9","modified":1562347930238},{"_id":"public/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png","hash":"bc31d28c66270fca84a8022ef19600006d9c765e","modified":1562347930238},{"_id":"public/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png","hash":"65ecf9260630ed39dfdf98b5e50a30854cc0871e","modified":1562347930238},{"_id":"public/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png","hash":"456021205e7579b54418b1046f88255c10618687","modified":1562347930238},{"_id":"public/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/03.png","hash":"c560714c834a534e24f8d2b95aa5ff386e38eb28","modified":1562347930239},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/00.jpg","hash":"dc88e11eb7381c99c68ee4c8ed9f9e329c5c060a","modified":1562347930239},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/02.jpg","hash":"5e61f307ae24e1c4164b78ae37cc282423da78b8","modified":1562347930239},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/03.jpg","hash":"65a0e5fce6f045a7f50bc8596e0d6d6c8d1ac2b7","modified":1562347930239},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/11.jpg","hash":"794097952326df5d576207922a2e5d2c59435581","modified":1562347930239},{"_id":"public/2019/04/20/天猫精灵，开灯/1.png","hash":"cb869e09faacb5bdddf05e3cf1fe8d3974a168b8","modified":1562347930239},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png","hash":"fb7c74d552c33d4a59651e87b8458ca1684d5e16","modified":1562347930239},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_16_0.png","hash":"e3d8a3208d79e971ccb82decde5ed8095c3694a2","modified":1562347930240},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_7_1.png","hash":"6b4032e90d76706f7418ec3d5b56946b623c5392","modified":1562347930240},{"_id":"public/assets/js/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1562347930240},{"_id":"public/2019/05/25/象棋残局机器人一：摄像头标定/001.jpg","hash":"8d6b4557e149dab52075bacfc4a506a40dd3de67","modified":1562347930277},{"_id":"public/2019/04/20/天猫精灵，开灯/2.png","hash":"a5477bd6d0ef8c44a412b4d0714592af503a27fb","modified":1562347930277},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_9_0.png","hash":"a1be4aa9d6f54935b1fc146a18776705ecd5a2d3","modified":1562347930281},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_13_0.png","hash":"8908b1fcc29a9e737f487c326412af55b8f64b3f","modified":1562347930290},{"_id":"public/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_4_0.png","hash":"eb5ac6f01c03d4700f6b4a626b5b83cce49fb17c","modified":1562347930290},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_17_0.png","hash":"dff181a113824c53d4518df4025bce3ded386731","modified":1562347930290},{"_id":"public/img/avatar.png","hash":"31f8c6a64a3ccaa454d41fc4eb074aeb94e6cbde","modified":1562347930304},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_2_0.png","hash":"2891fd9f9cbeab349e62cd6df7a25267aaea08fb","modified":1562347930304},{"_id":"public/2019/05/11/tkinter学习笔记/color.png","hash":"fa5ea684f8e40b865b26b0570aed9b1f77c23476","modified":1562347930311},{"_id":"public/2019/05/25/象棋残局机器人一：摄像头标定/003.png","hash":"b1d83610933a20115f195762ae33d35b2c9b0e4c","modified":1562347930311},{"_id":"public/2019/06/05/象棋残局机器人五：象棋棋子分类模型/001.jpg","hash":"7b5cba8f52fa147dc605d544c118d0ba97ea89b0","modified":1562347930315},{"_id":"public/2019/05/25/象棋残局机器人一：摄像头标定/002.png","hash":"98fbc1fd416bbf63997859b20c743461c4b85d10","modified":1562347930315},{"_id":"public/slider.e37972.js","hash":"6dec4e220c89049037eebc44404abd8455d22ad7","modified":1562347930319},{"_id":"public/2019/05/29/象棋残局机器人三：分类模型retrain/001.png","hash":"0f83b488878e6b7e531c32589fc203efecbb2800","modified":1562347930319},{"_id":"public/2019/05/29/象棋残局机器人三：分类模型retrain/002.png","hash":"6e8ec8165732fbbb935cadb8c7d7f3d54b278268","modified":1562347930319},{"_id":"public/2019/06/10/作业检查机器人/001.png","hash":"a9b3b3c94acfcbe16ed186fe21f68f17d34a6653","modified":1562347930319},{"_id":"public/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/opencv-delaunay-vornoi-subdiv-example.png","hash":"beb1b61d8bfda5b652bfffe3f9ccee261c7fbb2f","modified":1562347930320},{"_id":"public/main.0cf68a.css","hash":"ddf6e2c6b953c2c59a3c271e6070010a4cc81cf9","modified":1562347930323},{"_id":"public/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/07.jpg","hash":"066d59dd064e6711e980f6656be9a534dc0d778b","modified":1562347930323},{"_id":"public/main.0cf68a.js","hash":"993fadeb5f6d296e9d997a49ee20dc97333ceab7","modified":1562347930325},{"_id":"public/2019/06/10/作业检查机器人/002.png","hash":"632c559847a1e07fcd3de5b5e2c5b3300cbee354","modified":1562347930325},{"_id":"public/2019/05/26/loomo多服务机器人开发/设计思路-201905.png","hash":"366254dcca1877af1cb2b32cd8fded961dd6055b","modified":1562347930329},{"_id":"public/2019/04/24/简单手势分类器/02.png","hash":"40f67510cc5d8f6ae6d9b6843ea34ad25a8b9b83","modified":1562347930329},{"_id":"public/2019/05/14/Pixar-Lamp/设计思路.png","hash":"e8b5b06807fe39599f8cb147f066f9acf82a80f1","modified":1562347930332},{"_id":"public/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_18_0.png","hash":"a13c9e30a4b51e98dcef6d5ee647c876001eb4d7","modified":1562347930332},{"_id":"public/2019/05/02/Scikit-Learn学习笔记/machine_learning_map.png","hash":"ea8361d8304d169ecefc073c17c6ecf4567dd0a0","modified":1562347930337},{"_id":"public/mobile.992cbe.js","hash":"01b35e71e37aa2849664eb5daf26daede2278398","modified":1562347930339},{"_id":"public/2019/05/14/Pixar-Lamp/设计思路-201905.png","hash":"00eeec1e93894f71b7fa20ce07aed2a66bc6561b","modified":1562347930339},{"_id":"public/2019/06/07/桌面冰球机器人/001.gif","hash":"35355a3613efaa40cae5d38f901df25c4ce00ee5","modified":1562347930348},{"_id":"public/2019/05/05/象棋残局机器人/demo2.gif","hash":"108d3b958f4b607d0c78b5014d72af8a0de157ac","modified":1562347930360},{"_id":"public/2019/05/05/象棋残局机器人/demo3.gif","hash":"be104fb9a69c8565a924b852973a3827ce79b6c0","modified":1562347930364},{"_id":"public/2019/05/05/象棋残局机器人/demo1.gif","hash":"70ceb50cefc07f5292fbf2373a167d48f573cdb3","modified":1562347930366},{"_id":"public/2019/06/25/门禁人脸检测和识别/demo.gif","hash":"370d15448ab481ace650d98c16a163cacdee9a0e","modified":1562347930371}],"Category":[],"Data":[],"Page":[],"Post":[{"title":"AI通关超级马里奥","date":"2019-05-22T07:06:26.000Z","_content":"\n在windows下编译运行lua源程序 - weixin_38527697的博客 - CSDN博客 https://blog.csdn.net/weixin_38527697/article/details/80718168\n\n基于NEAT算法的马里奥AI实现 - 小天狼星的博客 - CSDN博客 https://blog.csdn.net/qq_37913997/article/details/81871589\n\naleju/mario-ai: Playing Mario with Deep Reinforcement Learning https://github.com/aleju/mario-ai\n\nBitTigerLab/ArtificialIntelligent/RetroContest at master · Fabsqrt/BitTigerLab https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest\n\nopenai/retro: Retro Games in Gym https://github.com/openai/retro#gym-retro\n\nBitTigerLab/README.md at master · Fabsqrt/BitTigerLab https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md\n\nNeuroEvolution of Augmenting Topologies http://www.cs.ucf.edu/~kstanley/neat.html\n\nCodeReclaimers/neat-python: Python implementation of the NEAT neuroevolution algorithm https://github.com/CodeReclaimers/neat-python\n\nNEAT 监督学习 - 进化算法 Evolutionary Algorithm | 莫烦Python https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/\n\n沁原的硅谷创新课 002 如何训练人工智能游戏高手？OpenAI、Gym Retro、DQN、PPO、TensorFlow - YouTube https://www.youtube.com/watch?v=cZa_xot8Wdc&list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&index=2\n\n","source":"_posts/AI通关超级马里奥.md","raw":"---\ntitle: AI通关超级马里奥\ndate: 2019-05-22 15:06:26\ntags:\n  - lua\n  - neat\n  - Mario\n---\n\n在windows下编译运行lua源程序 - weixin_38527697的博客 - CSDN博客 https://blog.csdn.net/weixin_38527697/article/details/80718168\n\n基于NEAT算法的马里奥AI实现 - 小天狼星的博客 - CSDN博客 https://blog.csdn.net/qq_37913997/article/details/81871589\n\naleju/mario-ai: Playing Mario with Deep Reinforcement Learning https://github.com/aleju/mario-ai\n\nBitTigerLab/ArtificialIntelligent/RetroContest at master · Fabsqrt/BitTigerLab https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest\n\nopenai/retro: Retro Games in Gym https://github.com/openai/retro#gym-retro\n\nBitTigerLab/README.md at master · Fabsqrt/BitTigerLab https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md\n\nNeuroEvolution of Augmenting Topologies http://www.cs.ucf.edu/~kstanley/neat.html\n\nCodeReclaimers/neat-python: Python implementation of the NEAT neuroevolution algorithm https://github.com/CodeReclaimers/neat-python\n\nNEAT 监督学习 - 进化算法 Evolutionary Algorithm | 莫烦Python https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/\n\n沁原的硅谷创新课 002 如何训练人工智能游戏高手？OpenAI、Gym Retro、DQN、PPO、TensorFlow - YouTube https://www.youtube.com/watch?v=cZa_xot8Wdc&list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&index=2\n\n","slug":"AI通关超级马里奥","published":1,"updated":"2019-06-12T13:58:12.173Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm73y0000rsvjluj4xcji","content":"<p>在windows下编译运行lua源程序 - weixin_38527697的博客 - CSDN博客 <a href=\"https://blog.csdn.net/weixin_38527697/article/details/80718168\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_38527697/article/details/80718168</a></p>\n<p>基于NEAT算法的马里奥AI实现 - 小天狼星的博客 - CSDN博客 <a href=\"https://blog.csdn.net/qq_37913997/article/details/81871589\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_37913997/article/details/81871589</a></p>\n<p>aleju/mario-ai: Playing Mario with Deep Reinforcement Learning <a href=\"https://github.com/aleju/mario-ai\" target=\"_blank\" rel=\"noopener\">https://github.com/aleju/mario-ai</a></p>\n<p>BitTigerLab/ArtificialIntelligent/RetroContest at master · Fabsqrt/BitTigerLab <a href=\"https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest\" target=\"_blank\" rel=\"noopener\">https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest</a></p>\n<p>openai/retro: Retro Games in Gym <a href=\"https://github.com/openai/retro#gym-retro\" target=\"_blank\" rel=\"noopener\">https://github.com/openai/retro#gym-retro</a></p>\n<p>BitTigerLab/README.md at master · Fabsqrt/BitTigerLab <a href=\"https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md</a></p>\n<p>NeuroEvolution of Augmenting Topologies <a href=\"http://www.cs.ucf.edu/~kstanley/neat.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.ucf.edu/~kstanley/neat.html</a></p>\n<p>CodeReclaimers/neat-python: Python implementation of the NEAT neuroevolution algorithm <a href=\"https://github.com/CodeReclaimers/neat-python\" target=\"_blank\" rel=\"noopener\">https://github.com/CodeReclaimers/neat-python</a></p>\n<p>NEAT 监督学习 - 进化算法 Evolutionary Algorithm | 莫烦Python <a href=\"https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/</a></p>\n<p>沁原的硅谷创新课 002 如何训练人工智能游戏高手？OpenAI、Gym Retro、DQN、PPO、TensorFlow - YouTube <a href=\"https://www.youtube.com/watch?v=cZa_xot8Wdc&amp;list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&amp;index=2\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=cZa_xot8Wdc&amp;list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&amp;index=2</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>在windows下编译运行lua源程序 - weixin_38527697的博客 - CSDN博客 <a href=\"https://blog.csdn.net/weixin_38527697/article/details/80718168\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_38527697/article/details/80718168</a></p>\n<p>基于NEAT算法的马里奥AI实现 - 小天狼星的博客 - CSDN博客 <a href=\"https://blog.csdn.net/qq_37913997/article/details/81871589\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_37913997/article/details/81871589</a></p>\n<p>aleju/mario-ai: Playing Mario with Deep Reinforcement Learning <a href=\"https://github.com/aleju/mario-ai\" target=\"_blank\" rel=\"noopener\">https://github.com/aleju/mario-ai</a></p>\n<p>BitTigerLab/ArtificialIntelligent/RetroContest at master · Fabsqrt/BitTigerLab <a href=\"https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest\" target=\"_blank\" rel=\"noopener\">https://github.com/Fabsqrt/BitTigerLab/tree/master/ArtificialIntelligent/RetroContest</a></p>\n<p>openai/retro: Retro Games in Gym <a href=\"https://github.com/openai/retro#gym-retro\" target=\"_blank\" rel=\"noopener\">https://github.com/openai/retro#gym-retro</a></p>\n<p>BitTigerLab/README.md at master · Fabsqrt/BitTigerLab <a href=\"https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md\" target=\"_blank\" rel=\"noopener\">https://github.com/Fabsqrt/BitTigerLab/blob/master/ArtificialIntelligent/Mario/README.md</a></p>\n<p>NeuroEvolution of Augmenting Topologies <a href=\"http://www.cs.ucf.edu/~kstanley/neat.html\" target=\"_blank\" rel=\"noopener\">http://www.cs.ucf.edu/~kstanley/neat.html</a></p>\n<p>CodeReclaimers/neat-python: Python implementation of the NEAT neuroevolution algorithm <a href=\"https://github.com/CodeReclaimers/neat-python\" target=\"_blank\" rel=\"noopener\">https://github.com/CodeReclaimers/neat-python</a></p>\n<p>NEAT 监督学习 - 进化算法 Evolutionary Algorithm | 莫烦Python <a href=\"https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/tutorials/machine-learning/evolutionary-algorithm/4-02-neat-supervised-learning/</a></p>\n<p>沁原的硅谷创新课 002 如何训练人工智能游戏高手？OpenAI、Gym Retro、DQN、PPO、TensorFlow - YouTube <a href=\"https://www.youtube.com/watch?v=cZa_xot8Wdc&amp;list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&amp;index=2\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=cZa_xot8Wdc&amp;list=PL34eqMVgn4cjnvak8FtJysKd6Ke_T5Lsl&amp;index=2</a></p>\n"},{"title":"Hexo：Hello Hexo","date":"2019-04-19T14:30:18.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n\n### 所需软件\n\n* git: http://git-scm.com/\n* node.js：http://nodejs.org/\n\n查看是否安装成功\n\n``` bash\n$ git --version\n$ npm -v\n```\n\n### Hexo 相关命令\n``` bash\n$ hexo new page\"pageName\"     新建页面\n$ cls                         清屏\n$ hexo clean                  清理项目\n$ hexo g(generate)            生成静态页面至public目录\n$ hexo s(server)              开启预览访问端口\n$ hexo d(deploy)              将.deploy目录部署到GitHub\n$ hexo help                   查看帮助\n$ hexo version                查看Hexo的版本\n```\n\n## 部署\n\n### 安装hexo\n\n``` bash\n$ npm install hexo-cli -g\n```\n\n安装hexo-deployer-git工具\n``` bash\n$ npm install hexo-deployer-git --save\n```\n#### npm install 慢的话\n``` bash\n显示当前的镜像网址\n$ npm get registry \nhttps://registry.npmjs.org/\n使用淘宝的镜像网址\n$ npm config set registry http://registry.npm.taobao.org\n```\n\n### 静态博客搭建\n``` bash\n$ hexo init blog\n$ cd blog\n$ npm install\n$ hexo s\n```\n浏览器访问：http://localhost:4000/ \n按Ctrl+C停止  \n\n\n### 配置到GitHub\n\n在github上创建仓库，仓库名称为：用户名.github.io\n配置blog\\\\_config.yml中的deploy\n\n``` yml\ndeploy:\n  type: git\n  repo: git@github.com:your_github_user_name/your_github_user_name.github.io.git\n  branch: master\n```\n\n生成 ssh key\n``` bash\n$ ssh-keygen -t rsa -C xxx@qq.com(your_email)\n$ 连按三次Enter\n```\n其中ssh-keygen.exe在.\\Git\\usr\\bin文件夹中  \n根据路径提示找到id_rsa.pub文件，拷贝公钥  \n进入github账户设置，在ssh and GPG keys中新增一个ssh key  \n把刚刚拷贝出来的公钥粘贴到key中，title放空就好</br>\n\n验证ssh key\n``` bash\n$ ssh -T git@github.com\n```\n\n在本地hexo init生成的文件夹中初始化git仓库\n``` bash\n$ git init\n```\n将本地仓库和远程仓库连接\n``` bash\n$ git remote add origin git@github.com:your_github_user_name/your_github_user_name.github.io.git\n```\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n\n## 网站部署\n\n``` bash\n$ hexo clean  //清除缓存文件db.json和已生成的静态文件public\n$ hexo g      //生成网站静态文件到默认设置的public文件夹\n$ hexo s      //开启服务器预览网址\n$ hexo d      //部署网站到设定的仓库\n```\n\n\n\n## 主题\n\n### 挑选主题\n* Themes | Hexo https://hexo.io/themes/\n* Themes · hexojs/hexo Wiki https://github.com/hexojs/hexo/wiki/Themes\n\n## 添加主题\n复制主题到themes目录下\n``` bash\ncd themes && git clone https://github.com/maochunguang/black-blue(主题地址)\n```\n\n配置blog\\\\_config.yml，修改对应主题目录名\n``` yml\ntheme: 主题名称\n```\n\n重新生成静态页面\n``` bash\nhexo g\n```\n启动本地服务，重新访问：http://localhost:4000/ ，查看新主题的效果\n``` bash\nhexo s\n```\n确认后上传到github，通过 用户名.github.io 访问查看最终效果\n``` bash\nhexo d\n```\n\n## 插入图片\n\n### 设置\n配置blog\\\\_config.yml\n\n``` yml\npost_asset_folder: true\n```\n安装插件\n``` bash\nnpm install hexo-asset-image --save\n```\n\nhtml语法\n``` html\n<div align=center>\n<img alt=\"title\" src = \"path to xxx.png\" width=999 height=999>\n</div>\n```","source":"_posts/Hexo：Hello Hexo.md","raw":"---\ntitle: Hexo：Hello Hexo\ndate: 2019-04-19 22:30:18\ntags:\n  - hexo\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n\n### 所需软件\n\n* git: http://git-scm.com/\n* node.js：http://nodejs.org/\n\n查看是否安装成功\n\n``` bash\n$ git --version\n$ npm -v\n```\n\n### Hexo 相关命令\n``` bash\n$ hexo new page\"pageName\"     新建页面\n$ cls                         清屏\n$ hexo clean                  清理项目\n$ hexo g(generate)            生成静态页面至public目录\n$ hexo s(server)              开启预览访问端口\n$ hexo d(deploy)              将.deploy目录部署到GitHub\n$ hexo help                   查看帮助\n$ hexo version                查看Hexo的版本\n```\n\n## 部署\n\n### 安装hexo\n\n``` bash\n$ npm install hexo-cli -g\n```\n\n安装hexo-deployer-git工具\n``` bash\n$ npm install hexo-deployer-git --save\n```\n#### npm install 慢的话\n``` bash\n显示当前的镜像网址\n$ npm get registry \nhttps://registry.npmjs.org/\n使用淘宝的镜像网址\n$ npm config set registry http://registry.npm.taobao.org\n```\n\n### 静态博客搭建\n``` bash\n$ hexo init blog\n$ cd blog\n$ npm install\n$ hexo s\n```\n浏览器访问：http://localhost:4000/ \n按Ctrl+C停止  \n\n\n### 配置到GitHub\n\n在github上创建仓库，仓库名称为：用户名.github.io\n配置blog\\\\_config.yml中的deploy\n\n``` yml\ndeploy:\n  type: git\n  repo: git@github.com:your_github_user_name/your_github_user_name.github.io.git\n  branch: master\n```\n\n生成 ssh key\n``` bash\n$ ssh-keygen -t rsa -C xxx@qq.com(your_email)\n$ 连按三次Enter\n```\n其中ssh-keygen.exe在.\\Git\\usr\\bin文件夹中  \n根据路径提示找到id_rsa.pub文件，拷贝公钥  \n进入github账户设置，在ssh and GPG keys中新增一个ssh key  \n把刚刚拷贝出来的公钥粘贴到key中，title放空就好</br>\n\n验证ssh key\n``` bash\n$ ssh -T git@github.com\n```\n\n在本地hexo init生成的文件夹中初始化git仓库\n``` bash\n$ git init\n```\n将本地仓库和远程仓库连接\n``` bash\n$ git remote add origin git@github.com:your_github_user_name/your_github_user_name.github.io.git\n```\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n\n\n## 网站部署\n\n``` bash\n$ hexo clean  //清除缓存文件db.json和已生成的静态文件public\n$ hexo g      //生成网站静态文件到默认设置的public文件夹\n$ hexo s      //开启服务器预览网址\n$ hexo d      //部署网站到设定的仓库\n```\n\n\n\n## 主题\n\n### 挑选主题\n* Themes | Hexo https://hexo.io/themes/\n* Themes · hexojs/hexo Wiki https://github.com/hexojs/hexo/wiki/Themes\n\n## 添加主题\n复制主题到themes目录下\n``` bash\ncd themes && git clone https://github.com/maochunguang/black-blue(主题地址)\n```\n\n配置blog\\\\_config.yml，修改对应主题目录名\n``` yml\ntheme: 主题名称\n```\n\n重新生成静态页面\n``` bash\nhexo g\n```\n启动本地服务，重新访问：http://localhost:4000/ ，查看新主题的效果\n``` bash\nhexo s\n```\n确认后上传到github，通过 用户名.github.io 访问查看最终效果\n``` bash\nhexo d\n```\n\n## 插入图片\n\n### 设置\n配置blog\\\\_config.yml\n\n``` yml\npost_asset_folder: true\n```\n安装插件\n``` bash\nnpm install hexo-asset-image --save\n```\n\nhtml语法\n``` html\n<div align=center>\n<img alt=\"title\" src = \"path to xxx.png\" width=999 height=999>\n</div>\n```","slug":"Hexo：Hello Hexo","published":1,"updated":"2019-07-01T14:20:04.062Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm7430001rsvjcdfgzynd","content":"<p><strong> Hexo：Hello Hexo：</strong> <excerpt in index | 首页摘要><br>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"所需软件\"><a href=\"#所需软件\" class=\"headerlink\" title=\"所需软件\"></a>所需软件</h3><ul>\n<li>git: <a href=\"http://git-scm.com/\" target=\"_blank\" rel=\"noopener\">http://git-scm.com/</a></li>\n<li>node.js：<a href=\"http://nodejs.org/\" target=\"_blank\" rel=\"noopener\">http://nodejs.org/</a></li>\n</ul>\n<p>查看是否安装成功</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git --version</span><br><span class=\"line\">$ npm -v</span><br></pre></td></tr></table></figure>\n<h3 id=\"Hexo-相关命令\"><a href=\"#Hexo-相关命令\" class=\"headerlink\" title=\"Hexo 相关命令\"></a>Hexo 相关命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page<span class=\"string\">\"pageName\"</span>     新建页面</span><br><span class=\"line\">$ cls                         清屏</span><br><span class=\"line\">$ hexo clean                  清理项目</span><br><span class=\"line\">$ hexo g(generate)            生成静态页面至public目录</span><br><span class=\"line\">$ hexo s(server)              开启预览访问端口</span><br><span class=\"line\">$ hexo d(deploy)              将.deploy目录部署到GitHub</span><br><span class=\"line\">$ hexo <span class=\"built_in\">help</span>                   查看帮助</span><br><span class=\"line\">$ hexo version                查看Hexo的版本</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><h3 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-cli -g</span><br></pre></td></tr></table></figure>\n<p>安装hexo-deployer-git工具<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"npm-install-慢的话\"><a href=\"#npm-install-慢的话\" class=\"headerlink\" title=\"npm install 慢的话\"></a>npm install 慢的话</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示当前的镜像网址</span><br><span class=\"line\">$ npm get registry </span><br><span class=\"line\">https://registry.npmjs.org/</span><br><span class=\"line\">使用淘宝的镜像网址</span><br><span class=\"line\">$ npm config <span class=\"built_in\">set</span> registry http://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>\n<h3 id=\"静态博客搭建\"><a href=\"#静态博客搭建\" class=\"headerlink\" title=\"静态博客搭建\"></a>静态博客搭建</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init blog</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> blog</span><br><span class=\"line\">$ npm install</span><br><span class=\"line\">$ hexo s</span><br></pre></td></tr></table></figure>\n<p>浏览器访问：<a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"noopener\">http://localhost:4000/</a><br>按Ctrl+C停止  </p>\n<h3 id=\"配置到GitHub\"><a href=\"#配置到GitHub\" class=\"headerlink\" title=\"配置到GitHub\"></a>配置到GitHub</h3><p>在github上创建仓库，仓库名称为：用户名.github.io<br>配置blog\\_config.yml中的deploy</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"string\">git@github.com:your_github_user_name/your_github_user_name.github.io.git</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">master</span></span><br></pre></td></tr></table></figure>\n<p>生成 ssh key<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh-keygen -t rsa -C xxx@qq.com(your_email)</span><br><span class=\"line\">$ 连按三次Enter</span><br></pre></td></tr></table></figure></p>\n<p>其中ssh-keygen.exe在.\\Git\\usr\\bin文件夹中<br>根据路径提示找到id_rsa.pub文件，拷贝公钥<br>进入github账户设置，在ssh and GPG keys中新增一个ssh key<br>把刚刚拷贝出来的公钥粘贴到key中，title放空就好&lt;/br&gt;</p>\n<p>验证ssh key<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure></p>\n<p>在本地hexo init生成的文件夹中初始化git仓库<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git init</span><br></pre></td></tr></table></figure></p>\n<p>将本地仓库和远程仓库连接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git remote add origin git@github.com:your_github_user_name/your_github_user_name.github.io.git</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n<h2 id=\"网站部署\"><a href=\"#网站部署\" class=\"headerlink\" title=\"网站部署\"></a>网站部署</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean  //清除缓存文件db.json和已生成的静态文件public</span><br><span class=\"line\">$ hexo g      //生成网站静态文件到默认设置的public文件夹</span><br><span class=\"line\">$ hexo s      //开启服务器预览网址</span><br><span class=\"line\">$ hexo d      //部署网站到设定的仓库</span><br></pre></td></tr></table></figure>\n<h2 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h2><h3 id=\"挑选主题\"><a href=\"#挑选主题\" class=\"headerlink\" title=\"挑选主题\"></a>挑选主题</h3><ul>\n<li>Themes | Hexo <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/themes/</a></li>\n<li>Themes · hexojs/hexo Wiki <a href=\"https://github.com/hexojs/hexo/wiki/Themes\" target=\"_blank\" rel=\"noopener\">https://github.com/hexojs/hexo/wiki/Themes</a></li>\n</ul>\n<h2 id=\"添加主题\"><a href=\"#添加主题\" class=\"headerlink\" title=\"添加主题\"></a>添加主题</h2><p>复制主题到themes目录下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> themes &amp;&amp; git <span class=\"built_in\">clone</span> https://github.com/maochunguang/black-blue(主题地址)</span><br></pre></td></tr></table></figure></p>\n<p>配置blog\\_config.yml，修改对应主题目录名<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">theme:</span> <span class=\"string\">主题名称</span></span><br></pre></td></tr></table></figure></p>\n<p>重新生成静态页面<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br></pre></td></tr></table></figure></p>\n<p>启动本地服务，重新访问：<a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"noopener\">http://localhost:4000/</a> ，查看新主题的效果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure></p>\n<p>确认后上传到github，通过 用户名.github.io 访问查看最终效果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"插入图片\"><a href=\"#插入图片\" class=\"headerlink\" title=\"插入图片\"></a>插入图片</h2><h3 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h3><p>配置blog\\_config.yml</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">post_asset_folder:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>安装插件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure></p>\n<p>html语法<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">align</span>=<span class=\"string\">center</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"title\"</span> <span class=\"attr\">src</span> = <span class=\"string\">\"path to xxx.png\"</span> <span class=\"attr\">width</span>=<span class=\"string\">999</span> <span class=\"attr\">height</span>=<span class=\"string\">999</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Hexo：Hello Hexo：</strong> <excerpt in index | 首页摘要><br>Welcome to <a href=\"https://hexo.io/\" target=\"_blank\" rel=\"noopener\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\" target=\"_blank\" rel=\"noopener\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"noopener\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"noopener\">GitHub</a>.<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"所需软件\"><a href=\"#所需软件\" class=\"headerlink\" title=\"所需软件\"></a>所需软件</h3><ul>\n<li>git: <a href=\"http://git-scm.com/\" target=\"_blank\" rel=\"noopener\">http://git-scm.com/</a></li>\n<li>node.js：<a href=\"http://nodejs.org/\" target=\"_blank\" rel=\"noopener\">http://nodejs.org/</a></li>\n</ul>\n<p>查看是否安装成功</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git --version</span><br><span class=\"line\">$ npm -v</span><br></pre></td></tr></table></figure>\n<h3 id=\"Hexo-相关命令\"><a href=\"#Hexo-相关命令\" class=\"headerlink\" title=\"Hexo 相关命令\"></a>Hexo 相关命令</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new page<span class=\"string\">\"pageName\"</span>     新建页面</span><br><span class=\"line\">$ cls                         清屏</span><br><span class=\"line\">$ hexo clean                  清理项目</span><br><span class=\"line\">$ hexo g(generate)            生成静态页面至public目录</span><br><span class=\"line\">$ hexo s(server)              开启预览访问端口</span><br><span class=\"line\">$ hexo d(deploy)              将.deploy目录部署到GitHub</span><br><span class=\"line\">$ hexo <span class=\"built_in\">help</span>                   查看帮助</span><br><span class=\"line\">$ hexo version                查看Hexo的版本</span><br></pre></td></tr></table></figure>\n<h2 id=\"部署\"><a href=\"#部署\" class=\"headerlink\" title=\"部署\"></a>部署</h2><h3 id=\"安装hexo\"><a href=\"#安装hexo\" class=\"headerlink\" title=\"安装hexo\"></a>安装hexo</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-cli -g</span><br></pre></td></tr></table></figure>\n<p>安装hexo-deployer-git工具<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure></p>\n<h4 id=\"npm-install-慢的话\"><a href=\"#npm-install-慢的话\" class=\"headerlink\" title=\"npm install 慢的话\"></a>npm install 慢的话</h4><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">显示当前的镜像网址</span><br><span class=\"line\">$ npm get registry </span><br><span class=\"line\">https://registry.npmjs.org/</span><br><span class=\"line\">使用淘宝的镜像网址</span><br><span class=\"line\">$ npm config <span class=\"built_in\">set</span> registry http://registry.npm.taobao.org</span><br></pre></td></tr></table></figure>\n<h3 id=\"静态博客搭建\"><a href=\"#静态博客搭建\" class=\"headerlink\" title=\"静态博客搭建\"></a>静态博客搭建</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo init blog</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> blog</span><br><span class=\"line\">$ npm install</span><br><span class=\"line\">$ hexo s</span><br></pre></td></tr></table></figure>\n<p>浏览器访问：<a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"noopener\">http://localhost:4000/</a><br>按Ctrl+C停止  </p>\n<h3 id=\"配置到GitHub\"><a href=\"#配置到GitHub\" class=\"headerlink\" title=\"配置到GitHub\"></a>配置到GitHub</h3><p>在github上创建仓库，仓库名称为：用户名.github.io<br>配置blog\\_config.yml中的deploy</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">deploy:</span></span><br><span class=\"line\"><span class=\"attr\">  type:</span> <span class=\"string\">git</span></span><br><span class=\"line\"><span class=\"attr\">  repo:</span> <span class=\"string\">git@github.com:your_github_user_name/your_github_user_name.github.io.git</span></span><br><span class=\"line\"><span class=\"attr\">  branch:</span> <span class=\"string\">master</span></span><br></pre></td></tr></table></figure>\n<p>生成 ssh key<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh-keygen -t rsa -C xxx@qq.com(your_email)</span><br><span class=\"line\">$ 连按三次Enter</span><br></pre></td></tr></table></figure></p>\n<p>其中ssh-keygen.exe在.\\Git\\usr\\bin文件夹中<br>根据路径提示找到id_rsa.pub文件，拷贝公钥<br>进入github账户设置，在ssh and GPG keys中新增一个ssh key<br>把刚刚拷贝出来的公钥粘贴到key中，title放空就好&lt;/br&gt;</p>\n<p>验证ssh key<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure></p>\n<p>在本地hexo init生成的文件夹中初始化git仓库<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git init</span><br></pre></td></tr></table></figure></p>\n<p>将本地仓库和远程仓库连接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git remote add origin git@github.com:your_github_user_name/your_github_user_name.github.io.git</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">\"My New Post\"</span></span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"noopener\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/server.html\" target=\"_blank\" rel=\"noopener\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\" target=\"_blank\" rel=\"noopener\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n<p>More info: <a href=\"https://hexo.io/docs/deployment.html\" target=\"_blank\" rel=\"noopener\">Deployment</a></p>\n<h2 id=\"网站部署\"><a href=\"#网站部署\" class=\"headerlink\" title=\"网站部署\"></a>网站部署</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo clean  //清除缓存文件db.json和已生成的静态文件public</span><br><span class=\"line\">$ hexo g      //生成网站静态文件到默认设置的public文件夹</span><br><span class=\"line\">$ hexo s      //开启服务器预览网址</span><br><span class=\"line\">$ hexo d      //部署网站到设定的仓库</span><br></pre></td></tr></table></figure>\n<h2 id=\"主题\"><a href=\"#主题\" class=\"headerlink\" title=\"主题\"></a>主题</h2><h3 id=\"挑选主题\"><a href=\"#挑选主题\" class=\"headerlink\" title=\"挑选主题\"></a>挑选主题</h3><ul>\n<li>Themes | Hexo <a href=\"https://hexo.io/themes/\" target=\"_blank\" rel=\"noopener\">https://hexo.io/themes/</a></li>\n<li>Themes · hexojs/hexo Wiki <a href=\"https://github.com/hexojs/hexo/wiki/Themes\" target=\"_blank\" rel=\"noopener\">https://github.com/hexojs/hexo/wiki/Themes</a></li>\n</ul>\n<h2 id=\"添加主题\"><a href=\"#添加主题\" class=\"headerlink\" title=\"添加主题\"></a>添加主题</h2><p>复制主题到themes目录下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> themes &amp;&amp; git <span class=\"built_in\">clone</span> https://github.com/maochunguang/black-blue(主题地址)</span><br></pre></td></tr></table></figure></p>\n<p>配置blog\\_config.yml，修改对应主题目录名<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">theme:</span> <span class=\"string\">主题名称</span></span><br></pre></td></tr></table></figure></p>\n<p>重新生成静态页面<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo g</span><br></pre></td></tr></table></figure></p>\n<p>启动本地服务，重新访问：<a href=\"http://localhost:4000/\" target=\"_blank\" rel=\"noopener\">http://localhost:4000/</a> ，查看新主题的效果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo s</span><br></pre></td></tr></table></figure></p>\n<p>确认后上传到github，通过 用户名.github.io 访问查看最终效果<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"插入图片\"><a href=\"#插入图片\" class=\"headerlink\" title=\"插入图片\"></a>插入图片</h2><h3 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h3><p>配置blog\\_config.yml</p>\n<figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">post_asset_folder:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure>\n<p>安装插件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm install hexo-asset-image --save</span><br></pre></td></tr></table></figure></p>\n<p>html语法<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">div</span> <span class=\"attr\">align</span>=<span class=\"string\">center</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">img</span> <span class=\"attr\">alt</span>=<span class=\"string\">\"title\"</span> <span class=\"attr\">src</span> = <span class=\"string\">\"path to xxx.png\"</span> <span class=\"attr\">width</span>=<span class=\"string\">999</span> <span class=\"attr\">height</span>=<span class=\"string\">999</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">div</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n</the>"},{"title":"FDM3D打印电吉他琴体，制作电吉他","date":"2019-06-23T17:05:39.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n涉及制作一把电吉他：  \n琴体部分完全采用FDM3D打印制作……  \n~~多图预警~~\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 展示\n\n<img alt=\"00\" src=\"FDM3D打印电吉他琴体，制作电吉他/00.jpg\">  \n\n\n## 模型\n* Stratocaster/Les Paul Hybrid Guitar by TheWhaleBiologist - Thingiverse   \nhttps://www.thingiverse.com/thing:352349\n\nTheWhaleBiologist大神的模型是一个琴体整体，并提供了可使用Inventor修改的.ipt原始文件。  \n我在琴体模型上添加了自己的logo，并将整个模型切分成22个小块，便于使用不同颜色进行打印。\n\n* Guitar by Binjun - Thingiverse  \nhttps://www.thingiverse.com/thing:3709391\n\n\n<img alt=\"01\" src=\"FDM3D打印电吉他琴体，制作电吉他/01.jpg\">  \n\n## 准备\n<img alt=\"02\" src=\"FDM3D打印电吉他琴体，制作电吉他/02.jpg\">  \n\n除了琴体外，还需要购买电吉他的其他配件。在某宝上可以购买到整套电吉他的DIY组装材料，主要包括：  \n* 琴颈\n* 弦准\n* 压弦扣\n* 琴弦\n* 连接加强板\n* 下驹后盖板\n* 尾钉\n* 护板\n* 琴码\n* 拾音器等电子配件\n\n<img alt=\"03\" src=\"FDM3D打印电吉他琴体，制作电吉他/03.jpg\">  \n\n工具准备\n* 手钻\n* 胶水(502、AB胶、亚克力胶水)\n* 打磨工具（锉刀、剪刀、美工刀）\n* 螺丝刀\n\n## 组装\n\n1.用胶水和剪刀将3D打印出来的塑料小块进行粘贴拼接，完成琴体的制作。\n\n<img alt=\"04\" src=\"FDM3D打印电吉他琴体，制作电吉他/04.jpg\">  \n\n2.在上弦枕底部涂抹胶水粘在指板的开槽处。  \n3.组装弦准，在琴头上打孔安装旋钮和压弦扣。\n\n<img alt=\"05\" src=\"FDM3D打印电吉他琴体，制作电吉他/05.jpg\">  \n\n\n4.连接琴柄和3D打印琴体，调整好琴柄和琴体开槽处的尺寸和高度，根据加强板螺丝孔的位置开孔，用螺丝将琴柄、琴身和加强板连在一起。\n\n<img alt=\"06\" src=\"FDM3D打印电吉他琴体，制作电吉他/06.jpg\">  \n\n5.将电路部分连接好，预留接地线和音频输出线，安装护板。\n\n<img alt=\"07\" src=\"FDM3D打印电吉他琴体，制作电吉他/07.jpg\"> \n\n6.安装琴码。  \n\n<img alt=\"08\" src=\"FDM3D打印电吉他琴体，制作电吉他/08.jpg\"> \n\n7.焊接插座线，安装插座片。  \n\n<img alt=\"09\" src=\"FDM3D打印电吉他琴体，制作电吉他/09.jpg\">  \n\n<img alt=\"10\" src=\"FDM3D打印电吉他琴体，制作电吉他/10.jpg\">  \n\n8.安装下驹在琴体背面的部件，焊接好接地线并固定好弹簧。\n\n<img alt=\"11\" src=\"FDM3D打印电吉他琴体，制作电吉他/11.jpg\">  \n\n<img alt=\"12\" src=\"FDM3D打印电吉他琴体，制作电吉他/12.jpg\">  \n\n9.安装琴弦并调音，摇把只是摆设可以不装。\n\n<img alt=\"13\" src=\"FDM3D打印电吉他琴体，制作电吉他/13.jpg\">  \n\n10.买个琴箱，完成。\n\n<img alt=\"14\" src=\"FDM3D打印电吉他琴体，制作电吉他/14.jpg\">  \n\n## 一些乐理知识\n\n### 有效弦长 Scale Length\n有效弦长是弦枕与第12品之间长度的二倍，这段长度也正好是一个八度的音程，琴桥的位置也由此确定，即琴桥必须调整到一个正确的位置，让这把琴得到一个正确的有效弦长。\n\n\n## 其他\n\n* 3D打印电吉他 撩妹技能Get起来！|3D学堂|3D虎  \nhttp://www.3dhoo.com/news/xuetang/39430.html\n\n","source":"_posts/FDM3D打印电吉他琴体，制作电吉他.md","raw":"---\ntitle: FDM3D打印电吉他琴体，制作电吉他\ndate: 2019-06-24 01:05:39\ntags:\n  - 3D打印\n  - 吉他\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n涉及制作一把电吉他：  \n琴体部分完全采用FDM3D打印制作……  \n~~多图预警~~\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 展示\n\n<img alt=\"00\" src=\"FDM3D打印电吉他琴体，制作电吉他/00.jpg\">  \n\n\n## 模型\n* Stratocaster/Les Paul Hybrid Guitar by TheWhaleBiologist - Thingiverse   \nhttps://www.thingiverse.com/thing:352349\n\nTheWhaleBiologist大神的模型是一个琴体整体，并提供了可使用Inventor修改的.ipt原始文件。  \n我在琴体模型上添加了自己的logo，并将整个模型切分成22个小块，便于使用不同颜色进行打印。\n\n* Guitar by Binjun - Thingiverse  \nhttps://www.thingiverse.com/thing:3709391\n\n\n<img alt=\"01\" src=\"FDM3D打印电吉他琴体，制作电吉他/01.jpg\">  \n\n## 准备\n<img alt=\"02\" src=\"FDM3D打印电吉他琴体，制作电吉他/02.jpg\">  \n\n除了琴体外，还需要购买电吉他的其他配件。在某宝上可以购买到整套电吉他的DIY组装材料，主要包括：  \n* 琴颈\n* 弦准\n* 压弦扣\n* 琴弦\n* 连接加强板\n* 下驹后盖板\n* 尾钉\n* 护板\n* 琴码\n* 拾音器等电子配件\n\n<img alt=\"03\" src=\"FDM3D打印电吉他琴体，制作电吉他/03.jpg\">  \n\n工具准备\n* 手钻\n* 胶水(502、AB胶、亚克力胶水)\n* 打磨工具（锉刀、剪刀、美工刀）\n* 螺丝刀\n\n## 组装\n\n1.用胶水和剪刀将3D打印出来的塑料小块进行粘贴拼接，完成琴体的制作。\n\n<img alt=\"04\" src=\"FDM3D打印电吉他琴体，制作电吉他/04.jpg\">  \n\n2.在上弦枕底部涂抹胶水粘在指板的开槽处。  \n3.组装弦准，在琴头上打孔安装旋钮和压弦扣。\n\n<img alt=\"05\" src=\"FDM3D打印电吉他琴体，制作电吉他/05.jpg\">  \n\n\n4.连接琴柄和3D打印琴体，调整好琴柄和琴体开槽处的尺寸和高度，根据加强板螺丝孔的位置开孔，用螺丝将琴柄、琴身和加强板连在一起。\n\n<img alt=\"06\" src=\"FDM3D打印电吉他琴体，制作电吉他/06.jpg\">  \n\n5.将电路部分连接好，预留接地线和音频输出线，安装护板。\n\n<img alt=\"07\" src=\"FDM3D打印电吉他琴体，制作电吉他/07.jpg\"> \n\n6.安装琴码。  \n\n<img alt=\"08\" src=\"FDM3D打印电吉他琴体，制作电吉他/08.jpg\"> \n\n7.焊接插座线，安装插座片。  \n\n<img alt=\"09\" src=\"FDM3D打印电吉他琴体，制作电吉他/09.jpg\">  \n\n<img alt=\"10\" src=\"FDM3D打印电吉他琴体，制作电吉他/10.jpg\">  \n\n8.安装下驹在琴体背面的部件，焊接好接地线并固定好弹簧。\n\n<img alt=\"11\" src=\"FDM3D打印电吉他琴体，制作电吉他/11.jpg\">  \n\n<img alt=\"12\" src=\"FDM3D打印电吉他琴体，制作电吉他/12.jpg\">  \n\n9.安装琴弦并调音，摇把只是摆设可以不装。\n\n<img alt=\"13\" src=\"FDM3D打印电吉他琴体，制作电吉他/13.jpg\">  \n\n10.买个琴箱，完成。\n\n<img alt=\"14\" src=\"FDM3D打印电吉他琴体，制作电吉他/14.jpg\">  \n\n## 一些乐理知识\n\n### 有效弦长 Scale Length\n有效弦长是弦枕与第12品之间长度的二倍，这段长度也正好是一个八度的音程，琴桥的位置也由此确定，即琴桥必须调整到一个正确的位置，让这把琴得到一个正确的有效弦长。\n\n\n## 其他\n\n* 3D打印电吉他 撩妹技能Get起来！|3D学堂|3D虎  \nhttp://www.3dhoo.com/news/xuetang/39430.html\n\n","slug":"FDM3D打印电吉他琴体，制作电吉他","published":1,"updated":"2019-07-03T13:07:16.176Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm7460003rsvjzzrwqk5g","content":"<p><strong> FDM3D打印电吉他琴体，制作电吉他：</strong> <excerpt in index | 首页摘要><br>涉及制作一把电吉他：<br>琴体部分完全采用FDM3D打印制作……<br><del>多图预警</del><br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"展示\"><a href=\"#展示\" class=\"headerlink\" title=\"展示\"></a>展示</h2><p><img alt=\"00\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/00.jpg\">  </p>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><ul>\n<li>Stratocaster/Les Paul Hybrid Guitar by TheWhaleBiologist - Thingiverse<br><a href=\"https://www.thingiverse.com/thing:352349\" target=\"_blank\" rel=\"noopener\">https://www.thingiverse.com/thing:352349</a></li>\n</ul>\n<p>TheWhaleBiologist大神的模型是一个琴体整体，并提供了可使用Inventor修改的.ipt原始文件。<br>我在琴体模型上添加了自己的logo，并将整个模型切分成22个小块，便于使用不同颜色进行打印。</p>\n<ul>\n<li>Guitar by Binjun - Thingiverse<br><a href=\"https://www.thingiverse.com/thing:3709391\" target=\"_blank\" rel=\"noopener\">https://www.thingiverse.com/thing:3709391</a></li>\n</ul>\n<p><img alt=\"01\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/01.jpg\">  </p>\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><p><img alt=\"02\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/02.jpg\">  </p>\n<p>除了琴体外，还需要购买电吉他的其他配件。在某宝上可以购买到整套电吉他的DIY组装材料，主要包括：  </p>\n<ul>\n<li>琴颈</li>\n<li>弦准</li>\n<li>压弦扣</li>\n<li>琴弦</li>\n<li>连接加强板</li>\n<li>下驹后盖板</li>\n<li>尾钉</li>\n<li>护板</li>\n<li>琴码</li>\n<li>拾音器等电子配件</li>\n</ul>\n<p><img alt=\"03\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/03.jpg\">  </p>\n<p>工具准备</p>\n<ul>\n<li>手钻</li>\n<li>胶水(502、AB胶、亚克力胶水)</li>\n<li>打磨工具（锉刀、剪刀、美工刀）</li>\n<li>螺丝刀</li>\n</ul>\n<h2 id=\"组装\"><a href=\"#组装\" class=\"headerlink\" title=\"组装\"></a>组装</h2><p>1.用胶水和剪刀将3D打印出来的塑料小块进行粘贴拼接，完成琴体的制作。</p>\n<p><img alt=\"04\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/04.jpg\">  </p>\n<p>2.在上弦枕底部涂抹胶水粘在指板的开槽处。<br>3.组装弦准，在琴头上打孔安装旋钮和压弦扣。</p>\n<p><img alt=\"05\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/05.jpg\">  </p>\n<p>4.连接琴柄和3D打印琴体，调整好琴柄和琴体开槽处的尺寸和高度，根据加强板螺丝孔的位置开孔，用螺丝将琴柄、琴身和加强板连在一起。</p>\n<p><img alt=\"06\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/06.jpg\">  </p>\n<p>5.将电路部分连接好，预留接地线和音频输出线，安装护板。</p>\n<p><img alt=\"07\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/07.jpg\"> </p>\n<p>6.安装琴码。  </p>\n<p><img alt=\"08\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/08.jpg\"> </p>\n<p>7.焊接插座线，安装插座片。  </p>\n<p><img alt=\"09\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/09.jpg\">  </p>\n<p><img alt=\"10\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/10.jpg\">  </p>\n<p>8.安装下驹在琴体背面的部件，焊接好接地线并固定好弹簧。</p>\n<p><img alt=\"11\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/11.jpg\">  </p>\n<p><img alt=\"12\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/12.jpg\">  </p>\n<p>9.安装琴弦并调音，摇把只是摆设可以不装。</p>\n<p><img alt=\"13\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/13.jpg\">  </p>\n<p>10.买个琴箱，完成。</p>\n<p><img alt=\"14\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/14.jpg\">  </p>\n<h2 id=\"一些乐理知识\"><a href=\"#一些乐理知识\" class=\"headerlink\" title=\"一些乐理知识\"></a>一些乐理知识</h2><h3 id=\"有效弦长-Scale-Length\"><a href=\"#有效弦长-Scale-Length\" class=\"headerlink\" title=\"有效弦长 Scale Length\"></a>有效弦长 Scale Length</h3><p>有效弦长是弦枕与第12品之间长度的二倍，这段长度也正好是一个八度的音程，琴桥的位置也由此确定，即琴桥必须调整到一个正确的位置，让这把琴得到一个正确的有效弦长。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><ul>\n<li>3D打印电吉他 撩妹技能Get起来！|3D学堂|3D虎<br><a href=\"http://www.3dhoo.com/news/xuetang/39430.html\" target=\"_blank\" rel=\"noopener\">http://www.3dhoo.com/news/xuetang/39430.html</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> FDM3D打印电吉他琴体，制作电吉他：</strong> <excerpt in index | 首页摘要><br>涉及制作一把电吉他：<br>琴体部分完全采用FDM3D打印制作……<br><del>多图预警</del><br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"展示\"><a href=\"#展示\" class=\"headerlink\" title=\"展示\"></a>展示</h2><p><img alt=\"00\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/00.jpg\">  </p>\n<h2 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h2><ul>\n<li>Stratocaster/Les Paul Hybrid Guitar by TheWhaleBiologist - Thingiverse<br><a href=\"https://www.thingiverse.com/thing:352349\" target=\"_blank\" rel=\"noopener\">https://www.thingiverse.com/thing:352349</a></li>\n</ul>\n<p>TheWhaleBiologist大神的模型是一个琴体整体，并提供了可使用Inventor修改的.ipt原始文件。<br>我在琴体模型上添加了自己的logo，并将整个模型切分成22个小块，便于使用不同颜色进行打印。</p>\n<ul>\n<li>Guitar by Binjun - Thingiverse<br><a href=\"https://www.thingiverse.com/thing:3709391\" target=\"_blank\" rel=\"noopener\">https://www.thingiverse.com/thing:3709391</a></li>\n</ul>\n<p><img alt=\"01\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/01.jpg\">  </p>\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><p><img alt=\"02\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/02.jpg\">  </p>\n<p>除了琴体外，还需要购买电吉他的其他配件。在某宝上可以购买到整套电吉他的DIY组装材料，主要包括：  </p>\n<ul>\n<li>琴颈</li>\n<li>弦准</li>\n<li>压弦扣</li>\n<li>琴弦</li>\n<li>连接加强板</li>\n<li>下驹后盖板</li>\n<li>尾钉</li>\n<li>护板</li>\n<li>琴码</li>\n<li>拾音器等电子配件</li>\n</ul>\n<p><img alt=\"03\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/03.jpg\">  </p>\n<p>工具准备</p>\n<ul>\n<li>手钻</li>\n<li>胶水(502、AB胶、亚克力胶水)</li>\n<li>打磨工具（锉刀、剪刀、美工刀）</li>\n<li>螺丝刀</li>\n</ul>\n<h2 id=\"组装\"><a href=\"#组装\" class=\"headerlink\" title=\"组装\"></a>组装</h2><p>1.用胶水和剪刀将3D打印出来的塑料小块进行粘贴拼接，完成琴体的制作。</p>\n<p><img alt=\"04\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/04.jpg\">  </p>\n<p>2.在上弦枕底部涂抹胶水粘在指板的开槽处。<br>3.组装弦准，在琴头上打孔安装旋钮和压弦扣。</p>\n<p><img alt=\"05\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/05.jpg\">  </p>\n<p>4.连接琴柄和3D打印琴体，调整好琴柄和琴体开槽处的尺寸和高度，根据加强板螺丝孔的位置开孔，用螺丝将琴柄、琴身和加强板连在一起。</p>\n<p><img alt=\"06\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/06.jpg\">  </p>\n<p>5.将电路部分连接好，预留接地线和音频输出线，安装护板。</p>\n<p><img alt=\"07\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/07.jpg\"> </p>\n<p>6.安装琴码。  </p>\n<p><img alt=\"08\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/08.jpg\"> </p>\n<p>7.焊接插座线，安装插座片。  </p>\n<p><img alt=\"09\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/09.jpg\">  </p>\n<p><img alt=\"10\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/10.jpg\">  </p>\n<p>8.安装下驹在琴体背面的部件，焊接好接地线并固定好弹簧。</p>\n<p><img alt=\"11\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/11.jpg\">  </p>\n<p><img alt=\"12\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/12.jpg\">  </p>\n<p>9.安装琴弦并调音，摇把只是摆设可以不装。</p>\n<p><img alt=\"13\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/13.jpg\">  </p>\n<p>10.买个琴箱，完成。</p>\n<p><img alt=\"14\" src=\"/2019/06/24/FDM3D打印电吉他琴体，制作电吉他/14.jpg\">  </p>\n<h2 id=\"一些乐理知识\"><a href=\"#一些乐理知识\" class=\"headerlink\" title=\"一些乐理知识\"></a>一些乐理知识</h2><h3 id=\"有效弦长-Scale-Length\"><a href=\"#有效弦长-Scale-Length\" class=\"headerlink\" title=\"有效弦长 Scale Length\"></a>有效弦长 Scale Length</h3><p>有效弦长是弦枕与第12品之间长度的二倍，这段长度也正好是一个八度的音程，琴桥的位置也由此确定，即琴桥必须调整到一个正确的位置，让这把琴得到一个正确的有效弦长。</p>\n<h2 id=\"其他\"><a href=\"#其他\" class=\"headerlink\" title=\"其他\"></a>其他</h2><ul>\n<li>3D打印电吉他 撩妹技能Get起来！|3D学堂|3D虎<br><a href=\"http://www.3dhoo.com/news/xuetang/39430.html\" target=\"_blank\" rel=\"noopener\">http://www.3dhoo.com/news/xuetang/39430.html</a></li>\n</ul>\n</the>"},{"title":"Hexo：yilia主题下使用LaTex添加公式","date":"2019-06-22T14:30:18.000Z","_content":"\n## 配置文件中开启mathjax\n\n修改/themes/yilia主题目录下的_config.yml文件,添加支持Mathjax\n``` yml\n# 数学公式\nmathjax: true\n```\n\n## 安装Kramed\n更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。\n``` bash\nnpm uninstall hexo-renderer-marked --save\nnpm install hexo-renderer-kramed --save\n```\n打开/node_modules/hexo-renderer-kramed/lib/renderer.js，进行如下更改：\n``` js\n// Change inline math rule\nfunction formatText(text) {\n    // Fit kramed's rule: $$ + \\1 + $$\n    // return text.replace(/`\\$(.*?)\\$`/g, '$$$$$1$$$$');\n    return text;\n}\n```\n### 停止使用 hexo-math，并安装mathjax包\n``` bash\nnpm uninstall hexo-math --save\nnpm install hexo-renderer-mathjax --save\n```\n打开/node_modules/hexo-renderer-mathjax/mathjax.html,更新Mathjax的配置文件\n``` html\n<!-- <script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"></script> -->\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"></script>\n```\n\n### 更改默认转义规则\nLaTeX与markdown语法有语义冲突，需要修改\\node_modules\\kramed\\lib\\rules\\inline.js中的默认规则\n``` js\nvar inline = {\n    // escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_>])/,\n    escape: /^\\\\([`*\\[\\]()# +\\-.!_>])/,\n    // em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,\n    em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,\n```\n\n### 公式输入相关\n\nMathpix Snip工具：只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  \n* Mathpix Snip  \nhttps://mathpix.com/\n\n基本语法\n* 03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客  \nhttps://blog.csdn.net/ds19991999/article/details/81275580\n\n\n### VScode下markdown公式预览\n安装markwown math扩展插件，重启，预览时使用快捷键 ctrl + shift + p","source":"_posts/Hexo：yilia主题下使用LaTex添加公式.md","raw":"---\ntitle: Hexo：yilia主题下使用LaTex添加公式\ndate: 2019-06-22 22:30:18\ntags:\n  - hexo\n---\n\n## 配置文件中开启mathjax\n\n修改/themes/yilia主题目录下的_config.yml文件,添加支持Mathjax\n``` yml\n# 数学公式\nmathjax: true\n```\n\n## 安装Kramed\n更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。\n``` bash\nnpm uninstall hexo-renderer-marked --save\nnpm install hexo-renderer-kramed --save\n```\n打开/node_modules/hexo-renderer-kramed/lib/renderer.js，进行如下更改：\n``` js\n// Change inline math rule\nfunction formatText(text) {\n    // Fit kramed's rule: $$ + \\1 + $$\n    // return text.replace(/`\\$(.*?)\\$`/g, '$$$$$1$$$$');\n    return text;\n}\n```\n### 停止使用 hexo-math，并安装mathjax包\n``` bash\nnpm uninstall hexo-math --save\nnpm install hexo-renderer-mathjax --save\n```\n打开/node_modules/hexo-renderer-mathjax/mathjax.html,更新Mathjax的配置文件\n``` html\n<!-- <script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"></script> -->\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"></script>\n```\n\n### 更改默认转义规则\nLaTeX与markdown语法有语义冲突，需要修改\\node_modules\\kramed\\lib\\rules\\inline.js中的默认规则\n``` js\nvar inline = {\n    // escape: /^\\\\([\\\\`*{}\\[\\]()#$+\\-.!_>])/,\n    escape: /^\\\\([`*\\[\\]()# +\\-.!_>])/,\n    // em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,\n    em: /^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,\n```\n\n### 公式输入相关\n\nMathpix Snip工具：只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  \n* Mathpix Snip  \nhttps://mathpix.com/\n\n基本语法\n* 03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客  \nhttps://blog.csdn.net/ds19991999/article/details/81275580\n\n\n### VScode下markdown公式预览\n安装markwown math扩展插件，重启，预览时使用快捷键 ctrl + shift + p","slug":"Hexo：yilia主题下使用LaTex添加公式","published":1,"updated":"2019-06-23T07:09:39.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm7480004rsvji3z4fm2b","content":"<h2 id=\"配置文件中开启mathjax\"><a href=\"#配置文件中开启mathjax\" class=\"headerlink\" title=\"配置文件中开启mathjax\"></a>配置文件中开启mathjax</h2><p>修改/themes/yilia主题目录下的_config.yml文件,添加支持Mathjax<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数学公式</span></span><br><span class=\"line\"><span class=\"attr\">mathjax:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装Kramed\"><a href=\"#安装Kramed\" class=\"headerlink\" title=\"安装Kramed\"></a>安装Kramed</h2><p>更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm uninstall hexo-renderer-marked --save</span><br><span class=\"line\">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure></p>\n<p>打开/node_modules/hexo-renderer-kramed/lib/renderer.js，进行如下更改：<br><figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Change inline math rule</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">formatText</span>(<span class=\"params\">text</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Fit kramed's rule: $$ + \\1 + $$</span></span><br><span class=\"line\">    <span class=\"comment\">// return text.replace(/`\\$(.*?)\\$`/g, '$$$$$1$$$$');</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> text;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"停止使用-hexo-math，并安装mathjax包\"><a href=\"#停止使用-hexo-math，并安装mathjax包\" class=\"headerlink\" title=\"停止使用 hexo-math，并安装mathjax包\"></a>停止使用 hexo-math，并安装mathjax包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm uninstall hexo-math --save</span><br><span class=\"line\">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure>\n<p>打开/node_modules/hexo-renderer-mathjax/mathjax.html,更新Mathjax的配置文件<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- &lt;script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"更改默认转义规则\"><a href=\"#更改默认转义规则\" class=\"headerlink\" title=\"更改默认转义规则\"></a>更改默认转义规则</h3><p>LaTeX与markdown语法有语义冲突，需要修改\\node_modules\\kramed\\lib\\rules\\inline.js中的默认规则<br><figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> inline = &#123;</span><br><span class=\"line\">    <span class=\"comment\">// escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()#$+\\-.!_&gt;])/,</span></span><br><span class=\"line\">    <span class=\"built_in\">escape</span>: <span class=\"regexp\">/^\\\\([`*\\[\\]()# +\\-.!_&gt;])/</span>,</span><br><span class=\"line\">    <span class=\"comment\">// em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,</span></span><br><span class=\"line\">    em: <span class=\"regexp\">/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span>,</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"公式输入相关\"><a href=\"#公式输入相关\" class=\"headerlink\" title=\"公式输入相关\"></a>公式输入相关</h3><p>Mathpix Snip工具：只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  </p>\n<ul>\n<li>Mathpix Snip<br><a href=\"https://mathpix.com/\" target=\"_blank\" rel=\"noopener\">https://mathpix.com/</a></li>\n</ul>\n<p>基本语法</p>\n<ul>\n<li>03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ds19991999/article/details/81275580\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ds19991999/article/details/81275580</a></li>\n</ul>\n<h3 id=\"VScode下markdown公式预览\"><a href=\"#VScode下markdown公式预览\" class=\"headerlink\" title=\"VScode下markdown公式预览\"></a>VScode下markdown公式预览</h3><p>安装markwown math扩展插件，重启，预览时使用快捷键 ctrl + shift + p</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"配置文件中开启mathjax\"><a href=\"#配置文件中开启mathjax\" class=\"headerlink\" title=\"配置文件中开启mathjax\"></a>配置文件中开启mathjax</h2><p>修改/themes/yilia主题目录下的_config.yml文件,添加支持Mathjax<br><figure class=\"highlight yml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 数学公式</span></span><br><span class=\"line\"><span class=\"attr\">mathjax:</span> <span class=\"literal\">true</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"安装Kramed\"><a href=\"#安装Kramed\" class=\"headerlink\" title=\"安装Kramed\"></a>安装Kramed</h2><p>更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm uninstall hexo-renderer-marked --save</span><br><span class=\"line\">npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure></p>\n<p>打开/node_modules/hexo-renderer-kramed/lib/renderer.js，进行如下更改：<br><figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// Change inline math rule</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">function</span> <span class=\"title\">formatText</span>(<span class=\"params\">text</span>) </span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// Fit kramed's rule: $$ + \\1 + $$</span></span><br><span class=\"line\">    <span class=\"comment\">// return text.replace(/`\\$(.*?)\\$`/g, '$$$$$1$$$$');</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> text;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"停止使用-hexo-math，并安装mathjax包\"><a href=\"#停止使用-hexo-math，并安装mathjax包\" class=\"headerlink\" title=\"停止使用 hexo-math，并安装mathjax包\"></a>停止使用 hexo-math，并安装mathjax包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm uninstall hexo-math --save</span><br><span class=\"line\">npm install hexo-renderer-mathjax --save</span><br></pre></td></tr></table></figure>\n<p>打开/node_modules/hexo-renderer-mathjax/mathjax.html,更新Mathjax的配置文件<br><figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">&lt;!-- &lt;script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"&gt;&lt;/script&gt; --&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">script</span> <span class=\"attr\">src</span>=<span class=\"string\">\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML\"</span>&gt;</span><span class=\"undefined\"></span><span class=\"tag\">&lt;/<span class=\"name\">script</span>&gt;</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"更改默认转义规则\"><a href=\"#更改默认转义规则\" class=\"headerlink\" title=\"更改默认转义规则\"></a>更改默认转义规则</h3><p>LaTeX与markdown语法有语义冲突，需要修改\\node_modules\\kramed\\lib\\rules\\inline.js中的默认规则<br><figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">var</span> inline = &#123;</span><br><span class=\"line\">    <span class=\"comment\">// escape: /^\\\\([\\\\`*&#123;&#125;\\[\\]()#$+\\-.!_&gt;])/,</span></span><br><span class=\"line\">    <span class=\"built_in\">escape</span>: <span class=\"regexp\">/^\\\\([`*\\[\\]()# +\\-.!_&gt;])/</span>,</span><br><span class=\"line\">    <span class=\"comment\">// em: /^\\b_((?:__|[\\s\\S])+?)_\\b|^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/,</span></span><br><span class=\"line\">    em: <span class=\"regexp\">/^\\*((?:\\*\\*|[\\s\\S])+?)\\*(?!\\*)/</span>,</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"公式输入相关\"><a href=\"#公式输入相关\" class=\"headerlink\" title=\"公式输入相关\"></a>公式输入相关</h3><p>Mathpix Snip工具：只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  </p>\n<ul>\n<li>Mathpix Snip<br><a href=\"https://mathpix.com/\" target=\"_blank\" rel=\"noopener\">https://mathpix.com/</a></li>\n</ul>\n<p>基本语法</p>\n<ul>\n<li>03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ds19991999/article/details/81275580\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ds19991999/article/details/81275580</a></li>\n</ul>\n<h3 id=\"VScode下markdown公式预览\"><a href=\"#VScode下markdown公式预览\" class=\"headerlink\" title=\"VScode下markdown公式预览\"></a>VScode下markdown公式预览</h3><p>安装markwown math扩展插件，重启，预览时使用快捷键 ctrl + shift + p</p>\n"},{"title":"Hexo:使用dev分支管理站点源文件，多地同步","date":"2019-06-15T16:14:49.000Z","_content":"\n## 使用dev分支管理站点、源文件，多地同步\n5点钟被蚊子吵醒了，dong还在睡觉于是跑来310用zb的电脑玩耍，突然想用zb的键盘写博客。  \n\nhttps://www.jianshu.com/p/4bcf2848b3fc\n```bash\nhexo d\n```\nhexo的部署命令会自动生成站点文件进行git commit，将修改push到指定的remote branch一般是master中。  \n根据Hexo建站完成部署，其实我们的本地源文件都没有同步在github上。我在我的xxx.github.io仓库中创建了一个dev分支，用于管理源文件。  \n使用vscode注意修改.git文件夹中的config文件就可以了  \n``` conf\n[core]\n\trepositoryformatversion = 0\n\tfilemode = false\n\tbare = false\n\tlogallrefupdates = true\n\tsymlinks = false\n\tignorecase = true\n[remote \"origin\"]\n\turl = https://github.com/leebinjun/leebinjun.github.io.git\n\tfetch = +refs/heads/*:refs/remotes/origin/*\n[branch \"dev\"]\n\tremote = origin\n\tmerge = refs/heads/dev\n```\n来到zb的电脑上，偷偷建一个文件夹  \nclone博客代码到本地，发现是网页那一堆，没有源文件  \n``` bash\ngit clone xxx.git\n```\n与远程仓库建立连接\n``` bash\ngit remote add origin xxx.git\n```\n查看本地是否具有dev分支\n``` bash\ngit branch  \n```\n没有dev分支,则从远端获取最新到本地，不会自动merge\n``` bash\ngit fetch origin dev\n```\n在本地创建分支dev并切换到该分支  \n``` bash\ngit checkout -b dev origin/dev   \n```\n拉取dev分支上的内容到本地了\n``` bash\ngit pull origin dev             \n```\n然后就可以愉快地开始写博客了。  \n推送时会有remote: Permission to A denied to B地问题，原因是系统已经记住了zb的密码，每次push操作都会读取zb的信息。查了一下解放方案，决定还是不删他账号也不重新生成密钥了。  \n敲完这些，发现他的电脑还没hexo，于是我把他的键盘和U盘一起拿走了。  ","source":"_posts/Hexo：使用dev分支管理站点源文件，多地同步.md","raw":"---\ntitle: 'Hexo:使用dev分支管理站点源文件，多地同步'\ndate: 2019-06-16 00:14:49\ntags:\n  - hexo\n---\n\n## 使用dev分支管理站点、源文件，多地同步\n5点钟被蚊子吵醒了，dong还在睡觉于是跑来310用zb的电脑玩耍，突然想用zb的键盘写博客。  \n\nhttps://www.jianshu.com/p/4bcf2848b3fc\n```bash\nhexo d\n```\nhexo的部署命令会自动生成站点文件进行git commit，将修改push到指定的remote branch一般是master中。  \n根据Hexo建站完成部署，其实我们的本地源文件都没有同步在github上。我在我的xxx.github.io仓库中创建了一个dev分支，用于管理源文件。  \n使用vscode注意修改.git文件夹中的config文件就可以了  \n``` conf\n[core]\n\trepositoryformatversion = 0\n\tfilemode = false\n\tbare = false\n\tlogallrefupdates = true\n\tsymlinks = false\n\tignorecase = true\n[remote \"origin\"]\n\turl = https://github.com/leebinjun/leebinjun.github.io.git\n\tfetch = +refs/heads/*:refs/remotes/origin/*\n[branch \"dev\"]\n\tremote = origin\n\tmerge = refs/heads/dev\n```\n来到zb的电脑上，偷偷建一个文件夹  \nclone博客代码到本地，发现是网页那一堆，没有源文件  \n``` bash\ngit clone xxx.git\n```\n与远程仓库建立连接\n``` bash\ngit remote add origin xxx.git\n```\n查看本地是否具有dev分支\n``` bash\ngit branch  \n```\n没有dev分支,则从远端获取最新到本地，不会自动merge\n``` bash\ngit fetch origin dev\n```\n在本地创建分支dev并切换到该分支  \n``` bash\ngit checkout -b dev origin/dev   \n```\n拉取dev分支上的内容到本地了\n``` bash\ngit pull origin dev             \n```\n然后就可以愉快地开始写博客了。  \n推送时会有remote: Permission to A denied to B地问题，原因是系统已经记住了zb的密码，每次push操作都会读取zb的信息。查了一下解放方案，决定还是不删他账号也不重新生成密钥了。  \n敲完这些，发现他的电脑还没hexo，于是我把他的键盘和U盘一起拿走了。  ","slug":"Hexo：使用dev分支管理站点源文件，多地同步","published":1,"updated":"2019-06-23T07:09:39.725Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74g0005rsvjlpzsuwf4","content":"<h2 id=\"使用dev分支管理站点、源文件，多地同步\"><a href=\"#使用dev分支管理站点、源文件，多地同步\" class=\"headerlink\" title=\"使用dev分支管理站点、源文件，多地同步\"></a>使用dev分支管理站点、源文件，多地同步</h2><p>5点钟被蚊子吵醒了，dong还在睡觉于是跑来310用zb的电脑玩耍，突然想用zb的键盘写博客。  </p>\n<p><a href=\"https://www.jianshu.com/p/4bcf2848b3fc\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4bcf2848b3fc</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure></p>\n<p>hexo的部署命令会自动生成站点文件进行git commit，将修改push到指定的remote branch一般是master中。<br>根据Hexo建站完成部署，其实我们的本地源文件都没有同步在github上。我在我的xxx.github.io仓库中创建了一个dev分支，用于管理源文件。<br>使用vscode注意修改.git文件夹中的config文件就可以了<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[core]</span><br><span class=\"line\">\trepositoryformatversion = 0</span><br><span class=\"line\">\tfilemode = false</span><br><span class=\"line\">\tbare = false</span><br><span class=\"line\">\tlogallrefupdates = true</span><br><span class=\"line\">\tsymlinks = false</span><br><span class=\"line\">\tignorecase = true</span><br><span class=\"line\">[remote &quot;origin&quot;]</span><br><span class=\"line\">\turl = https://github.com/leebinjun/leebinjun.github.io.git</span><br><span class=\"line\">\tfetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class=\"line\">[branch &quot;dev&quot;]</span><br><span class=\"line\">\tremote = origin</span><br><span class=\"line\">\tmerge = refs/heads/dev</span><br></pre></td></tr></table></figure></p>\n<p>来到zb的电脑上，偷偷建一个文件夹<br>clone博客代码到本地，发现是网页那一堆，没有源文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> xxx.git</span><br></pre></td></tr></table></figure></p>\n<p>与远程仓库建立连接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote add origin xxx.git</span><br></pre></td></tr></table></figure></p>\n<p>查看本地是否具有dev分支<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch</span><br></pre></td></tr></table></figure></p>\n<p>没有dev分支,则从远端获取最新到本地，不会自动merge<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git fetch origin dev</span><br></pre></td></tr></table></figure></p>\n<p>在本地创建分支dev并切换到该分支<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure></p>\n<p>拉取dev分支上的内容到本地了<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git pull origin dev</span><br></pre></td></tr></table></figure></p>\n<p>然后就可以愉快地开始写博客了。<br>推送时会有remote: Permission to A denied to B地问题，原因是系统已经记住了zb的密码，每次push操作都会读取zb的信息。查了一下解放方案，决定还是不删他账号也不重新生成密钥了。<br>敲完这些，发现他的电脑还没hexo，于是我把他的键盘和U盘一起拿走了。  </p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"使用dev分支管理站点、源文件，多地同步\"><a href=\"#使用dev分支管理站点、源文件，多地同步\" class=\"headerlink\" title=\"使用dev分支管理站点、源文件，多地同步\"></a>使用dev分支管理站点、源文件，多地同步</h2><p>5点钟被蚊子吵醒了，dong还在睡觉于是跑来310用zb的电脑玩耍，突然想用zb的键盘写博客。  </p>\n<p><a href=\"https://www.jianshu.com/p/4bcf2848b3fc\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/4bcf2848b3fc</a><br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hexo d</span><br></pre></td></tr></table></figure></p>\n<p>hexo的部署命令会自动生成站点文件进行git commit，将修改push到指定的remote branch一般是master中。<br>根据Hexo建站完成部署，其实我们的本地源文件都没有同步在github上。我在我的xxx.github.io仓库中创建了一个dev分支，用于管理源文件。<br>使用vscode注意修改.git文件夹中的config文件就可以了<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[core]</span><br><span class=\"line\">\trepositoryformatversion = 0</span><br><span class=\"line\">\tfilemode = false</span><br><span class=\"line\">\tbare = false</span><br><span class=\"line\">\tlogallrefupdates = true</span><br><span class=\"line\">\tsymlinks = false</span><br><span class=\"line\">\tignorecase = true</span><br><span class=\"line\">[remote &quot;origin&quot;]</span><br><span class=\"line\">\turl = https://github.com/leebinjun/leebinjun.github.io.git</span><br><span class=\"line\">\tfetch = +refs/heads/*:refs/remotes/origin/*</span><br><span class=\"line\">[branch &quot;dev&quot;]</span><br><span class=\"line\">\tremote = origin</span><br><span class=\"line\">\tmerge = refs/heads/dev</span><br></pre></td></tr></table></figure></p>\n<p>来到zb的电脑上，偷偷建一个文件夹<br>clone博客代码到本地，发现是网页那一堆，没有源文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git <span class=\"built_in\">clone</span> xxx.git</span><br></pre></td></tr></table></figure></p>\n<p>与远程仓库建立连接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git remote add origin xxx.git</span><br></pre></td></tr></table></figure></p>\n<p>查看本地是否具有dev分支<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git branch</span><br></pre></td></tr></table></figure></p>\n<p>没有dev分支,则从远端获取最新到本地，不会自动merge<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git fetch origin dev</span><br></pre></td></tr></table></figure></p>\n<p>在本地创建分支dev并切换到该分支<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git checkout -b dev origin/dev</span><br></pre></td></tr></table></figure></p>\n<p>拉取dev分支上的内容到本地了<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git pull origin dev</span><br></pre></td></tr></table></figure></p>\n<p>然后就可以愉快地开始写博客了。<br>推送时会有remote: Permission to A denied to B地问题，原因是系统已经记住了zb的密码，每次push操作都会读取zb的信息。查了一下解放方案，决定还是不删他账号也不重新生成密钥了。<br>敲完这些，发现他的电脑还没hexo，于是我把他的键盘和U盘一起拿走了。  </p>\n"},{"title":"Hikey970使用记录","date":"2019-05-12T03:16:12.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\nHikey970使用记录一：ubuntu16.04下烧写lebian系统  \nHikey970使用记录二：编译安装opencv4.0.0  \nHikey970使用记录三：USB转串口驱动安装  \n<!-- more -->\n<The rest of contents | 余下全文>\n\nHikey970使用记录一：[ubuntu16.04下烧写lebian系统](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%EF%BC%9Aubuntu16-04%E4%B8%8B%E7%83%A7%E5%86%99lebian%E7%B3%BB%E7%BB%9F/)\n\nHikey970使用记录二：[编译安装opencv4.0.0](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%EF%BC%9A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85opencv4-0-0/)  \n\nHikey970使用记录三：[USB转串口驱动安装](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%89%EF%BC%9AUSB%E8%BD%AC%E4%B8%B2%E5%8F%A3%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/)\n\n\nHikey970使用记录四：[python加载运行OpenCL](https://leebinjun.github.io/2019/06/08/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E5%9B%9B%EF%BC%9Apython%E5%8A%A0%E8%BD%BD%E8%BF%90%E8%A1%8COpenCL/)\n\n\n\n## 问题记录 \n### apt-get 安装时出现dpkg: error processing package XXX的问题\n``` bash\n$ sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_backup/\n$ sudo mkdir /var/lib/dpkg/info/\n```\n* Ubuntu在apt-get 安装时出现dpkg: error processing package XXX的问题 - tnaig的博客 - CSDN博客  \nhttps://blog.csdn.net/tnaig/article/details/78497792\n\n\n* Linux应用环境实战13：我该如何备份系统 - ichsonx的专栏 - CSDN博客  \nhttps://blog.csdn.net/ichsonx/article/details/49387855\n\n### hub集线器和MobaXterm终端的冲突\nhikey970的USB口有限，插上hub集线器(鼠标、键盘、摄像头)，终端会掉线。  \n应该是供电问题，hub最好单独供电。\n\n\n## 常用指令 \n\n截图\n``` bash\nsudo apt-get install scrot\nsudo scrot\n```\n\npip指定安装源安装\n``` bash\nsudo pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple XXX\n```\n","source":"_posts/Hikey970使用记录.md","raw":"---\ntitle: Hikey970使用记录\ndate: 2019-05-12 11:16:12\ntags:\n  - Hikey970\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\nHikey970使用记录一：ubuntu16.04下烧写lebian系统  \nHikey970使用记录二：编译安装opencv4.0.0  \nHikey970使用记录三：USB转串口驱动安装  \n<!-- more -->\n<The rest of contents | 余下全文>\n\nHikey970使用记录一：[ubuntu16.04下烧写lebian系统](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%EF%BC%9Aubuntu16-04%E4%B8%8B%E7%83%A7%E5%86%99lebian%E7%B3%BB%E7%BB%9F/)\n\nHikey970使用记录二：[编译安装opencv4.0.0](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%EF%BC%9A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85opencv4-0-0/)  \n\nHikey970使用记录三：[USB转串口驱动安装](https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%89%EF%BC%9AUSB%E8%BD%AC%E4%B8%B2%E5%8F%A3%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/)\n\n\nHikey970使用记录四：[python加载运行OpenCL](https://leebinjun.github.io/2019/06/08/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E5%9B%9B%EF%BC%9Apython%E5%8A%A0%E8%BD%BD%E8%BF%90%E8%A1%8COpenCL/)\n\n\n\n## 问题记录 \n### apt-get 安装时出现dpkg: error processing package XXX的问题\n``` bash\n$ sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_backup/\n$ sudo mkdir /var/lib/dpkg/info/\n```\n* Ubuntu在apt-get 安装时出现dpkg: error processing package XXX的问题 - tnaig的博客 - CSDN博客  \nhttps://blog.csdn.net/tnaig/article/details/78497792\n\n\n* Linux应用环境实战13：我该如何备份系统 - ichsonx的专栏 - CSDN博客  \nhttps://blog.csdn.net/ichsonx/article/details/49387855\n\n### hub集线器和MobaXterm终端的冲突\nhikey970的USB口有限，插上hub集线器(鼠标、键盘、摄像头)，终端会掉线。  \n应该是供电问题，hub最好单独供电。\n\n\n## 常用指令 \n\n截图\n``` bash\nsudo apt-get install scrot\nsudo scrot\n```\n\npip指定安装源安装\n``` bash\nsudo pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple XXX\n```\n","slug":"Hikey970使用记录","published":1,"updated":"2019-06-23T07:09:39.728Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74i0007rsvjtlr9pz42","content":"<p><strong> Hikey970使用记录：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>Hikey970使用记录一：ubuntu16.04下烧写lebian系统<br>Hikey970使用记录二：编译安装opencv4.0.0<br>Hikey970使用记录三：USB转串口驱动安装<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<p>Hikey970使用记录一：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%EF%BC%9Aubuntu16-04%E4%B8%8B%E7%83%A7%E5%86%99lebian%E7%B3%BB%E7%BB%9F/\" target=\"_blank\" rel=\"noopener\">ubuntu16.04下烧写lebian系统</a></p>\n<p>Hikey970使用记录二：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%EF%BC%9A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85opencv4-0-0/\" target=\"_blank\" rel=\"noopener\">编译安装opencv4.0.0</a>  </p>\n<p>Hikey970使用记录三：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%89%EF%BC%9AUSB%E8%BD%AC%E4%B8%B2%E5%8F%A3%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/\" target=\"_blank\" rel=\"noopener\">USB转串口驱动安装</a></p>\n<p>Hikey970使用记录四：<a href=\"https://leebinjun.github.io/2019/06/08/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E5%9B%9B%EF%BC%9Apython%E5%8A%A0%E8%BD%BD%E8%BF%90%E8%A1%8COpenCL/\" target=\"_blank\" rel=\"noopener\">python加载运行OpenCL</a></p>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"apt-get-安装时出现dpkg-error-processing-package-XXX的问题\"><a href=\"#apt-get-安装时出现dpkg-error-processing-package-XXX的问题\" class=\"headerlink\" title=\"apt-get 安装时出现dpkg: error processing package XXX的问题\"></a>apt-get 安装时出现dpkg: error processing package XXX的问题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_backup/</span><br><span class=\"line\">$ sudo mkdir /var/lib/dpkg/info/</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Ubuntu在apt-get 安装时出现dpkg: error processing package XXX的问题 - tnaig的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/tnaig/article/details/78497792\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tnaig/article/details/78497792</a></li>\n</ul>\n<ul>\n<li>Linux应用环境实战13：我该如何备份系统 - ichsonx的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/ichsonx/article/details/49387855\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ichsonx/article/details/49387855</a></li>\n</ul>\n<h3 id=\"hub集线器和MobaXterm终端的冲突\"><a href=\"#hub集线器和MobaXterm终端的冲突\" class=\"headerlink\" title=\"hub集线器和MobaXterm终端的冲突\"></a>hub集线器和MobaXterm终端的冲突</h3><p>hikey970的USB口有限，插上hub集线器(鼠标、键盘、摄像头)，终端会掉线。<br>应该是供电问题，hub最好单独供电。</p>\n<h2 id=\"常用指令\"><a href=\"#常用指令\" class=\"headerlink\" title=\"常用指令\"></a>常用指令</h2><p>截图<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install scrot</span><br><span class=\"line\">sudo scrot</span><br></pre></td></tr></table></figure></p>\n<p>pip指定安装源安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple XXX</span><br></pre></td></tr></table></figure></p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Hikey970使用记录：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>Hikey970使用记录一：ubuntu16.04下烧写lebian系统<br>Hikey970使用记录二：编译安装opencv4.0.0<br>Hikey970使用记录三：USB转串口驱动安装<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<p>Hikey970使用记录一：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%80%EF%BC%9Aubuntu16-04%E4%B8%8B%E7%83%A7%E5%86%99lebian%E7%B3%BB%E7%BB%9F/\" target=\"_blank\" rel=\"noopener\">ubuntu16.04下烧写lebian系统</a></p>\n<p>Hikey970使用记录二：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%BA%8C%EF%BC%9A%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85opencv4-0-0/\" target=\"_blank\" rel=\"noopener\">编译安装opencv4.0.0</a>  </p>\n<p>Hikey970使用记录三：<a href=\"https://leebinjun.github.io/2019/05/22/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E4%B8%89%EF%BC%9AUSB%E8%BD%AC%E4%B8%B2%E5%8F%A3%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85/\" target=\"_blank\" rel=\"noopener\">USB转串口驱动安装</a></p>\n<p>Hikey970使用记录四：<a href=\"https://leebinjun.github.io/2019/06/08/Hikey970%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95%E5%9B%9B%EF%BC%9Apython%E5%8A%A0%E8%BD%BD%E8%BF%90%E8%A1%8COpenCL/\" target=\"_blank\" rel=\"noopener\">python加载运行OpenCL</a></p>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"apt-get-安装时出现dpkg-error-processing-package-XXX的问题\"><a href=\"#apt-get-安装时出现dpkg-error-processing-package-XXX的问题\" class=\"headerlink\" title=\"apt-get 安装时出现dpkg: error processing package XXX的问题\"></a>apt-get 安装时出现dpkg: error processing package XXX的问题</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mv /var/lib/dpkg/info/ /var/lib/dpkg/info_backup/</span><br><span class=\"line\">$ sudo mkdir /var/lib/dpkg/info/</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Ubuntu在apt-get 安装时出现dpkg: error processing package XXX的问题 - tnaig的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/tnaig/article/details/78497792\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/tnaig/article/details/78497792</a></li>\n</ul>\n<ul>\n<li>Linux应用环境实战13：我该如何备份系统 - ichsonx的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/ichsonx/article/details/49387855\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ichsonx/article/details/49387855</a></li>\n</ul>\n<h3 id=\"hub集线器和MobaXterm终端的冲突\"><a href=\"#hub集线器和MobaXterm终端的冲突\" class=\"headerlink\" title=\"hub集线器和MobaXterm终端的冲突\"></a>hub集线器和MobaXterm终端的冲突</h3><p>hikey970的USB口有限，插上hub集线器(鼠标、键盘、摄像头)，终端会掉线。<br>应该是供电问题，hub最好单独供电。</p>\n<h2 id=\"常用指令\"><a href=\"#常用指令\" class=\"headerlink\" title=\"常用指令\"></a>常用指令</h2><p>截图<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install scrot</span><br><span class=\"line\">sudo scrot</span><br></pre></td></tr></table></figure></p>\n<p>pip指定安装源安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo pip3 install -i https://pypi.tuna.tsinghua.edu.cn/simple XXX</span><br></pre></td></tr></table></figure></p>\n</the>"},{"title":"Hikey970使用记录一：ubuntu16.04下烧写lebian系统","date":"2019-05-22T01:53:43.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\nubuntu16.04下烧写lebian系统  \n<!-- more -->\n<The rest of contents | 余下全文>\n\n# ubuntu16.04下烧写lebian系统\n## 准备 \n* hikey970 开发板\n* 开发板电源 12V2A\n* ubuntu16.04 主机\n* type-C 数据线\n\n## 安装\n\n安装安卓fastboot  \n``` bash\n$ sudo apt-get install android-tools-adb\n$ sudo apt-get install android-tools-fastboot\n```\n\n## 下载镜像  \n* LeMaker | The Single Board Computers Community  \n http://www.lemaker.org/product-hikey970-download-86.html\n\n``` bash\n$ cd Workplace/\n$ mkdir hikey970work\n$ cd hikey970work/\n$ wget http://mirror.lemaker.org/hikey970-lebian-9.tar.gz\n$ tar -xzvf hikey970-lebian-9.tar.gz\n$ cd hikey970-lebian-9/\n```\n\n版本的镜像有语法错误，要进行修改一下三个文件\n* flash-all-binaries.sh\n* flash-minimum-binaries.sh\n* /binaries/recovery-flash.sh\n``` bash\n$ cat flash-all-binaries.sh\n    #/bin/bash\n    ...\n$ vim flash-all-binaries.sh\n    #!/bin/bash\n    ...\n```\n\n## 烧写\n先把板子上的开关1-4拨为On Off On Off  \n连接typeC线到板子上(注意是HDMI和USB口中间的那个typec口，而不是debug口)  \n开发板上电\n\n``` bash\n~/Workplace/hikey970work/hikey970-lebian-9$ sudo ./flash-all-binaries.sh\n```\n等待刷机完成(100s)\n\n## 刷入分区补丁\n\n默认的系统分区很小，所以需要打一个补丁\n* 分区补丁下载</br>https://www.bwbot.org/s/GWciA9\n从上面的的下载地址下载补丁，之后解压。 把解压后的内容复制到 hikey970-lebian-9 文件夹内，执行\n\n``` bash\nsudo fastboot flash boot boot-hikey970.uefi.2.img\nsudo fastboot flash userdata hikey970-lebian9-tf.img\n```\n\n## 启动系统\n断开板子的电源，然后把开关拨至on off off off。给板子连接上鼠标键盘网线和显示器。然后给板子上电。 等待系统启动完成。正常情况下应该可以看到登陆界面。用户名和密码都是shunya。\n\n## 调整分区\n\n运行下面的指令调整分区\n\n``` bash\n$ sudo resize2fs /dev/sdd15\n```\n\n这样能够把系统分区扩展到20G，剩下的需要用gparted扩展\n\n``` bash\n$ sudo apt-get install gparted\n$ sudo gparted-pkexec # 注意此指令只能再外接显示器的情况下才能运行\n```\n在GParted工具中，首先选择60G的硬盘，再点击未分配分区上一个分区进行resize，注意增加分区大小或者合并只能是相邻的分区，如果不是连续，发现中间有swap分区可先删除，然后把未分配的空间全部扩展到最后一个分区，最后应用就可以了。\n``` bash\nshunya@hikey970:~$ df -h\n```\n可以看到系统空间已经增大到50G了\n\n## 更换国内源\n修改源文件\n``` bash\n$ sudo vim /etc/apt/sources.list\n\n    # deb http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free\n    # deb http://http.debian.net/debian/ stretch main contrib non-free\n    # deb-src http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse\n    # deb-src http://http.debian.net/debian/ stretch main contrib non-free\n    # deb http://security.debian.org/ stretch/updates main contrib non-free\n    # deb-src http://security.debian.org/ stretch/updates main contrib non-free\n    # deb http://http.debian.net/debian/ stretch-updates main contrib non-free\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security main\n    # deb https://packages.debian.org/zh-tw/jessie/ xenial-security main\n    # deb-src https://packages.debian.org/zh-tw/jessie/ xenial-security main\n    # deb-src http://http.debian.net/debian/ stretch-updates main contrib non-free\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security main\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security universe\n    deb http://ftp.ports.debian.org/debian-ports/ sid main\n    # deb-src http://ftp.ports.debian.org/debian-ports/ sid main\n    deb http://debian.nctu.edu.tw/debian-ports/ sid main\n    # deb-src debian.nctu.edu.tw/debian-ports/ sid main\n    # deb https://packages.debian.org/ stretch main contrib non-free\n```\n更新\n``` bash\n$ sudo apt-get update\n$ sudo apt-get upgrade\n```\n\n## 参考资料\n* 引言 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/en/books-online/hikey970-doc/\n* hikey970学习-005 update image guide 镜像升级指南 - Mingyong_Zhuang的技术博客 - CSDN博客  \nhttps://blog.csdn.net/qqqzmy/article/details/82667142\n* Ubuntu 使用Gparted工具扩大第一分区方法步骤 - zalebool - 博客园  \nhttps://www.cnblogs.com/zalebool/p/5814907.html\n\n\n\n\n","source":"_posts/Hikey970使用记录一：ubuntu16-04下烧写lebian系统.md","raw":"---\ntitle: Hikey970使用记录一：ubuntu16.04下烧写lebian系统\ndate: 2019-05-22 09:53:43\ntags:\n  - Hikey970\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\nubuntu16.04下烧写lebian系统  \n<!-- more -->\n<The rest of contents | 余下全文>\n\n# ubuntu16.04下烧写lebian系统\n## 准备 \n* hikey970 开发板\n* 开发板电源 12V2A\n* ubuntu16.04 主机\n* type-C 数据线\n\n## 安装\n\n安装安卓fastboot  \n``` bash\n$ sudo apt-get install android-tools-adb\n$ sudo apt-get install android-tools-fastboot\n```\n\n## 下载镜像  \n* LeMaker | The Single Board Computers Community  \n http://www.lemaker.org/product-hikey970-download-86.html\n\n``` bash\n$ cd Workplace/\n$ mkdir hikey970work\n$ cd hikey970work/\n$ wget http://mirror.lemaker.org/hikey970-lebian-9.tar.gz\n$ tar -xzvf hikey970-lebian-9.tar.gz\n$ cd hikey970-lebian-9/\n```\n\n版本的镜像有语法错误，要进行修改一下三个文件\n* flash-all-binaries.sh\n* flash-minimum-binaries.sh\n* /binaries/recovery-flash.sh\n``` bash\n$ cat flash-all-binaries.sh\n    #/bin/bash\n    ...\n$ vim flash-all-binaries.sh\n    #!/bin/bash\n    ...\n```\n\n## 烧写\n先把板子上的开关1-4拨为On Off On Off  \n连接typeC线到板子上(注意是HDMI和USB口中间的那个typec口，而不是debug口)  \n开发板上电\n\n``` bash\n~/Workplace/hikey970work/hikey970-lebian-9$ sudo ./flash-all-binaries.sh\n```\n等待刷机完成(100s)\n\n## 刷入分区补丁\n\n默认的系统分区很小，所以需要打一个补丁\n* 分区补丁下载</br>https://www.bwbot.org/s/GWciA9\n从上面的的下载地址下载补丁，之后解压。 把解压后的内容复制到 hikey970-lebian-9 文件夹内，执行\n\n``` bash\nsudo fastboot flash boot boot-hikey970.uefi.2.img\nsudo fastboot flash userdata hikey970-lebian9-tf.img\n```\n\n## 启动系统\n断开板子的电源，然后把开关拨至on off off off。给板子连接上鼠标键盘网线和显示器。然后给板子上电。 等待系统启动完成。正常情况下应该可以看到登陆界面。用户名和密码都是shunya。\n\n## 调整分区\n\n运行下面的指令调整分区\n\n``` bash\n$ sudo resize2fs /dev/sdd15\n```\n\n这样能够把系统分区扩展到20G，剩下的需要用gparted扩展\n\n``` bash\n$ sudo apt-get install gparted\n$ sudo gparted-pkexec # 注意此指令只能再外接显示器的情况下才能运行\n```\n在GParted工具中，首先选择60G的硬盘，再点击未分配分区上一个分区进行resize，注意增加分区大小或者合并只能是相邻的分区，如果不是连续，发现中间有swap分区可先删除，然后把未分配的空间全部扩展到最后一个分区，最后应用就可以了。\n``` bash\nshunya@hikey970:~$ df -h\n```\n可以看到系统空间已经增大到50G了\n\n## 更换国内源\n修改源文件\n``` bash\n$ sudo vim /etc/apt/sources.list\n\n    # deb http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free\n    deb https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free\n    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free\n    # deb http://http.debian.net/debian/ stretch main contrib non-free\n    # deb-src http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse\n    # deb-src http://http.debian.net/debian/ stretch main contrib non-free\n    # deb http://security.debian.org/ stretch/updates main contrib non-free\n    # deb-src http://security.debian.org/ stretch/updates main contrib non-free\n    # deb http://http.debian.net/debian/ stretch-updates main contrib non-free\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security main\n    # deb https://packages.debian.org/zh-tw/jessie/ xenial-security main\n    # deb-src https://packages.debian.org/zh-tw/jessie/ xenial-security main\n    # deb-src http://http.debian.net/debian/ stretch-updates main contrib non-free\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security main\n    # deb-src http://security.ubuntu.com/ubuntu xenial-security universe\n    deb http://ftp.ports.debian.org/debian-ports/ sid main\n    # deb-src http://ftp.ports.debian.org/debian-ports/ sid main\n    deb http://debian.nctu.edu.tw/debian-ports/ sid main\n    # deb-src debian.nctu.edu.tw/debian-ports/ sid main\n    # deb https://packages.debian.org/ stretch main contrib non-free\n```\n更新\n``` bash\n$ sudo apt-get update\n$ sudo apt-get upgrade\n```\n\n## 参考资料\n* 引言 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/en/books-online/hikey970-doc/\n* hikey970学习-005 update image guide 镜像升级指南 - Mingyong_Zhuang的技术博客 - CSDN博客  \nhttps://blog.csdn.net/qqqzmy/article/details/82667142\n* Ubuntu 使用Gparted工具扩大第一分区方法步骤 - zalebool - 博客园  \nhttps://www.cnblogs.com/zalebool/p/5814907.html\n\n\n\n\n","slug":"Hikey970使用记录一：ubuntu16-04下烧写lebian系统","published":1,"updated":"2019-06-23T07:09:39.731Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74j0008rsvjj2ximybt","content":"<p><strong> Hikey970使用记录一：ubuntu16.04下烧写lebian系统：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>ubuntu16.04下烧写lebian系统<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"ubuntu16-04下烧写lebian系统\"><a href=\"#ubuntu16-04下烧写lebian系统\" class=\"headerlink\" title=\"ubuntu16.04下烧写lebian系统\"></a>ubuntu16.04下烧写lebian系统</h1><h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>hikey970 开发板</li>\n<li>开发板电源 12V2A</li>\n<li>ubuntu16.04 主机</li>\n<li>type-C 数据线</li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>安装安卓fastboot<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install android-tools-adb</span><br><span class=\"line\">$ sudo apt-get install android-tools-fastboot</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h2><ul>\n<li>LeMaker | The Single Board Computers Community<br><a href=\"http://www.lemaker.org/product-hikey970-download-86.html\" target=\"_blank\" rel=\"noopener\">http://www.lemaker.org/product-hikey970-download-86.html</a></li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/</span><br><span class=\"line\">$ mkdir hikey970work</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> hikey970work/</span><br><span class=\"line\">$ wget http://mirror.lemaker.org/hikey970-lebian-9.tar.gz</span><br><span class=\"line\">$ tar -xzvf hikey970-lebian-9.tar.gz</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> hikey970-lebian-9/</span><br></pre></td></tr></table></figure>\n<p>版本的镜像有语法错误，要进行修改一下三个文件</p>\n<ul>\n<li>flash-all-binaries.sh</li>\n<li>flash-minimum-binaries.sh</li>\n<li>/binaries/recovery-flash.sh<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat flash-all-binaries.sh</span><br><span class=\"line\">    <span class=\"comment\">#/bin/bash</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">$ vim flash-all-binaries.sh</span><br><span class=\"line\">    <span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"烧写\"><a href=\"#烧写\" class=\"headerlink\" title=\"烧写\"></a>烧写</h2><p>先把板子上的开关1-4拨为On Off On Off<br>连接typeC线到板子上(注意是HDMI和USB口中间的那个typec口，而不是debug口)<br>开发板上电</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/Workplace/hikey970work/hikey970-lebian-9$ sudo ./flash-all-binaries.sh</span><br></pre></td></tr></table></figure>\n<p>等待刷机完成(100s)</p>\n<h2 id=\"刷入分区补丁\"><a href=\"#刷入分区补丁\" class=\"headerlink\" title=\"刷入分区补丁\"></a>刷入分区补丁</h2><p>默认的系统分区很小，所以需要打一个补丁</p>\n<ul>\n<li>分区补丁下载&lt;/br&gt;<a href=\"https://www.bwbot.org/s/GWciA9\" target=\"_blank\" rel=\"noopener\">https://www.bwbot.org/s/GWciA9</a><br>从上面的的下载地址下载补丁，之后解压。 把解压后的内容复制到 hikey970-lebian-9 文件夹内，执行</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo fastboot flash boot boot-hikey970.uefi.2.img</span><br><span class=\"line\">sudo fastboot flash userdata hikey970-lebian9-tf.img</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动系统\"><a href=\"#启动系统\" class=\"headerlink\" title=\"启动系统\"></a>启动系统</h2><p>断开板子的电源，然后把开关拨至on off off off。给板子连接上鼠标键盘网线和显示器。然后给板子上电。 等待系统启动完成。正常情况下应该可以看到登陆界面。用户名和密码都是shunya。</p>\n<h2 id=\"调整分区\"><a href=\"#调整分区\" class=\"headerlink\" title=\"调整分区\"></a>调整分区</h2><p>运行下面的指令调整分区</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo resize2fs /dev/sdd15</span><br></pre></td></tr></table></figure>\n<p>这样能够把系统分区扩展到20G，剩下的需要用gparted扩展</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install gparted</span><br><span class=\"line\">$ sudo gparted-pkexec <span class=\"comment\"># 注意此指令只能再外接显示器的情况下才能运行</span></span><br></pre></td></tr></table></figure>\n<p>在GParted工具中，首先选择60G的硬盘，再点击未分配分区上一个分区进行resize，注意增加分区大小或者合并只能是相邻的分区，如果不是连续，发现中间有swap分区可先删除，然后把未分配的空间全部扩展到最后一个分区，最后应用就可以了。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shunya@hikey970:~$ df -h</span><br></pre></td></tr></table></figure></p>\n<p>可以看到系统空间已经增大到50G了</p>\n<h2 id=\"更换国内源\"><a href=\"#更换国内源\" class=\"headerlink\" title=\"更换国内源\"></a>更换国内源</h2><p>修改源文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># deb http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse</span></span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free</span><br><span class=\"line\">    <span class=\"comment\"># deb http://http.debian.net/debian/ stretch main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://http.debian.net/debian/ stretch main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb http://security.debian.org/ stretch/updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.debian.org/ stretch/updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb http://http.debian.net/debian/ stretch-updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb https://packages.debian.org/zh-tw/jessie/ xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src https://packages.debian.org/zh-tw/jessie/ xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://http.debian.net/debian/ stretch-updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security universe</span></span><br><span class=\"line\">    deb http://ftp.ports.debian.org/debian-ports/ sid main</span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://ftp.ports.debian.org/debian-ports/ sid main</span></span><br><span class=\"line\">    deb http://debian.nctu.edu.tw/debian-ports/ sid main</span><br><span class=\"line\">    <span class=\"comment\"># deb-src debian.nctu.edu.tw/debian-ports/ sid main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb https://packages.debian.org/ stretch main contrib non-free</span></span><br></pre></td></tr></table></figure></p>\n<p>更新<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get upgrade</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>引言 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/en/books-online/hikey970-doc/\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/en/books-online/hikey970-doc/</a></li>\n<li>hikey970学习-005 update image guide 镜像升级指南 - Mingyong_Zhuang的技术博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qqqzmy/article/details/82667142\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qqqzmy/article/details/82667142</a></li>\n<li>Ubuntu 使用Gparted工具扩大第一分区方法步骤 - zalebool - 博客园<br><a href=\"https://www.cnblogs.com/zalebool/p/5814907.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zalebool/p/5814907.html</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Hikey970使用记录一：ubuntu16.04下烧写lebian系统：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>ubuntu16.04下烧写lebian系统<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"ubuntu16-04下烧写lebian系统\"><a href=\"#ubuntu16-04下烧写lebian系统\" class=\"headerlink\" title=\"ubuntu16.04下烧写lebian系统\"></a>ubuntu16.04下烧写lebian系统</h1><h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>hikey970 开发板</li>\n<li>开发板电源 12V2A</li>\n<li>ubuntu16.04 主机</li>\n<li>type-C 数据线</li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><p>安装安卓fastboot<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install android-tools-adb</span><br><span class=\"line\">$ sudo apt-get install android-tools-fastboot</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"下载镜像\"><a href=\"#下载镜像\" class=\"headerlink\" title=\"下载镜像\"></a>下载镜像</h2><ul>\n<li>LeMaker | The Single Board Computers Community<br><a href=\"http://www.lemaker.org/product-hikey970-download-86.html\" target=\"_blank\" rel=\"noopener\">http://www.lemaker.org/product-hikey970-download-86.html</a></li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/</span><br><span class=\"line\">$ mkdir hikey970work</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> hikey970work/</span><br><span class=\"line\">$ wget http://mirror.lemaker.org/hikey970-lebian-9.tar.gz</span><br><span class=\"line\">$ tar -xzvf hikey970-lebian-9.tar.gz</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> hikey970-lebian-9/</span><br></pre></td></tr></table></figure>\n<p>版本的镜像有语法错误，要进行修改一下三个文件</p>\n<ul>\n<li>flash-all-binaries.sh</li>\n<li>flash-minimum-binaries.sh</li>\n<li>/binaries/recovery-flash.sh<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cat flash-all-binaries.sh</span><br><span class=\"line\">    <span class=\"comment\">#/bin/bash</span></span><br><span class=\"line\">    ...</span><br><span class=\"line\">$ vim flash-all-binaries.sh</span><br><span class=\"line\">    <span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">    ...</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"烧写\"><a href=\"#烧写\" class=\"headerlink\" title=\"烧写\"></a>烧写</h2><p>先把板子上的开关1-4拨为On Off On Off<br>连接typeC线到板子上(注意是HDMI和USB口中间的那个typec口，而不是debug口)<br>开发板上电</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">~/Workplace/hikey970work/hikey970-lebian-9$ sudo ./flash-all-binaries.sh</span><br></pre></td></tr></table></figure>\n<p>等待刷机完成(100s)</p>\n<h2 id=\"刷入分区补丁\"><a href=\"#刷入分区补丁\" class=\"headerlink\" title=\"刷入分区补丁\"></a>刷入分区补丁</h2><p>默认的系统分区很小，所以需要打一个补丁</p>\n<ul>\n<li>分区补丁下载&lt;/br&gt;<a href=\"https://www.bwbot.org/s/GWciA9\" target=\"_blank\" rel=\"noopener\">https://www.bwbot.org/s/GWciA9</a><br>从上面的的下载地址下载补丁，之后解压。 把解压后的内容复制到 hikey970-lebian-9 文件夹内，执行</li>\n</ul>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo fastboot flash boot boot-hikey970.uefi.2.img</span><br><span class=\"line\">sudo fastboot flash userdata hikey970-lebian9-tf.img</span><br></pre></td></tr></table></figure>\n<h2 id=\"启动系统\"><a href=\"#启动系统\" class=\"headerlink\" title=\"启动系统\"></a>启动系统</h2><p>断开板子的电源，然后把开关拨至on off off off。给板子连接上鼠标键盘网线和显示器。然后给板子上电。 等待系统启动完成。正常情况下应该可以看到登陆界面。用户名和密码都是shunya。</p>\n<h2 id=\"调整分区\"><a href=\"#调整分区\" class=\"headerlink\" title=\"调整分区\"></a>调整分区</h2><p>运行下面的指令调整分区</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo resize2fs /dev/sdd15</span><br></pre></td></tr></table></figure>\n<p>这样能够把系统分区扩展到20G，剩下的需要用gparted扩展</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install gparted</span><br><span class=\"line\">$ sudo gparted-pkexec <span class=\"comment\"># 注意此指令只能再外接显示器的情况下才能运行</span></span><br></pre></td></tr></table></figure>\n<p>在GParted工具中，首先选择60G的硬盘，再点击未分配分区上一个分区进行resize，注意增加分区大小或者合并只能是相邻的分区，如果不是连续，发现中间有swap分区可先删除，然后把未分配的空间全部扩展到最后一个分区，最后应用就可以了。<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">shunya@hikey970:~$ df -h</span><br></pre></td></tr></table></figure></p>\n<p>可以看到系统空间已经增大到50G了</p>\n<h2 id=\"更换国内源\"><a href=\"#更换国内源\" class=\"headerlink\" title=\"更换国内源\"></a>更换国内源</h2><p>修改源文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/apt/sources.list</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># deb http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse</span></span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-updates main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian/ stretch-backports main contrib non-free</span><br><span class=\"line\">    deb https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free</span><br><span class=\"line\">    deb-src https://mirrors.tuna.tsinghua.edu.cn/debian-security/ stretch/updates main contrib non-free</span><br><span class=\"line\">    <span class=\"comment\"># deb http://http.debian.net/debian/ stretch main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://mirrors.ustc.edu.cn/debian/ xenial main restricted universe multiverse</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://http.debian.net/debian/ stretch main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb http://security.debian.org/ stretch/updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.debian.org/ stretch/updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb http://http.debian.net/debian/ stretch-updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb https://packages.debian.org/zh-tw/jessie/ xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src https://packages.debian.org/zh-tw/jessie/ xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://http.debian.net/debian/ stretch-updates main contrib non-free</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://security.ubuntu.com/ubuntu xenial-security universe</span></span><br><span class=\"line\">    deb http://ftp.ports.debian.org/debian-ports/ sid main</span><br><span class=\"line\">    <span class=\"comment\"># deb-src http://ftp.ports.debian.org/debian-ports/ sid main</span></span><br><span class=\"line\">    deb http://debian.nctu.edu.tw/debian-ports/ sid main</span><br><span class=\"line\">    <span class=\"comment\"># deb-src debian.nctu.edu.tw/debian-ports/ sid main</span></span><br><span class=\"line\">    <span class=\"comment\"># deb https://packages.debian.org/ stretch main contrib non-free</span></span><br></pre></td></tr></table></figure></p>\n<p>更新<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get upgrade</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>引言 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/en/books-online/hikey970-doc/\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/en/books-online/hikey970-doc/</a></li>\n<li>hikey970学习-005 update image guide 镜像升级指南 - Mingyong_Zhuang的技术博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qqqzmy/article/details/82667142\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qqqzmy/article/details/82667142</a></li>\n<li>Ubuntu 使用Gparted工具扩大第一分区方法步骤 - zalebool - 博客园<br><a href=\"https://www.cnblogs.com/zalebool/p/5814907.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zalebool/p/5814907.html</a></li>\n</ul>\n</the>"},{"title":"Hikey970使用记录三：USB转串口驱动安装","date":"2019-05-22T01:54:51.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要> \nhello hikey!  \nUSB转串口驱动安装    \n* 3. usb转串口驱动安装 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n安装USB转串口驱动需要编译对应的驱动程序,方法如下。\n\n## 下载linux内核源码\n``` bash\n$ git clone --single-branch -b hikey970-v4.9 --depth=1 https://github.com/96boards-hikey/linux\n$ cd linux\n$ ls\n$ git checkout hikey970-v4.9\n```\n\n## 配置内核源代码\n获取内核配置文件\n``` bash\ncp /proc/config.gz ~/\ngzip -d ~/config.gz\n```\n进入内核源代码文件夹\n``` bash\ncd ~/linux\n```\n将内核配置文件复制到此处\n``` bash\nmake mrproper\ncp ~/config .config\nsudo chmod 666 .config\n```\n配置内核文件\n``` bash\nsudo apt-get install libncurses5-dev\nsudo apt-get install bc\nmake menuconfig\n```\n内核配置界面如下,Device Drivers-->USB Support --> USB Serial Converter Support 将其设置成M。编译内核module有两种模式，一种是直接编译到内核里面，另一种是编译成独立的.ko文件module。我们采用的是.ko的模式。这样不用重新编译内核更加方便。 继续进入此选项将想要编译的驱动设置成M，如果不清楚自己的型号可以全部设置成M 设置完成后选择保存，之后再退出此界面  \n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\01.png\" witdh=1200 height=600>\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\02.png\" witdh=1200 height=600>\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\03.png\" witdh=1200 height=600>\n\n## 编译驱动module\n``` bash\nmake modules_prepare\nsudo make -j4 modules # 需要执行这个才会生成modules.order,modules.builtin\nsudo make M=drivers/usb/serial\n```\n编译完成之后可以在drivers/usb/serial中看到生成了许多.ko文件,这些就是我们需要的驱动文件。\n\n## 安装驱动module\n创建module文件目录\n``` bash\nsudo mkdir -p /lib/modules/$(uname -r)/kernel/drivers/usb/serial/\nsudo cp drivers/usb/serial/*.ko /lib/modules/$(uname -r)/kernel/drivers/usb/serial/\n```\n复制depmod依赖文件\n``` bash\nsudo cp ~/linux/modules.order /lib/modules/$(uname -r)/\nsudo cp ~/linux/modules.builtin /lib/modules/$(uname -r)/\n```\n生成对应文件\n``` bash\ncd /lib/modules/$(uname -r)\nsudo depmod -a\n```\n加载驱动\n``` bash\nsudo modprobe pl2303\n```\n\n## 测试驱动\n\n查看驱动是否正常加载\n``` bash\n$ lsmod\n```\n可以看到pl2303驱动已经成功加载,这时再插上U转串试一下\n``` bash\n$ ls /dev/tty*\n```\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\04.png\" witdh=1200 height=600>\n  \n## 自动加载驱动\n修改 /etc/modules文件 在其中加入想要加载的内核模块的名称，比如对于我的设备就是pl2303。文件内容如下  \n``` bash\n$ sudo vim /etc/modules\n\n    # /etc/modules: kernel modules to load at boot time.\n    #\n    # This file contains the names of kernel modules that should be loaded\n    # at boot time, one per line. Lines beginning with \"#\" are ignored.\n    pl2303\n```\n保存退出，下次在系统启动时就会自动加载这个驱动了。\n\n\n## 串口测试\n``` bash\n$ pip3 install pyserial\n$ python\n>>> import serial\n```\n\n## 问题记录\n\n### 明明已经安装matplotlib 还是报错ImportError: No module named 'matplotlib'\n``` bash\n$ sudo apt-get install python-matplotlib\n```\n### sudo python 下找不到模块\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\03.png\" witdh=600 height=300>\n在.py文件中添加sys.path\n``` bash\n$ vim serial_test.py\n    import sys\n    sys.path.append(\"/home/shunya/.local/lib/python3.5/site-packages\")\n$ sudo python serial_test.py\n```\n\n\n## 参考资料\n* 3. usb转串口驱动安装 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\n\n","source":"_posts/Hikey970使用记录三：USB转串口驱动安装.md","raw":"---\ntitle: Hikey970使用记录三：USB转串口驱动安装\ndate: 2019-05-22 09:54:51\ntags:\n  - Hikey970\n---\n** {{ title }}：** <Excerpt in index | 首页摘要> \nhello hikey!  \nUSB转串口驱动安装    \n* 3. usb转串口驱动安装 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n安装USB转串口驱动需要编译对应的驱动程序,方法如下。\n\n## 下载linux内核源码\n``` bash\n$ git clone --single-branch -b hikey970-v4.9 --depth=1 https://github.com/96boards-hikey/linux\n$ cd linux\n$ ls\n$ git checkout hikey970-v4.9\n```\n\n## 配置内核源代码\n获取内核配置文件\n``` bash\ncp /proc/config.gz ~/\ngzip -d ~/config.gz\n```\n进入内核源代码文件夹\n``` bash\ncd ~/linux\n```\n将内核配置文件复制到此处\n``` bash\nmake mrproper\ncp ~/config .config\nsudo chmod 666 .config\n```\n配置内核文件\n``` bash\nsudo apt-get install libncurses5-dev\nsudo apt-get install bc\nmake menuconfig\n```\n内核配置界面如下,Device Drivers-->USB Support --> USB Serial Converter Support 将其设置成M。编译内核module有两种模式，一种是直接编译到内核里面，另一种是编译成独立的.ko文件module。我们采用的是.ko的模式。这样不用重新编译内核更加方便。 继续进入此选项将想要编译的驱动设置成M，如果不清楚自己的型号可以全部设置成M 设置完成后选择保存，之后再退出此界面  \n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\01.png\" witdh=1200 height=600>\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\02.png\" witdh=1200 height=600>\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\03.png\" witdh=1200 height=600>\n\n## 编译驱动module\n``` bash\nmake modules_prepare\nsudo make -j4 modules # 需要执行这个才会生成modules.order,modules.builtin\nsudo make M=drivers/usb/serial\n```\n编译完成之后可以在drivers/usb/serial中看到生成了许多.ko文件,这些就是我们需要的驱动文件。\n\n## 安装驱动module\n创建module文件目录\n``` bash\nsudo mkdir -p /lib/modules/$(uname -r)/kernel/drivers/usb/serial/\nsudo cp drivers/usb/serial/*.ko /lib/modules/$(uname -r)/kernel/drivers/usb/serial/\n```\n复制depmod依赖文件\n``` bash\nsudo cp ~/linux/modules.order /lib/modules/$(uname -r)/\nsudo cp ~/linux/modules.builtin /lib/modules/$(uname -r)/\n```\n生成对应文件\n``` bash\ncd /lib/modules/$(uname -r)\nsudo depmod -a\n```\n加载驱动\n``` bash\nsudo modprobe pl2303\n```\n\n## 测试驱动\n\n查看驱动是否正常加载\n``` bash\n$ lsmod\n```\n可以看到pl2303驱动已经成功加载,这时再插上U转串试一下\n``` bash\n$ ls /dev/tty*\n```\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\04.png\" witdh=1200 height=600>\n  \n## 自动加载驱动\n修改 /etc/modules文件 在其中加入想要加载的内核模块的名称，比如对于我的设备就是pl2303。文件内容如下  \n``` bash\n$ sudo vim /etc/modules\n\n    # /etc/modules: kernel modules to load at boot time.\n    #\n    # This file contains the names of kernel modules that should be loaded\n    # at boot time, one per line. Lines beginning with \"#\" are ignored.\n    pl2303\n```\n保存退出，下次在系统启动时就会自动加载这个驱动了。\n\n\n## 串口测试\n``` bash\n$ pip3 install pyserial\n$ python\n>>> import serial\n```\n\n## 问题记录\n\n### 明明已经安装matplotlib 还是报错ImportError: No module named 'matplotlib'\n``` bash\n$ sudo apt-get install python-matplotlib\n```\n### sudo python 下找不到模块\n<img src=\"Hikey970使用记录三：USB转串口驱动安装\\03.png\" witdh=600 height=300>\n在.py文件中添加sys.path\n``` bash\n$ vim serial_test.py\n    import sys\n    sys.path.append(\"/home/shunya/.local/lib/python3.5/site-packages\")\n$ sudo python serial_test.py\n```\n\n\n## 参考资料\n* 3. usb转串口驱动安装 · Hikey 970 开发板使用教程  \nhttps://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\n\n","slug":"Hikey970使用记录三：USB转串口驱动安装","published":1,"updated":"2019-06-23T07:09:39.734Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74k000arsvjpbc80pqr","content":"<p><strong> Hikey970使用记录三：USB转串口驱动安装：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>USB转串口驱动安装    </excerpt></p>\n<ul>\n<li><ol>\n<li>usb转串口驱动安装 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html</a><a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n</the></li>\n</ol>\n</li>\n</ul>\n<p>安装USB转串口驱动需要编译对应的驱动程序,方法如下。</p>\n<h2 id=\"下载linux内核源码\"><a href=\"#下载linux内核源码\" class=\"headerlink\" title=\"下载linux内核源码\"></a>下载linux内核源码</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> --single-branch -b hikey970-v4.9 --depth=1 https://github.com/96boards-hikey/linux</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> linux</span><br><span class=\"line\">$ ls</span><br><span class=\"line\">$ git checkout hikey970-v4.9</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置内核源代码\"><a href=\"#配置内核源代码\" class=\"headerlink\" title=\"配置内核源代码\"></a>配置内核源代码</h2><p>获取内核配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /proc/config.gz ~/</span><br><span class=\"line\">gzip -d ~/config.gz</span><br></pre></td></tr></table></figure></p>\n<p>进入内核源代码文件夹<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> ~/linux</span><br></pre></td></tr></table></figure></p>\n<p>将内核配置文件复制到此处<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make mrproper</span><br><span class=\"line\">cp ~/config .config</span><br><span class=\"line\">sudo chmod 666 .config</span><br></pre></td></tr></table></figure></p>\n<p>配置内核文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install libncurses5-dev</span><br><span class=\"line\">sudo apt-get install bc</span><br><span class=\"line\">make menuconfig</span><br></pre></td></tr></table></figure></p>\n<p>内核配置界面如下,Device Drivers—&gt;USB Support —&gt; USB Serial Converter Support 将其设置成M。编译内核module有两种模式，一种是直接编译到内核里面，另一种是编译成独立的.ko文件module。我们采用的是.ko的模式。这样不用重新编译内核更加方便。 继续进入此选项将想要编译的驱动设置成M，如果不清楚自己的型号可以全部设置成M 设置完成后选择保存，之后再退出此界面<br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/01.png\" witdh=\"1200\" height=\"600\"><br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/02.png\" witdh=\"1200\" height=\"600\"><br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/03.png\" witdh=\"1200\" height=\"600\"></p>\n<h2 id=\"编译驱动module\"><a href=\"#编译驱动module\" class=\"headerlink\" title=\"编译驱动module\"></a>编译驱动module</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make modules_prepare</span><br><span class=\"line\">sudo make -j4 modules <span class=\"comment\"># 需要执行这个才会生成modules.order,modules.builtin</span></span><br><span class=\"line\">sudo make M=drivers/usb/serial</span><br></pre></td></tr></table></figure>\n<p>编译完成之后可以在drivers/usb/serial中看到生成了许多.ko文件,这些就是我们需要的驱动文件。</p>\n<h2 id=\"安装驱动module\"><a href=\"#安装驱动module\" class=\"headerlink\" title=\"安装驱动module\"></a>安装驱动module</h2><p>创建module文件目录<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /lib/modules/$(uname -r)/kernel/drivers/usb/serial/</span><br><span class=\"line\">sudo cp drivers/usb/serial/*.ko /lib/modules/$(uname -r)/kernel/drivers/usb/serial/</span><br></pre></td></tr></table></figure></p>\n<p>复制depmod依赖文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp ~/linux/modules.order /lib/modules/$(uname -r)/</span><br><span class=\"line\">sudo cp ~/linux/modules.builtin /lib/modules/$(uname -r)/</span><br></pre></td></tr></table></figure></p>\n<p>生成对应文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /lib/modules/$(uname -r)</span><br><span class=\"line\">sudo depmod -a</span><br></pre></td></tr></table></figure></p>\n<p>加载驱动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo modprobe pl2303</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试驱动\"><a href=\"#测试驱动\" class=\"headerlink\" title=\"测试驱动\"></a>测试驱动</h2><p>查看驱动是否正常加载<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsmod</span><br></pre></td></tr></table></figure></p>\n<p>可以看到pl2303驱动已经成功加载,这时再插上U转串试一下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /dev/tty*</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/04.png\" witdh=\"1200\" height=\"600\"></p>\n<h2 id=\"自动加载驱动\"><a href=\"#自动加载驱动\" class=\"headerlink\" title=\"自动加载驱动\"></a>自动加载驱动</h2><p>修改 /etc/modules文件 在其中加入想要加载的内核模块的名称，比如对于我的设备就是pl2303。文件内容如下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/modules</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># /etc/modules: kernel modules to load at boot time.</span></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    <span class=\"comment\"># This file contains the names of kernel modules that should be loaded</span></span><br><span class=\"line\">    <span class=\"comment\"># at boot time, one per line. Lines beginning with \"#\" are ignored.</span></span><br><span class=\"line\">    pl2303</span><br></pre></td></tr></table></figure></p>\n<p>保存退出，下次在系统启动时就会自动加载这个驱动了。</p>\n<h2 id=\"串口测试\"><a href=\"#串口测试\" class=\"headerlink\" title=\"串口测试\"></a>串口测试</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install pyserial</span><br><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; import serial</span><br></pre></td></tr></table></figure>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"明明已经安装matplotlib-还是报错ImportError-No-module-named-‘matplotlib’\"><a href=\"#明明已经安装matplotlib-还是报错ImportError-No-module-named-‘matplotlib’\" class=\"headerlink\" title=\"明明已经安装matplotlib 还是报错ImportError: No module named ‘matplotlib’\"></a>明明已经安装matplotlib 还是报错ImportError: No module named ‘matplotlib’</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-matplotlib</span><br></pre></td></tr></table></figure>\n<h3 id=\"sudo-python-下找不到模块\"><a href=\"#sudo-python-下找不到模块\" class=\"headerlink\" title=\"sudo python 下找不到模块\"></a>sudo python 下找不到模块</h3><p><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/03.png\" witdh=\"600\" height=\"300\"><br>在.py文件中添加sys.path<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim serial_test.py</span><br><span class=\"line\">    import sys</span><br><span class=\"line\">    sys.path.append(<span class=\"string\">\"/home/shunya/.local/lib/python3.5/site-packages\"</span>)</span><br><span class=\"line\">$ sudo python serial_test.py</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><ol>\n<li>usb转串口驱动安装 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html</a></li>\n</ol>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p><strong> Hikey970使用记录三：USB转串口驱动安装：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>USB转串口驱动安装    </excerpt></p>\n<ul>\n<li><ol>\n<li>usb转串口驱动安装 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html</a></li></ol></li></ul>","more":"<the rest of contents | 余下全文>\n\n\n</the>\n\n\n\n<p>安装USB转串口驱动需要编译对应的驱动程序,方法如下。</p>\n<h2 id=\"下载linux内核源码\"><a href=\"#下载linux内核源码\" class=\"headerlink\" title=\"下载linux内核源码\"></a>下载linux内核源码</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ git <span class=\"built_in\">clone</span> --single-branch -b hikey970-v4.9 --depth=1 https://github.com/96boards-hikey/linux</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> linux</span><br><span class=\"line\">$ ls</span><br><span class=\"line\">$ git checkout hikey970-v4.9</span><br></pre></td></tr></table></figure>\n<h2 id=\"配置内核源代码\"><a href=\"#配置内核源代码\" class=\"headerlink\" title=\"配置内核源代码\"></a>配置内核源代码</h2><p>获取内核配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cp /proc/config.gz ~/</span><br><span class=\"line\">gzip -d ~/config.gz</span><br></pre></td></tr></table></figure></p>\n<p>进入内核源代码文件夹<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> ~/linux</span><br></pre></td></tr></table></figure></p>\n<p>将内核配置文件复制到此处<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make mrproper</span><br><span class=\"line\">cp ~/config .config</span><br><span class=\"line\">sudo chmod 666 .config</span><br></pre></td></tr></table></figure></p>\n<p>配置内核文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt-get install libncurses5-dev</span><br><span class=\"line\">sudo apt-get install bc</span><br><span class=\"line\">make menuconfig</span><br></pre></td></tr></table></figure></p>\n<p>内核配置界面如下,Device Drivers—&gt;USB Support —&gt; USB Serial Converter Support 将其设置成M。编译内核module有两种模式，一种是直接编译到内核里面，另一种是编译成独立的.ko文件module。我们采用的是.ko的模式。这样不用重新编译内核更加方便。 继续进入此选项将想要编译的驱动设置成M，如果不清楚自己的型号可以全部设置成M 设置完成后选择保存，之后再退出此界面<br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/01.png\" witdh=\"1200\" height=\"600\"><br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/02.png\" witdh=\"1200\" height=\"600\"><br><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/03.png\" witdh=\"1200\" height=\"600\"></p>\n<h2 id=\"编译驱动module\"><a href=\"#编译驱动module\" class=\"headerlink\" title=\"编译驱动module\"></a>编译驱动module</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">make modules_prepare</span><br><span class=\"line\">sudo make -j4 modules <span class=\"comment\"># 需要执行这个才会生成modules.order,modules.builtin</span></span><br><span class=\"line\">sudo make M=drivers/usb/serial</span><br></pre></td></tr></table></figure>\n<p>编译完成之后可以在drivers/usb/serial中看到生成了许多.ko文件,这些就是我们需要的驱动文件。</p>\n<h2 id=\"安装驱动module\"><a href=\"#安装驱动module\" class=\"headerlink\" title=\"安装驱动module\"></a>安装驱动module</h2><p>创建module文件目录<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo mkdir -p /lib/modules/$(uname -r)/kernel/drivers/usb/serial/</span><br><span class=\"line\">sudo cp drivers/usb/serial/*.ko /lib/modules/$(uname -r)/kernel/drivers/usb/serial/</span><br></pre></td></tr></table></figure></p>\n<p>复制depmod依赖文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo cp ~/linux/modules.order /lib/modules/$(uname -r)/</span><br><span class=\"line\">sudo cp ~/linux/modules.builtin /lib/modules/$(uname -r)/</span><br></pre></td></tr></table></figure></p>\n<p>生成对应文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> /lib/modules/$(uname -r)</span><br><span class=\"line\">sudo depmod -a</span><br></pre></td></tr></table></figure></p>\n<p>加载驱动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo modprobe pl2303</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"测试驱动\"><a href=\"#测试驱动\" class=\"headerlink\" title=\"测试驱动\"></a>测试驱动</h2><p>查看驱动是否正常加载<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ lsmod</span><br></pre></td></tr></table></figure></p>\n<p>可以看到pl2303驱动已经成功加载,这时再插上U转串试一下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /dev/tty*</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/04.png\" witdh=\"1200\" height=\"600\"></p>\n<h2 id=\"自动加载驱动\"><a href=\"#自动加载驱动\" class=\"headerlink\" title=\"自动加载驱动\"></a>自动加载驱动</h2><p>修改 /etc/modules文件 在其中加入想要加载的内核模块的名称，比如对于我的设备就是pl2303。文件内容如下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/modules</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># /etc/modules: kernel modules to load at boot time.</span></span><br><span class=\"line\">    <span class=\"comment\">#</span></span><br><span class=\"line\">    <span class=\"comment\"># This file contains the names of kernel modules that should be loaded</span></span><br><span class=\"line\">    <span class=\"comment\"># at boot time, one per line. Lines beginning with \"#\" are ignored.</span></span><br><span class=\"line\">    pl2303</span><br></pre></td></tr></table></figure></p>\n<p>保存退出，下次在系统启动时就会自动加载这个驱动了。</p>\n<h2 id=\"串口测试\"><a href=\"#串口测试\" class=\"headerlink\" title=\"串口测试\"></a>串口测试</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install pyserial</span><br><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; import serial</span><br></pre></td></tr></table></figure>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"明明已经安装matplotlib-还是报错ImportError-No-module-named-‘matplotlib’\"><a href=\"#明明已经安装matplotlib-还是报错ImportError-No-module-named-‘matplotlib’\" class=\"headerlink\" title=\"明明已经安装matplotlib 还是报错ImportError: No module named ‘matplotlib’\"></a>明明已经安装matplotlib 还是报错ImportError: No module named ‘matplotlib’</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-matplotlib</span><br></pre></td></tr></table></figure>\n<h3 id=\"sudo-python-下找不到模块\"><a href=\"#sudo-python-下找不到模块\" class=\"headerlink\" title=\"sudo python 下找不到模块\"></a>sudo python 下找不到模块</h3><p><img src=\"/2019/05/22/Hikey970使用记录三：USB转串口驱动安装/03.png\" witdh=\"600\" height=\"300\"><br>在.py文件中添加sys.path<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ vim serial_test.py</span><br><span class=\"line\">    import sys</span><br><span class=\"line\">    sys.path.append(<span class=\"string\">\"/home/shunya/.local/lib/python3.5/site-packages\"</span>)</span><br><span class=\"line\">$ sudo python serial_test.py</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><ol>\n<li>usb转串口驱动安装 · Hikey 970 开发板使用教程<br><a href=\"https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html\" target=\"_blank\" rel=\"noopener\">https://doc.bwbot.org/zh-cn/books-online/hikey970-doc/topic/485.html</a></li>\n</ol>\n</li>\n</ul>"},{"title":"Jetson Nano 使用记录","date":"2019-05-18T10:00:32.000Z","_content":"\n\n\n\n* balenaEtcher - Home  \nhttps://www.balena.io/etcher/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n* Jetson-Nano开箱配置及Tensorflow安装使用 - dwSun的博客 - CSDN博客 </br>https://blog.csdn.net/dvd_sun/article/details/88975005","source":"_posts/Jetson-Nano-使用记录.md","raw":"---\ntitle: Jetson Nano 使用记录\ndate: 2019-05-18 18:00:32\ntags:\n---\n\n\n\n\n* balenaEtcher - Home  \nhttps://www.balena.io/etcher/\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n* Jetson-Nano开箱配置及Tensorflow安装使用 - dwSun的博客 - CSDN博客 </br>https://blog.csdn.net/dvd_sun/article/details/88975005","slug":"Jetson-Nano-使用记录","published":1,"updated":"2019-06-23T07:09:39.743Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74l000brsvjf6z7jzbt","content":"<ul>\n<li>balenaEtcher - Home<br><a href=\"https://www.balena.io/etcher/\" target=\"_blank\" rel=\"noopener\">https://www.balena.io/etcher/</a></li>\n</ul>\n<ul>\n<li>Jetson-Nano开箱配置及Tensorflow安装使用 - dwSun的博客 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/dvd_sun/article/details/88975005\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dvd_sun/article/details/88975005</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>balenaEtcher - Home<br><a href=\"https://www.balena.io/etcher/\" target=\"_blank\" rel=\"noopener\">https://www.balena.io/etcher/</a></li>\n</ul>\n<ul>\n<li>Jetson-Nano开箱配置及Tensorflow安装使用 - dwSun的博客 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/dvd_sun/article/details/88975005\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dvd_sun/article/details/88975005</a></li>\n</ul>\n"},{"title":"Hikey970使用记录二：编译安装opencv4.0.0","date":"2019-05-22T01:54:03.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\n编译安装opencv4.0.0  \n<!-- more -->\n<The rest of contents | 余下全文>\n\n# 编译安装opencv4.0.0\n## 准备\n\n查看ip\n``` bash\n$ ip addr\n```\n\n调整系统默认python版本\n``` bash\n$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2\n$ update-alternatives --config python\n$ python\n```\n\n电源管理中关屏保  \n更新源\n``` bash\n$ sudo apt-get update\n$ sudo apt-get upgrade\n```\n### 相关依赖\n``` bash\n$ sudo apt-get install build-essential pkg-config\n$ sudo apt-get install cmake\n$ sudo apt-get install libjpeg-dev\n$ sudo apt-get install libtiff5-dev\n$ sudo apt-get install libpng12-dev\n$ sudo apt-get install libpng-dev\n$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\n$ sudo apt-get install libxvidcore-dev libx264-dev\n$ sudo apt-get install libgtk2.0-dev\n$ sudo apt-get install libatlas-base-dev gfortran\n$ sudo apt-get install python3-dev\n```\n\n``` bash\n$ sudo apt-get install libjasper-dev\n```\nlibjasper-dev安装可能会报错，原因是Arm64架构的版本目前还没有被Debian官方收录，可以直接下载deb文件安装，注意相关依赖。\n\n``` bash\n$ sudo apt --fix-broken install\n$ sudo apt-get --purge remove libjpeg62-turbo-dev\n$ wget http://launchpadlibrarian.net/152841589/libjpeg8_8c-2ubuntu8_arm64.deb\n$ sudo dpkg -i libjpeg8_8c-2ubuntu8_arm64.deb\n$ wget http://launchpadlibrarian.net/376191785/libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ sudo dpkg -i libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ wget http://launchpadlibrarian.net/376191781/libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ sudo dpkg -i libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n```\n\n### 下载opencv源码\n``` bash\n$ cd Workplace/opencv/\n$ wget https://github.com/opencv/opencv/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n```\n下载比较慢，建议提前下好后上传\n\n### 设置编译环境\n安装cmake-qt-gui，使用图形界面  \n使用MobaXterm时，CMake界面可以弹出  \n``` bash\n$ mkdir build\n$ cd build/\n$ sudo apt-get install cmake-qt-gui\n$ cmake-gui\n```\n\n选择源文件路径，编译文件夹选择刚才新建的build文件夹\n点击左下角Configure，默认Generator为Unix Makefile，完成后界面变红\n\n然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0/modules的路径填进去，点击左下角Configure，如图\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\01.png\" height=300 width=600 >\n\n开启python接口选项，注意PYTHON3的参数，路径没有问题BUILD_opencv_python3会自动生成。  \n勾选INSTALL_PYTHON_EXMAPLES\n再次点击Configure\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\03.png\" height=300 width=600 >\n\n\n生成编译文件时，face_landmark_model.dat可能下载不了，所以提前将其下载，并放入./cache/data/文件夹下，重命名为7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat\n* face_landmark_model.dat 下载地址  \nhttps://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat\n\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\02.png\" height=150 width=510 >\n\n然后就可以生成编译文件了，点击Generate\n\n### 调整SWAP分区\n\n``` bash\n$ cd /var && ls\n```\n创建一个swap文件,如果已经有swap就卸载它\n``` bash\n$ sudo swapoff swap \n```\n删除swap虚拟内存文件:\n``` bash\n$ rm /var/swap\n```\n使用dd命令创建一个文件，of后面跟你需要创建swap的位置\n``` bash\n$ sudo dd if=/dev/zero of=swap bs=1M count=4096\n```\n格式化为swap文件\n``` bash\n$ sudo mkswap swap \n```\n装载新的swap文件\n``` bash\n$ sudo swapon swap \n$ htop\n```\n可以在htop中看到swap分区大小为4GB，完成  \n注意每次reboot后swap分区不会自动挂载\n\n## 编译\n确定一下swap分区\n``` bash\n$ htop\n```\n\n键入下述命令开始编译\n``` bash\n$ sudo make -j4\n```\n安装\n``` bash\n$ sudo make install \n$ sudo ldconfig\n```\n因编译后的库文件cv2.so生成位置为~/Workplace/opencv/opencv-4.0.0/build /lib/python3/cv2.cpython-35m-aarch64-linux-gnu.so\n，这将导致该模块在Python3中无法import进来，将其拷贝到python3的第三方库文件夹dist-packages下\n``` bash\n$ sudo cp /usr/local/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/local/lib/python3.5/dist-packages\n$ cd /usr/local/lib/python3.5/dist-packages/\n$ ls\n```\n\nImportError: numpy.core.multiarray failed to import  \n出现这个错误的原因是numpy的版本太低了\n``` bash\n$ pip3 install -U numpy\n```\nimport cv2 没有报错，则安装正常\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0/04.png\" height=100 width=600>\n\n\n\n\n\n### 创建虚拟环境\n\n``` bash\n$ pip3 install virtualenv\n$ virtualenv\n-bash: virtualenv: command not found\n$ sudo apt-get install python-virtualenv\n$ virtualenv\n-bash: virtualenv: command not found\n$ sudo find / -name virtualenv\n$ /home/shunya/.local/bin/virtualenv py35 -p /usr/bin/python3\n$ source ~/python-env/py35/bin/activate\n```\n\n\n### 测试_人体姿态点检测\n``` bash\n$ pip3 install scipy\n$ cd Workplace/pose/\n$ python main.py\n```\n\n## 参考资料\n* face_landmark_model.dat 下载地址 - dspeia的博客 - CSDN博客  \nhttps://blog.csdn.net/qq_34806812/article/details/82501999\n* hikey970学习-011 hikey970上安装opencv - Mingyong_Zhuang的技术博客 - CSDN博客  \nhttps://blog.csdn.net/qqqzmy/article/details/82855377\n","source":"_posts/Hikey970使用记录二：编译安装opencv4-0-0.md","raw":"---\ntitle: Hikey970使用记录二：编译安装opencv4.0.0\ndate: 2019-05-22 09:54:03\ntags:\n  - Hikey970\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\nhello hikey!\n编译安装opencv4.0.0  \n<!-- more -->\n<The rest of contents | 余下全文>\n\n# 编译安装opencv4.0.0\n## 准备\n\n查看ip\n``` bash\n$ ip addr\n```\n\n调整系统默认python版本\n``` bash\n$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2\n$ update-alternatives --config python\n$ python\n```\n\n电源管理中关屏保  \n更新源\n``` bash\n$ sudo apt-get update\n$ sudo apt-get upgrade\n```\n### 相关依赖\n``` bash\n$ sudo apt-get install build-essential pkg-config\n$ sudo apt-get install cmake\n$ sudo apt-get install libjpeg-dev\n$ sudo apt-get install libtiff5-dev\n$ sudo apt-get install libpng12-dev\n$ sudo apt-get install libpng-dev\n$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\n$ sudo apt-get install libxvidcore-dev libx264-dev\n$ sudo apt-get install libgtk2.0-dev\n$ sudo apt-get install libatlas-base-dev gfortran\n$ sudo apt-get install python3-dev\n```\n\n``` bash\n$ sudo apt-get install libjasper-dev\n```\nlibjasper-dev安装可能会报错，原因是Arm64架构的版本目前还没有被Debian官方收录，可以直接下载deb文件安装，注意相关依赖。\n\n``` bash\n$ sudo apt --fix-broken install\n$ sudo apt-get --purge remove libjpeg62-turbo-dev\n$ wget http://launchpadlibrarian.net/152841589/libjpeg8_8c-2ubuntu8_arm64.deb\n$ sudo dpkg -i libjpeg8_8c-2ubuntu8_arm64.deb\n$ wget http://launchpadlibrarian.net/376191785/libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ sudo dpkg -i libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ wget http://launchpadlibrarian.net/376191781/libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n$ sudo dpkg -i libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb\n```\n\n### 下载opencv源码\n``` bash\n$ cd Workplace/opencv/\n$ wget https://github.com/opencv/opencv/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n```\n下载比较慢，建议提前下好后上传\n\n### 设置编译环境\n安装cmake-qt-gui，使用图形界面  \n使用MobaXterm时，CMake界面可以弹出  \n``` bash\n$ mkdir build\n$ cd build/\n$ sudo apt-get install cmake-qt-gui\n$ cmake-gui\n```\n\n选择源文件路径，编译文件夹选择刚才新建的build文件夹\n点击左下角Configure，默认Generator为Unix Makefile，完成后界面变红\n\n然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0/modules的路径填进去，点击左下角Configure，如图\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\01.png\" height=300 width=600 >\n\n开启python接口选项，注意PYTHON3的参数，路径没有问题BUILD_opencv_python3会自动生成。  \n勾选INSTALL_PYTHON_EXMAPLES\n再次点击Configure\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\03.png\" height=300 width=600 >\n\n\n生成编译文件时，face_landmark_model.dat可能下载不了，所以提前将其下载，并放入./cache/data/文件夹下，重命名为7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat\n* face_landmark_model.dat 下载地址  \nhttps://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat\n\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0\\02.png\" height=150 width=510 >\n\n然后就可以生成编译文件了，点击Generate\n\n### 调整SWAP分区\n\n``` bash\n$ cd /var && ls\n```\n创建一个swap文件,如果已经有swap就卸载它\n``` bash\n$ sudo swapoff swap \n```\n删除swap虚拟内存文件:\n``` bash\n$ rm /var/swap\n```\n使用dd命令创建一个文件，of后面跟你需要创建swap的位置\n``` bash\n$ sudo dd if=/dev/zero of=swap bs=1M count=4096\n```\n格式化为swap文件\n``` bash\n$ sudo mkswap swap \n```\n装载新的swap文件\n``` bash\n$ sudo swapon swap \n$ htop\n```\n可以在htop中看到swap分区大小为4GB，完成  \n注意每次reboot后swap分区不会自动挂载\n\n## 编译\n确定一下swap分区\n``` bash\n$ htop\n```\n\n键入下述命令开始编译\n``` bash\n$ sudo make -j4\n```\n安装\n``` bash\n$ sudo make install \n$ sudo ldconfig\n```\n因编译后的库文件cv2.so生成位置为~/Workplace/opencv/opencv-4.0.0/build /lib/python3/cv2.cpython-35m-aarch64-linux-gnu.so\n，这将导致该模块在Python3中无法import进来，将其拷贝到python3的第三方库文件夹dist-packages下\n``` bash\n$ sudo cp /usr/local/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/local/lib/python3.5/dist-packages\n$ cd /usr/local/lib/python3.5/dist-packages/\n$ ls\n```\n\nImportError: numpy.core.multiarray failed to import  \n出现这个错误的原因是numpy的版本太低了\n``` bash\n$ pip3 install -U numpy\n```\nimport cv2 没有报错，则安装正常\n<img src=\"Hikey970使用记录二：编译安装opencv4-0-0/04.png\" height=100 width=600>\n\n\n\n\n\n### 创建虚拟环境\n\n``` bash\n$ pip3 install virtualenv\n$ virtualenv\n-bash: virtualenv: command not found\n$ sudo apt-get install python-virtualenv\n$ virtualenv\n-bash: virtualenv: command not found\n$ sudo find / -name virtualenv\n$ /home/shunya/.local/bin/virtualenv py35 -p /usr/bin/python3\n$ source ~/python-env/py35/bin/activate\n```\n\n\n### 测试_人体姿态点检测\n``` bash\n$ pip3 install scipy\n$ cd Workplace/pose/\n$ python main.py\n```\n\n## 参考资料\n* face_landmark_model.dat 下载地址 - dspeia的博客 - CSDN博客  \nhttps://blog.csdn.net/qq_34806812/article/details/82501999\n* hikey970学习-011 hikey970上安装opencv - Mingyong_Zhuang的技术博客 - CSDN博客  \nhttps://blog.csdn.net/qqqzmy/article/details/82855377\n","slug":"Hikey970使用记录二：编译安装opencv4-0-0","published":1,"updated":"2019-06-23T07:09:39.736Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74m000drsvjix8msthk","content":"<p><strong> Hikey970使用记录二：编译安装opencv4.0.0：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>编译安装opencv4.0.0<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"编译安装opencv4-0-0\"><a href=\"#编译安装opencv4-0-0\" class=\"headerlink\" title=\"编译安装opencv4.0.0\"></a>编译安装opencv4.0.0</h1><h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><p>查看ip<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr</span><br></pre></td></tr></table></figure></p>\n<p>调整系统默认python版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1</span><br><span class=\"line\">$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2</span><br><span class=\"line\">$ update-alternatives --config python</span><br><span class=\"line\">$ python</span><br></pre></td></tr></table></figure></p>\n<p>电源管理中关屏保<br>更新源<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get upgrade</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"相关依赖\"><a href=\"#相关依赖\" class=\"headerlink\" title=\"相关依赖\"></a>相关依赖</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install build-essential pkg-config</span><br><span class=\"line\">$ sudo apt-get install cmake</span><br><span class=\"line\">$ sudo apt-get install libjpeg-dev</span><br><span class=\"line\">$ sudo apt-get install libtiff5-dev</span><br><span class=\"line\">$ sudo apt-get install libpng12-dev</span><br><span class=\"line\">$ sudo apt-get install libpng-dev</span><br><span class=\"line\">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</span><br><span class=\"line\">$ sudo apt-get install libxvidcore-dev libx264-dev</span><br><span class=\"line\">$ sudo apt-get install libgtk2.0-dev</span><br><span class=\"line\">$ sudo apt-get install libatlas-base-dev gfortran</span><br><span class=\"line\">$ sudo apt-get install python3-dev</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install libjasper-dev</span><br></pre></td></tr></table></figure>\n<p>libjasper-dev安装可能会报错，原因是Arm64架构的版本目前还没有被Debian官方收录，可以直接下载deb文件安装，注意相关依赖。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt --fix-broken install</span><br><span class=\"line\">$ sudo apt-get --purge remove libjpeg62-turbo-dev</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/152841589/libjpeg8_8c-2ubuntu8_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjpeg8_8c-2ubuntu8_arm64.deb</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/376191785/libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/376191781/libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br></pre></td></tr></table></figure>\n<h3 id=\"下载opencv源码\"><a href=\"#下载opencv源码\" class=\"headerlink\" title=\"下载opencv源码\"></a>下载opencv源码</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/opencv/</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br></pre></td></tr></table></figure>\n<p>下载比较慢，建议提前下好后上传</p>\n<h3 id=\"设置编译环境\"><a href=\"#设置编译环境\" class=\"headerlink\" title=\"设置编译环境\"></a>设置编译环境</h3><p>安装cmake-qt-gui，使用图形界面<br>使用MobaXterm时，CMake界面可以弹出<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir build</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> build/</span><br><span class=\"line\">$ sudo apt-get install cmake-qt-gui</span><br><span class=\"line\">$ cmake-gui</span><br></pre></td></tr></table></figure></p>\n<p>选择源文件路径，编译文件夹选择刚才新建的build文件夹<br>点击左下角Configure，默认Generator为Unix Makefile，完成后界面变红</p>\n<p>然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0/modules的路径填进去，点击左下角Configure，如图<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/01.png\" height=\"300\" width=\"600\"></p>\n<p>开启python接口选项，注意PYTHON3的参数，路径没有问题BUILD_opencv_python3会自动生成。<br>勾选INSTALL_PYTHON_EXMAPLES<br>再次点击Configure<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/03.png\" height=\"300\" width=\"600\"></p>\n<p>生成编译文件时，face_landmark_model.dat可能下载不了，所以提前将其下载，并放入./cache/data/文件夹下，重命名为7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat</p>\n<ul>\n<li>face_landmark_model.dat 下载地址<br><a href=\"https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat</a></li>\n</ul>\n<p><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/02.png\" height=\"150\" width=\"510\"></p>\n<p>然后就可以生成编译文件了，点击Generate</p>\n<h3 id=\"调整SWAP分区\"><a href=\"#调整SWAP分区\" class=\"headerlink\" title=\"调整SWAP分区\"></a>调整SWAP分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var &amp;&amp; ls</span><br></pre></td></tr></table></figure>\n<p>创建一个swap文件,如果已经有swap就卸载它<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapoff swap</span><br></pre></td></tr></table></figure></p>\n<p>删除swap虚拟内存文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm /var/swap</span><br></pre></td></tr></table></figure></p>\n<p>使用dd命令创建一个文件，of后面跟你需要创建swap的位置<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo dd <span class=\"keyword\">if</span>=/dev/zero of=swap bs=1M count=4096</span><br></pre></td></tr></table></figure></p>\n<p>格式化为swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkswap swap</span><br></pre></td></tr></table></figure></p>\n<p>装载新的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapon swap </span><br><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>可以在htop中看到swap分区大小为4GB，完成<br>注意每次reboot后swap分区不会自动挂载</p>\n<h2 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h2><p>确定一下swap分区<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>键入下述命令开始编译<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make -j4</span><br></pre></td></tr></table></figure></p>\n<p>安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make install </span><br><span class=\"line\">$ sudo ldconfig</span><br></pre></td></tr></table></figure></p>\n<p>因编译后的库文件cv2.so生成位置为~/Workplace/opencv/opencv-4.0.0/build /lib/python3/cv2.cpython-35m-aarch64-linux-gnu.so<br>，这将导致该模块在Python3中无法import进来，将其拷贝到python3的第三方库文件夹dist-packages下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cp /usr/<span class=\"built_in\">local</span>/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/</span><br><span class=\"line\">$ ls</span><br></pre></td></tr></table></figure></p>\n<p>ImportError: numpy.core.multiarray failed to import<br>出现这个错误的原因是numpy的版本太低了<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install -U numpy</span><br></pre></td></tr></table></figure></p>\n<p>import cv2 没有报错，则安装正常<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/04.png\" height=\"100\" width=\"600\"></p>\n<h3 id=\"创建虚拟环境\"><a href=\"#创建虚拟环境\" class=\"headerlink\" title=\"创建虚拟环境\"></a>创建虚拟环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install virtualenv</span><br><span class=\"line\">$ virtualenv</span><br><span class=\"line\">-bash: virtualenv: <span class=\"built_in\">command</span> not found</span><br><span class=\"line\">$ sudo apt-get install python-virtualenv</span><br><span class=\"line\">$ virtualenv</span><br><span class=\"line\">-bash: virtualenv: <span class=\"built_in\">command</span> not found</span><br><span class=\"line\">$ sudo find / -name virtualenv</span><br><span class=\"line\">$ /home/shunya/.<span class=\"built_in\">local</span>/bin/virtualenv py35 -p /usr/bin/python3</span><br><span class=\"line\">$ <span class=\"built_in\">source</span> ~/python-env/py35/bin/activate</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试-人体姿态点检测\"><a href=\"#测试-人体姿态点检测\" class=\"headerlink\" title=\"测试_人体姿态点检测\"></a>测试_人体姿态点检测</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install scipy</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/pose/</span><br><span class=\"line\">$ python main.py</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>face_landmark_model.dat 下载地址 - dspeia的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_34806812/article/details/82501999\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_34806812/article/details/82501999</a></li>\n<li>hikey970学习-011 hikey970上安装opencv - Mingyong_Zhuang的技术博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qqqzmy/article/details/82855377\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qqqzmy/article/details/82855377</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Hikey970使用记录二：编译安装opencv4.0.0：</strong> <excerpt in index | 首页摘要><br>hello hikey!<br>编译安装opencv4.0.0<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"编译安装opencv4-0-0\"><a href=\"#编译安装opencv4-0-0\" class=\"headerlink\" title=\"编译安装opencv4.0.0\"></a>编译安装opencv4.0.0</h1><h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><p>查看ip<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ip addr</span><br></pre></td></tr></table></figure></p>\n<p>调整系统默认python版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1</span><br><span class=\"line\">$ sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2</span><br><span class=\"line\">$ update-alternatives --config python</span><br><span class=\"line\">$ python</span><br></pre></td></tr></table></figure></p>\n<p>电源管理中关屏保<br>更新源<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt-get upgrade</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"相关依赖\"><a href=\"#相关依赖\" class=\"headerlink\" title=\"相关依赖\"></a>相关依赖</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install build-essential pkg-config</span><br><span class=\"line\">$ sudo apt-get install cmake</span><br><span class=\"line\">$ sudo apt-get install libjpeg-dev</span><br><span class=\"line\">$ sudo apt-get install libtiff5-dev</span><br><span class=\"line\">$ sudo apt-get install libpng12-dev</span><br><span class=\"line\">$ sudo apt-get install libpng-dev</span><br><span class=\"line\">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</span><br><span class=\"line\">$ sudo apt-get install libxvidcore-dev libx264-dev</span><br><span class=\"line\">$ sudo apt-get install libgtk2.0-dev</span><br><span class=\"line\">$ sudo apt-get install libatlas-base-dev gfortran</span><br><span class=\"line\">$ sudo apt-get install python3-dev</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install libjasper-dev</span><br></pre></td></tr></table></figure>\n<p>libjasper-dev安装可能会报错，原因是Arm64架构的版本目前还没有被Debian官方收录，可以直接下载deb文件安装，注意相关依赖。</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt --fix-broken install</span><br><span class=\"line\">$ sudo apt-get --purge remove libjpeg62-turbo-dev</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/152841589/libjpeg8_8c-2ubuntu8_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjpeg8_8c-2ubuntu8_arm64.deb</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/376191785/libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjasper1_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ wget http://launchpadlibrarian.net/376191781/libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br><span class=\"line\">$ sudo dpkg -i libjasper-dev_1.900.1-debian1-2.4ubuntu1.2_arm64.deb</span><br></pre></td></tr></table></figure>\n<h3 id=\"下载opencv源码\"><a href=\"#下载opencv源码\" class=\"headerlink\" title=\"下载opencv源码\"></a>下载opencv源码</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/opencv/</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br></pre></td></tr></table></figure>\n<p>下载比较慢，建议提前下好后上传</p>\n<h3 id=\"设置编译环境\"><a href=\"#设置编译环境\" class=\"headerlink\" title=\"设置编译环境\"></a>设置编译环境</h3><p>安装cmake-qt-gui，使用图形界面<br>使用MobaXterm时，CMake界面可以弹出<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mkdir build</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> build/</span><br><span class=\"line\">$ sudo apt-get install cmake-qt-gui</span><br><span class=\"line\">$ cmake-gui</span><br></pre></td></tr></table></figure></p>\n<p>选择源文件路径，编译文件夹选择刚才新建的build文件夹<br>点击左下角Configure，默认Generator为Unix Makefile，完成后界面变红</p>\n<p>然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0/modules的路径填进去，点击左下角Configure，如图<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/01.png\" height=\"300\" width=\"600\"></p>\n<p>开启python接口选项，注意PYTHON3的参数，路径没有问题BUILD_opencv_python3会自动生成。<br>勾选INSTALL_PYTHON_EXMAPLES<br>再次点击Configure<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/03.png\" height=\"300\" width=\"600\"></p>\n<p>生成编译文件时，face_landmark_model.dat可能下载不了，所以提前将其下载，并放入./cache/data/文件夹下，重命名为7505c44ca4eb54b4ab1e4777cb96ac05-face_landmark_model.dat</p>\n<ul>\n<li>face_landmark_model.dat 下载地址<br><a href=\"https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat\" target=\"_blank\" rel=\"noopener\">https://raw.githubusercontent.com/opencv/opencv_3rdparty/8afa57abc8229d611c4937165d20e2a2d9fc5a12/face_landmark_model.dat</a></li>\n</ul>\n<p><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/02.png\" height=\"150\" width=\"510\"></p>\n<p>然后就可以生成编译文件了，点击Generate</p>\n<h3 id=\"调整SWAP分区\"><a href=\"#调整SWAP分区\" class=\"headerlink\" title=\"调整SWAP分区\"></a>调整SWAP分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var &amp;&amp; ls</span><br></pre></td></tr></table></figure>\n<p>创建一个swap文件,如果已经有swap就卸载它<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapoff swap</span><br></pre></td></tr></table></figure></p>\n<p>删除swap虚拟内存文件:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ rm /var/swap</span><br></pre></td></tr></table></figure></p>\n<p>使用dd命令创建一个文件，of后面跟你需要创建swap的位置<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo dd <span class=\"keyword\">if</span>=/dev/zero of=swap bs=1M count=4096</span><br></pre></td></tr></table></figure></p>\n<p>格式化为swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkswap swap</span><br></pre></td></tr></table></figure></p>\n<p>装载新的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapon swap </span><br><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>可以在htop中看到swap分区大小为4GB，完成<br>注意每次reboot后swap分区不会自动挂载</p>\n<h2 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h2><p>确定一下swap分区<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>键入下述命令开始编译<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make -j4</span><br></pre></td></tr></table></figure></p>\n<p>安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make install </span><br><span class=\"line\">$ sudo ldconfig</span><br></pre></td></tr></table></figure></p>\n<p>因编译后的库文件cv2.so生成位置为~/Workplace/opencv/opencv-4.0.0/build /lib/python3/cv2.cpython-35m-aarch64-linux-gnu.so<br>，这将导致该模块在Python3中无法import进来，将其拷贝到python3的第三方库文件夹dist-packages下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cp /usr/<span class=\"built_in\">local</span>/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/</span><br><span class=\"line\">$ ls</span><br></pre></td></tr></table></figure></p>\n<p>ImportError: numpy.core.multiarray failed to import<br>出现这个错误的原因是numpy的版本太低了<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install -U numpy</span><br></pre></td></tr></table></figure></p>\n<p>import cv2 没有报错，则安装正常<br><img src=\"/2019/05/22/Hikey970使用记录二：编译安装opencv4-0-0/04.png\" height=\"100\" width=\"600\"></p>\n<h3 id=\"创建虚拟环境\"><a href=\"#创建虚拟环境\" class=\"headerlink\" title=\"创建虚拟环境\"></a>创建虚拟环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install virtualenv</span><br><span class=\"line\">$ virtualenv</span><br><span class=\"line\">-bash: virtualenv: <span class=\"built_in\">command</span> not found</span><br><span class=\"line\">$ sudo apt-get install python-virtualenv</span><br><span class=\"line\">$ virtualenv</span><br><span class=\"line\">-bash: virtualenv: <span class=\"built_in\">command</span> not found</span><br><span class=\"line\">$ sudo find / -name virtualenv</span><br><span class=\"line\">$ /home/shunya/.<span class=\"built_in\">local</span>/bin/virtualenv py35 -p /usr/bin/python3</span><br><span class=\"line\">$ <span class=\"built_in\">source</span> ~/python-env/py35/bin/activate</span><br></pre></td></tr></table></figure>\n<h3 id=\"测试-人体姿态点检测\"><a href=\"#测试-人体姿态点检测\" class=\"headerlink\" title=\"测试_人体姿态点检测\"></a>测试_人体姿态点检测</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install scipy</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> Workplace/pose/</span><br><span class=\"line\">$ python main.py</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>face_landmark_model.dat 下载地址 - dspeia的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_34806812/article/details/82501999\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_34806812/article/details/82501999</a></li>\n<li>hikey970学习-011 hikey970上安装opencv - Mingyong_Zhuang的技术博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qqqzmy/article/details/82855377\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qqqzmy/article/details/82855377</a></li>\n</ul>\n</the>"},{"title":"OpenCV学习笔记","date":"2019-06-14T10:01:28.000Z","_content":"\n\n\n\n\n","source":"_posts/OpenCV学习笔记.md","raw":"---\ntitle: 'OpenCV学习笔记'\ndate: 2019-06-14 18:01:28\ntags:\n  - opencv\n---\n\n\n\n\n\n","slug":"OpenCV学习笔记","published":1,"updated":"2019-06-22T13:59:05.628Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74n000frsvjxb3i5hdb","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Hikey970使用记录四：python加载运行OpenCL","date":"2019-06-08T02:39:59.000Z","_content":"\n## 参考资料\n\n\n* Python 并行计算 - SoftStar的专栏 - CSDN博客  \nhttps://blog.csdn.net/u011532367/article/details/51008993\n\n\n## 安装\n``` bash\n$ sudo apt-get install opencl-dev\n$ pip3 install pybind11\n$ pip3 install pyopencl\n$ sudo apt-get install clinfo\n$ sudo clinfo\n```\n测试结果\n<img src=\"Hikey970使用记录四：python加载运行OpenCL\\001.png\" witdh=400 height=200>\n\n\n## 问题记录\nimport pyopencl as cl  \nImportError: No module named 'numpy.core._multiarray_umath'\nterminate called after throwing an instance of 'std::runtime_error'\n  what():  numpy failed to initialize\nAborted\n\n查看numpy的当前版本\n``` bash\npip show numpy\n```\n更新numpy的版本\n``` bash\npip  install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade numpy\n```\n\n## 参考资料\n* python - TensorFlow GPU比CPU更慢 - SegmentFault 思否  \nhttps://segmentfault.com/q/1010000012693363\n* https://discuss.96boards.org/search?q=opencl\n* https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu\n","source":"_posts/Hikey970使用记录四：python加载运行OpenCL.md","raw":"---\ntitle: Hikey970使用记录四：python加载运行OpenCL\ndate: 2019-06-08 10:39:59\ntags:\n  - pyopencl\n---\n\n## 参考资料\n\n\n* Python 并行计算 - SoftStar的专栏 - CSDN博客  \nhttps://blog.csdn.net/u011532367/article/details/51008993\n\n\n## 安装\n``` bash\n$ sudo apt-get install opencl-dev\n$ pip3 install pybind11\n$ pip3 install pyopencl\n$ sudo apt-get install clinfo\n$ sudo clinfo\n```\n测试结果\n<img src=\"Hikey970使用记录四：python加载运行OpenCL\\001.png\" witdh=400 height=200>\n\n\n## 问题记录\nimport pyopencl as cl  \nImportError: No module named 'numpy.core._multiarray_umath'\nterminate called after throwing an instance of 'std::runtime_error'\n  what():  numpy failed to initialize\nAborted\n\n查看numpy的当前版本\n``` bash\npip show numpy\n```\n更新numpy的版本\n``` bash\npip  install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade numpy\n```\n\n## 参考资料\n* python - TensorFlow GPU比CPU更慢 - SegmentFault 思否  \nhttps://segmentfault.com/q/1010000012693363\n* https://discuss.96boards.org/search?q=opencl\n* https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu\n","slug":"Hikey970使用记录四：python加载运行OpenCL","published":1,"updated":"2019-06-23T07:09:39.740Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74o000irsvj1q2v70ly","content":"<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Python 并行计算 - SoftStar的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/u011532367/article/details/51008993\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011532367/article/details/51008993</a></li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install opencl-dev</span><br><span class=\"line\">$ pip3 install pybind11</span><br><span class=\"line\">$ pip3 install pyopencl</span><br><span class=\"line\">$ sudo apt-get install clinfo</span><br><span class=\"line\">$ sudo clinfo</span><br></pre></td></tr></table></figure>\n<p>测试结果<br><img src=\"/2019/06/08/Hikey970使用记录四：python加载运行OpenCL/001.png\" witdh=\"400\" height=\"200\"></p>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><p>import pyopencl as cl<br>ImportError: No module named ‘numpy.core._multiarray_umath’<br>terminate called after throwing an instance of ‘std::runtime_error’<br>  what():  numpy failed to initialize<br>Aborted</p>\n<p>查看numpy的当前版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip show numpy</span><br></pre></td></tr></table></figure></p>\n<p>更新numpy的版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip  install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade numpy</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料-1\"><a href=\"#参考资料-1\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>python - TensorFlow GPU比CPU更慢 - SegmentFault 思否<br><a href=\"https://segmentfault.com/q/1010000012693363\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/q/1010000012693363</a></li>\n<li><a href=\"https://discuss.96boards.org/search?q=opencl\" target=\"_blank\" rel=\"noopener\">https://discuss.96boards.org/search?q=opencl</a></li>\n<li><a href=\"https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu\" target=\"_blank\" rel=\"noopener\">https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>Python 并行计算 - SoftStar的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/u011532367/article/details/51008993\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u011532367/article/details/51008993</a></li>\n</ul>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install opencl-dev</span><br><span class=\"line\">$ pip3 install pybind11</span><br><span class=\"line\">$ pip3 install pyopencl</span><br><span class=\"line\">$ sudo apt-get install clinfo</span><br><span class=\"line\">$ sudo clinfo</span><br></pre></td></tr></table></figure>\n<p>测试结果<br><img src=\"/2019/06/08/Hikey970使用记录四：python加载运行OpenCL/001.png\" witdh=\"400\" height=\"200\"></p>\n<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><p>import pyopencl as cl<br>ImportError: No module named ‘numpy.core._multiarray_umath’<br>terminate called after throwing an instance of ‘std::runtime_error’<br>  what():  numpy failed to initialize<br>Aborted</p>\n<p>查看numpy的当前版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip show numpy</span><br></pre></td></tr></table></figure></p>\n<p>更新numpy的版本<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip  install -i https://pypi.tuna.tsinghua.edu.cn/simple --upgrade numpy</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料-1\"><a href=\"#参考资料-1\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>python - TensorFlow GPU比CPU更慢 - SegmentFault 思否<br><a href=\"https://segmentfault.com/q/1010000012693363\" target=\"_blank\" rel=\"noopener\">https://segmentfault.com/q/1010000012693363</a></li>\n<li><a href=\"https://discuss.96boards.org/search?q=opencl\" target=\"_blank\" rel=\"noopener\">https://discuss.96boards.org/search?q=opencl</a></li>\n<li><a href=\"https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu\" target=\"_blank\" rel=\"noopener\">https://community.arm.com/cn/f/discussions/13001/hikey960-arm-gpu</a></li>\n</ul>\n"},{"title":"Pixar Lamp","date":"2019-05-14T11:25:43.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n做个跳跳灯！\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# 设计思路\n\n### 2018年3月\n<div align=center>\n<img src = \"Pixar-Lamp\\设计思路.png\" width=1000 height=800>\n</div>\n\n### 2019年5月\n<div align=center>\n<img src = \"Pixar-Lamp\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n# 准备\n\n``` bash\n> conda create -n lamp python=3.6\n> activate lamp\n> pip install numpy\n> pip install pandas\n> pip install scipy\n> pip install tensorflow\n> pip install baidu-aip\n> pip install pyserial\n> pip install opencv-python\n> pip install opencv-contrib-python\n```\n\n\n调用华为api\n* huaweicloud/huaweicloud-sdk-python-frs https://github.com/huaweicloud/huaweicloud-sdk-python-frs\n\n姿态点检测\n<div align=center>\n<img src = \"Pixar-Lamp\\001.jpg\" width=200 height=200>\n</div>\n\n* Ilovepose </br>http://ilovepose.luohuank.xin/\n* 如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎 </br>https://www.zhihu.com/question/59750782\n* 基于OpenPose的人体姿态检测 - yph001的博客 - CSDN博客 </br>https://blog.csdn.net/yph001/article/details/83218839\n\n\n\n\n\n\n## 单人姿态估计\n\n### 综述\n* 【极市】张锋-2D单人人体姿态估计及其应用_腾讯视频 </br>https://v.qq.com/x/page/w0543yfwrhq.html\n* PowerPoint Template</br> http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf\n* MPII Human Pose Database </br> http://human-pose.mpi-inf.mpg.de/#results\n\n应用\n* 人机交互\n* 行人再识别 person re-id\n* 行为识别\n\n问题\n* 遮挡\n* 复杂背景\n* 光照\n* 复杂姿态\n* 多尺度\n* 拍摄角度\n\n### 方法\n\n* 多尺度、多分辨率\n* 基于Residual Block\n* 扩大感受野\n* 预处理\n* 后处理\n\n传统方法\n* 基于图结构(Pictorial Structures)\n* DPM(形变部件模型)目标价侧算法  \nDPM算法采用了改进后的HOG特征，SVM分类器和滑动窗口（Sliding Windows）检测思想，针对目标的多视角问题，采用了多组件（Component）的策略，针对目标本身的形变问题，采用了基于图结构（Pictorial Structure）的部件模型策略。此外，将样本的所属的模型类别，部件模型的位置等作为潜变量（Latent Variable），采用多示例学习（Multiple-instance Learning）来自动确定。\n\n基于深度学习的方法\n* 直接回归坐标 \n  * CNN多阶段 \n\n* 通过热力图回归坐标\n  * CNN+图模型\n\n#### Deep Pose\n* CNN分类效果好，能不能直接用CNN回归关节坐标\n* 2014， Szegedy\n* AlesNet\n\n#### 迭代误差反馈模型\n* 让网络学习到一个多阶段反馈的模型\n* 2016\n\n#### 双源CNN\n* 给网络添加先验知识\n* Fuan xiaochuan\n* 2015\n\n\n#### CNN\n* 由于人的尺度是不一样的，能不能让网络客服这一问题，并学习到关节与关节之间的关系(pair wise relation)？\n* Yann lecun\n* 2014\n* CNN+图模型\n\n#### DCNN\n* CNN+树状结构图模型\n* 2016\n* Wang xiaogang\n\n#### CPM\n* 卷积姿态机 + 大卷积核提升感受野 + 多阶段回归\n* 2016\n\n#### hourglass\n* 堆叠的沙漏模型 + 极大提升感受野 + 多阶段回归\n* 2016\n\n#### \n* 图模型太慢，直接使用卷积核来实现\n* 树状结构的特征学习\n* 2016\n\n\n### Efficient Concolutional Network\n* 关注efficience\n* 2016\n\n \n\n\n\n\n\n\n## 参考博客\n- 如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎   \nhttps://www.zhihu.com/question/59750782\n- CMU-Perceptual-Computing-Lab/openpose: OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation   \nhttps://github.com/CMU-Perceptual-Computing-Lab/openpose\n- 人体姿态估计数据集整理（Pose Estimation/Keypoint） - 上善若水 - CSDN博客   \nhttps://blog.csdn.net/guo1988kui/article/details/84321581\n- openpose实时多人2D姿态估计 - weixin_41441682的博客 - CSDN博客   \nhttps://blog.csdn.net/weixin_41441682/article/details/81357369#\n- 人体姿态估计资源大列表（Human Pose Estimation） - xiaolouhan的博客 - CSDN博客   \nhttps://blog.csdn.net/xiaolouhan/article/details/84321148\n- 新人求教如何从头学习人体姿态估计 - Ilovepose http://ilovepose.luohuank.xin/t/66\n论文解析与翻译：《Stacked Hourglass Networks for Human Pose Estimation》 - qq_38522972的博客 - CSDN博客  \nhttps://blog.csdn.net/qq_38522972/article/details/82958077\n- 人体姿态估计资源大列表（Human Pose Estimation） - weixin_38367817的博客 - CSDN博客  \nhttps://blog.csdn.net/weixin_38367817/article/details/86522569\n- 人体姿态估计综述（Human Pose Estimation Overview） - 青青韶华 - CSDN博客   \nhttps://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&fps=1\n- 人体姿态估计（人体关键点检测）分类与经典方法分析（附GitHub地址） - ls83776736的博客 - CSDN博客  \nhttps://blog.csdn.net/ls83776736/article/details/87991515\nMPII Human Pose Database http://human-pose.mpi-inf.mpg.de/#results\n\n\n\n\n* #3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube</br>https://www.youtube.com/watch?v=T5QlePZ4s3U&list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&index=3","source":"_posts/Pixar-Lamp.md","raw":"---\ntitle: Pixar Lamp\ndate: 2019-05-14 19:25:43\ntags:\n  - python\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n做个跳跳灯！\n<!-- more -->\n<The rest of contents | 余下全文>\n\n# 设计思路\n\n### 2018年3月\n<div align=center>\n<img src = \"Pixar-Lamp\\设计思路.png\" width=1000 height=800>\n</div>\n\n### 2019年5月\n<div align=center>\n<img src = \"Pixar-Lamp\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n# 准备\n\n``` bash\n> conda create -n lamp python=3.6\n> activate lamp\n> pip install numpy\n> pip install pandas\n> pip install scipy\n> pip install tensorflow\n> pip install baidu-aip\n> pip install pyserial\n> pip install opencv-python\n> pip install opencv-contrib-python\n```\n\n\n调用华为api\n* huaweicloud/huaweicloud-sdk-python-frs https://github.com/huaweicloud/huaweicloud-sdk-python-frs\n\n姿态点检测\n<div align=center>\n<img src = \"Pixar-Lamp\\001.jpg\" width=200 height=200>\n</div>\n\n* Ilovepose </br>http://ilovepose.luohuank.xin/\n* 如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎 </br>https://www.zhihu.com/question/59750782\n* 基于OpenPose的人体姿态检测 - yph001的博客 - CSDN博客 </br>https://blog.csdn.net/yph001/article/details/83218839\n\n\n\n\n\n\n## 单人姿态估计\n\n### 综述\n* 【极市】张锋-2D单人人体姿态估计及其应用_腾讯视频 </br>https://v.qq.com/x/page/w0543yfwrhq.html\n* PowerPoint Template</br> http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf\n* MPII Human Pose Database </br> http://human-pose.mpi-inf.mpg.de/#results\n\n应用\n* 人机交互\n* 行人再识别 person re-id\n* 行为识别\n\n问题\n* 遮挡\n* 复杂背景\n* 光照\n* 复杂姿态\n* 多尺度\n* 拍摄角度\n\n### 方法\n\n* 多尺度、多分辨率\n* 基于Residual Block\n* 扩大感受野\n* 预处理\n* 后处理\n\n传统方法\n* 基于图结构(Pictorial Structures)\n* DPM(形变部件模型)目标价侧算法  \nDPM算法采用了改进后的HOG特征，SVM分类器和滑动窗口（Sliding Windows）检测思想，针对目标的多视角问题，采用了多组件（Component）的策略，针对目标本身的形变问题，采用了基于图结构（Pictorial Structure）的部件模型策略。此外，将样本的所属的模型类别，部件模型的位置等作为潜变量（Latent Variable），采用多示例学习（Multiple-instance Learning）来自动确定。\n\n基于深度学习的方法\n* 直接回归坐标 \n  * CNN多阶段 \n\n* 通过热力图回归坐标\n  * CNN+图模型\n\n#### Deep Pose\n* CNN分类效果好，能不能直接用CNN回归关节坐标\n* 2014， Szegedy\n* AlesNet\n\n#### 迭代误差反馈模型\n* 让网络学习到一个多阶段反馈的模型\n* 2016\n\n#### 双源CNN\n* 给网络添加先验知识\n* Fuan xiaochuan\n* 2015\n\n\n#### CNN\n* 由于人的尺度是不一样的，能不能让网络客服这一问题，并学习到关节与关节之间的关系(pair wise relation)？\n* Yann lecun\n* 2014\n* CNN+图模型\n\n#### DCNN\n* CNN+树状结构图模型\n* 2016\n* Wang xiaogang\n\n#### CPM\n* 卷积姿态机 + 大卷积核提升感受野 + 多阶段回归\n* 2016\n\n#### hourglass\n* 堆叠的沙漏模型 + 极大提升感受野 + 多阶段回归\n* 2016\n\n#### \n* 图模型太慢，直接使用卷积核来实现\n* 树状结构的特征学习\n* 2016\n\n\n### Efficient Concolutional Network\n* 关注efficience\n* 2016\n\n \n\n\n\n\n\n\n## 参考博客\n- 如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎   \nhttps://www.zhihu.com/question/59750782\n- CMU-Perceptual-Computing-Lab/openpose: OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation   \nhttps://github.com/CMU-Perceptual-Computing-Lab/openpose\n- 人体姿态估计数据集整理（Pose Estimation/Keypoint） - 上善若水 - CSDN博客   \nhttps://blog.csdn.net/guo1988kui/article/details/84321581\n- openpose实时多人2D姿态估计 - weixin_41441682的博客 - CSDN博客   \nhttps://blog.csdn.net/weixin_41441682/article/details/81357369#\n- 人体姿态估计资源大列表（Human Pose Estimation） - xiaolouhan的博客 - CSDN博客   \nhttps://blog.csdn.net/xiaolouhan/article/details/84321148\n- 新人求教如何从头学习人体姿态估计 - Ilovepose http://ilovepose.luohuank.xin/t/66\n论文解析与翻译：《Stacked Hourglass Networks for Human Pose Estimation》 - qq_38522972的博客 - CSDN博客  \nhttps://blog.csdn.net/qq_38522972/article/details/82958077\n- 人体姿态估计资源大列表（Human Pose Estimation） - weixin_38367817的博客 - CSDN博客  \nhttps://blog.csdn.net/weixin_38367817/article/details/86522569\n- 人体姿态估计综述（Human Pose Estimation Overview） - 青青韶华 - CSDN博客   \nhttps://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&fps=1\n- 人体姿态估计（人体关键点检测）分类与经典方法分析（附GitHub地址） - ls83776736的博客 - CSDN博客  \nhttps://blog.csdn.net/ls83776736/article/details/87991515\nMPII Human Pose Database http://human-pose.mpi-inf.mpg.de/#results\n\n\n\n\n* #3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube</br>https://www.youtube.com/watch?v=T5QlePZ4s3U&list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&index=3","slug":"Pixar-Lamp","published":1,"updated":"2019-06-26T00:36:23.180Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74p000krsvjjtmr5xfk","content":"<p><strong> Pixar Lamp：</strong> <excerpt in index | 首页摘要><br>做个跳跳灯！<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h1><h3 id=\"2018年3月\"><a href=\"#2018年3月\" class=\"headerlink\" title=\"2018年3月\"></a>2018年3月</h3><div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/设计思路.png\" width=\"1000\" height=\"800\">\n</div>\n\n<h3 id=\"2019年5月\"><a href=\"#2019年5月\" class=\"headerlink\" title=\"2019年5月\"></a>2019年5月</h3><div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n<h1 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; conda create -n lamp python=3.6</span><br><span class=\"line\">&gt; activate lamp</span><br><span class=\"line\">&gt; pip install numpy</span><br><span class=\"line\">&gt; pip install pandas</span><br><span class=\"line\">&gt; pip install scipy</span><br><span class=\"line\">&gt; pip install tensorflow</span><br><span class=\"line\">&gt; pip install baidu-aip</span><br><span class=\"line\">&gt; pip install pyserial</span><br><span class=\"line\">&gt; pip install opencv-python</span><br><span class=\"line\">&gt; pip install opencv-contrib-python</span><br></pre></td></tr></table></figure>\n<p>调用华为api</p>\n<ul>\n<li>huaweicloud/huaweicloud-sdk-python-frs <a href=\"https://github.com/huaweicloud/huaweicloud-sdk-python-frs\" target=\"_blank\" rel=\"noopener\">https://github.com/huaweicloud/huaweicloud-sdk-python-frs</a></li>\n</ul>\n<p>姿态点检测</p>\n<div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/001.jpg\" width=\"200\" height=\"200\">\n</div>\n\n<ul>\n<li>Ilovepose &lt;/br&gt;<a href=\"http://ilovepose.luohuank.xin/\" target=\"_blank\" rel=\"noopener\">http://ilovepose.luohuank.xin/</a></li>\n<li>如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎 &lt;/br&gt;<a href=\"https://www.zhihu.com/question/59750782\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/59750782</a></li>\n<li>基于OpenPose的人体姿态检测 - yph001的博客 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/yph001/article/details/83218839\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yph001/article/details/83218839</a></li>\n</ul>\n<h2 id=\"单人姿态估计\"><a href=\"#单人姿态估计\" class=\"headerlink\" title=\"单人姿态估计\"></a>单人姿态估计</h2><h3 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h3><ul>\n<li>【极市】张锋-2D单人人体姿态估计及其应用_腾讯视频 &lt;/br&gt;<a href=\"https://v.qq.com/x/page/w0543yfwrhq.html\" target=\"_blank\" rel=\"noopener\">https://v.qq.com/x/page/w0543yfwrhq.html</a></li>\n<li>PowerPoint Template&lt;/br&gt; <a href=\"http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf\" target=\"_blank\" rel=\"noopener\">http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf</a></li>\n<li>MPII Human Pose Database &lt;/br&gt; <a href=\"http://human-pose.mpi-inf.mpg.de/#results\" target=\"_blank\" rel=\"noopener\">http://human-pose.mpi-inf.mpg.de/#results</a></li>\n</ul>\n<p>应用</p>\n<ul>\n<li>人机交互</li>\n<li>行人再识别 person re-id</li>\n<li>行为识别</li>\n</ul>\n<p>问题</p>\n<ul>\n<li>遮挡</li>\n<li>复杂背景</li>\n<li>光照</li>\n<li>复杂姿态</li>\n<li>多尺度</li>\n<li>拍摄角度</li>\n</ul>\n<h3 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h3><ul>\n<li>多尺度、多分辨率</li>\n<li>基于Residual Block</li>\n<li>扩大感受野</li>\n<li>预处理</li>\n<li>后处理</li>\n</ul>\n<p>传统方法</p>\n<ul>\n<li>基于图结构(Pictorial Structures)</li>\n<li>DPM(形变部件模型)目标价侧算法<br>DPM算法采用了改进后的HOG特征，SVM分类器和滑动窗口（Sliding Windows）检测思想，针对目标的多视角问题，采用了多组件（Component）的策略，针对目标本身的形变问题，采用了基于图结构（Pictorial Structure）的部件模型策略。此外，将样本的所属的模型类别，部件模型的位置等作为潜变量（Latent Variable），采用多示例学习（Multiple-instance Learning）来自动确定。</li>\n</ul>\n<p>基于深度学习的方法</p>\n<ul>\n<li><p>直接回归坐标 </p>\n<ul>\n<li>CNN多阶段 </li>\n</ul>\n</li>\n<li><p>通过热力图回归坐标</p>\n<ul>\n<li>CNN+图模型</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Deep-Pose\"><a href=\"#Deep-Pose\" class=\"headerlink\" title=\"Deep Pose\"></a>Deep Pose</h4><ul>\n<li>CNN分类效果好，能不能直接用CNN回归关节坐标</li>\n<li>2014， Szegedy</li>\n<li>AlesNet</li>\n</ul>\n<h4 id=\"迭代误差反馈模型\"><a href=\"#迭代误差反馈模型\" class=\"headerlink\" title=\"迭代误差反馈模型\"></a>迭代误差反馈模型</h4><ul>\n<li>让网络学习到一个多阶段反馈的模型</li>\n<li>2016</li>\n</ul>\n<h4 id=\"双源CNN\"><a href=\"#双源CNN\" class=\"headerlink\" title=\"双源CNN\"></a>双源CNN</h4><ul>\n<li>给网络添加先验知识</li>\n<li>Fuan xiaochuan</li>\n<li>2015</li>\n</ul>\n<h4 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h4><ul>\n<li>由于人的尺度是不一样的，能不能让网络客服这一问题，并学习到关节与关节之间的关系(pair wise relation)？</li>\n<li>Yann lecun</li>\n<li>2014</li>\n<li>CNN+图模型</li>\n</ul>\n<h4 id=\"DCNN\"><a href=\"#DCNN\" class=\"headerlink\" title=\"DCNN\"></a>DCNN</h4><ul>\n<li>CNN+树状结构图模型</li>\n<li>2016</li>\n<li>Wang xiaogang</li>\n</ul>\n<h4 id=\"CPM\"><a href=\"#CPM\" class=\"headerlink\" title=\"CPM\"></a>CPM</h4><ul>\n<li>卷积姿态机 + 大卷积核提升感受野 + 多阶段回归</li>\n<li>2016</li>\n</ul>\n<h4 id=\"hourglass\"><a href=\"#hourglass\" class=\"headerlink\" title=\"hourglass\"></a>hourglass</h4><ul>\n<li>堆叠的沙漏模型 + 极大提升感受野 + 多阶段回归</li>\n<li>2016</li>\n</ul>\n<h4 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h4><ul>\n<li>图模型太慢，直接使用卷积核来实现</li>\n<li>树状结构的特征学习</li>\n<li>2016</li>\n</ul>\n<h3 id=\"Efficient-Concolutional-Network\"><a href=\"#Efficient-Concolutional-Network\" class=\"headerlink\" title=\"Efficient Concolutional Network\"></a>Efficient Concolutional Network</h3><ul>\n<li>关注efficience</li>\n<li>2016</li>\n</ul>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎<br><a href=\"https://www.zhihu.com/question/59750782\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/59750782</a></li>\n<li>CMU-Perceptual-Computing-Lab/openpose: OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation<br><a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\" target=\"_blank\" rel=\"noopener\">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a></li>\n<li>人体姿态估计数据集整理（Pose Estimation/Keypoint） - 上善若水 - CSDN博客<br><a href=\"https://blog.csdn.net/guo1988kui/article/details/84321581\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/guo1988kui/article/details/84321581</a></li>\n<li>openpose实时多人2D姿态估计 - weixin_41441682的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_41441682/article/details/81357369#\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_41441682/article/details/81357369#</a></li>\n<li>人体姿态估计资源大列表（Human Pose Estimation） - xiaolouhan的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/xiaolouhan/article/details/84321148\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/xiaolouhan/article/details/84321148</a></li>\n<li>新人求教如何从头学习人体姿态估计 - Ilovepose <a href=\"http://ilovepose.luohuank.xin/t/66\" target=\"_blank\" rel=\"noopener\">http://ilovepose.luohuank.xin/t/66</a><br>论文解析与翻译：《Stacked Hourglass Networks for Human Pose Estimation》 - qq_38522972的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_38522972/article/details/82958077\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_38522972/article/details/82958077</a></li>\n<li>人体姿态估计资源大列表（Human Pose Estimation） - weixin_38367817的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_38367817/article/details/86522569\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_38367817/article/details/86522569</a></li>\n<li>人体姿态估计综述（Human Pose Estimation Overview） - 青青韶华 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&amp;fps=1\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&amp;fps=1</a></li>\n<li>人体姿态估计（人体关键点检测）分类与经典方法分析（附GitHub地址） - ls83776736的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ls83776736/article/details/87991515\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ls83776736/article/details/87991515</a><br>MPII Human Pose Database <a href=\"http://human-pose.mpi-inf.mpg.de/#results\" target=\"_blank\" rel=\"noopener\">http://human-pose.mpi-inf.mpg.de/#results</a></li>\n</ul>\n<ul>\n<li><h1 id=\"3-机械手臂从零开始-写动态环境-机器学习实战-教程教学-tutorial-YouTube-lt-br-gt-https-www-youtube-com-watch-v-T5QlePZ4s3U-amp-list-PLXO45tsB95cL8HTAlqkrmKLN-VSjlq4J8-amp-index-3\"><a href=\"#3-机械手臂从零开始-写动态环境-机器学习实战-教程教学-tutorial-YouTube-lt-br-gt-https-www-youtube-com-watch-v-T5QlePZ4s3U-amp-list-PLXO45tsB95cL8HTAlqkrmKLN-VSjlq4J8-amp-index-3\" class=\"headerlink\" title=\"3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube&lt;/br&gt;https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3\"></a>3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube&lt;/br&gt;<a href=\"https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3</a></h1></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Pixar Lamp：</strong> <excerpt in index | 首页摘要><br>做个跳跳灯！<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h1 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h1><h3 id=\"2018年3月\"><a href=\"#2018年3月\" class=\"headerlink\" title=\"2018年3月\"></a>2018年3月</h3><div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/设计思路.png\" width=\"1000\" height=\"800\">\n</div>\n\n<h3 id=\"2019年5月\"><a href=\"#2019年5月\" class=\"headerlink\" title=\"2019年5月\"></a>2019年5月</h3><div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n<h1 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; conda create -n lamp python=3.6</span><br><span class=\"line\">&gt; activate lamp</span><br><span class=\"line\">&gt; pip install numpy</span><br><span class=\"line\">&gt; pip install pandas</span><br><span class=\"line\">&gt; pip install scipy</span><br><span class=\"line\">&gt; pip install tensorflow</span><br><span class=\"line\">&gt; pip install baidu-aip</span><br><span class=\"line\">&gt; pip install pyserial</span><br><span class=\"line\">&gt; pip install opencv-python</span><br><span class=\"line\">&gt; pip install opencv-contrib-python</span><br></pre></td></tr></table></figure>\n<p>调用华为api</p>\n<ul>\n<li>huaweicloud/huaweicloud-sdk-python-frs <a href=\"https://github.com/huaweicloud/huaweicloud-sdk-python-frs\" target=\"_blank\" rel=\"noopener\">https://github.com/huaweicloud/huaweicloud-sdk-python-frs</a></li>\n</ul>\n<p>姿态点检测</p>\n<div align=\"center\">\n<img src=\"/2019/05/14/Pixar-Lamp/001.jpg\" width=\"200\" height=\"200\">\n</div>\n\n<ul>\n<li>Ilovepose &lt;/br&gt;<a href=\"http://ilovepose.luohuank.xin/\" target=\"_blank\" rel=\"noopener\">http://ilovepose.luohuank.xin/</a></li>\n<li>如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎 &lt;/br&gt;<a href=\"https://www.zhihu.com/question/59750782\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/59750782</a></li>\n<li>基于OpenPose的人体姿态检测 - yph001的博客 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/yph001/article/details/83218839\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/yph001/article/details/83218839</a></li>\n</ul>\n<h2 id=\"单人姿态估计\"><a href=\"#单人姿态估计\" class=\"headerlink\" title=\"单人姿态估计\"></a>单人姿态估计</h2><h3 id=\"综述\"><a href=\"#综述\" class=\"headerlink\" title=\"综述\"></a>综述</h3><ul>\n<li>【极市】张锋-2D单人人体姿态估计及其应用_腾讯视频 &lt;/br&gt;<a href=\"https://v.qq.com/x/page/w0543yfwrhq.html\" target=\"_blank\" rel=\"noopener\">https://v.qq.com/x/page/w0543yfwrhq.html</a></li>\n<li>PowerPoint Template&lt;/br&gt; <a href=\"http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf\" target=\"_blank\" rel=\"noopener\">http://static.extremevision.com.cn/donkey_84b48a46-86f7-4db3-a5fd-87b0f8e6389a.pdf</a></li>\n<li>MPII Human Pose Database &lt;/br&gt; <a href=\"http://human-pose.mpi-inf.mpg.de/#results\" target=\"_blank\" rel=\"noopener\">http://human-pose.mpi-inf.mpg.de/#results</a></li>\n</ul>\n<p>应用</p>\n<ul>\n<li>人机交互</li>\n<li>行人再识别 person re-id</li>\n<li>行为识别</li>\n</ul>\n<p>问题</p>\n<ul>\n<li>遮挡</li>\n<li>复杂背景</li>\n<li>光照</li>\n<li>复杂姿态</li>\n<li>多尺度</li>\n<li>拍摄角度</li>\n</ul>\n<h3 id=\"方法\"><a href=\"#方法\" class=\"headerlink\" title=\"方法\"></a>方法</h3><ul>\n<li>多尺度、多分辨率</li>\n<li>基于Residual Block</li>\n<li>扩大感受野</li>\n<li>预处理</li>\n<li>后处理</li>\n</ul>\n<p>传统方法</p>\n<ul>\n<li>基于图结构(Pictorial Structures)</li>\n<li>DPM(形变部件模型)目标价侧算法<br>DPM算法采用了改进后的HOG特征，SVM分类器和滑动窗口（Sliding Windows）检测思想，针对目标的多视角问题，采用了多组件（Component）的策略，针对目标本身的形变问题，采用了基于图结构（Pictorial Structure）的部件模型策略。此外，将样本的所属的模型类别，部件模型的位置等作为潜变量（Latent Variable），采用多示例学习（Multiple-instance Learning）来自动确定。</li>\n</ul>\n<p>基于深度学习的方法</p>\n<ul>\n<li><p>直接回归坐标 </p>\n<ul>\n<li>CNN多阶段 </li>\n</ul>\n</li>\n<li><p>通过热力图回归坐标</p>\n<ul>\n<li>CNN+图模型</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Deep-Pose\"><a href=\"#Deep-Pose\" class=\"headerlink\" title=\"Deep Pose\"></a>Deep Pose</h4><ul>\n<li>CNN分类效果好，能不能直接用CNN回归关节坐标</li>\n<li>2014， Szegedy</li>\n<li>AlesNet</li>\n</ul>\n<h4 id=\"迭代误差反馈模型\"><a href=\"#迭代误差反馈模型\" class=\"headerlink\" title=\"迭代误差反馈模型\"></a>迭代误差反馈模型</h4><ul>\n<li>让网络学习到一个多阶段反馈的模型</li>\n<li>2016</li>\n</ul>\n<h4 id=\"双源CNN\"><a href=\"#双源CNN\" class=\"headerlink\" title=\"双源CNN\"></a>双源CNN</h4><ul>\n<li>给网络添加先验知识</li>\n<li>Fuan xiaochuan</li>\n<li>2015</li>\n</ul>\n<h4 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h4><ul>\n<li>由于人的尺度是不一样的，能不能让网络客服这一问题，并学习到关节与关节之间的关系(pair wise relation)？</li>\n<li>Yann lecun</li>\n<li>2014</li>\n<li>CNN+图模型</li>\n</ul>\n<h4 id=\"DCNN\"><a href=\"#DCNN\" class=\"headerlink\" title=\"DCNN\"></a>DCNN</h4><ul>\n<li>CNN+树状结构图模型</li>\n<li>2016</li>\n<li>Wang xiaogang</li>\n</ul>\n<h4 id=\"CPM\"><a href=\"#CPM\" class=\"headerlink\" title=\"CPM\"></a>CPM</h4><ul>\n<li>卷积姿态机 + 大卷积核提升感受野 + 多阶段回归</li>\n<li>2016</li>\n</ul>\n<h4 id=\"hourglass\"><a href=\"#hourglass\" class=\"headerlink\" title=\"hourglass\"></a>hourglass</h4><ul>\n<li>堆叠的沙漏模型 + 极大提升感受野 + 多阶段回归</li>\n<li>2016</li>\n</ul>\n<h4 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h4><ul>\n<li>图模型太慢，直接使用卷积核来实现</li>\n<li>树状结构的特征学习</li>\n<li>2016</li>\n</ul>\n<h3 id=\"Efficient-Concolutional-Network\"><a href=\"#Efficient-Concolutional-Network\" class=\"headerlink\" title=\"Efficient Concolutional Network\"></a>Efficient Concolutional Network</h3><ul>\n<li>关注efficience</li>\n<li>2016</li>\n</ul>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>如何评价卡内基梅隆大学的开源项目 OpenPose？ - 知乎<br><a href=\"https://www.zhihu.com/question/59750782\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/59750782</a></li>\n<li>CMU-Perceptual-Computing-Lab/openpose: OpenPose: Real-time multi-person keypoint detection library for body, face, hands, and foot estimation<br><a href=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose\" target=\"_blank\" rel=\"noopener\">https://github.com/CMU-Perceptual-Computing-Lab/openpose</a></li>\n<li>人体姿态估计数据集整理（Pose Estimation/Keypoint） - 上善若水 - CSDN博客<br><a href=\"https://blog.csdn.net/guo1988kui/article/details/84321581\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/guo1988kui/article/details/84321581</a></li>\n<li>openpose实时多人2D姿态估计 - weixin_41441682的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_41441682/article/details/81357369#\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_41441682/article/details/81357369#</a></li>\n<li>人体姿态估计资源大列表（Human Pose Estimation） - xiaolouhan的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/xiaolouhan/article/details/84321148\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/xiaolouhan/article/details/84321148</a></li>\n<li>新人求教如何从头学习人体姿态估计 - Ilovepose <a href=\"http://ilovepose.luohuank.xin/t/66\" target=\"_blank\" rel=\"noopener\">http://ilovepose.luohuank.xin/t/66</a><br>论文解析与翻译：《Stacked Hourglass Networks for Human Pose Estimation》 - qq_38522972的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_38522972/article/details/82958077\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_38522972/article/details/82958077</a></li>\n<li>人体姿态估计资源大列表（Human Pose Estimation） - weixin_38367817的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_38367817/article/details/86522569\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_38367817/article/details/86522569</a></li>\n<li>人体姿态估计综述（Human Pose Estimation Overview） - 青青韶华 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&amp;fps=1\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_36165459/article/details/78320535?locationNum=10&amp;fps=1</a></li>\n<li>人体姿态估计（人体关键点检测）分类与经典方法分析（附GitHub地址） - ls83776736的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ls83776736/article/details/87991515\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ls83776736/article/details/87991515</a><br>MPII Human Pose Database <a href=\"http://human-pose.mpi-inf.mpg.de/#results\" target=\"_blank\" rel=\"noopener\">http://human-pose.mpi-inf.mpg.de/#results</a></li>\n</ul>\n<ul>\n<li><h1 id=\"3-机械手臂从零开始-写动态环境-机器学习实战-教程教学-tutorial-YouTube-lt-br-gt-https-www-youtube-com-watch-v-T5QlePZ4s3U-amp-list-PLXO45tsB95cL8HTAlqkrmKLN-VSjlq4J8-amp-index-3\"><a href=\"#3-机械手臂从零开始-写动态环境-机器学习实战-教程教学-tutorial-YouTube-lt-br-gt-https-www-youtube-com-watch-v-T5QlePZ4s3U-amp-list-PLXO45tsB95cL8HTAlqkrmKLN-VSjlq4J8-amp-index-3\" class=\"headerlink\" title=\"3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube&lt;/br&gt;https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3\"></a>3 机械手臂从零开始 写动态环境 (机器学习实战 教程教学 tutorial) - YouTube&lt;/br&gt;<a href=\"https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=T5QlePZ4s3U&amp;list=PLXO45tsB95cL8HTAlqkrmKLN_VSjlq4J8&amp;index=3</a></h1></li>\n</ul>\n</the>"},{"title":"RL学习笔记","date":"2019-05-22T07:56:59.000Z","_content":"\n## windows安装gym\n安装依赖包\n``` bash\n> pip install pillow ...\n```\n安装gym和游戏仿真环境Atari\n``` bash\n> pip install gym\n> pip install - -no-index -f https://github.com/Kojoley/atari-py/releases atari_py\n```\n\n\n\n\n``` bash\n(root) C:\\Users\\Administrator\\Desktop\\DQN-2048-master>python\nPython 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pandas as pf\n>>> import pandas as pd\n>>> import numpy as np\n>>> table = pd.DataFrame(np.random.random((3,4)), index=[2,4,6], columns=['a', 'c', 'd', 'd'])\n>>> table\n          a         c         d         d\n2  0.444598  0.907250  0.629258  0.607062\n4  0.531954  0.341319  0.477738  0.480921\n6  0.102290  0.765902  0.923868  0.159364\n>>> table_alist = table.loc[4,:]\n>>> table_alist\na    0.531954\nc    0.341319\nd    0.477738\nd    0.480921\nName: 4, dtype: float64\n>>> table_alist.max()\n0.5319538779267701\n>>> table_alist.argmax()\n'a'\n>>>\n\n```\n\n\n* 深度增强学习（DRL）漫谈 - 从DQN到AlphaGo - 世事难料，保持低调 - CSDN博客</br>https://blog.csdn.net/jinzhuojun/article/details/52752561\n\n* 深度增强学习DDPG（Deep Deterministic Policy Gradient）算法源码走读 - 世事难料，保持低调 - CSDN博客 </br>https://blog.csdn.net/jinzhuojun/article/details/82556127\n\n\n\n* 在Windows下使用OpenAI Gym - HelloGym - 止于至玄 - CSDN博客</br> https://blog.csdn.net/philthinker/article/details/79810249\n\n","source":"_posts/RL学习笔记.md","raw":"---\ntitle: RL学习笔记\ndate: 2019-05-22 15:56:59\ntags:\n  - RL\n---\n\n## windows安装gym\n安装依赖包\n``` bash\n> pip install pillow ...\n```\n安装gym和游戏仿真环境Atari\n``` bash\n> pip install gym\n> pip install - -no-index -f https://github.com/Kojoley/atari-py/releases atari_py\n```\n\n\n\n\n``` bash\n(root) C:\\Users\\Administrator\\Desktop\\DQN-2048-master>python\nPython 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import pandas as pf\n>>> import pandas as pd\n>>> import numpy as np\n>>> table = pd.DataFrame(np.random.random((3,4)), index=[2,4,6], columns=['a', 'c', 'd', 'd'])\n>>> table\n          a         c         d         d\n2  0.444598  0.907250  0.629258  0.607062\n4  0.531954  0.341319  0.477738  0.480921\n6  0.102290  0.765902  0.923868  0.159364\n>>> table_alist = table.loc[4,:]\n>>> table_alist\na    0.531954\nc    0.341319\nd    0.477738\nd    0.480921\nName: 4, dtype: float64\n>>> table_alist.max()\n0.5319538779267701\n>>> table_alist.argmax()\n'a'\n>>>\n\n```\n\n\n* 深度增强学习（DRL）漫谈 - 从DQN到AlphaGo - 世事难料，保持低调 - CSDN博客</br>https://blog.csdn.net/jinzhuojun/article/details/52752561\n\n* 深度增强学习DDPG（Deep Deterministic Policy Gradient）算法源码走读 - 世事难料，保持低调 - CSDN博客 </br>https://blog.csdn.net/jinzhuojun/article/details/82556127\n\n\n\n* 在Windows下使用OpenAI Gym - HelloGym - 止于至玄 - CSDN博客</br> https://blog.csdn.net/philthinker/article/details/79810249\n\n","slug":"RL学习笔记","published":1,"updated":"2019-06-26T00:37:51.995Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74q000mrsvj1ui1gwll","content":"<h2 id=\"windows安装gym\"><a href=\"#windows安装gym\" class=\"headerlink\" title=\"windows安装gym\"></a>windows安装gym</h2><p>安装依赖包<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; pip install pillow ...</span><br></pre></td></tr></table></figure></p>\n<p>安装gym和游戏仿真环境Atari<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; pip install gym</span><br><span class=\"line\">&gt; pip install - -no-index -f https://github.com/Kojoley/atari-py/releases atari_py</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(root) C:\\Users\\Administrator\\Desktop\\DQN-2048-master&gt;python</span><br><span class=\"line\">Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)] on win32</span><br><span class=\"line\">Type <span class=\"string\">\"help\"</span>, <span class=\"string\">\"copyright\"</span>, <span class=\"string\">\"credits\"</span> or <span class=\"string\">\"license\"</span> <span class=\"keyword\">for</span> more information.</span><br><span class=\"line\">&gt;&gt;&gt; import pandas as pf</span><br><span class=\"line\">&gt;&gt;&gt; import pandas as pd</span><br><span class=\"line\">&gt;&gt;&gt; import numpy as np</span><br><span class=\"line\">&gt;&gt;&gt; table = pd.DataFrame(np.random.random((3,4)), index=[2,4,6], columns=[<span class=\"string\">'a'</span>, <span class=\"string\">'c'</span>, <span class=\"string\">'d'</span>, <span class=\"string\">'d'</span>])</span><br><span class=\"line\">&gt;&gt;&gt; table</span><br><span class=\"line\">          a         c         d         d</span><br><span class=\"line\">2  0.444598  0.907250  0.629258  0.607062</span><br><span class=\"line\">4  0.531954  0.341319  0.477738  0.480921</span><br><span class=\"line\">6  0.102290  0.765902  0.923868  0.159364</span><br><span class=\"line\">&gt;&gt;&gt; table_alist = table.loc[4,:]</span><br><span class=\"line\">&gt;&gt;&gt; table_alist</span><br><span class=\"line\">a    0.531954</span><br><span class=\"line\">c    0.341319</span><br><span class=\"line\">d    0.477738</span><br><span class=\"line\">d    0.480921</span><br><span class=\"line\">Name: 4, dtype: float64</span><br><span class=\"line\">&gt;&gt;&gt; table_alist.max()</span><br><span class=\"line\">0.5319538779267701</span><br><span class=\"line\">&gt;&gt;&gt; table_alist.argmax()</span><br><span class=\"line\"><span class=\"string\">'a'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>深度增强学习（DRL）漫谈 - 从DQN到AlphaGo - 世事难料，保持低调 - CSDN博客&lt;/br&gt;<a href=\"https://blog.csdn.net/jinzhuojun/article/details/52752561\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jinzhuojun/article/details/52752561</a></p>\n</li>\n<li><p>深度增强学习DDPG（Deep Deterministic Policy Gradient）算法源码走读 - 世事难料，保持低调 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/jinzhuojun/article/details/82556127\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jinzhuojun/article/details/82556127</a></p>\n</li>\n</ul>\n<ul>\n<li>在Windows下使用OpenAI Gym - HelloGym - 止于至玄 - CSDN博客&lt;/br&gt; <a href=\"https://blog.csdn.net/philthinker/article/details/79810249\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/philthinker/article/details/79810249</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"windows安装gym\"><a href=\"#windows安装gym\" class=\"headerlink\" title=\"windows安装gym\"></a>windows安装gym</h2><p>安装依赖包<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; pip install pillow ...</span><br></pre></td></tr></table></figure></p>\n<p>安装gym和游戏仿真环境Atari<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; pip install gym</span><br><span class=\"line\">&gt; pip install - -no-index -f https://github.com/Kojoley/atari-py/releases atari_py</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">(root) C:\\Users\\Administrator\\Desktop\\DQN-2048-master&gt;python</span><br><span class=\"line\">Python 3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)] on win32</span><br><span class=\"line\">Type <span class=\"string\">\"help\"</span>, <span class=\"string\">\"copyright\"</span>, <span class=\"string\">\"credits\"</span> or <span class=\"string\">\"license\"</span> <span class=\"keyword\">for</span> more information.</span><br><span class=\"line\">&gt;&gt;&gt; import pandas as pf</span><br><span class=\"line\">&gt;&gt;&gt; import pandas as pd</span><br><span class=\"line\">&gt;&gt;&gt; import numpy as np</span><br><span class=\"line\">&gt;&gt;&gt; table = pd.DataFrame(np.random.random((3,4)), index=[2,4,6], columns=[<span class=\"string\">'a'</span>, <span class=\"string\">'c'</span>, <span class=\"string\">'d'</span>, <span class=\"string\">'d'</span>])</span><br><span class=\"line\">&gt;&gt;&gt; table</span><br><span class=\"line\">          a         c         d         d</span><br><span class=\"line\">2  0.444598  0.907250  0.629258  0.607062</span><br><span class=\"line\">4  0.531954  0.341319  0.477738  0.480921</span><br><span class=\"line\">6  0.102290  0.765902  0.923868  0.159364</span><br><span class=\"line\">&gt;&gt;&gt; table_alist = table.loc[4,:]</span><br><span class=\"line\">&gt;&gt;&gt; table_alist</span><br><span class=\"line\">a    0.531954</span><br><span class=\"line\">c    0.341319</span><br><span class=\"line\">d    0.477738</span><br><span class=\"line\">d    0.480921</span><br><span class=\"line\">Name: 4, dtype: float64</span><br><span class=\"line\">&gt;&gt;&gt; table_alist.max()</span><br><span class=\"line\">0.5319538779267701</span><br><span class=\"line\">&gt;&gt;&gt; table_alist.argmax()</span><br><span class=\"line\"><span class=\"string\">'a'</span></span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>\n<ul>\n<li><p>深度增强学习（DRL）漫谈 - 从DQN到AlphaGo - 世事难料，保持低调 - CSDN博客&lt;/br&gt;<a href=\"https://blog.csdn.net/jinzhuojun/article/details/52752561\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jinzhuojun/article/details/52752561</a></p>\n</li>\n<li><p>深度增强学习DDPG（Deep Deterministic Policy Gradient）算法源码走读 - 世事难料，保持低调 - CSDN博客 &lt;/br&gt;<a href=\"https://blog.csdn.net/jinzhuojun/article/details/82556127\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jinzhuojun/article/details/82556127</a></p>\n</li>\n</ul>\n<ul>\n<li>在Windows下使用OpenAI Gym - HelloGym - 止于至玄 - CSDN博客&lt;/br&gt; <a href=\"https://blog.csdn.net/philthinker/article/details/79810249\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/philthinker/article/details/79810249</a></li>\n</ul>\n"},{"title":"golang学习笔记","date":"2019-06-25T11:15:09.000Z","_content":"\n\n\n## 安装Golang\n下载\n* http://golang.org/dl/  \n\n安装文档\n* http://golang.org/doc/install。\n\nWindows - MSI installer\n\nOpen the MSI file and follow the prompts to install the Go tools. By default, the installer puts the Go distribution in c:\\Go.  \nThe installer should put the c:\\Go\\bin directory in your PATH environment variable. You may need to restart any open command prompts for the change to take effect.  \n\n\n\n\n\n\n\n\n\n","source":"_posts/golang学习笔记.md","raw":"---\ntitle: golang学习笔记\ndate: 2019-06-25 19:15:09\ntags:\n  - go\n---\n\n\n\n## 安装Golang\n下载\n* http://golang.org/dl/  \n\n安装文档\n* http://golang.org/doc/install。\n\nWindows - MSI installer\n\nOpen the MSI file and follow the prompts to install the Go tools. By default, the installer puts the Go distribution in c:\\Go.  \nThe installer should put the c:\\Go\\bin directory in your PATH environment variable. You may need to restart any open command prompts for the change to take effect.  \n\n\n\n\n\n\n\n\n\n","slug":"golang学习笔记","published":1,"updated":"2019-06-25T11:18:00.533Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74r000orsvjjvawzmes","content":"<h2 id=\"安装Golang\"><a href=\"#安装Golang\" class=\"headerlink\" title=\"安装Golang\"></a>安装Golang</h2><p>下载</p>\n<ul>\n<li><a href=\"http://golang.org/dl/\" target=\"_blank\" rel=\"noopener\">http://golang.org/dl/</a>  </li>\n</ul>\n<p>安装文档</p>\n<ul>\n<li><a href=\"http://golang.org/doc/install。\" target=\"_blank\" rel=\"noopener\">http://golang.org/doc/install。</a></li>\n</ul>\n<p>Windows - MSI installer</p>\n<p>Open the MSI file and follow the prompts to install the Go tools. By default, the installer puts the Go distribution in c:\\Go.<br>The installer should put the c:\\Go\\bin directory in your PATH environment variable. You may need to restart any open command prompts for the change to take effect.  </p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"安装Golang\"><a href=\"#安装Golang\" class=\"headerlink\" title=\"安装Golang\"></a>安装Golang</h2><p>下载</p>\n<ul>\n<li><a href=\"http://golang.org/dl/\" target=\"_blank\" rel=\"noopener\">http://golang.org/dl/</a>  </li>\n</ul>\n<p>安装文档</p>\n<ul>\n<li><a href=\"http://golang.org/doc/install。\" target=\"_blank\" rel=\"noopener\">http://golang.org/doc/install。</a></li>\n</ul>\n<p>Windows - MSI installer</p>\n<p>Open the MSI file and follow the prompts to install the Go tools. By default, the installer puts the Go distribution in c:\\Go.<br>The installer should put the c:\\Go\\bin directory in your PATH environment variable. You may need to restart any open command prompts for the change to take effect.  </p>\n"},{"title":"loomo多服务机器人开发","date":"2019-05-26T11:43:22.000Z","_content":"\n## 设计思路\n\n<div align=center>\n<img alt=\"design\" src = \"loomo多服务机器人开发\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/loomo多服务机器人开发.1.md","raw":"---\ntitle: loomo多服务机器人开发\ndate: 2019-05-26 19:43:22\ntags:\n  - loomo\n  - Android\n  - 机械手\n---\n\n## 设计思路\n\n<div align=center>\n<img alt=\"design\" src = \"loomo多服务机器人开发\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"loomo多服务机器人开发.1","published":1,"updated":"2019-06-27T18:07:11.185Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74r000prsvjmscx60bn","content":"<h2 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h2><div align=\"center\">\n<img alt=\"design\" src=\"/2019/05/26/loomo多服务机器人开发.1/loomo多服务机器人开发/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h2><div align=\"center\">\n<img alt=\"design\" src=\"/2019/05/26/loomo多服务机器人开发.1/loomo多服务机器人开发/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"TensorFlow 手写数字识别","date":"2019-04-26T02:13:08.000Z","_content":"\n## tensorflow基础\n\n### 基本概念\n\ntensorflow是一个编程系统，使用图(graphs)来表示计算任务，在会话(Seeeion)的context中执行graphs，graphs中的节点称为op(operation)，一个op获得零个或多个Tensor，执行计算产生零个或多个Tensor，Tensor可以看做n维数组或列表，图必须在会话中启动，通过变量(Variable)维护装填，使用feed和fetch可以为任意的操作赋值获从中获取数据。\n\n* TensorFlow Core  |  TensorFlow  \nhttps://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg\n\n* 优化器 Optimizer 加速神经网络训练 (深度学习) Speed up neural network training process (deep learning) - YouTube  \nhttps://www.youtube.com/watch?v=UlUGGB7akfE&list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&index=18&app=desktop\n\n\n\n\n\n\n\n\n\n","source":"_posts/TensorFlow-手写数字识别.md","raw":"---\ntitle: TensorFlow 手写数字识别\ndate: 2019-04-26 10:13:08\ntags:\n  - tensorflow\n---\n\n## tensorflow基础\n\n### 基本概念\n\ntensorflow是一个编程系统，使用图(graphs)来表示计算任务，在会话(Seeeion)的context中执行graphs，graphs中的节点称为op(operation)，一个op获得零个或多个Tensor，执行计算产生零个或多个Tensor，Tensor可以看做n维数组或列表，图必须在会话中启动，通过变量(Variable)维护装填，使用feed和fetch可以为任意的操作赋值获从中获取数据。\n\n* TensorFlow Core  |  TensorFlow  \nhttps://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg\n\n* 优化器 Optimizer 加速神经网络训练 (深度学习) Speed up neural network training process (deep learning) - YouTube  \nhttps://www.youtube.com/watch?v=UlUGGB7akfE&list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&index=18&app=desktop\n\n\n\n\n\n\n\n\n\n","slug":"TensorFlow-手写数字识别","published":1,"updated":"2019-06-23T07:09:39.758Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74t000rrsvj66lky429","content":"<h2 id=\"tensorflow基础\"><a href=\"#tensorflow基础\" class=\"headerlink\" title=\"tensorflow基础\"></a>tensorflow基础</h2><h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>tensorflow是一个编程系统，使用图(graphs)来表示计算任务，在会话(Seeeion)的context中执行graphs，graphs中的节点称为op(operation)，一个op获得零个或多个Tensor，执行计算产生零个或多个Tensor，Tensor可以看做n维数组或列表，图必须在会话中启动，通过变量(Variable)维护装填，使用feed和fetch可以为任意的操作赋值获从中获取数据。</p>\n<ul>\n<li><p>TensorFlow Core  |  TensorFlow<br><a href=\"https://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg\" target=\"_blank\" rel=\"noopener\">https://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg</a></p>\n</li>\n<li><p>优化器 Optimizer 加速神经网络训练 (深度学习) Speed up neural network training process (deep learning) - YouTube<br><a href=\"https://www.youtube.com/watch?v=UlUGGB7akfE&amp;list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&amp;index=18&amp;app=desktop\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=UlUGGB7akfE&amp;list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&amp;index=18&amp;app=desktop</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"tensorflow基础\"><a href=\"#tensorflow基础\" class=\"headerlink\" title=\"tensorflow基础\"></a>tensorflow基础</h2><h3 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>tensorflow是一个编程系统，使用图(graphs)来表示计算任务，在会话(Seeeion)的context中执行graphs，graphs中的节点称为op(operation)，一个op获得零个或多个Tensor，执行计算产生零个或多个Tensor，Tensor可以看做n维数组或列表，图必须在会话中启动，通过变量(Variable)维护装填，使用feed和fetch可以为任意的操作赋值获从中获取数据。</p>\n<ul>\n<li><p>TensorFlow Core  |  TensorFlow<br><a href=\"https://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg\" target=\"_blank\" rel=\"noopener\">https://tensorflow.google.cn/tutorials?tdsourcetag=s_pcqq_aiomsg</a></p>\n</li>\n<li><p>优化器 Optimizer 加速神经网络训练 (深度学习) Speed up neural network training process (deep learning) - YouTube<br><a href=\"https://www.youtube.com/watch?v=UlUGGB7akfE&amp;list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&amp;index=18&amp;app=desktop\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=UlUGGB7akfE&amp;list=PLXO45tsB95cKI5AIlf5TxxFPzb-0zeVZ8&amp;index=18&amp;app=desktop</a></p>\n</li>\n</ul>\n"},{"title":"Scikit-Learn学习笔记","date":"2019-05-02T12:56:38.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n\n## 选择学习方法\nSklearn官网提供了一个流程图\n<div align=center>\n<img src = \"Scikit-Learn学习笔记\\machine_learning_map.png\" width=600 height=300>\n</div>\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 通用学习模式\n### 导入模块\n``` python\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n```\n### 加载数据\n``` python\niris = datasets.load_iris()\niris_X = iris.data\niris_y = iris.target \nprint(iris_X[:2,:])\nprint(iris_y)\n```\n### 划分训练集和测试集\n``` python\nX_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size = 0.3)\n```\n### 创建模型，训练，预测\n``` python\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.predict(X_test))\nprint(y_test)\n```\n### 模型保存和加载\n* method 1: pickle\n\n``` python\nimport pickle\nfrom sklearn.externals import joblib\n# save\nwith open('clf.pickle', 'wb') as f:\n    pickle.dump(model, f)\n# restore\nwith open('clf.pickle', 'rb') as f:\n    model = pickle.load(f)\n```\n\n* method 2: joblib\n\n``` python\nfrom sklearn.externals import joblib\n# save\njoblib.dump(model, 'clf.plk')\n# restore\nmodel2 = joblib.load('clf.plk')\n```\n\n## datasets数据库 \n### sklearn.datasets\n* API Reference — scikit-learn 0.20.3 documentation  \nhttps://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n\n### Sklearn的数据表示\n* 数据表\n* 特征矩阵\n* 目标数组\n``` python\n# 用seaborn加载数据\nimport seaborn as sns\niris = sns.load_dataset('iris')\niris.head()\n# 可视化\n%matplotlib inline\nimport seaborn as sns; sns.set()\nsns.pairplot(iris, hue='species', size=1.5);\n# 抽取特征矩阵和目标数组\nX_iris = iris.drop('species', axis=1)\nX_iris.shape\ny_iris = iris['species']\ny_iris.shape\n```\n\n## Sklearn评估器API\n### 步骤 \n(1)选择模型类;  \n(2)配置模型超参数(hyperparameter);  \n(3)整理数据，获取特征矩阵和目标数组;  \n(4)调用模型实例的fit()方法对数据进行拟合;  \n(5)对新数据应用模型:有监督用predict()预测标签,无监督用transform()或predict()转换或推断数据性质。\n\n## model\n### 属性  \nmodel.intercept_  \nmodel.coef_  \n### 功能  \nmodel.predict  \nmodel.score  \n\n## 模型验证\n\n## 数据预处理\n### 标准化\n### 缺失值\n### 特征工程\n\n\n\n## 参考博客\n* jakevdp/PythonDataScienceHandbook: Python Data Science Handbook: full text in Jupyter Notebooks  \nhttps://github.com/jakevdp/PythonDataScienceHandbook  \n* 莫烦Python  \nhttps://morvanzhou.github.io/  \n* 使用sklearn做单机特征工程 - jasonfreak - 博客园  \nhttps://www.cnblogs.com/jasonfreak/p/5448385.html\n\n","source":"_posts/Scikit-Learn学习笔记.md","raw":"---\ntitle: Scikit-Learn学习笔记\ndate: 2019-05-02 20:56:38\ntags:\n  - sklearn\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n## 选择学习方法\nSklearn官网提供了一个流程图\n<div align=center>\n<img src = \"Scikit-Learn学习笔记\\machine_learning_map.png\" width=600 height=300>\n</div>\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 通用学习模式\n### 导入模块\n``` python\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\n```\n### 加载数据\n``` python\niris = datasets.load_iris()\niris_X = iris.data\niris_y = iris.target \nprint(iris_X[:2,:])\nprint(iris_y)\n```\n### 划分训练集和测试集\n``` python\nX_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size = 0.3)\n```\n### 创建模型，训练，预测\n``` python\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\nprint(knn.predict(X_test))\nprint(y_test)\n```\n### 模型保存和加载\n* method 1: pickle\n\n``` python\nimport pickle\nfrom sklearn.externals import joblib\n# save\nwith open('clf.pickle', 'wb') as f:\n    pickle.dump(model, f)\n# restore\nwith open('clf.pickle', 'rb') as f:\n    model = pickle.load(f)\n```\n\n* method 2: joblib\n\n``` python\nfrom sklearn.externals import joblib\n# save\njoblib.dump(model, 'clf.plk')\n# restore\nmodel2 = joblib.load('clf.plk')\n```\n\n## datasets数据库 \n### sklearn.datasets\n* API Reference — scikit-learn 0.20.3 documentation  \nhttps://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\n\n### Sklearn的数据表示\n* 数据表\n* 特征矩阵\n* 目标数组\n``` python\n# 用seaborn加载数据\nimport seaborn as sns\niris = sns.load_dataset('iris')\niris.head()\n# 可视化\n%matplotlib inline\nimport seaborn as sns; sns.set()\nsns.pairplot(iris, hue='species', size=1.5);\n# 抽取特征矩阵和目标数组\nX_iris = iris.drop('species', axis=1)\nX_iris.shape\ny_iris = iris['species']\ny_iris.shape\n```\n\n## Sklearn评估器API\n### 步骤 \n(1)选择模型类;  \n(2)配置模型超参数(hyperparameter);  \n(3)整理数据，获取特征矩阵和目标数组;  \n(4)调用模型实例的fit()方法对数据进行拟合;  \n(5)对新数据应用模型:有监督用predict()预测标签,无监督用transform()或predict()转换或推断数据性质。\n\n## model\n### 属性  \nmodel.intercept_  \nmodel.coef_  \n### 功能  \nmodel.predict  \nmodel.score  \n\n## 模型验证\n\n## 数据预处理\n### 标准化\n### 缺失值\n### 特征工程\n\n\n\n## 参考博客\n* jakevdp/PythonDataScienceHandbook: Python Data Science Handbook: full text in Jupyter Notebooks  \nhttps://github.com/jakevdp/PythonDataScienceHandbook  \n* 莫烦Python  \nhttps://morvanzhou.github.io/  \n* 使用sklearn做单机特征工程 - jasonfreak - 博客园  \nhttps://www.cnblogs.com/jasonfreak/p/5448385.html\n\n","slug":"Scikit-Learn学习笔记","published":1,"updated":"2019-06-23T07:09:39.754Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74u000trsvj6mwbl92u","content":"<p><strong> Scikit-Learn学习笔记：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"选择学习方法\"><a href=\"#选择学习方法\" class=\"headerlink\" title=\"选择学习方法\"></a>选择学习方法</h2><p>Sklearn官网提供了一个流程图</p>\n<p><div align=\"center\">\n<img src=\"/2019/05/02/Scikit-Learn学习笔记/machine_learning_map.png\" width=\"600\" height=\"300\">\n</div><br><a id=\"more\"></a></p>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"通用学习模式\"><a href=\"#通用学习模式\" class=\"headerlink\" title=\"通用学习模式\"></a>通用学习模式</h2><h3 id=\"导入模块\"><a href=\"#导入模块\" class=\"headerlink\" title=\"导入模块\"></a>导入模块</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cross_validation <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>\n<h3 id=\"加载数据\"><a href=\"#加载数据\" class=\"headerlink\" title=\"加载数据\"></a>加载数据</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">iris_X = iris.data</span><br><span class=\"line\">iris_y = iris.target </span><br><span class=\"line\">print(iris_X[:<span class=\"number\">2</span>,:])</span><br><span class=\"line\">print(iris_y)</span><br></pre></td></tr></table></figure>\n<h3 id=\"划分训练集和测试集\"><a href=\"#划分训练集和测试集\" class=\"headerlink\" title=\"划分训练集和测试集\"></a>划分训练集和测试集</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size = <span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"创建模型，训练，预测\"><a href=\"#创建模型，训练，预测\" class=\"headerlink\" title=\"创建模型，训练，预测\"></a>创建模型，训练，预测</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">knn = KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(X_train, y_train)</span><br><span class=\"line\">print(knn.predict(X_test))</span><br><span class=\"line\">print(y_test)</span><br></pre></td></tr></table></figure>\n<h3 id=\"模型保存和加载\"><a href=\"#模型保存和加载\" class=\"headerlink\" title=\"模型保存和加载\"></a>模型保存和加载</h3><ul>\n<li>method 1: pickle</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\"># save</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(<span class=\"string\">'clf.pickle'</span>, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(model, f)</span><br><span class=\"line\"><span class=\"comment\"># restore</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(<span class=\"string\">'clf.pickle'</span>, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    model = pickle.load(f)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>method 2: joblib</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\"># save</span></span><br><span class=\"line\">joblib.dump(model, <span class=\"string\">'clf.plk'</span>)</span><br><span class=\"line\"><span class=\"comment\"># restore</span></span><br><span class=\"line\">model2 = joblib.load(<span class=\"string\">'clf.plk'</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"datasets数据库\"><a href=\"#datasets数据库\" class=\"headerlink\" title=\"datasets数据库\"></a>datasets数据库</h2><h3 id=\"sklearn-datasets\"><a href=\"#sklearn-datasets\" class=\"headerlink\" title=\"sklearn.datasets\"></a>sklearn.datasets</h3><ul>\n<li>API Reference — scikit-learn 0.20.3 documentation<br><a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\" target=\"_blank\" rel=\"noopener\">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets</a></li>\n</ul>\n<h3 id=\"Sklearn的数据表示\"><a href=\"#Sklearn的数据表示\" class=\"headerlink\" title=\"Sklearn的数据表示\"></a>Sklearn的数据表示</h3><ul>\n<li>数据表</li>\n<li>特征矩阵</li>\n<li>目标数组<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 用seaborn加载数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">iris = sns.load_dataset(<span class=\"string\">'iris'</span>)</span><br><span class=\"line\">iris.head()</span><br><span class=\"line\"><span class=\"comment\"># 可视化</span></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns; sns.set()</span><br><span class=\"line\">sns.pairplot(iris, hue=<span class=\"string\">'species'</span>, size=<span class=\"number\">1.5</span>);</span><br><span class=\"line\"><span class=\"comment\"># 抽取特征矩阵和目标数组</span></span><br><span class=\"line\">X_iris = iris.drop(<span class=\"string\">'species'</span>, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">X_iris.shape</span><br><span class=\"line\">y_iris = iris[<span class=\"string\">'species'</span>]</span><br><span class=\"line\">y_iris.shape</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"Sklearn评估器API\"><a href=\"#Sklearn评估器API\" class=\"headerlink\" title=\"Sklearn评估器API\"></a>Sklearn评估器API</h2><h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><p>(1)选择模型类;<br>(2)配置模型超参数(hyperparameter);<br>(3)整理数据，获取特征矩阵和目标数组;<br>(4)调用模型实例的fit()方法对数据进行拟合;<br>(5)对新数据应用模型:有监督用predict()预测标签,无监督用transform()或predict()转换或推断数据性质。</p>\n<h2 id=\"model\"><a href=\"#model\" class=\"headerlink\" title=\"model\"></a>model</h2><h3 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h3><p>model.intercept_<br>model.coef_  </p>\n<h3 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h3><p>model.predict<br>model.score  </p>\n<h2 id=\"模型验证\"><a href=\"#模型验证\" class=\"headerlink\" title=\"模型验证\"></a>模型验证</h2><h2 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h2><h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><h3 id=\"缺失值\"><a href=\"#缺失值\" class=\"headerlink\" title=\"缺失值\"></a>缺失值</h3><h3 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>jakevdp/PythonDataScienceHandbook: Python Data Science Handbook: full text in Jupyter Notebooks<br><a href=\"https://github.com/jakevdp/PythonDataScienceHandbook\" target=\"_blank\" rel=\"noopener\">https://github.com/jakevdp/PythonDataScienceHandbook</a>  </li>\n<li>莫烦Python<br><a href=\"https://morvanzhou.github.io/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/</a>  </li>\n<li>使用sklearn做单机特征工程 - jasonfreak - 博客园<br><a href=\"https://www.cnblogs.com/jasonfreak/p/5448385.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jasonfreak/p/5448385.html</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> Scikit-Learn学习笔记：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"选择学习方法\"><a href=\"#选择学习方法\" class=\"headerlink\" title=\"选择学习方法\"></a>选择学习方法</h2><p>Sklearn官网提供了一个流程图</p>\n<p><div align=\"center\">\n<img src=\"/2019/05/02/Scikit-Learn学习笔记/machine_learning_map.png\" width=\"600\" height=\"300\">\n</div><br></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"通用学习模式\"><a href=\"#通用学习模式\" class=\"headerlink\" title=\"通用学习模式\"></a>通用学习模式</h2><h3 id=\"导入模块\"><a href=\"#导入模块\" class=\"headerlink\" title=\"导入模块\"></a>导入模块</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn <span class=\"keyword\">import</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.cross_validation <span class=\"keyword\">import</span> train_test_split</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.neighbors <span class=\"keyword\">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>\n<h3 id=\"加载数据\"><a href=\"#加载数据\" class=\"headerlink\" title=\"加载数据\"></a>加载数据</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">iris = datasets.load_iris()</span><br><span class=\"line\">iris_X = iris.data</span><br><span class=\"line\">iris_y = iris.target </span><br><span class=\"line\">print(iris_X[:<span class=\"number\">2</span>,:])</span><br><span class=\"line\">print(iris_y)</span><br></pre></td></tr></table></figure>\n<h3 id=\"划分训练集和测试集\"><a href=\"#划分训练集和测试集\" class=\"headerlink\" title=\"划分训练集和测试集\"></a>划分训练集和测试集</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">X_train, X_test, y_train, y_test = train_test_split(iris_X, iris_y, test_size = <span class=\"number\">0.3</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"创建模型，训练，预测\"><a href=\"#创建模型，训练，预测\" class=\"headerlink\" title=\"创建模型，训练，预测\"></a>创建模型，训练，预测</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">knn = KNeighborsClassifier()</span><br><span class=\"line\">knn.fit(X_train, y_train)</span><br><span class=\"line\">print(knn.predict(X_test))</span><br><span class=\"line\">print(y_test)</span><br></pre></td></tr></table></figure>\n<h3 id=\"模型保存和加载\"><a href=\"#模型保存和加载\" class=\"headerlink\" title=\"模型保存和加载\"></a>模型保存和加载</h3><ul>\n<li>method 1: pickle</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pickle</span><br><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\"># save</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(<span class=\"string\">'clf.pickle'</span>, <span class=\"string\">'wb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    pickle.dump(model, f)</span><br><span class=\"line\"><span class=\"comment\"># restore</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> open(<span class=\"string\">'clf.pickle'</span>, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    model = pickle.load(f)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>method 2: joblib</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> sklearn.externals <span class=\"keyword\">import</span> joblib</span><br><span class=\"line\"><span class=\"comment\"># save</span></span><br><span class=\"line\">joblib.dump(model, <span class=\"string\">'clf.plk'</span>)</span><br><span class=\"line\"><span class=\"comment\"># restore</span></span><br><span class=\"line\">model2 = joblib.load(<span class=\"string\">'clf.plk'</span>)</span><br></pre></td></tr></table></figure>\n<h2 id=\"datasets数据库\"><a href=\"#datasets数据库\" class=\"headerlink\" title=\"datasets数据库\"></a>datasets数据库</h2><h3 id=\"sklearn-datasets\"><a href=\"#sklearn-datasets\" class=\"headerlink\" title=\"sklearn.datasets\"></a>sklearn.datasets</h3><ul>\n<li>API Reference — scikit-learn 0.20.3 documentation<br><a href=\"https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets\" target=\"_blank\" rel=\"noopener\">https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets</a></li>\n</ul>\n<h3 id=\"Sklearn的数据表示\"><a href=\"#Sklearn的数据表示\" class=\"headerlink\" title=\"Sklearn的数据表示\"></a>Sklearn的数据表示</h3><ul>\n<li>数据表</li>\n<li>特征矩阵</li>\n<li>目标数组<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 用seaborn加载数据</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns</span><br><span class=\"line\">iris = sns.load_dataset(<span class=\"string\">'iris'</span>)</span><br><span class=\"line\">iris.head()</span><br><span class=\"line\"><span class=\"comment\"># 可视化</span></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"><span class=\"keyword\">import</span> seaborn <span class=\"keyword\">as</span> sns; sns.set()</span><br><span class=\"line\">sns.pairplot(iris, hue=<span class=\"string\">'species'</span>, size=<span class=\"number\">1.5</span>);</span><br><span class=\"line\"><span class=\"comment\"># 抽取特征矩阵和目标数组</span></span><br><span class=\"line\">X_iris = iris.drop(<span class=\"string\">'species'</span>, axis=<span class=\"number\">1</span>)</span><br><span class=\"line\">X_iris.shape</span><br><span class=\"line\">y_iris = iris[<span class=\"string\">'species'</span>]</span><br><span class=\"line\">y_iris.shape</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"Sklearn评估器API\"><a href=\"#Sklearn评估器API\" class=\"headerlink\" title=\"Sklearn评估器API\"></a>Sklearn评估器API</h2><h3 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a>步骤</h3><p>(1)选择模型类;<br>(2)配置模型超参数(hyperparameter);<br>(3)整理数据，获取特征矩阵和目标数组;<br>(4)调用模型实例的fit()方法对数据进行拟合;<br>(5)对新数据应用模型:有监督用predict()预测标签,无监督用transform()或predict()转换或推断数据性质。</p>\n<h2 id=\"model\"><a href=\"#model\" class=\"headerlink\" title=\"model\"></a>model</h2><h3 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性\"></a>属性</h3><p>model.intercept_<br>model.coef_  </p>\n<h3 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h3><p>model.predict<br>model.score  </p>\n<h2 id=\"模型验证\"><a href=\"#模型验证\" class=\"headerlink\" title=\"模型验证\"></a>模型验证</h2><h2 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h2><h3 id=\"标准化\"><a href=\"#标准化\" class=\"headerlink\" title=\"标准化\"></a>标准化</h3><h3 id=\"缺失值\"><a href=\"#缺失值\" class=\"headerlink\" title=\"缺失值\"></a>缺失值</h3><h3 id=\"特征工程\"><a href=\"#特征工程\" class=\"headerlink\" title=\"特征工程\"></a>特征工程</h3><h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>jakevdp/PythonDataScienceHandbook: Python Data Science Handbook: full text in Jupyter Notebooks<br><a href=\"https://github.com/jakevdp/PythonDataScienceHandbook\" target=\"_blank\" rel=\"noopener\">https://github.com/jakevdp/PythonDataScienceHandbook</a>  </li>\n<li>莫烦Python<br><a href=\"https://morvanzhou.github.io/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/</a>  </li>\n<li>使用sklearn做单机特征工程 - jasonfreak - 博客园<br><a href=\"https://www.cnblogs.com/jasonfreak/p/5448385.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/jasonfreak/p/5448385.html</a></li>\n</ul>\n</the>"},{"title":"loomo多服务机器人开发","date":"2019-05-26T11:43:22.000Z","_content":"\n## 设计思路\n\n<div align=center>\n<img alt=\"design\" src = \"loomo多服务机器人开发\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/loomo多服务机器人开发.md","raw":"---\ntitle: loomo多服务机器人开发\ndate: 2019-05-26 19:43:22\ntags:\n  - loomo\n  - Android\n  - 机械手\n---\n\n## 设计思路\n\n<div align=center>\n<img alt=\"design\" src = \"loomo多服务机器人开发\\设计思路-201905.png\" width=1000 height=800>\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"loomo多服务机器人开发","published":1,"updated":"2019-05-27T05:55:10.872Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74v000wrsvj2v9tlitp","content":"<h2 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h2><div align=\"center\">\n<img alt=\"design\" src=\"/2019/05/26/loomo多服务机器人开发/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"设计思路\"><a href=\"#设计思路\" class=\"headerlink\" title=\"设计思路\"></a>设计思路</h2><div align=\"center\">\n<img alt=\"design\" src=\"/2019/05/26/loomo多服务机器人开发/设计思路-201905.png\" width=\"1000\" height=\"800\">\n</div>\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"},{"title":"tkinter学习笔记","date":"2019-05-11T06:28:52.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n## tkinter 可以使用的颜色\n\n<div align=center>\n<img src = \"tkinter学习笔记/color.png\" width=600 height=300>\n</div>\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## tkinter python（图形开发界面）\nTkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。Tk和Tkinter可以在大多数的Unix平台下使用，同样可以应用在Windows和Macintosh系统里。由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。\n``` python\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\nimport tkinter as tk\ntop = tk.Tk()\n# 进入消息循环\ntop.mainloop()\n```\n\n## tkinter 常用控件\n\n• tk.Tk()  \n• tk.Lable()   \n• tk.button()   \n• tk.Entry()  \n• tk.Text()  \n• tk.Radiobutton()  \n• tk.Scale()  \n• tk.Canvas()  \n\n### 标签\n可以显示文本和位图\n\n### 按键\n按钮组件用于在 Python 应用程序中添加按钮，按钮上可以放上文本或图像，按钮可用于监听用户行为，能够与一个 Python 函数关联，当按钮被按下时，自动调用该函数。\n``` python\nwindows = tk.Tk()\nwindows.title('hello')\nwindows.geometry('200x100')\n\nvar = tk.StringVar()\nlable = tk.Label(windows, textvariable=var, bg='green', font=('Arial', 15), width=15, height=2)\nlable.pack()\n\non_hit = False\ndef hit_me():\n    global on_hit\n    if on_hit == False:\n        var.set('u hit me')\n        on_hit = True\n    else:\n        on_hit = False\n        var.set('')\n\nbutton = tk.Button(windows, text='hit me', command=hit_me, width=15, height=2)\nbutton.pack()\n\nwindows.mainloop()\n```\n\n### 画布\n``` python\nwindows = tk.Tk()\nwindows.title('hey')\nwindows.geometry(\"200x200\")\n\nconvas = tk.Canvas(windows, bg='blue', height=100, width=200).pack()\nimage_file = tk.PhotoImage(file='ins.gif')\nimage = canvas.creat_image(10, 10, anchor='nw', image=image_file)\ndef hi():\n    pass\n\nbutton = tk.Button(windows, text='hi', command=hi).pack()\n\nwindows.mainloop()\n```\n### 弹窗\n\n\n\n* Python Tkinter教程（GUI图形界面开发教程）  \nhttp://c.biancheng.net/python/tkinter/\n* Tkinter GUI 教程系列 | 莫烦Python  \nhttps://morvanzhou.github.io/tutorials/python-basic/tkinter/","source":"_posts/tkinter学习笔记.md","raw":"---\ntitle: tkinter学习笔记\ndate: 2019-05-11 14:28:52\ntags:\n  - tkinter\n  - python\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n## tkinter 可以使用的颜色\n\n<div align=center>\n<img src = \"tkinter学习笔记/color.png\" width=600 height=300>\n</div>\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## tkinter python（图形开发界面）\nTkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。Tk和Tkinter可以在大多数的Unix平台下使用，同样可以应用在Windows和Macintosh系统里。由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。\n``` python\n#!/usr/bin/python\n# -*- coding: UTF-8 -*-\nimport tkinter as tk\ntop = tk.Tk()\n# 进入消息循环\ntop.mainloop()\n```\n\n## tkinter 常用控件\n\n• tk.Tk()  \n• tk.Lable()   \n• tk.button()   \n• tk.Entry()  \n• tk.Text()  \n• tk.Radiobutton()  \n• tk.Scale()  \n• tk.Canvas()  \n\n### 标签\n可以显示文本和位图\n\n### 按键\n按钮组件用于在 Python 应用程序中添加按钮，按钮上可以放上文本或图像，按钮可用于监听用户行为，能够与一个 Python 函数关联，当按钮被按下时，自动调用该函数。\n``` python\nwindows = tk.Tk()\nwindows.title('hello')\nwindows.geometry('200x100')\n\nvar = tk.StringVar()\nlable = tk.Label(windows, textvariable=var, bg='green', font=('Arial', 15), width=15, height=2)\nlable.pack()\n\non_hit = False\ndef hit_me():\n    global on_hit\n    if on_hit == False:\n        var.set('u hit me')\n        on_hit = True\n    else:\n        on_hit = False\n        var.set('')\n\nbutton = tk.Button(windows, text='hit me', command=hit_me, width=15, height=2)\nbutton.pack()\n\nwindows.mainloop()\n```\n\n### 画布\n``` python\nwindows = tk.Tk()\nwindows.title('hey')\nwindows.geometry(\"200x200\")\n\nconvas = tk.Canvas(windows, bg='blue', height=100, width=200).pack()\nimage_file = tk.PhotoImage(file='ins.gif')\nimage = canvas.creat_image(10, 10, anchor='nw', image=image_file)\ndef hi():\n    pass\n\nbutton = tk.Button(windows, text='hi', command=hi).pack()\n\nwindows.mainloop()\n```\n### 弹窗\n\n\n\n* Python Tkinter教程（GUI图形界面开发教程）  \nhttp://c.biancheng.net/python/tkinter/\n* Tkinter GUI 教程系列 | 莫烦Python  \nhttps://morvanzhou.github.io/tutorials/python-basic/tkinter/","slug":"tkinter学习笔记","published":1,"updated":"2019-06-23T07:09:39.761Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74w000yrsvjusoshyse","content":"<p><strong> tkinter学习笔记：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"tkinter-可以使用的颜色\"><a href=\"#tkinter-可以使用的颜色\" class=\"headerlink\" title=\"tkinter 可以使用的颜色\"></a>tkinter 可以使用的颜色</h2><div align=\"center\">\n<img src=\"/2019/05/11/tkinter学习笔记/color.png\" width=\"600\" height=\"300\">\n</div>\n\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"tkinter-python（图形开发界面）\"><a href=\"#tkinter-python（图形开发界面）\" class=\"headerlink\" title=\"tkinter python（图形开发界面）\"></a>tkinter python（图形开发界面）</h2><p>Tkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。Tk和Tkinter可以在大多数的Unix平台下使用，同样可以应用在Windows和Macintosh系统里。由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: UTF-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter <span class=\"keyword\">as</span> tk</span><br><span class=\"line\">top = tk.Tk()</span><br><span class=\"line\"><span class=\"comment\"># 进入消息循环</span></span><br><span class=\"line\">top.mainloop()</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"tkinter-常用控件\"><a href=\"#tkinter-常用控件\" class=\"headerlink\" title=\"tkinter 常用控件\"></a>tkinter 常用控件</h2><p>• tk.Tk()<br>• tk.Lable()<br>• tk.button()<br>• tk.Entry()<br>• tk.Text()<br>• tk.Radiobutton()<br>• tk.Scale()<br>• tk.Canvas()  </p>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><p>可以显示文本和位图</p>\n<h3 id=\"按键\"><a href=\"#按键\" class=\"headerlink\" title=\"按键\"></a>按键</h3><p>按钮组件用于在 Python 应用程序中添加按钮，按钮上可以放上文本或图像，按钮可用于监听用户行为，能够与一个 Python 函数关联，当按钮被按下时，自动调用该函数。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows = tk.Tk()</span><br><span class=\"line\">windows.title(<span class=\"string\">'hello'</span>)</span><br><span class=\"line\">windows.geometry(<span class=\"string\">'200x100'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">var = tk.StringVar()</span><br><span class=\"line\">lable = tk.Label(windows, textvariable=var, bg=<span class=\"string\">'green'</span>, font=(<span class=\"string\">'Arial'</span>, <span class=\"number\">15</span>), width=<span class=\"number\">15</span>, height=<span class=\"number\">2</span>)</span><br><span class=\"line\">lable.pack()</span><br><span class=\"line\"></span><br><span class=\"line\">on_hit = <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hit_me</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> on_hit</span><br><span class=\"line\">    <span class=\"keyword\">if</span> on_hit == <span class=\"literal\">False</span>:</span><br><span class=\"line\">        var.set(<span class=\"string\">'u hit me'</span>)</span><br><span class=\"line\">        on_hit = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        on_hit = <span class=\"literal\">False</span></span><br><span class=\"line\">        var.set(<span class=\"string\">''</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">button = tk.Button(windows, text=<span class=\"string\">'hit me'</span>, command=hit_me, width=<span class=\"number\">15</span>, height=<span class=\"number\">2</span>)</span><br><span class=\"line\">button.pack()</span><br><span class=\"line\"></span><br><span class=\"line\">windows.mainloop()</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"画布\"><a href=\"#画布\" class=\"headerlink\" title=\"画布\"></a>画布</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows = tk.Tk()</span><br><span class=\"line\">windows.title(<span class=\"string\">'hey'</span>)</span><br><span class=\"line\">windows.geometry(<span class=\"string\">\"200x200\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">convas = tk.Canvas(windows, bg=<span class=\"string\">'blue'</span>, height=<span class=\"number\">100</span>, width=<span class=\"number\">200</span>).pack()</span><br><span class=\"line\">image_file = tk.PhotoImage(file=<span class=\"string\">'ins.gif'</span>)</span><br><span class=\"line\">image = canvas.creat_image(<span class=\"number\">10</span>, <span class=\"number\">10</span>, anchor=<span class=\"string\">'nw'</span>, image=image_file)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hi</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">button = tk.Button(windows, text=<span class=\"string\">'hi'</span>, command=hi).pack()</span><br><span class=\"line\"></span><br><span class=\"line\">windows.mainloop()</span><br></pre></td></tr></table></figure>\n<h3 id=\"弹窗\"><a href=\"#弹窗\" class=\"headerlink\" title=\"弹窗\"></a>弹窗</h3><ul>\n<li>Python Tkinter教程（GUI图形界面开发教程）<br><a href=\"http://c.biancheng.net/python/tkinter/\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/python/tkinter/</a></li>\n<li>Tkinter GUI 教程系列 | 莫烦Python<br><a href=\"https://morvanzhou.github.io/tutorials/python-basic/tkinter/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/tutorials/python-basic/tkinter/</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> tkinter学习笔记：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"tkinter-可以使用的颜色\"><a href=\"#tkinter-可以使用的颜色\" class=\"headerlink\" title=\"tkinter 可以使用的颜色\"></a>tkinter 可以使用的颜色</h2><div align=\"center\">\n<img src=\"/2019/05/11/tkinter学习笔记/color.png\" width=\"600\" height=\"300\">\n</div>","more":"<the rest of contents | 余下全文>\n\n\n<h2 id=\"tkinter-python（图形开发界面）\"><a href=\"#tkinter-python（图形开发界面）\" class=\"headerlink\" title=\"tkinter python（图形开发界面）\"></a>tkinter python（图形开发界面）</h2><p>Tkinter 是 Python 的标准 GUI 库。Python 使用 Tkinter 可以快速的创建 GUI 应用程序。Tk和Tkinter可以在大多数的Unix平台下使用，同样可以应用在Windows和Macintosh系统里。由于 Tkinter 是内置到 python 的安装包中、只要安装好 Python 之后就能 import Tkinter 库、而且 IDLE 也是用 Tkinter 编写而成、对于简单的图形界面 Tkinter 还是能应付自如。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#!/usr/bin/python</span></span><br><span class=\"line\"><span class=\"comment\"># -*- coding: UTF-8 -*-</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter <span class=\"keyword\">as</span> tk</span><br><span class=\"line\">top = tk.Tk()</span><br><span class=\"line\"><span class=\"comment\"># 进入消息循环</span></span><br><span class=\"line\">top.mainloop()</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"tkinter-常用控件\"><a href=\"#tkinter-常用控件\" class=\"headerlink\" title=\"tkinter 常用控件\"></a>tkinter 常用控件</h2><p>• tk.Tk()<br>• tk.Lable()<br>• tk.button()<br>• tk.Entry()<br>• tk.Text()<br>• tk.Radiobutton()<br>• tk.Scale()<br>• tk.Canvas()  </p>\n<h3 id=\"标签\"><a href=\"#标签\" class=\"headerlink\" title=\"标签\"></a>标签</h3><p>可以显示文本和位图</p>\n<h3 id=\"按键\"><a href=\"#按键\" class=\"headerlink\" title=\"按键\"></a>按键</h3><p>按钮组件用于在 Python 应用程序中添加按钮，按钮上可以放上文本或图像，按钮可用于监听用户行为，能够与一个 Python 函数关联，当按钮被按下时，自动调用该函数。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows = tk.Tk()</span><br><span class=\"line\">windows.title(<span class=\"string\">'hello'</span>)</span><br><span class=\"line\">windows.geometry(<span class=\"string\">'200x100'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">var = tk.StringVar()</span><br><span class=\"line\">lable = tk.Label(windows, textvariable=var, bg=<span class=\"string\">'green'</span>, font=(<span class=\"string\">'Arial'</span>, <span class=\"number\">15</span>), width=<span class=\"number\">15</span>, height=<span class=\"number\">2</span>)</span><br><span class=\"line\">lable.pack()</span><br><span class=\"line\"></span><br><span class=\"line\">on_hit = <span class=\"literal\">False</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hit_me</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">global</span> on_hit</span><br><span class=\"line\">    <span class=\"keyword\">if</span> on_hit == <span class=\"literal\">False</span>:</span><br><span class=\"line\">        var.set(<span class=\"string\">'u hit me'</span>)</span><br><span class=\"line\">        on_hit = <span class=\"literal\">True</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        on_hit = <span class=\"literal\">False</span></span><br><span class=\"line\">        var.set(<span class=\"string\">''</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">button = tk.Button(windows, text=<span class=\"string\">'hit me'</span>, command=hit_me, width=<span class=\"number\">15</span>, height=<span class=\"number\">2</span>)</span><br><span class=\"line\">button.pack()</span><br><span class=\"line\"></span><br><span class=\"line\">windows.mainloop()</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"画布\"><a href=\"#画布\" class=\"headerlink\" title=\"画布\"></a>画布</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows = tk.Tk()</span><br><span class=\"line\">windows.title(<span class=\"string\">'hey'</span>)</span><br><span class=\"line\">windows.geometry(<span class=\"string\">\"200x200\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">convas = tk.Canvas(windows, bg=<span class=\"string\">'blue'</span>, height=<span class=\"number\">100</span>, width=<span class=\"number\">200</span>).pack()</span><br><span class=\"line\">image_file = tk.PhotoImage(file=<span class=\"string\">'ins.gif'</span>)</span><br><span class=\"line\">image = canvas.creat_image(<span class=\"number\">10</span>, <span class=\"number\">10</span>, anchor=<span class=\"string\">'nw'</span>, image=image_file)</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">hi</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">button = tk.Button(windows, text=<span class=\"string\">'hi'</span>, command=hi).pack()</span><br><span class=\"line\"></span><br><span class=\"line\">windows.mainloop()</span><br></pre></td></tr></table></figure>\n<h3 id=\"弹窗\"><a href=\"#弹窗\" class=\"headerlink\" title=\"弹窗\"></a>弹窗</h3><ul>\n<li>Python Tkinter教程（GUI图形界面开发教程）<br><a href=\"http://c.biancheng.net/python/tkinter/\" target=\"_blank\" rel=\"noopener\">http://c.biancheng.net/python/tkinter/</a></li>\n<li>Tkinter GUI 教程系列 | 莫烦Python<br><a href=\"https://morvanzhou.github.io/tutorials/python-basic/tkinter/\" target=\"_blank\" rel=\"noopener\">https://morvanzhou.github.io/tutorials/python-basic/tkinter/</a></li>\n</ul>\n</the>"},{"title":"作业检查机器人","date":"2019-06-10T02:55:10.000Z","_content":"\n# 100以内加减法（小学二年级）算数机器人\n\n## 当前的功能\n拍一张答题纸，画四个点，透射变换为标准尺寸后进行算式分割，对每张算式图片检测识别数字后进行计算，并打印结果;  \n手指指到相应算式下方，语音播报该计算结果。\n\n## 待解决的问题\n* 阴影下识别出错\n\n## 接下来的工作\n* 写字机器人接入?\n* 更复杂的算式？\n\n## Demo\n<div align=center>\n<iframe height=498 width=510 src=\"http://player.youku.com/embed/XNDIyNzA4NDM0MA==\">\n</iframe>\n</div>\n\n* 算数-其他-高清完整正版视频在线观看-优酷  \nhttps://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html\n\n\n\n## 愉快地一天\nQ: 如何才能有很多作品，参加很多比赛？\n<div align=center>\n<img src='作业检查机器人/002.png' width=700 height=450>\n</div>\n","source":"_posts/作业检查机器人.md","raw":"---\ntitle: 作业检查机器人 \ndate: 2019-06-10 10:55:10\ntags:\n - python\n - opencv\n---\n\n# 100以内加减法（小学二年级）算数机器人\n\n## 当前的功能\n拍一张答题纸，画四个点，透射变换为标准尺寸后进行算式分割，对每张算式图片检测识别数字后进行计算，并打印结果;  \n手指指到相应算式下方，语音播报该计算结果。\n\n## 待解决的问题\n* 阴影下识别出错\n\n## 接下来的工作\n* 写字机器人接入?\n* 更复杂的算式？\n\n## Demo\n<div align=center>\n<iframe height=498 width=510 src=\"http://player.youku.com/embed/XNDIyNzA4NDM0MA==\">\n</iframe>\n</div>\n\n* 算数-其他-高清完整正版视频在线观看-优酷  \nhttps://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html\n\n\n\n## 愉快地一天\nQ: 如何才能有很多作品，参加很多比赛？\n<div align=center>\n<img src='作业检查机器人/002.png' width=700 height=450>\n</div>\n","slug":"作业检查机器人","published":1,"updated":"2019-06-23T07:09:39.767Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74x0010rsvjd2dvqzp8","content":"<h1 id=\"100以内加减法（小学二年级）算数机器人\"><a href=\"#100以内加减法（小学二年级）算数机器人\" class=\"headerlink\" title=\"100以内加减法（小学二年级）算数机器人\"></a>100以内加减法（小学二年级）算数机器人</h1><h2 id=\"当前的功能\"><a href=\"#当前的功能\" class=\"headerlink\" title=\"当前的功能\"></a>当前的功能</h2><p>拍一张答题纸，画四个点，透射变换为标准尺寸后进行算式分割，对每张算式图片检测识别数字后进行计算，并打印结果;<br>手指指到相应算式下方，语音播报该计算结果。</p>\n<h2 id=\"待解决的问题\"><a href=\"#待解决的问题\" class=\"headerlink\" title=\"待解决的问题\"></a>待解决的问题</h2><ul>\n<li>阴影下识别出错</li>\n</ul>\n<h2 id=\"接下来的工作\"><a href=\"#接下来的工作\" class=\"headerlink\" title=\"接下来的工作\"></a>接下来的工作</h2><ul>\n<li>写字机器人接入?</li>\n<li>更复杂的算式？</li>\n</ul>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><div align=\"center\">\n<iframe height=\"498\" width=\"510\" src=\"http://player.youku.com/embed/XNDIyNzA4NDM0MA==\">\n</iframe>\n</div>\n\n<ul>\n<li>算数-其他-高清完整正版视频在线观看-优酷<br><a href=\"https://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html\" target=\"_blank\" rel=\"noopener\">https://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html</a></li>\n</ul>\n<h2 id=\"愉快地一天\"><a href=\"#愉快地一天\" class=\"headerlink\" title=\"愉快地一天\"></a>愉快地一天</h2><p>Q: 如何才能有很多作品，参加很多比赛？</p>\n<div align=\"center\">\n<img src=\"/2019/06/10/作业检查机器人/002.png\" width=\"700\" height=\"450\">\n</div>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"100以内加减法（小学二年级）算数机器人\"><a href=\"#100以内加减法（小学二年级）算数机器人\" class=\"headerlink\" title=\"100以内加减法（小学二年级）算数机器人\"></a>100以内加减法（小学二年级）算数机器人</h1><h2 id=\"当前的功能\"><a href=\"#当前的功能\" class=\"headerlink\" title=\"当前的功能\"></a>当前的功能</h2><p>拍一张答题纸，画四个点，透射变换为标准尺寸后进行算式分割，对每张算式图片检测识别数字后进行计算，并打印结果;<br>手指指到相应算式下方，语音播报该计算结果。</p>\n<h2 id=\"待解决的问题\"><a href=\"#待解决的问题\" class=\"headerlink\" title=\"待解决的问题\"></a>待解决的问题</h2><ul>\n<li>阴影下识别出错</li>\n</ul>\n<h2 id=\"接下来的工作\"><a href=\"#接下来的工作\" class=\"headerlink\" title=\"接下来的工作\"></a>接下来的工作</h2><ul>\n<li>写字机器人接入?</li>\n<li>更复杂的算式？</li>\n</ul>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><div align=\"center\">\n<iframe height=\"498\" width=\"510\" src=\"http://player.youku.com/embed/XNDIyNzA4NDM0MA==\">\n</iframe>\n</div>\n\n<ul>\n<li>算数-其他-高清完整正版视频在线观看-优酷<br><a href=\"https://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html\" target=\"_blank\" rel=\"noopener\">https://v.youku.com/v_show/id_XNDIyNzA4NDM0MA==.html</a></li>\n</ul>\n<h2 id=\"愉快地一天\"><a href=\"#愉快地一天\" class=\"headerlink\" title=\"愉快地一天\"></a>愉快地一天</h2><p>Q: 如何才能有很多作品，参加很多比赛？</p>\n<div align=\"center\">\n<img src=\"/2019/06/10/作业检查机器人/002.png\" width=\"700\" height=\"450\">\n</div>\n"},{"title":"人生苦短，我用python","date":"2019-05-16T15:56:01.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n\nLife is short, you need Python \n1989 年，为了打发无所事事的圣诞节假期，Guido 开始写 Python 语言的编译/解释器，Python这个名字来自他所喜欢的电视剧 Monty Python's Flying Circus (一部情景幽默剧)。两年后，Python 第一个版本终于问世。\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n\n## 迭代器\n迭代器（iterator）是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素，每个迭代器对象代表容器中的确定的地址。\n\n``` python\ni = iter(range(10))\nnext(i)\n```\n我们简单说迭代器就是访问集合元素，迭代器就是有一个next()方法的对象，而不是通过索引来计数的。\n\n\n## test\nQ1: 计算一年的第几天\n``` python\nimport datetime\nres = datetime.date(year, month, day) - datetime.date(year-1, 12, 31)\n```\n\nQ2: 找最小数\n``` python\nalist = list(map(int, input().split()))\nres = min(alist)\n```\n\nQ3: 大于平均值的数的和\n``` python\nres = sum([i for i in alist if i > sum(alist)/len(alist)])\n```\n\nQ4: 数列求和\n``` python\nres = sum([1/(i*2) for i in range(1, n)])\n```\n\n\n\n\n## 云服务器运行Jupyter Notebook\n\n配置云服务器的安全组  \n控制台>轻量应用服务器>服务器列表>Ubuntu>安全>防火墙>添加规则\n\n|应用类型 | 协议 | 端口范围 |\n|:---------|:--------------------|:----------------|\n|自定义 | TCP | 8888/8890 |\n\n安装Jupyter\n``` bash\n$ apt-get update\n$ sudo apt install jupyter-notebook\n$ apt-get install python3-pip\n$ pip3 install --upgrade pip\n$ pip3 install jupyter\n```\n创建Jupyter默认配置文件\n``` bash\n$ jupyter notebook --generate-config\n```\n生成SHA1加密的密钥，保存密钥，如'sha1:XXXXXX'\n``` bash\n$ python\n>>> from notebook.auth import passwd \n>>> passwd()\n```\n设置密钥，修改配置文件\n``` bash\n$ sudo vim ~/.jupyter/jupyter_notebook_config.py\n\n    c.NotebookApp.allow_remote_access = True\n    c.NotebookApp.ip = '*'\n    c.NotebookApp.open_browser = False\n    c.NotebookApp.password = u'sha1:XXXXXX'\n    c.NotebookApp.port = 8888\n```\n启动Jupter notebook\n``` bash\n$ jupyter notebook --ip=0.0.0.0 --no-browser --allow-root\n```\n\n## 一些加速技巧\n\n加速查找  \n``` python\ndata = (i**2+1 for i in range(1000000))\n%%time\nlist_data = list(data)\n4535251 in list_data\n\n%%time\nset_data = set(data)\n4535251 in set_data\n```\n\n加速函数  \n``` python\n%%time\ndef fib(n):\n    return(1 if n in (1,2) else fib(n-1)+fib(n-2))\nfib(30)\n```\n* 用缓存机制加速递归函数  \n``` python\n%%time\nfrom functools import lru_cache\n@lru_cache(100)\ndef fib(n):\n    return(1 if n in (1,2) else fib(n-1)+fib(n-2))\nfib(30)\n```\n* 用循环机制代替递归函数  \n``` python\n%%time\ndef fib(n):\n    if n in (1,2):\n        return n\n    a, b = 1, 1\n    for i in range(2,n):\n        a, b = b, a+b\n    return b\nfib(30)\n```\n* 使用map代替推导式进行加速  \n``` python \n%%time\nalist = [i**2 for i in range(1000)]\n%%time\nalist = map(lambda x: x**2, range(1000))\n```\n* 使用filter代替推导式进行加速  \n``` python \n%%time\nalist = [i for i in range(1000) if i%7==0]\n%%time\nalist = filter(lambda x: x%7==0, range(1000))\n```\n\n使用np.where代替if  \n``` python\n%%time\nrelu = lambda x:np.where(x>0, x, 0)\narray_b = relu(array_a)\n```\n\n应用多线程加速IO密集型任务  \n应用多进程加速CPU密集型任务  \n\n\n\n### \n\n* 03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客  \nhttps://blog.csdn.net/ds19991999/article/details/81275580","source":"_posts/人生苦短，我用python.md","raw":"---\ntitle: 人生苦短，我用python\ndate: 2019-05-16 23:56:01\ntags:\n  - python\n  - jupyter notebook\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\nLife is short, you need Python \n1989 年，为了打发无所事事的圣诞节假期，Guido 开始写 Python 语言的编译/解释器，Python这个名字来自他所喜欢的电视剧 Monty Python's Flying Circus (一部情景幽默剧)。两年后，Python 第一个版本终于问世。\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n\n## 迭代器\n迭代器（iterator）是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素，每个迭代器对象代表容器中的确定的地址。\n\n``` python\ni = iter(range(10))\nnext(i)\n```\n我们简单说迭代器就是访问集合元素，迭代器就是有一个next()方法的对象，而不是通过索引来计数的。\n\n\n## test\nQ1: 计算一年的第几天\n``` python\nimport datetime\nres = datetime.date(year, month, day) - datetime.date(year-1, 12, 31)\n```\n\nQ2: 找最小数\n``` python\nalist = list(map(int, input().split()))\nres = min(alist)\n```\n\nQ3: 大于平均值的数的和\n``` python\nres = sum([i for i in alist if i > sum(alist)/len(alist)])\n```\n\nQ4: 数列求和\n``` python\nres = sum([1/(i*2) for i in range(1, n)])\n```\n\n\n\n\n## 云服务器运行Jupyter Notebook\n\n配置云服务器的安全组  \n控制台>轻量应用服务器>服务器列表>Ubuntu>安全>防火墙>添加规则\n\n|应用类型 | 协议 | 端口范围 |\n|:---------|:--------------------|:----------------|\n|自定义 | TCP | 8888/8890 |\n\n安装Jupyter\n``` bash\n$ apt-get update\n$ sudo apt install jupyter-notebook\n$ apt-get install python3-pip\n$ pip3 install --upgrade pip\n$ pip3 install jupyter\n```\n创建Jupyter默认配置文件\n``` bash\n$ jupyter notebook --generate-config\n```\n生成SHA1加密的密钥，保存密钥，如'sha1:XXXXXX'\n``` bash\n$ python\n>>> from notebook.auth import passwd \n>>> passwd()\n```\n设置密钥，修改配置文件\n``` bash\n$ sudo vim ~/.jupyter/jupyter_notebook_config.py\n\n    c.NotebookApp.allow_remote_access = True\n    c.NotebookApp.ip = '*'\n    c.NotebookApp.open_browser = False\n    c.NotebookApp.password = u'sha1:XXXXXX'\n    c.NotebookApp.port = 8888\n```\n启动Jupter notebook\n``` bash\n$ jupyter notebook --ip=0.0.0.0 --no-browser --allow-root\n```\n\n## 一些加速技巧\n\n加速查找  \n``` python\ndata = (i**2+1 for i in range(1000000))\n%%time\nlist_data = list(data)\n4535251 in list_data\n\n%%time\nset_data = set(data)\n4535251 in set_data\n```\n\n加速函数  \n``` python\n%%time\ndef fib(n):\n    return(1 if n in (1,2) else fib(n-1)+fib(n-2))\nfib(30)\n```\n* 用缓存机制加速递归函数  \n``` python\n%%time\nfrom functools import lru_cache\n@lru_cache(100)\ndef fib(n):\n    return(1 if n in (1,2) else fib(n-1)+fib(n-2))\nfib(30)\n```\n* 用循环机制代替递归函数  \n``` python\n%%time\ndef fib(n):\n    if n in (1,2):\n        return n\n    a, b = 1, 1\n    for i in range(2,n):\n        a, b = b, a+b\n    return b\nfib(30)\n```\n* 使用map代替推导式进行加速  \n``` python \n%%time\nalist = [i**2 for i in range(1000)]\n%%time\nalist = map(lambda x: x**2, range(1000))\n```\n* 使用filter代替推导式进行加速  \n``` python \n%%time\nalist = [i for i in range(1000) if i%7==0]\n%%time\nalist = filter(lambda x: x%7==0, range(1000))\n```\n\n使用np.where代替if  \n``` python\n%%time\nrelu = lambda x:np.where(x>0, x, 0)\narray_b = relu(array_a)\n```\n\n应用多线程加速IO密集型任务  \n应用多进程加速CPU密集型任务  \n\n\n\n### \n\n* 03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客  \nhttps://blog.csdn.net/ds19991999/article/details/81275580","slug":"人生苦短，我用python","published":1,"updated":"2019-06-23T07:09:39.764Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74x0012rsvjj59io5x8","content":"<p><strong> 人生苦短，我用python：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<p>Life is short, you need Python<br>1989 年，为了打发无所事事的圣诞节假期，Guido 开始写 Python 语言的编译/解释器，Python这个名字来自他所喜欢的电视剧 Monty Python’s Flying Circus (一部情景幽默剧)。两年后，Python 第一个版本终于问世。</p>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n\n<h2 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h2><p>迭代器（iterator）是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素，每个迭代器对象代表容器中的确定的地址。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i = iter(range(<span class=\"number\">10</span>))</span><br><span class=\"line\">next(i)</span><br></pre></td></tr></table></figure>\n<p>我们简单说迭代器就是访问集合元素，迭代器就是有一个next()方法的对象，而不是通过索引来计数的。</p>\n<h2 id=\"test\"><a href=\"#test\" class=\"headerlink\" title=\"test\"></a>test</h2><p>Q1: 计算一年的第几天<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\">res = datetime.date(year, month, day) - datetime.date(year<span class=\"number\">-1</span>, <span class=\"number\">12</span>, <span class=\"number\">31</span>)</span><br></pre></td></tr></table></figure></p>\n<p>Q2: 找最小数<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alist = list(map(int, input().split()))</span><br><span class=\"line\">res = min(alist)</span><br></pre></td></tr></table></figure></p>\n<p>Q3: 大于平均值的数的和<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">res = sum([i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> alist <span class=\"keyword\">if</span> i &gt; sum(alist)/len(alist)])</span><br></pre></td></tr></table></figure></p>\n<p>Q4: 数列求和<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">res = sum([<span class=\"number\">1</span>/(i*<span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n)])</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"云服务器运行Jupyter-Notebook\"><a href=\"#云服务器运行Jupyter-Notebook\" class=\"headerlink\" title=\"云服务器运行Jupyter Notebook\"></a>云服务器运行Jupyter Notebook</h2><p>配置云服务器的安全组<br>控制台&gt;轻量应用服务器&gt;服务器列表&gt;Ubuntu&gt;安全&gt;防火墙&gt;添加规则</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">应用类型</th>\n<th style=\"text-align:left\">协议</th>\n<th style=\"text-align:left\">端口范围</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">自定义</td>\n<td style=\"text-align:left\">TCP</td>\n<td style=\"text-align:left\">8888/8890</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>安装Jupyter<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ apt-get update</span><br><span class=\"line\">$ sudo apt install jupyter-notebook</span><br><span class=\"line\">$ apt-get install python3-pip</span><br><span class=\"line\">$ pip3 install --upgrade pip</span><br><span class=\"line\">$ pip3 install jupyter</span><br></pre></td></tr></table></figure></p>\n<p>创建Jupyter默认配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></p>\n<p>生成SHA1加密的密钥，保存密钥，如’sha1:XXXXXX’<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; from notebook.auth import passwd </span><br><span class=\"line\">&gt;&gt;&gt; passwd()</span><br></pre></td></tr></table></figure></p>\n<p>设置密钥，修改配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim ~/.jupyter/jupyter_notebook_config.py</span><br><span class=\"line\"></span><br><span class=\"line\">    c.NotebookApp.allow_remote_access = True</span><br><span class=\"line\">    c.NotebookApp.ip = <span class=\"string\">'*'</span></span><br><span class=\"line\">    c.NotebookApp.open_browser = False</span><br><span class=\"line\">    c.NotebookApp.password = u<span class=\"string\">'sha1:XXXXXX'</span></span><br><span class=\"line\">    c.NotebookApp.port = 8888</span><br></pre></td></tr></table></figure></p>\n<p>启动Jupter notebook<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jupyter notebook --ip=0.0.0.0 --no-browser --allow-root</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"一些加速技巧\"><a href=\"#一些加速技巧\" class=\"headerlink\" title=\"一些加速技巧\"></a>一些加速技巧</h2><p>加速查找<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = (i**<span class=\"number\">2</span>+<span class=\"number\">1</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000000</span>))</span><br><span class=\"line\">%%time</span><br><span class=\"line\">list_data = list(data)</span><br><span class=\"line\"><span class=\"number\">4535251</span> <span class=\"keyword\">in</span> list_data</span><br><span class=\"line\"></span><br><span class=\"line\">%%time</span><br><span class=\"line\">set_data = set(data)</span><br><span class=\"line\"><span class=\"number\">4535251</span> <span class=\"keyword\">in</span> set_data</span><br></pre></td></tr></table></figure></p>\n<p>加速函数<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span>(<span class=\"number\">1</span> <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>) <span class=\"keyword\">else</span> fib(n<span class=\"number\">-1</span>)+fib(n<span class=\"number\">-2</span>))</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li><p>用缓存机制加速递归函数  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"keyword\">from</span> functools <span class=\"keyword\">import</span> lru_cache</span><br><span class=\"line\"><span class=\"meta\">@lru_cache(100)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span>(<span class=\"number\">1</span> <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>) <span class=\"keyword\">else</span> fib(n<span class=\"number\">-1</span>)+fib(n<span class=\"number\">-2</span>))</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>用循环机制代替递归函数  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> n</span><br><span class=\"line\">    a, b = <span class=\"number\">1</span>, <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>,n):</span><br><span class=\"line\">        a, b = b, a+b</span><br><span class=\"line\">    <span class=\"keyword\">return</span> b</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用map代替推导式进行加速  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">alist = [i**<span class=\"number\">2</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>)]</span><br><span class=\"line\">%%time</span><br><span class=\"line\">alist = map(<span class=\"keyword\">lambda</span> x: x**<span class=\"number\">2</span>, range(<span class=\"number\">1000</span>))</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用filter代替推导式进行加速  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">alist = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>) <span class=\"keyword\">if</span> i%<span class=\"number\">7</span>==<span class=\"number\">0</span>]</span><br><span class=\"line\">%%time</span><br><span class=\"line\">alist = filter(<span class=\"keyword\">lambda</span> x: x%<span class=\"number\">7</span>==<span class=\"number\">0</span>, range(<span class=\"number\">1000</span>))</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使用np.where代替if<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">relu = <span class=\"keyword\">lambda</span> x:np.where(x&gt;<span class=\"number\">0</span>, x, <span class=\"number\">0</span>)</span><br><span class=\"line\">array_b = relu(array_a)</span><br></pre></td></tr></table></figure></p>\n<p>应用多线程加速IO密集型任务<br>应用多进程加速CPU密集型任务  </p>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><ul>\n<li>03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ds19991999/article/details/81275580\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ds19991999/article/details/81275580</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 人生苦短，我用python：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<p>Life is short, you need Python<br>1989 年，为了打发无所事事的圣诞节假期，Guido 开始写 Python 语言的编译/解释器，Python这个名字来自他所喜欢的电视剧 Monty Python’s Flying Circus (一部情景幽默剧)。两年后，Python 第一个版本终于问世。</p>","more":"<the rest of contents | 余下全文>\n\n\n\n<h2 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h2><p>迭代器（iterator）是一种对象，它能够用来遍历标准模板库容器中的部分或全部元素，每个迭代器对象代表容器中的确定的地址。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">i = iter(range(<span class=\"number\">10</span>))</span><br><span class=\"line\">next(i)</span><br></pre></td></tr></table></figure>\n<p>我们简单说迭代器就是访问集合元素，迭代器就是有一个next()方法的对象，而不是通过索引来计数的。</p>\n<h2 id=\"test\"><a href=\"#test\" class=\"headerlink\" title=\"test\"></a>test</h2><p>Q1: 计算一年的第几天<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> datetime</span><br><span class=\"line\">res = datetime.date(year, month, day) - datetime.date(year<span class=\"number\">-1</span>, <span class=\"number\">12</span>, <span class=\"number\">31</span>)</span><br></pre></td></tr></table></figure></p>\n<p>Q2: 找最小数<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">alist = list(map(int, input().split()))</span><br><span class=\"line\">res = min(alist)</span><br></pre></td></tr></table></figure></p>\n<p>Q3: 大于平均值的数的和<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">res = sum([i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> alist <span class=\"keyword\">if</span> i &gt; sum(alist)/len(alist)])</span><br></pre></td></tr></table></figure></p>\n<p>Q4: 数列求和<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">res = sum([<span class=\"number\">1</span>/(i*<span class=\"number\">2</span>) <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>, n)])</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"云服务器运行Jupyter-Notebook\"><a href=\"#云服务器运行Jupyter-Notebook\" class=\"headerlink\" title=\"云服务器运行Jupyter Notebook\"></a>云服务器运行Jupyter Notebook</h2><p>配置云服务器的安全组<br>控制台&gt;轻量应用服务器&gt;服务器列表&gt;Ubuntu&gt;安全&gt;防火墙&gt;添加规则</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th style=\"text-align:left\">应用类型</th>\n<th style=\"text-align:left\">协议</th>\n<th style=\"text-align:left\">端口范围</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:left\">自定义</td>\n<td style=\"text-align:left\">TCP</td>\n<td style=\"text-align:left\">8888/8890</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>安装Jupyter<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ apt-get update</span><br><span class=\"line\">$ sudo apt install jupyter-notebook</span><br><span class=\"line\">$ apt-get install python3-pip</span><br><span class=\"line\">$ pip3 install --upgrade pip</span><br><span class=\"line\">$ pip3 install jupyter</span><br></pre></td></tr></table></figure></p>\n<p>创建Jupyter默认配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jupyter notebook --generate-config</span><br></pre></td></tr></table></figure></p>\n<p>生成SHA1加密的密钥，保存密钥，如’sha1:XXXXXX’<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python</span><br><span class=\"line\">&gt;&gt;&gt; from notebook.auth import passwd </span><br><span class=\"line\">&gt;&gt;&gt; passwd()</span><br></pre></td></tr></table></figure></p>\n<p>设置密钥，修改配置文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim ~/.jupyter/jupyter_notebook_config.py</span><br><span class=\"line\"></span><br><span class=\"line\">    c.NotebookApp.allow_remote_access = True</span><br><span class=\"line\">    c.NotebookApp.ip = <span class=\"string\">'*'</span></span><br><span class=\"line\">    c.NotebookApp.open_browser = False</span><br><span class=\"line\">    c.NotebookApp.password = u<span class=\"string\">'sha1:XXXXXX'</span></span><br><span class=\"line\">    c.NotebookApp.port = 8888</span><br></pre></td></tr></table></figure></p>\n<p>启动Jupter notebook<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ jupyter notebook --ip=0.0.0.0 --no-browser --allow-root</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"一些加速技巧\"><a href=\"#一些加速技巧\" class=\"headerlink\" title=\"一些加速技巧\"></a>一些加速技巧</h2><p>加速查找<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = (i**<span class=\"number\">2</span>+<span class=\"number\">1</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000000</span>))</span><br><span class=\"line\">%%time</span><br><span class=\"line\">list_data = list(data)</span><br><span class=\"line\"><span class=\"number\">4535251</span> <span class=\"keyword\">in</span> list_data</span><br><span class=\"line\"></span><br><span class=\"line\">%%time</span><br><span class=\"line\">set_data = set(data)</span><br><span class=\"line\"><span class=\"number\">4535251</span> <span class=\"keyword\">in</span> set_data</span><br></pre></td></tr></table></figure></p>\n<p>加速函数<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span>(<span class=\"number\">1</span> <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>) <span class=\"keyword\">else</span> fib(n<span class=\"number\">-1</span>)+fib(n<span class=\"number\">-2</span>))</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li><p>用缓存机制加速递归函数  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"keyword\">from</span> functools <span class=\"keyword\">import</span> lru_cache</span><br><span class=\"line\"><span class=\"meta\">@lru_cache(100)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span>(<span class=\"number\">1</span> <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>) <span class=\"keyword\">else</span> fib(n<span class=\"number\">-1</span>)+fib(n<span class=\"number\">-2</span>))</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>用循环机制代替递归函数  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fib</span><span class=\"params\">(n)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> n <span class=\"keyword\">in</span> (<span class=\"number\">1</span>,<span class=\"number\">2</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> n</span><br><span class=\"line\">    a, b = <span class=\"number\">1</span>, <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">2</span>,n):</span><br><span class=\"line\">        a, b = b, a+b</span><br><span class=\"line\">    <span class=\"keyword\">return</span> b</span><br><span class=\"line\">fib(<span class=\"number\">30</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用map代替推导式进行加速  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">alist = [i**<span class=\"number\">2</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>)]</span><br><span class=\"line\">%%time</span><br><span class=\"line\">alist = map(<span class=\"keyword\">lambda</span> x: x**<span class=\"number\">2</span>, range(<span class=\"number\">1000</span>))</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用filter代替推导式进行加速  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">alist = [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1000</span>) <span class=\"keyword\">if</span> i%<span class=\"number\">7</span>==<span class=\"number\">0</span>]</span><br><span class=\"line\">%%time</span><br><span class=\"line\">alist = filter(<span class=\"keyword\">lambda</span> x: x%<span class=\"number\">7</span>==<span class=\"number\">0</span>, range(<span class=\"number\">1000</span>))</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>使用np.where代替if<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%%time</span><br><span class=\"line\">relu = <span class=\"keyword\">lambda</span> x:np.where(x&gt;<span class=\"number\">0</span>, x, <span class=\"number\">0</span>)</span><br><span class=\"line\">array_b = relu(array_a)</span><br></pre></td></tr></table></figure></p>\n<p>应用多线程加速IO密集型任务<br>应用多进程加速CPU密集型任务  </p>\n<h3 id><a href=\"#\" class=\"headerlink\" title=\" \"></a> </h3><ul>\n<li>03-用Jupyter编写数学公式 - ds19991999的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/ds19991999/article/details/81275580\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/ds19991999/article/details/81275580</a></li>\n</ul>\n</the>"},{"title":"打磨工具的日常","date":"2019-04-26T01:57:47.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n* MobaXterm\n* cloc\n* Mathpix Snip \n* \n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 终端工具：MobaXterm\n\nMobaXterm这个软件很低调，一直没有发现这个软件，直到有一天它出现在了知乎的一个角落，下载试用一下，发现它是一款令人痴迷的终端神器，很全能，很Geek。它支持SSH、VNC、Serial、FTP、X11、RDP、MOSH等等协议的连接，于是，我的电脑上原有的XShell、XFTP、VNC Viewer都退役了。同时，它又是一个X服务器和Unix工具箱，它支持以X服务器为基础的X.org，可以轻松地模拟GNU Unix的指令，甚至可以集成一些插件之后 Emacs、Gcc, G++ and development tools、MPlayer、Perl、Curl等程序，拥有极强的拓展性。同时，它还有很舒适的用户界面和诸多个性化的配置选项，用户体验极佳。\n\n* MobaXterm官网  \nhttps://mobaxterm.mobatek.net/\n* MobaXterm下载链接  \nhttps://mobaxterm.mobatek.net/download.html\n\n\n\n\n\n将目录下所有文件生成树结构\n``` bash\n$ tree . >contest.txt /f\n```\n\n使用pip命令自动生成项目安装依赖清单\n``` bash\n$ pip freeze > requirements.txt\n```\n\n使用cloc进行代码统计  \nCloc官网下载exe文件，放于当前目标文件夹下\n``` bash\n$ cloc .\n```\n\n\n* 推荐九个堪称神器的命令行工具给程序员们-技术圈-程序员客栈 </br>https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg\n\n\n* 【必须收藏】那些酷炫的深度学习网络图怎么画出来的？ - 知乎 </br>https://zhuanlan.zhihu.com/p/68007906\n\n\n## 公式输入工具：Mathpix Snip \n只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  \n\n* Mathpix Snip  \nhttps://mathpix.com/\n\n\n## Chrome插件\n* Momentum\n漂亮的背景图片、时间显示、天气预报、收藏夹、待办事项的功能\n* Vimium \nVimium 这个名字其实是 Vim 和 Chromium 的合体。她继承了Vim的常用操作，完全脱离鼠标来控制浏览器，是一款黑客级别的Chrome插件。对熟悉linux的同学来说，简直是神器。  \n* OneTab\n将许多Tab合并在一个页面。  \n我之前的常用方法是不关闭浏览器重启电脑。\n* octotree\n浏览github项目结构。\n\n* chrome上有哪些牛逼的插件？ - 知乎  \nhttps://www.zhihu.com/question/64829125\n","source":"_posts/打磨工具的日常.md","raw":"---\ntitle: 打磨工具的日常\ndate: 2019-04-26 09:57:47\ntags:\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n* MobaXterm\n* cloc\n* Mathpix Snip \n* \n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 终端工具：MobaXterm\n\nMobaXterm这个软件很低调，一直没有发现这个软件，直到有一天它出现在了知乎的一个角落，下载试用一下，发现它是一款令人痴迷的终端神器，很全能，很Geek。它支持SSH、VNC、Serial、FTP、X11、RDP、MOSH等等协议的连接，于是，我的电脑上原有的XShell、XFTP、VNC Viewer都退役了。同时，它又是一个X服务器和Unix工具箱，它支持以X服务器为基础的X.org，可以轻松地模拟GNU Unix的指令，甚至可以集成一些插件之后 Emacs、Gcc, G++ and development tools、MPlayer、Perl、Curl等程序，拥有极强的拓展性。同时，它还有很舒适的用户界面和诸多个性化的配置选项，用户体验极佳。\n\n* MobaXterm官网  \nhttps://mobaxterm.mobatek.net/\n* MobaXterm下载链接  \nhttps://mobaxterm.mobatek.net/download.html\n\n\n\n\n\n将目录下所有文件生成树结构\n``` bash\n$ tree . >contest.txt /f\n```\n\n使用pip命令自动生成项目安装依赖清单\n``` bash\n$ pip freeze > requirements.txt\n```\n\n使用cloc进行代码统计  \nCloc官网下载exe文件，放于当前目标文件夹下\n``` bash\n$ cloc .\n```\n\n\n* 推荐九个堪称神器的命令行工具给程序员们-技术圈-程序员客栈 </br>https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg\n\n\n* 【必须收藏】那些酷炫的深度学习网络图怎么画出来的？ - 知乎 </br>https://zhuanlan.zhihu.com/p/68007906\n\n\n## 公式输入工具：Mathpix Snip \n只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  \n\n* Mathpix Snip  \nhttps://mathpix.com/\n\n\n## Chrome插件\n* Momentum\n漂亮的背景图片、时间显示、天气预报、收藏夹、待办事项的功能\n* Vimium \nVimium 这个名字其实是 Vim 和 Chromium 的合体。她继承了Vim的常用操作，完全脱离鼠标来控制浏览器，是一款黑客级别的Chrome插件。对熟悉linux的同学来说，简直是神器。  \n* OneTab\n将许多Tab合并在一个页面。  \n我之前的常用方法是不关闭浏览器重启电脑。\n* octotree\n浏览github项目结构。\n\n* chrome上有哪些牛逼的插件？ - 知乎  \nhttps://www.zhihu.com/question/64829125\n","slug":"打磨工具的日常","published":1,"updated":"2019-07-05T17:30:23.180Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74y0014rsvjkp3vb0an","content":"<p><strong> 打磨工具的日常：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>MobaXterm</li>\n<li>cloc</li>\n<li>Mathpix Snip </li>\n<li><a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n</the></li>\n</ul>\n<h2 id=\"终端工具：MobaXterm\"><a href=\"#终端工具：MobaXterm\" class=\"headerlink\" title=\"终端工具：MobaXterm\"></a>终端工具：MobaXterm</h2><p>MobaXterm这个软件很低调，一直没有发现这个软件，直到有一天它出现在了知乎的一个角落，下载试用一下，发现它是一款令人痴迷的终端神器，很全能，很Geek。它支持SSH、VNC、Serial、FTP、X11、RDP、MOSH等等协议的连接，于是，我的电脑上原有的XShell、XFTP、VNC Viewer都退役了。同时，它又是一个X服务器和Unix工具箱，它支持以X服务器为基础的X.org，可以轻松地模拟GNU Unix的指令，甚至可以集成一些插件之后 Emacs、Gcc, G++ and development tools、MPlayer、Perl、Curl等程序，拥有极强的拓展性。同时，它还有很舒适的用户界面和诸多个性化的配置选项，用户体验极佳。</p>\n<ul>\n<li>MobaXterm官网<br><a href=\"https://mobaxterm.mobatek.net/\" target=\"_blank\" rel=\"noopener\">https://mobaxterm.mobatek.net/</a></li>\n<li>MobaXterm下载链接<br><a href=\"https://mobaxterm.mobatek.net/download.html\" target=\"_blank\" rel=\"noopener\">https://mobaxterm.mobatek.net/download.html</a></li>\n</ul>\n<p>将目录下所有文件生成树结构<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree . &gt;contest.txt /f</span><br></pre></td></tr></table></figure></p>\n<p>使用pip命令自动生成项目安装依赖清单<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure></p>\n<p>使用cloc进行代码统计<br>Cloc官网下载exe文件，放于当前目标文件夹下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cloc .</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>推荐九个堪称神器的命令行工具给程序员们-技术圈-程序员客栈 &lt;/br&gt;<a href=\"https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg\" target=\"_blank\" rel=\"noopener\">https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg</a></li>\n</ul>\n<ul>\n<li>【必须收藏】那些酷炫的深度学习网络图怎么画出来的？ - 知乎 &lt;/br&gt;<a href=\"https://zhuanlan.zhihu.com/p/68007906\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/68007906</a></li>\n</ul>\n<h2 id=\"公式输入工具：Mathpix-Snip\"><a href=\"#公式输入工具：Mathpix-Snip\" class=\"headerlink\" title=\"公式输入工具：Mathpix Snip\"></a>公式输入工具：Mathpix Snip</h2><p>只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  </p>\n<ul>\n<li>Mathpix Snip<br><a href=\"https://mathpix.com/\" target=\"_blank\" rel=\"noopener\">https://mathpix.com/</a></li>\n</ul>\n<h2 id=\"Chrome插件\"><a href=\"#Chrome插件\" class=\"headerlink\" title=\"Chrome插件\"></a>Chrome插件</h2><ul>\n<li>Momentum<br>漂亮的背景图片、时间显示、天气预报、收藏夹、待办事项的功能</li>\n<li>Vimium<br>Vimium 这个名字其实是 Vim 和 Chromium 的合体。她继承了Vim的常用操作，完全脱离鼠标来控制浏览器，是一款黑客级别的Chrome插件。对熟悉linux的同学来说，简直是神器。  </li>\n<li>OneTab<br>将许多Tab合并在一个页面。<br>我之前的常用方法是不关闭浏览器重启电脑。</li>\n<li><p>octotree<br>浏览github项目结构。</p>\n</li>\n<li><p>chrome上有哪些牛逼的插件？ - 知乎<br><a href=\"https://www.zhihu.com/question/64829125\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/64829125</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p><strong> 打磨工具的日常：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>MobaXterm</li>\n<li>cloc</li>\n<li>Mathpix Snip </li>\n<li></li></ul>","more":"<the rest of contents | 余下全文>\n\n\n</the>\n\n<h2 id=\"终端工具：MobaXterm\"><a href=\"#终端工具：MobaXterm\" class=\"headerlink\" title=\"终端工具：MobaXterm\"></a>终端工具：MobaXterm</h2><p>MobaXterm这个软件很低调，一直没有发现这个软件，直到有一天它出现在了知乎的一个角落，下载试用一下，发现它是一款令人痴迷的终端神器，很全能，很Geek。它支持SSH、VNC、Serial、FTP、X11、RDP、MOSH等等协议的连接，于是，我的电脑上原有的XShell、XFTP、VNC Viewer都退役了。同时，它又是一个X服务器和Unix工具箱，它支持以X服务器为基础的X.org，可以轻松地模拟GNU Unix的指令，甚至可以集成一些插件之后 Emacs、Gcc, G++ and development tools、MPlayer、Perl、Curl等程序，拥有极强的拓展性。同时，它还有很舒适的用户界面和诸多个性化的配置选项，用户体验极佳。</p>\n<ul>\n<li>MobaXterm官网<br><a href=\"https://mobaxterm.mobatek.net/\" target=\"_blank\" rel=\"noopener\">https://mobaxterm.mobatek.net/</a></li>\n<li>MobaXterm下载链接<br><a href=\"https://mobaxterm.mobatek.net/download.html\" target=\"_blank\" rel=\"noopener\">https://mobaxterm.mobatek.net/download.html</a></li>\n</ul>\n<p>将目录下所有文件生成树结构<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ tree . &gt;contest.txt /f</span><br></pre></td></tr></table></figure></p>\n<p>使用pip命令自动生成项目安装依赖清单<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip freeze &gt; requirements.txt</span><br></pre></td></tr></table></figure></p>\n<p>使用cloc进行代码统计<br>Cloc官网下载exe文件，放于当前目标文件夹下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ cloc .</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>推荐九个堪称神器的命令行工具给程序员们-技术圈-程序员客栈 &lt;/br&gt;<a href=\"https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg\" target=\"_blank\" rel=\"noopener\">https://www.proginn.com/community/topics/3555?tdsourcetag=s_pcqq_aiomsg</a></li>\n</ul>\n<ul>\n<li>【必须收藏】那些酷炫的深度学习网络图怎么画出来的？ - 知乎 &lt;/br&gt;<a href=\"https://zhuanlan.zhihu.com/p/68007906\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/68007906</a></li>\n</ul>\n<h2 id=\"公式输入工具：Mathpix-Snip\"><a href=\"#公式输入工具：Mathpix-Snip\" class=\"headerlink\" title=\"公式输入工具：Mathpix Snip\"></a>公式输入工具：Mathpix Snip</h2><p>只要截图就能识别公式，手写的公式都能识别，可以方便转换图片的公式到word、markdown和latex文件。  </p>\n<ul>\n<li>Mathpix Snip<br><a href=\"https://mathpix.com/\" target=\"_blank\" rel=\"noopener\">https://mathpix.com/</a></li>\n</ul>\n<h2 id=\"Chrome插件\"><a href=\"#Chrome插件\" class=\"headerlink\" title=\"Chrome插件\"></a>Chrome插件</h2><ul>\n<li>Momentum<br>漂亮的背景图片、时间显示、天气预报、收藏夹、待办事项的功能</li>\n<li>Vimium<br>Vimium 这个名字其实是 Vim 和 Chromium 的合体。她继承了Vim的常用操作，完全脱离鼠标来控制浏览器，是一款黑客级别的Chrome插件。对熟悉linux的同学来说，简直是神器。  </li>\n<li>OneTab<br>将许多Tab合并在一个页面。<br>我之前的常用方法是不关闭浏览器重启电脑。</li>\n<li><p>octotree<br>浏览github项目结构。</p>\n</li>\n<li><p>chrome上有哪些牛逼的插件？ - 知乎<br><a href=\"https://www.zhihu.com/question/64829125\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/64829125</a></p>\n</li>\n</ul>"},{"title":"天猫精灵：绑定贝壳物联设备","date":"2019-04-27T16:39:24.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n## 整体方案\n目前天猫精灵绑定贝壳物联账号后，即可使用天猫精灵控制贝壳物联账号下设备；\nesp8266开机自动连接路由器，连接贝壳物联服务器，登陆设备，监听服务器发送消息，根据不同消息控制gpio引脚输出高低电平，从而达到给出控制信号的目的；\nMCU接受esp8266引脚信号，完成控制步进电机拉窗帘等动作。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n* NodeMcu 物联网开发板 ESP8266无线收发模块\n* 天猫精灵\n\n## 天猫精灵绑定贝壳物联设备\n登录贝壳物联，创建智能设备\n* 首页-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/\n下载天猫精灵APP，添加智能设备，绑定贝壳物联账号，选择设备\n\n## esp8266配置\n\n* [NodeMCU固件](https://www.bigiot.net/Public/upload/UEditor/file/20160322/1458642990199254.rar)\n* 烧录工具 ESP8266Flasher\n* IDE NodeMCU Studio 2015  \n\n刷写固件，并写入启动脚本（LED=4）\n登录用户中心对话设备，遥控设备输入play、stop验证，LED灯是否有变化。\n\n## 参考资料\n\n* 贝壳物联平台通讯协议-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/help/1.html\n* 远程控制通讯——基于NodeMCU固件的ESP8266控制LED灯并返回控制结果-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/help/20.html\n* 天猫精灵绑定控制贝壳物联设备方法-贝壳物联，让你与智能设备沟通更方便的物联网云平台 </br>https://www.bigiot.net/talk/359.html\n","source":"_posts/天猫精灵：绑定贝壳物联设备.md","raw":"---\ntitle: 天猫精灵：绑定贝壳物联设备\ndate: 2019-04-28 00:39:24\ntags:\n  - 天猫精灵\n  - esp8266\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n## 整体方案\n目前天猫精灵绑定贝壳物联账号后，即可使用天猫精灵控制贝壳物联账号下设备；\nesp8266开机自动连接路由器，连接贝壳物联服务器，登陆设备，监听服务器发送消息，根据不同消息控制gpio引脚输出高低电平，从而达到给出控制信号的目的；\nMCU接受esp8266引脚信号，完成控制步进电机拉窗帘等动作。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n* NodeMcu 物联网开发板 ESP8266无线收发模块\n* 天猫精灵\n\n## 天猫精灵绑定贝壳物联设备\n登录贝壳物联，创建智能设备\n* 首页-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/\n下载天猫精灵APP，添加智能设备，绑定贝壳物联账号，选择设备\n\n## esp8266配置\n\n* [NodeMCU固件](https://www.bigiot.net/Public/upload/UEditor/file/20160322/1458642990199254.rar)\n* 烧录工具 ESP8266Flasher\n* IDE NodeMCU Studio 2015  \n\n刷写固件，并写入启动脚本（LED=4）\n登录用户中心对话设备，遥控设备输入play、stop验证，LED灯是否有变化。\n\n## 参考资料\n\n* 贝壳物联平台通讯协议-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/help/1.html\n* 远程控制通讯——基于NodeMCU固件的ESP8266控制LED灯并返回控制结果-贝壳物联，让你与智能设备沟通更方便的物联网云平台</br>https://www.bigiot.net/help/20.html\n* 天猫精灵绑定控制贝壳物联设备方法-贝壳物联，让你与智能设备沟通更方便的物联网云平台 </br>https://www.bigiot.net/talk/359.html\n","slug":"天猫精灵：绑定贝壳物联设备","published":1,"updated":"2019-06-25T00:44:24.724Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm74z0016rsvjv63wlyv3","content":"<p><strong> 天猫精灵：绑定贝壳物联设备：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"整体方案\"><a href=\"#整体方案\" class=\"headerlink\" title=\"整体方案\"></a>整体方案</h2><p>目前天猫精灵绑定贝壳物联账号后，即可使用天猫精灵控制贝壳物联账号下设备；<br>esp8266开机自动连接路由器，连接贝壳物联服务器，登陆设备，监听服务器发送消息，根据不同消息控制gpio引脚输出高低电平，从而达到给出控制信号的目的；<br>MCU接受esp8266引脚信号，完成控制步进电机拉窗帘等动作。<br><a id=\"more\"></a></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>NodeMcu 物联网开发板 ESP8266无线收发模块</li>\n<li>天猫精灵</li>\n</ul>\n<h2 id=\"天猫精灵绑定贝壳物联设备\"><a href=\"#天猫精灵绑定贝壳物联设备\" class=\"headerlink\" title=\"天猫精灵绑定贝壳物联设备\"></a>天猫精灵绑定贝壳物联设备</h2><p>登录贝壳物联，创建智能设备</p>\n<ul>\n<li>首页-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/</a><br>下载天猫精灵APP，添加智能设备，绑定贝壳物联账号，选择设备</li>\n</ul>\n<h2 id=\"esp8266配置\"><a href=\"#esp8266配置\" class=\"headerlink\" title=\"esp8266配置\"></a>esp8266配置</h2><ul>\n<li><a href=\"https://www.bigiot.net/Public/upload/UEditor/file/20160322/1458642990199254.rar\" target=\"_blank\" rel=\"noopener\">NodeMCU固件</a></li>\n<li>烧录工具 ESP8266Flasher</li>\n<li>IDE NodeMCU Studio 2015  </li>\n</ul>\n<p>刷写固件，并写入启动脚本（LED=4）<br>登录用户中心对话设备，遥控设备输入play、stop验证，LED灯是否有变化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>贝壳物联平台通讯协议-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/help/1.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/help/1.html</a></li>\n<li>远程控制通讯——基于NodeMCU固件的ESP8266控制LED灯并返回控制结果-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/help/20.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/help/20.html</a></li>\n<li>天猫精灵绑定控制贝壳物联设备方法-贝壳物联，让你与智能设备沟通更方便的物联网云平台 &lt;/br&gt;<a href=\"https://www.bigiot.net/talk/359.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/talk/359.html</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 天猫精灵：绑定贝壳物联设备：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"整体方案\"><a href=\"#整体方案\" class=\"headerlink\" title=\"整体方案\"></a>整体方案</h2><p>目前天猫精灵绑定贝壳物联账号后，即可使用天猫精灵控制贝壳物联账号下设备；<br>esp8266开机自动连接路由器，连接贝壳物联服务器，登陆设备，监听服务器发送消息，根据不同消息控制gpio引脚输出高低电平，从而达到给出控制信号的目的；<br>MCU接受esp8266引脚信号，完成控制步进电机拉窗帘等动作。<br></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>NodeMcu 物联网开发板 ESP8266无线收发模块</li>\n<li>天猫精灵</li>\n</ul>\n<h2 id=\"天猫精灵绑定贝壳物联设备\"><a href=\"#天猫精灵绑定贝壳物联设备\" class=\"headerlink\" title=\"天猫精灵绑定贝壳物联设备\"></a>天猫精灵绑定贝壳物联设备</h2><p>登录贝壳物联，创建智能设备</p>\n<ul>\n<li>首页-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/</a><br>下载天猫精灵APP，添加智能设备，绑定贝壳物联账号，选择设备</li>\n</ul>\n<h2 id=\"esp8266配置\"><a href=\"#esp8266配置\" class=\"headerlink\" title=\"esp8266配置\"></a>esp8266配置</h2><ul>\n<li><a href=\"https://www.bigiot.net/Public/upload/UEditor/file/20160322/1458642990199254.rar\" target=\"_blank\" rel=\"noopener\">NodeMCU固件</a></li>\n<li>烧录工具 ESP8266Flasher</li>\n<li>IDE NodeMCU Studio 2015  </li>\n</ul>\n<p>刷写固件，并写入启动脚本（LED=4）<br>登录用户中心对话设备，遥控设备输入play、stop验证，LED灯是否有变化。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>贝壳物联平台通讯协议-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/help/1.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/help/1.html</a></li>\n<li>远程控制通讯——基于NodeMCU固件的ESP8266控制LED灯并返回控制结果-贝壳物联，让你与智能设备沟通更方便的物联网云平台&lt;/br&gt;<a href=\"https://www.bigiot.net/help/20.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/help/20.html</a></li>\n<li>天猫精灵绑定控制贝壳物联设备方法-贝壳物联，让你与智能设备沟通更方便的物联网云平台 &lt;/br&gt;<a href=\"https://www.bigiot.net/talk/359.html\" target=\"_blank\" rel=\"noopener\">https://www.bigiot.net/talk/359.html</a></li>\n</ul>\n</the>"},{"title":"树莓派3b 编译安装OpenCV-4.0.0 for Python3","date":"2019-04-20T13:14:22.000Z","_content":"\n## 准备\n\n### 调整SWAP分区\n\n``` bash\n$ cd /var && ls\n```\n卸载swap文件\n``` bash\n$ sudo swapoff swap\n```\n查看一下\n``` bash\n$ htop\n```\n创建一个更大的swap文件\n``` bash\n$ sudo dd if=/dev/zero of=swap bs=1M count=2048\n```\n装载新的swap文件\n``` bash\n$ sudo mkswap swap \n$ sudo swapon swap \n```\n可以在htop中看到新的swap分区大小为2GB，完成\n\n### 相关依赖\n\n``` bash\n$ sudo apt-get install build-essential cmake pkg-config\n$ sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev\n$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\n$ sudo apt-get install libxvidcore-dev libx264-dev\n$ sudo apt-get install libgtk2.0-dev\n$ sudo apt-get install libatlas-base-dev gfortran\n$ sudo apt-get install python2.7-dev python3-dev\n```\n\n安装numpy\n``` bash\n$ pip3 install numpy\n```\n\n### 下载opencv源码\n``` bash\n$ cd Documents/\n$ wget https://github.com/opencv/opencv/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n```\n\n## 编译\n\n### 进入虚拟环境\n``` bash\n$ cd python-env\n$ pyvenv py35\n$ source python-env/py35/bin/activate\n```\n\n### 设置编译环境\n安装cmake-qt-gui，使用图形界面\n``` bash\n$ cd Documents/opencv-4.0.0/\n$ mkdir build\n$ cd build/\n$ sudo apt-get install cmake-qt-gui\n$ (venv) pi@raspberrypi:~/Documents/opencv-4.0.0/build $ cmake-gui\n```\n\n选择源文件路径，编译文件夹选择刚才新建的build文件夹\n点击左下角Configure，第一次完成是红色的，再点一次就变成白色了，如图</br>\n\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png\" width=600 height=300>\n\n然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0的路径填进去，点击Configure，如图\n\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png\" width=600 height=300>\n\n这样OpenCV_Contrib-4.0.0就被添加进去了，然后我们修改关于Python的参数，在查找栏键入PYTHON：取消BIULD_opencv_python2，勾选INSTALL_PYTHON_EXMAPLES，这样就设置为编译Python3的版本了，再次点击Configure，如图：\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png\" width=600 height=300>\n\n然后就可以生成编译文件了，点击Generate</br>\n\n### 编译\n键入下述命令开始编译，有风扇-j4，没风扇-j2-j3\n``` bash\n$ make -j4\n```\n安装\n``` bash\n$ sudo make install \n$ sudo ldconfig\n```\n因编译后的库文件cv2.so被输出为 cv2.cpython-35m-arm-linux-gnueabihf.so，这将导致该模块在Python3中无法import进来\n``` bash\n$ sudo cp /usr/local/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/local/lib/python3.5/dist-packages\n$ cd /usr/local/lib/python3.5/dist-packages/\n$ sudo mv cv2.cpython-35m-arm-linux-gnueabihf.so cv.so\n$ ln -s /usr/local/lib/python3.5/dist-packages/cv2.so cv2.so\n```\n\n## 参考博客 \n\n* Raspberry Pi-树莓派搭建基于Python3和OpenCV实现的解魔方机器人-爱板网论坛 - 电子工程师学习交流园地  \nhttp://www.eeboard.com/bbs/thread-99451-1-1.html\n* 树莓派3b编译安装完整OpenCV-3.4.1 for Python3 - 爱板网经验频道 - Eeboard爱板网  \nhttps://jingyan.eeboard.com/article/76476\n* 树莓派安装opencv调用cv2时提示ModuleNotFoundError: NO module named 'cv'的解决方法 - Mrkinte的博客 - CSDN博客  \nhttps://blog.csdn.net/Mrkinte/article/details/85058507\n* Ubuntu 16.04: How to install OpenCV - PyImageSearch  \nhttps://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/\n\n","source":"_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3.md","raw":"---\ntitle: 树莓派3b 编译安装OpenCV-4.0.0 for Python3\ndate: 2019-04-20 21:14:22\ntags: \n  - opencv\n  - raspberry\n  - python\n---\n\n## 准备\n\n### 调整SWAP分区\n\n``` bash\n$ cd /var && ls\n```\n卸载swap文件\n``` bash\n$ sudo swapoff swap\n```\n查看一下\n``` bash\n$ htop\n```\n创建一个更大的swap文件\n``` bash\n$ sudo dd if=/dev/zero of=swap bs=1M count=2048\n```\n装载新的swap文件\n``` bash\n$ sudo mkswap swap \n$ sudo swapon swap \n```\n可以在htop中看到新的swap分区大小为2GB，完成\n\n### 相关依赖\n\n``` bash\n$ sudo apt-get install build-essential cmake pkg-config\n$ sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev\n$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev\n$ sudo apt-get install libxvidcore-dev libx264-dev\n$ sudo apt-get install libgtk2.0-dev\n$ sudo apt-get install libatlas-base-dev gfortran\n$ sudo apt-get install python2.7-dev python3-dev\n```\n\n安装numpy\n``` bash\n$ pip3 install numpy\n```\n\n### 下载opencv源码\n``` bash\n$ cd Documents/\n$ wget https://github.com/opencv/opencv/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip\n$ unzip 4.0.0.zip\n```\n\n## 编译\n\n### 进入虚拟环境\n``` bash\n$ cd python-env\n$ pyvenv py35\n$ source python-env/py35/bin/activate\n```\n\n### 设置编译环境\n安装cmake-qt-gui，使用图形界面\n``` bash\n$ cd Documents/opencv-4.0.0/\n$ mkdir build\n$ cd build/\n$ sudo apt-get install cmake-qt-gui\n$ (venv) pi@raspberrypi:~/Documents/opencv-4.0.0/build $ cmake-gui\n```\n\n选择源文件路径，编译文件夹选择刚才新建的build文件夹\n点击左下角Configure，第一次完成是红色的，再点一次就变成白色了，如图</br>\n\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png\" width=600 height=300>\n\n然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0的路径填进去，点击Configure，如图\n\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png\" width=600 height=300>\n\n这样OpenCV_Contrib-4.0.0就被添加进去了，然后我们修改关于Python的参数，在查找栏键入PYTHON：取消BIULD_opencv_python2，勾选INSTALL_PYTHON_EXMAPLES，这样就设置为编译Python3的版本了，再次点击Configure，如图：\n<img src = \"树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png\" width=600 height=300>\n\n然后就可以生成编译文件了，点击Generate</br>\n\n### 编译\n键入下述命令开始编译，有风扇-j4，没风扇-j2-j3\n``` bash\n$ make -j4\n```\n安装\n``` bash\n$ sudo make install \n$ sudo ldconfig\n```\n因编译后的库文件cv2.so被输出为 cv2.cpython-35m-arm-linux-gnueabihf.so，这将导致该模块在Python3中无法import进来\n``` bash\n$ sudo cp /usr/local/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/local/lib/python3.5/dist-packages\n$ cd /usr/local/lib/python3.5/dist-packages/\n$ sudo mv cv2.cpython-35m-arm-linux-gnueabihf.so cv.so\n$ ln -s /usr/local/lib/python3.5/dist-packages/cv2.so cv2.so\n```\n\n## 参考博客 \n\n* Raspberry Pi-树莓派搭建基于Python3和OpenCV实现的解魔方机器人-爱板网论坛 - 电子工程师学习交流园地  \nhttp://www.eeboard.com/bbs/thread-99451-1-1.html\n* 树莓派3b编译安装完整OpenCV-3.4.1 for Python3 - 爱板网经验频道 - Eeboard爱板网  \nhttps://jingyan.eeboard.com/article/76476\n* 树莓派安装opencv调用cv2时提示ModuleNotFoundError: NO module named 'cv'的解决方法 - Mrkinte的博客 - CSDN博客  \nhttps://blog.csdn.net/Mrkinte/article/details/85058507\n* Ubuntu 16.04: How to install OpenCV - PyImageSearch  \nhttps://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/\n\n","slug":"树莓派3b 编译安装OpenCV-4.0.0 for Python3","published":1,"updated":"2019-06-23T07:09:39.778Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm7500018rsvj1bhiswl6","content":"<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"调整SWAP分区\"><a href=\"#调整SWAP分区\" class=\"headerlink\" title=\"调整SWAP分区\"></a>调整SWAP分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var &amp;&amp; ls</span><br></pre></td></tr></table></figure>\n<p>卸载swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapoff swap</span><br></pre></td></tr></table></figure></p>\n<p>查看一下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>创建一个更大的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo dd <span class=\"keyword\">if</span>=/dev/zero of=swap bs=1M count=2048</span><br></pre></td></tr></table></figure></p>\n<p>装载新的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkswap swap </span><br><span class=\"line\">$ sudo swapon swap</span><br></pre></td></tr></table></figure></p>\n<p>可以在htop中看到新的swap分区大小为2GB，完成</p>\n<h3 id=\"相关依赖\"><a href=\"#相关依赖\" class=\"headerlink\" title=\"相关依赖\"></a>相关依赖</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install build-essential cmake pkg-config</span><br><span class=\"line\">$ sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev</span><br><span class=\"line\">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</span><br><span class=\"line\">$ sudo apt-get install libxvidcore-dev libx264-dev</span><br><span class=\"line\">$ sudo apt-get install libgtk2.0-dev</span><br><span class=\"line\">$ sudo apt-get install libatlas-base-dev gfortran</span><br><span class=\"line\">$ sudo apt-get install python2.7-dev python3-dev</span><br></pre></td></tr></table></figure>\n<p>安装numpy<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install numpy</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"下载opencv源码\"><a href=\"#下载opencv源码\" class=\"headerlink\" title=\"下载opencv源码\"></a>下载opencv源码</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Documents/</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br></pre></td></tr></table></figure>\n<h2 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h2><h3 id=\"进入虚拟环境\"><a href=\"#进入虚拟环境\" class=\"headerlink\" title=\"进入虚拟环境\"></a>进入虚拟环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> python-env</span><br><span class=\"line\">$ pyvenv py35</span><br><span class=\"line\">$ <span class=\"built_in\">source</span> python-env/py35/bin/activate</span><br></pre></td></tr></table></figure>\n<h3 id=\"设置编译环境\"><a href=\"#设置编译环境\" class=\"headerlink\" title=\"设置编译环境\"></a>设置编译环境</h3><p>安装cmake-qt-gui，使用图形界面<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Documents/opencv-4.0.0/</span><br><span class=\"line\">$ mkdir build</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> build/</span><br><span class=\"line\">$ sudo apt-get install cmake-qt-gui</span><br><span class=\"line\">$ (venv) pi@raspberrypi:~/Documents/opencv-4.0.0/build $ cmake-gui</span><br></pre></td></tr></table></figure></p>\n<p>选择源文件路径，编译文件夹选择刚才新建的build文件夹<br>点击左下角Configure，第一次完成是红色的，再点一次就变成白色了，如图&lt;/br&gt;</p>\n<p><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png\" width=\"600\" height=\"300\"></p>\n<p>然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0的路径填进去，点击Configure，如图</p>\n<p><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png\" width=\"600\" height=\"300\"></p>\n<p>这样OpenCV_Contrib-4.0.0就被添加进去了，然后我们修改关于Python的参数，在查找栏键入PYTHON：取消BIULD_opencv_python2，勾选INSTALL_PYTHON_EXMAPLES，这样就设置为编译Python3的版本了，再次点击Configure，如图：<br><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png\" width=\"600\" height=\"300\"></p>\n<p>然后就可以生成编译文件了，点击Generate&lt;/br&gt;</p>\n<h3 id=\"编译-1\"><a href=\"#编译-1\" class=\"headerlink\" title=\"编译\"></a>编译</h3><p>键入下述命令开始编译，有风扇-j4，没风扇-j2-j3<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ make -j4</span><br></pre></td></tr></table></figure></p>\n<p>安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make install </span><br><span class=\"line\">$ sudo ldconfig</span><br></pre></td></tr></table></figure></p>\n<p>因编译后的库文件cv2.so被输出为 cv2.cpython-35m-arm-linux-gnueabihf.so，这将导致该模块在Python3中无法import进来<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cp /usr/<span class=\"built_in\">local</span>/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/</span><br><span class=\"line\">$ sudo mv cv2.cpython-35m-arm-linux-gnueabihf.so cv.so</span><br><span class=\"line\">$ ln -s /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/cv2.so cv2.so</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>Raspberry Pi-树莓派搭建基于Python3和OpenCV实现的解魔方机器人-爱板网论坛 - 电子工程师学习交流园地<br><a href=\"http://www.eeboard.com/bbs/thread-99451-1-1.html\" target=\"_blank\" rel=\"noopener\">http://www.eeboard.com/bbs/thread-99451-1-1.html</a></li>\n<li>树莓派3b编译安装完整OpenCV-3.4.1 for Python3 - 爱板网经验频道 - Eeboard爱板网<br><a href=\"https://jingyan.eeboard.com/article/76476\" target=\"_blank\" rel=\"noopener\">https://jingyan.eeboard.com/article/76476</a></li>\n<li>树莓派安装opencv调用cv2时提示ModuleNotFoundError: NO module named ‘cv’的解决方法 - Mrkinte的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/Mrkinte/article/details/85058507\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Mrkinte/article/details/85058507</a></li>\n<li>Ubuntu 16.04: How to install OpenCV - PyImageSearch<br><a href=\"https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/\" target=\"_blank\" rel=\"noopener\">https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"调整SWAP分区\"><a href=\"#调整SWAP分区\" class=\"headerlink\" title=\"调整SWAP分区\"></a>调整SWAP分区</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var &amp;&amp; ls</span><br></pre></td></tr></table></figure>\n<p>卸载swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo swapoff swap</span><br></pre></td></tr></table></figure></p>\n<p>查看一下<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ htop</span><br></pre></td></tr></table></figure></p>\n<p>创建一个更大的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo dd <span class=\"keyword\">if</span>=/dev/zero of=swap bs=1M count=2048</span><br></pre></td></tr></table></figure></p>\n<p>装载新的swap文件<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo mkswap swap </span><br><span class=\"line\">$ sudo swapon swap</span><br></pre></td></tr></table></figure></p>\n<p>可以在htop中看到新的swap分区大小为2GB，完成</p>\n<h3 id=\"相关依赖\"><a href=\"#相关依赖\" class=\"headerlink\" title=\"相关依赖\"></a>相关依赖</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install build-essential cmake pkg-config</span><br><span class=\"line\">$ sudo apt-get install libjpeg-dev libtiff5-dev libjasper-dev libpng12-dev</span><br><span class=\"line\">$ sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev</span><br><span class=\"line\">$ sudo apt-get install libxvidcore-dev libx264-dev</span><br><span class=\"line\">$ sudo apt-get install libgtk2.0-dev</span><br><span class=\"line\">$ sudo apt-get install libatlas-base-dev gfortran</span><br><span class=\"line\">$ sudo apt-get install python2.7-dev python3-dev</span><br></pre></td></tr></table></figure>\n<p>安装numpy<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ pip3 install numpy</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"下载opencv源码\"><a href=\"#下载opencv源码\" class=\"headerlink\" title=\"下载opencv源码\"></a>下载opencv源码</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Documents/</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br><span class=\"line\">$ wget https://github.com/opencv/opencv_contrib/archive/4.0.0.zip</span><br><span class=\"line\">$ unzip 4.0.0.zip</span><br></pre></td></tr></table></figure>\n<h2 id=\"编译\"><a href=\"#编译\" class=\"headerlink\" title=\"编译\"></a>编译</h2><h3 id=\"进入虚拟环境\"><a href=\"#进入虚拟环境\" class=\"headerlink\" title=\"进入虚拟环境\"></a>进入虚拟环境</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> python-env</span><br><span class=\"line\">$ pyvenv py35</span><br><span class=\"line\">$ <span class=\"built_in\">source</span> python-env/py35/bin/activate</span><br></pre></td></tr></table></figure>\n<h3 id=\"设置编译环境\"><a href=\"#设置编译环境\" class=\"headerlink\" title=\"设置编译环境\"></a>设置编译环境</h3><p>安装cmake-qt-gui，使用图形界面<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> Documents/opencv-4.0.0/</span><br><span class=\"line\">$ mkdir build</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> build/</span><br><span class=\"line\">$ sudo apt-get install cmake-qt-gui</span><br><span class=\"line\">$ (venv) pi@raspberrypi:~/Documents/opencv-4.0.0/build $ cmake-gui</span><br></pre></td></tr></table></figure></p>\n<p>选择源文件路径，编译文件夹选择刚才新建的build文件夹<br>点击左下角Configure，第一次完成是红色的，再点一次就变成白色了，如图&lt;/br&gt;</p>\n<p><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png\" width=\"600\" height=\"300\"></p>\n<p>然后查找OPENCV_EXTRA_MODULES_PATH项，将OpenCV_Contrib-4.0.0的路径填进去，点击Configure，如图</p>\n<p><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png\" width=\"600\" height=\"300\"></p>\n<p>这样OpenCV_Contrib-4.0.0就被添加进去了，然后我们修改关于Python的参数，在查找栏键入PYTHON：取消BIULD_opencv_python2，勾选INSTALL_PYTHON_EXMAPLES，这样就设置为编译Python3的版本了，再次点击Configure，如图：<br><img src=\"/2019/04/20/树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png\" width=\"600\" height=\"300\"></p>\n<p>然后就可以生成编译文件了，点击Generate&lt;/br&gt;</p>\n<h3 id=\"编译-1\"><a href=\"#编译-1\" class=\"headerlink\" title=\"编译\"></a>编译</h3><p>键入下述命令开始编译，有风扇-j4，没风扇-j2-j3<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ make -j4</span><br></pre></td></tr></table></figure></p>\n<p>安装<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo make install </span><br><span class=\"line\">$ sudo ldconfig</span><br></pre></td></tr></table></figure></p>\n<p>因编译后的库文件cv2.so被输出为 cv2.cpython-35m-arm-linux-gnueabihf.so，这将导致该模块在Python3中无法import进来<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo cp /usr/<span class=\"built_in\">local</span>/python/cv2/python-3.5/cv2.cpython-35m-arm-linux-gnueabihf.so /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/</span><br><span class=\"line\">$ sudo mv cv2.cpython-35m-arm-linux-gnueabihf.so cv.so</span><br><span class=\"line\">$ ln -s /usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages/cv2.so cv2.so</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>Raspberry Pi-树莓派搭建基于Python3和OpenCV实现的解魔方机器人-爱板网论坛 - 电子工程师学习交流园地<br><a href=\"http://www.eeboard.com/bbs/thread-99451-1-1.html\" target=\"_blank\" rel=\"noopener\">http://www.eeboard.com/bbs/thread-99451-1-1.html</a></li>\n<li>树莓派3b编译安装完整OpenCV-3.4.1 for Python3 - 爱板网经验频道 - Eeboard爱板网<br><a href=\"https://jingyan.eeboard.com/article/76476\" target=\"_blank\" rel=\"noopener\">https://jingyan.eeboard.com/article/76476</a></li>\n<li>树莓派安装opencv调用cv2时提示ModuleNotFoundError: NO module named ‘cv’的解决方法 - Mrkinte的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/Mrkinte/article/details/85058507\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Mrkinte/article/details/85058507</a></li>\n<li>Ubuntu 16.04: How to install OpenCV - PyImageSearch<br><a href=\"https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/\" target=\"_blank\" rel=\"noopener\">https://www.pyimagesearch.com/2016/10/24/ubuntu-16-04-how-to-install-opencv/</a></li>\n</ul>\n"},{"title":"简单手势分类器","date":"2019-04-24T12:41:48.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n\n树莓派作为一个视觉传感器，串口实时返回手势分类结果。\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n\n### 安装tensorflow\n维护树莓派交叉编译版本的github项目\n* samjabrahams/tensorflow-on-raspberry-pi: TensorFlow for Raspberry Pi  \nhttps://github.com/samjabrahams/tensorflow-on-raspberry-pi\n``` bash\nsudo apt install libatlas-base-dev\npip3 install tensorflow\n``` \n安装旧版本\n``` bash \n$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v0.11.0/tensorflow-0.11.0-py3-none-any.whl\n$ sudo pip3 install tensorflow-0.11.0-py3-none-any.whl\n```\n### 安装serial\n\n安装串口模块\n``` bash\n$ sudo apt-get install python-serial\n$ pip install serial\n$ pip install pyserial\n```\n如果需要指定位置\n``` bash\n$ sudo pip install --target=/usr/local/lib/python3.5/dist-packages pyserial\n```\n\n### 一些包\n``` bash\npip install pillow\npip install matplotlib\n```\n\n## 数据处理\n使用OpenCV的BackgroundSubtractor类，分割前景和背景，获得手势灰度图\n``` python\ncamera = cv2.VideoCapture(0) # 参数0表示第一个摄像头\nbs = cv2.createBackgroundSubtractorKNN(detectShadows=True)\nes = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\nwhile True:\n    grabbed, frame_lwpCV = camera.read()\n    fgmask = bs.apply(frame_lwpCV) # 背景分割器，该函数计算了前景掩码\n    # 二值化阈值处理，前景掩码含有前景的白色值以及阴影的灰色值，在阈值化图像中，将非纯白色（244~255）的所有像素都设为0，而不是255\n    th = cv2.threshold(fgmask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\n    # 下面就跟基本运动检测中方法相同，识别目标，检测轮廓，在原始帧上绘制检测结果\n    dilated = cv2.dilate(th, es, iterations=2) # 形态学膨胀\n    image, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓\n    # rasp\n    # contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓\n    for c in contours:\n        if cv2.contourArea(c) > 2000: #1600:\n            (x, y, w, h) = cv2.boundingRect(c)\n            cv2.rectangle(frame_lwpCV, (x, y), (x + w, y + h), (255, 255, 0), 2)\n    cv2.imshow('detection', frame_lwpCV)\n    # 按'q'健退出循环\n# When everything done, release the capture\n```\n\n## 模型和训练\n通过一个小的卷积网络来实现分类，两层卷积+两层全连接\n``` python\ndef model(x, keep_prob):\n    '''Build the classify model\n    Args:\n      x: Input, tf.placeholder, the dimension is [-1, 784]\n      keep_prob: \n    Returns:\n      y: Classification probability\n    '''\n    x_image = tf.reshape(x, [-1, w, h, 1])\n    # Conv1\n    with tf.name_scope('conv1'):\n        W_conv1 = weight_variable([3, 3, 1, 16], name=\"weight\")\n        b_conv1 = bias_variable([16], name='bias')\n        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding=\"SAME\", name='conv')+ b_conv1)\n        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool\")\n    # Conv2\n    with tf.name_scope('conv2'):\n        W_conv2 = weight_variable([3, 3, 16, 32], name=\"weight\")\n        b_conv2 = bias_variable([32], name='bias')\n        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding=\"SAME\", name='conv')+ b_conv2)\n        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool\")\n    # fc1\n    with tf.name_scope('fc1'):\n        W_fc1 = weight_variable([7*7*32, 256], name=\"weight\")\n        b_fc1 = bias_variable([256], name='bias')\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)\n    # Dropout\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    # fc2\n    with tf.name_scope('fc2'):\n        W_fc2 = weight_variable([256, 4], name=\"weight\")\n        b_fc2 = bias_variable([4], name='bias')\n        y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2, name=\"output\")\n    return y\n```\n\n## HC-05蓝牙串口\n\n### 蓝牙配对\n\n连接(rt反接)\n* usb-ttl ---------- bluetooth\n* RXD &nbsp;&nbsp;&nbsp;&nbsp;---------- TXD\n* TXD &nbsp;&nbsp;&nbsp;&nbsp;---------- RXD\n\n按住复位键插USB，进入AT模式\n打开串口助手，设置波特率38400，数据位8位，停止位1位，无校验位，加回车换行(发送消息包含换行符)\n修改名称\n``` bash\n→ AT+ NAME=xxx\n→ AT+ NAME?\n```\n设置蓝牙密码，注意两块蓝牙的密码都要一样\n``` bash\n→ AT+ PSWD=1234\n→ AT+ PSWD?\n```\n设置主从模式\n串口调试助手A，将蓝牙A配置为主机模式\n``` bash\n→ AT+ ROLE=1\n→ AT+ ROLE?\n```\n串口调试助手B，将蓝牙B配置为从机模式\n``` bash\n→ AT+ ROLE=0\n```\n设置波特率9600，无校验位，1停止位\n``` bash\n→ AT+ UART:9600,0,0\n→ AT+ UART?\n```\n设置连接模式\n``` bash\n→ AT+ CMODE=0\n→ AT+ CMODE?\n```\n查询蓝牙地址，并相互绑定，注意把地址的冒号换成逗号\n``` bash\n→ AT+ ADDR?\n→ AT+ BIND=98d3,32,307440\n```\n\n\n## 结果\n查看端口\n``` bash\n$ ls /dev/tty*\n```\n运行\n``` bash\n$ python run.py --serial /dev/ttyUSB0\n```\n<img src = \"简单手势分类器\\02.png\" width=600 height=300>\n<img src = \"简单手势分类器\\01.png\" width=600 height=300>\n\n\n## 参考博客\n* 【Python+OpenCV】目标跟踪-背景分割器：KNN、MOG2和GMG - CSDN博客  \nhttps://blog.csdn.net/lwplwf/article/details/73551648\n* Tensorflow+树莓派，自制“猜拳神器” - Lauyeed的博客 - CSDN博客  \nhttps://blog.csdn.net/Lauyeed/article/details/79345685\n* 蓝牙模块HC-05使用说明_图文_百度文库  \nhttp://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq\n* AttributeError: module 'serial' has no attribute 'Serial' - m0_37827405的博客 - CSDN博客  \nhttps://blog.csdn.net/m0_37827405/article/details/80879678\n","source":"_posts/简单手势分类器.md","raw":"---\ntitle: 简单手势分类器\ndate: 2019-04-24 20:41:48\ntags:\n  - raspberry \n  - tf\n  - opencv\n  - python\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n树莓派作为一个视觉传感器，串口实时返回手势分类结果。\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 准备\n\n### 安装tensorflow\n维护树莓派交叉编译版本的github项目\n* samjabrahams/tensorflow-on-raspberry-pi: TensorFlow for Raspberry Pi  \nhttps://github.com/samjabrahams/tensorflow-on-raspberry-pi\n``` bash\nsudo apt install libatlas-base-dev\npip3 install tensorflow\n``` \n安装旧版本\n``` bash \n$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v0.11.0/tensorflow-0.11.0-py3-none-any.whl\n$ sudo pip3 install tensorflow-0.11.0-py3-none-any.whl\n```\n### 安装serial\n\n安装串口模块\n``` bash\n$ sudo apt-get install python-serial\n$ pip install serial\n$ pip install pyserial\n```\n如果需要指定位置\n``` bash\n$ sudo pip install --target=/usr/local/lib/python3.5/dist-packages pyserial\n```\n\n### 一些包\n``` bash\npip install pillow\npip install matplotlib\n```\n\n## 数据处理\n使用OpenCV的BackgroundSubtractor类，分割前景和背景，获得手势灰度图\n``` python\ncamera = cv2.VideoCapture(0) # 参数0表示第一个摄像头\nbs = cv2.createBackgroundSubtractorKNN(detectShadows=True)\nes = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\nwhile True:\n    grabbed, frame_lwpCV = camera.read()\n    fgmask = bs.apply(frame_lwpCV) # 背景分割器，该函数计算了前景掩码\n    # 二值化阈值处理，前景掩码含有前景的白色值以及阴影的灰色值，在阈值化图像中，将非纯白色（244~255）的所有像素都设为0，而不是255\n    th = cv2.threshold(fgmask.copy(), 244, 255, cv2.THRESH_BINARY)[1]\n    # 下面就跟基本运动检测中方法相同，识别目标，检测轮廓，在原始帧上绘制检测结果\n    dilated = cv2.dilate(th, es, iterations=2) # 形态学膨胀\n    image, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓\n    # rasp\n    # contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓\n    for c in contours:\n        if cv2.contourArea(c) > 2000: #1600:\n            (x, y, w, h) = cv2.boundingRect(c)\n            cv2.rectangle(frame_lwpCV, (x, y), (x + w, y + h), (255, 255, 0), 2)\n    cv2.imshow('detection', frame_lwpCV)\n    # 按'q'健退出循环\n# When everything done, release the capture\n```\n\n## 模型和训练\n通过一个小的卷积网络来实现分类，两层卷积+两层全连接\n``` python\ndef model(x, keep_prob):\n    '''Build the classify model\n    Args:\n      x: Input, tf.placeholder, the dimension is [-1, 784]\n      keep_prob: \n    Returns:\n      y: Classification probability\n    '''\n    x_image = tf.reshape(x, [-1, w, h, 1])\n    # Conv1\n    with tf.name_scope('conv1'):\n        W_conv1 = weight_variable([3, 3, 1, 16], name=\"weight\")\n        b_conv1 = bias_variable([16], name='bias')\n        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding=\"SAME\", name='conv')+ b_conv1)\n        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool\")\n    # Conv2\n    with tf.name_scope('conv2'):\n        W_conv2 = weight_variable([3, 3, 16, 32], name=\"weight\")\n        b_conv2 = bias_variable([32], name='bias')\n        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding=\"SAME\", name='conv')+ b_conv2)\n        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\", name=\"pool\")\n    # fc1\n    with tf.name_scope('fc1'):\n        W_fc1 = weight_variable([7*7*32, 256], name=\"weight\")\n        b_fc1 = bias_variable([256], name='bias')\n        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)\n    # Dropout\n    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n    # fc2\n    with tf.name_scope('fc2'):\n        W_fc2 = weight_variable([256, 4], name=\"weight\")\n        b_fc2 = bias_variable([4], name='bias')\n        y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2, name=\"output\")\n    return y\n```\n\n## HC-05蓝牙串口\n\n### 蓝牙配对\n\n连接(rt反接)\n* usb-ttl ---------- bluetooth\n* RXD &nbsp;&nbsp;&nbsp;&nbsp;---------- TXD\n* TXD &nbsp;&nbsp;&nbsp;&nbsp;---------- RXD\n\n按住复位键插USB，进入AT模式\n打开串口助手，设置波特率38400，数据位8位，停止位1位，无校验位，加回车换行(发送消息包含换行符)\n修改名称\n``` bash\n→ AT+ NAME=xxx\n→ AT+ NAME?\n```\n设置蓝牙密码，注意两块蓝牙的密码都要一样\n``` bash\n→ AT+ PSWD=1234\n→ AT+ PSWD?\n```\n设置主从模式\n串口调试助手A，将蓝牙A配置为主机模式\n``` bash\n→ AT+ ROLE=1\n→ AT+ ROLE?\n```\n串口调试助手B，将蓝牙B配置为从机模式\n``` bash\n→ AT+ ROLE=0\n```\n设置波特率9600，无校验位，1停止位\n``` bash\n→ AT+ UART:9600,0,0\n→ AT+ UART?\n```\n设置连接模式\n``` bash\n→ AT+ CMODE=0\n→ AT+ CMODE?\n```\n查询蓝牙地址，并相互绑定，注意把地址的冒号换成逗号\n``` bash\n→ AT+ ADDR?\n→ AT+ BIND=98d3,32,307440\n```\n\n\n## 结果\n查看端口\n``` bash\n$ ls /dev/tty*\n```\n运行\n``` bash\n$ python run.py --serial /dev/ttyUSB0\n```\n<img src = \"简单手势分类器\\02.png\" width=600 height=300>\n<img src = \"简单手势分类器\\01.png\" width=600 height=300>\n\n\n## 参考博客\n* 【Python+OpenCV】目标跟踪-背景分割器：KNN、MOG2和GMG - CSDN博客  \nhttps://blog.csdn.net/lwplwf/article/details/73551648\n* Tensorflow+树莓派，自制“猜拳神器” - Lauyeed的博客 - CSDN博客  \nhttps://blog.csdn.net/Lauyeed/article/details/79345685\n* 蓝牙模块HC-05使用说明_图文_百度文库  \nhttp://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq\n* AttributeError: module 'serial' has no attribute 'Serial' - m0_37827405的博客 - CSDN博客  \nhttps://blog.csdn.net/m0_37827405/article/details/80879678\n","slug":"简单手势分类器","published":1,"updated":"2019-06-23T07:09:39.785Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm751001arsvj79vrqh57","content":"<p><strong> 简单手势分类器：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<p>树莓派作为一个视觉传感器，串口实时返回手势分类结果。</p>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"安装tensorflow\"><a href=\"#安装tensorflow\" class=\"headerlink\" title=\"安装tensorflow\"></a>安装tensorflow</h3><p>维护树莓派交叉编译版本的github项目</p>\n<ul>\n<li>samjabrahams/tensorflow-on-raspberry-pi: TensorFlow for Raspberry Pi<br><a href=\"https://github.com/samjabrahams/tensorflow-on-raspberry-pi\" target=\"_blank\" rel=\"noopener\">https://github.com/samjabrahams/tensorflow-on-raspberry-pi</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install libatlas-base-dev</span><br><span class=\"line\">pip3 install tensorflow</span><br><span class=\"line\">``` </span><br><span class=\"line\">安装旧版本</span><br><span class=\"line\">``` bash </span><br><span class=\"line\">$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v0.11.0/tensorflow-0.11.0-py3-none-any.whl</span><br><span class=\"line\">$ sudo pip3 install tensorflow-0.11.0-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"安装serial\"><a href=\"#安装serial\" class=\"headerlink\" title=\"安装serial\"></a>安装serial</h3><p>安装串口模块<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-serial</span><br><span class=\"line\">$ pip install serial</span><br><span class=\"line\">$ pip install pyserial</span><br></pre></td></tr></table></figure></p>\n<p>如果需要指定位置<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo pip install --target=/usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages pyserial</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"一些包\"><a href=\"#一些包\" class=\"headerlink\" title=\"一些包\"></a>一些包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pillow</span><br><span class=\"line\">pip install matplotlib</span><br></pre></td></tr></table></figure>\n<h2 id=\"数据处理\"><a href=\"#数据处理\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h2><p>使用OpenCV的BackgroundSubtractor类，分割前景和背景，获得手势灰度图<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera = cv2.VideoCapture(<span class=\"number\">0</span>) <span class=\"comment\"># 参数0表示第一个摄像头</span></span><br><span class=\"line\">bs = cv2.createBackgroundSubtractorKNN(detectShadows=<span class=\"literal\">True</span>)</span><br><span class=\"line\">es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (<span class=\"number\">3</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    grabbed, frame_lwpCV = camera.read()</span><br><span class=\"line\">    fgmask = bs.apply(frame_lwpCV) <span class=\"comment\"># 背景分割器，该函数计算了前景掩码</span></span><br><span class=\"line\">    <span class=\"comment\"># 二值化阈值处理，前景掩码含有前景的白色值以及阴影的灰色值，在阈值化图像中，将非纯白色（244~255）的所有像素都设为0，而不是255</span></span><br><span class=\"line\">    th = cv2.threshold(fgmask.copy(), <span class=\"number\">244</span>, <span class=\"number\">255</span>, cv2.THRESH_BINARY)[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"comment\"># 下面就跟基本运动检测中方法相同，识别目标，检测轮廓，在原始帧上绘制检测结果</span></span><br><span class=\"line\">    dilated = cv2.dilate(th, es, iterations=<span class=\"number\">2</span>) <span class=\"comment\"># 形态学膨胀</span></span><br><span class=\"line\">    image, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) <span class=\"comment\"># 该函数计算一幅图像中目标的轮廓</span></span><br><span class=\"line\">    <span class=\"comment\"># rasp</span></span><br><span class=\"line\">    <span class=\"comment\"># contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cv2.contourArea(c) &gt; <span class=\"number\">2000</span>: <span class=\"comment\">#1600:</span></span><br><span class=\"line\">            (x, y, w, h) = cv2.boundingRect(c)</span><br><span class=\"line\">            cv2.rectangle(frame_lwpCV, (x, y), (x + w, y + h), (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'detection'</span>, frame_lwpCV)</span><br><span class=\"line\">    <span class=\"comment\"># 按'q'健退出循环</span></span><br><span class=\"line\"><span class=\"comment\"># When everything done, release the capture</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"模型和训练\"><a href=\"#模型和训练\" class=\"headerlink\" title=\"模型和训练\"></a>模型和训练</h2><p>通过一个小的卷积网络来实现分类，两层卷积+两层全连接<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">model</span><span class=\"params\">(x, keep_prob)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''Build the classify model</span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">      x: Input, tf.placeholder, the dimension is [-1, 784]</span></span><br><span class=\"line\"><span class=\"string\">      keep_prob: </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">      y: Classification probability</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    x_image = tf.reshape(x, [<span class=\"number\">-1</span>, w, h, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># Conv1</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'conv1'</span>):</span><br><span class=\"line\">        W_conv1 = weight_variable([<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">16</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_conv1 = bias_variable([<span class=\"number\">16</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">'conv'</span>)+ b_conv1)</span><br><span class=\"line\">        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">\"pool\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Conv2</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'conv2'</span>):</span><br><span class=\"line\">        W_conv2 = weight_variable([<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">16</span>, <span class=\"number\">32</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_conv2 = bias_variable([<span class=\"number\">32</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">'conv'</span>)+ b_conv2)</span><br><span class=\"line\">        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">\"pool\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># fc1</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'fc1'</span>):</span><br><span class=\"line\">        W_fc1 = weight_variable([<span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">32</span>, <span class=\"number\">256</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_fc1 = bias_variable([<span class=\"number\">256</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_pool2_flat = tf.reshape(h_pool2, [<span class=\"number\">-1</span>, <span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">32</span>])</span><br><span class=\"line\">        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)</span><br><span class=\"line\">    <span class=\"comment\"># Dropout</span></span><br><span class=\"line\">    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class=\"line\">    <span class=\"comment\"># fc2</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'fc2'</span>):</span><br><span class=\"line\">        W_fc2 = weight_variable([<span class=\"number\">256</span>, <span class=\"number\">4</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_fc2 = bias_variable([<span class=\"number\">4</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2, name=<span class=\"string\">\"output\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> y</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"HC-05蓝牙串口\"><a href=\"#HC-05蓝牙串口\" class=\"headerlink\" title=\"HC-05蓝牙串口\"></a>HC-05蓝牙串口</h2><h3 id=\"蓝牙配对\"><a href=\"#蓝牙配对\" class=\"headerlink\" title=\"蓝牙配对\"></a>蓝牙配对</h3><p>连接(rt反接)</p>\n<ul>\n<li>usb-ttl ————— bluetooth</li>\n<li>RXD &nbsp;&nbsp;&nbsp;&nbsp;————— TXD</li>\n<li>TXD &nbsp;&nbsp;&nbsp;&nbsp;————— RXD</li>\n</ul>\n<p>按住复位键插USB，进入AT模式<br>打开串口助手，设置波特率38400，数据位8位，停止位1位，无校验位，加回车换行(发送消息包含换行符)<br>修改名称<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ NAME=xxx</span><br><span class=\"line\">→ AT+ NAME?</span><br></pre></td></tr></table></figure></p>\n<p>设置蓝牙密码，注意两块蓝牙的密码都要一样<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ PSWD=1234</span><br><span class=\"line\">→ AT+ PSWD?</span><br></pre></td></tr></table></figure></p>\n<p>设置主从模式<br>串口调试助手A，将蓝牙A配置为主机模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ROLE=1</span><br><span class=\"line\">→ AT+ ROLE?</span><br></pre></td></tr></table></figure></p>\n<p>串口调试助手B，将蓝牙B配置为从机模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ROLE=0</span><br></pre></td></tr></table></figure></p>\n<p>设置波特率9600，无校验位，1停止位<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ UART:9600,0,0</span><br><span class=\"line\">→ AT+ UART?</span><br></pre></td></tr></table></figure></p>\n<p>设置连接模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ CMODE=0</span><br><span class=\"line\">→ AT+ CMODE?</span><br></pre></td></tr></table></figure></p>\n<p>查询蓝牙地址，并相互绑定，注意把地址的冒号换成逗号<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ADDR?</span><br><span class=\"line\">→ AT+ BIND=98d3,32,307440</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h2><p>查看端口<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /dev/tty*</span><br></pre></td></tr></table></figure></p>\n<p>运行<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python run.py --serial /dev/ttyUSB0</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/2019/04/24/简单手势分类器/02.png\" width=\"600\" height=\"300\"><br><img src=\"/2019/04/24/简单手势分类器/01.png\" width=\"600\" height=\"300\"></p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>【Python+OpenCV】目标跟踪-背景分割器：KNN、MOG2和GMG - CSDN博客<br><a href=\"https://blog.csdn.net/lwplwf/article/details/73551648\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lwplwf/article/details/73551648</a></li>\n<li>Tensorflow+树莓派，自制“猜拳神器” - Lauyeed的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/Lauyeed/article/details/79345685\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Lauyeed/article/details/79345685</a></li>\n<li>蓝牙模块HC-05使用说明_图文_百度文库<br><a href=\"http://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq\" target=\"_blank\" rel=\"noopener\">http://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq</a></li>\n<li>AttributeError: module ‘serial’ has no attribute ‘Serial’ - m0_37827405的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/m0_37827405/article/details/80879678\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/m0_37827405/article/details/80879678</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 简单手势分类器：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<p>树莓派作为一个视觉传感器，串口实时返回手势分类结果。</p>","more":"<the rest of contents | 余下全文>\n\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><h3 id=\"安装tensorflow\"><a href=\"#安装tensorflow\" class=\"headerlink\" title=\"安装tensorflow\"></a>安装tensorflow</h3><p>维护树莓派交叉编译版本的github项目</p>\n<ul>\n<li>samjabrahams/tensorflow-on-raspberry-pi: TensorFlow for Raspberry Pi<br><a href=\"https://github.com/samjabrahams/tensorflow-on-raspberry-pi\" target=\"_blank\" rel=\"noopener\">https://github.com/samjabrahams/tensorflow-on-raspberry-pi</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install libatlas-base-dev</span><br><span class=\"line\">pip3 install tensorflow</span><br><span class=\"line\">``` </span><br><span class=\"line\">安装旧版本</span><br><span class=\"line\">``` bash </span><br><span class=\"line\">$ wget https://github.com/samjabrahams/tensorflow-on-raspberry-pi/releases/download/v0.11.0/tensorflow-0.11.0-py3-none-any.whl</span><br><span class=\"line\">$ sudo pip3 install tensorflow-0.11.0-py3-none-any.whl</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h3 id=\"安装serial\"><a href=\"#安装serial\" class=\"headerlink\" title=\"安装serial\"></a>安装serial</h3><p>安装串口模块<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-serial</span><br><span class=\"line\">$ pip install serial</span><br><span class=\"line\">$ pip install pyserial</span><br></pre></td></tr></table></figure></p>\n<p>如果需要指定位置<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo pip install --target=/usr/<span class=\"built_in\">local</span>/lib/python3.5/dist-packages pyserial</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"一些包\"><a href=\"#一些包\" class=\"headerlink\" title=\"一些包\"></a>一些包</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install pillow</span><br><span class=\"line\">pip install matplotlib</span><br></pre></td></tr></table></figure>\n<h2 id=\"数据处理\"><a href=\"#数据处理\" class=\"headerlink\" title=\"数据处理\"></a>数据处理</h2><p>使用OpenCV的BackgroundSubtractor类，分割前景和背景，获得手势灰度图<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">camera = cv2.VideoCapture(<span class=\"number\">0</span>) <span class=\"comment\"># 参数0表示第一个摄像头</span></span><br><span class=\"line\">bs = cv2.createBackgroundSubtractorKNN(detectShadows=<span class=\"literal\">True</span>)</span><br><span class=\"line\">es = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (<span class=\"number\">3</span>, <span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"keyword\">while</span> <span class=\"literal\">True</span>:</span><br><span class=\"line\">    grabbed, frame_lwpCV = camera.read()</span><br><span class=\"line\">    fgmask = bs.apply(frame_lwpCV) <span class=\"comment\"># 背景分割器，该函数计算了前景掩码</span></span><br><span class=\"line\">    <span class=\"comment\"># 二值化阈值处理，前景掩码含有前景的白色值以及阴影的灰色值，在阈值化图像中，将非纯白色（244~255）的所有像素都设为0，而不是255</span></span><br><span class=\"line\">    th = cv2.threshold(fgmask.copy(), <span class=\"number\">244</span>, <span class=\"number\">255</span>, cv2.THRESH_BINARY)[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"comment\"># 下面就跟基本运动检测中方法相同，识别目标，检测轮廓，在原始帧上绘制检测结果</span></span><br><span class=\"line\">    dilated = cv2.dilate(th, es, iterations=<span class=\"number\">2</span>) <span class=\"comment\"># 形态学膨胀</span></span><br><span class=\"line\">    image, contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) <span class=\"comment\"># 该函数计算一幅图像中目标的轮廓</span></span><br><span class=\"line\">    <span class=\"comment\"># rasp</span></span><br><span class=\"line\">    <span class=\"comment\"># contours, hierarchy = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE) # 该函数计算一幅图像中目标的轮廓</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> contours:</span><br><span class=\"line\">        <span class=\"keyword\">if</span> cv2.contourArea(c) &gt; <span class=\"number\">2000</span>: <span class=\"comment\">#1600:</span></span><br><span class=\"line\">            (x, y, w, h) = cv2.boundingRect(c)</span><br><span class=\"line\">            cv2.rectangle(frame_lwpCV, (x, y), (x + w, y + h), (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'detection'</span>, frame_lwpCV)</span><br><span class=\"line\">    <span class=\"comment\"># 按'q'健退出循环</span></span><br><span class=\"line\"><span class=\"comment\"># When everything done, release the capture</span></span><br></pre></td></tr></table></figure></p>\n<h2 id=\"模型和训练\"><a href=\"#模型和训练\" class=\"headerlink\" title=\"模型和训练\"></a>模型和训练</h2><p>通过一个小的卷积网络来实现分类，两层卷积+两层全连接<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">model</span><span class=\"params\">(x, keep_prob)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">'''Build the classify model</span></span><br><span class=\"line\"><span class=\"string\">    Args:</span></span><br><span class=\"line\"><span class=\"string\">      x: Input, tf.placeholder, the dimension is [-1, 784]</span></span><br><span class=\"line\"><span class=\"string\">      keep_prob: </span></span><br><span class=\"line\"><span class=\"string\">    Returns:</span></span><br><span class=\"line\"><span class=\"string\">      y: Classification probability</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    x_image = tf.reshape(x, [<span class=\"number\">-1</span>, w, h, <span class=\"number\">1</span>])</span><br><span class=\"line\">    <span class=\"comment\"># Conv1</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'conv1'</span>):</span><br><span class=\"line\">        W_conv1 = weight_variable([<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">1</span>, <span class=\"number\">16</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_conv1 = bias_variable([<span class=\"number\">16</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">'conv'</span>)+ b_conv1)</span><br><span class=\"line\">        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">\"pool\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># Conv2</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'conv2'</span>):</span><br><span class=\"line\">        W_conv2 = weight_variable([<span class=\"number\">3</span>, <span class=\"number\">3</span>, <span class=\"number\">16</span>, <span class=\"number\">32</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_conv2 = bias_variable([<span class=\"number\">32</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">'conv'</span>)+ b_conv2)</span><br><span class=\"line\">        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], strides=[<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>], padding=<span class=\"string\">\"SAME\"</span>, name=<span class=\"string\">\"pool\"</span>)</span><br><span class=\"line\">    <span class=\"comment\"># fc1</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'fc1'</span>):</span><br><span class=\"line\">        W_fc1 = weight_variable([<span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">32</span>, <span class=\"number\">256</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_fc1 = bias_variable([<span class=\"number\">256</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        h_pool2_flat = tf.reshape(h_pool2, [<span class=\"number\">-1</span>, <span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">32</span>])</span><br><span class=\"line\">        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1)+b_fc1)</span><br><span class=\"line\">    <span class=\"comment\"># Dropout</span></span><br><span class=\"line\">    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class=\"line\">    <span class=\"comment\"># fc2</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> tf.name_scope(<span class=\"string\">'fc2'</span>):</span><br><span class=\"line\">        W_fc2 = weight_variable([<span class=\"number\">256</span>, <span class=\"number\">4</span>], name=<span class=\"string\">\"weight\"</span>)</span><br><span class=\"line\">        b_fc2 = bias_variable([<span class=\"number\">4</span>], name=<span class=\"string\">'bias'</span>)</span><br><span class=\"line\">        y = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2)+b_fc2, name=<span class=\"string\">\"output\"</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> y</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"HC-05蓝牙串口\"><a href=\"#HC-05蓝牙串口\" class=\"headerlink\" title=\"HC-05蓝牙串口\"></a>HC-05蓝牙串口</h2><h3 id=\"蓝牙配对\"><a href=\"#蓝牙配对\" class=\"headerlink\" title=\"蓝牙配对\"></a>蓝牙配对</h3><p>连接(rt反接)</p>\n<ul>\n<li>usb-ttl ————— bluetooth</li>\n<li>RXD &nbsp;&nbsp;&nbsp;&nbsp;————— TXD</li>\n<li>TXD &nbsp;&nbsp;&nbsp;&nbsp;————— RXD</li>\n</ul>\n<p>按住复位键插USB，进入AT模式<br>打开串口助手，设置波特率38400，数据位8位，停止位1位，无校验位，加回车换行(发送消息包含换行符)<br>修改名称<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ NAME=xxx</span><br><span class=\"line\">→ AT+ NAME?</span><br></pre></td></tr></table></figure></p>\n<p>设置蓝牙密码，注意两块蓝牙的密码都要一样<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ PSWD=1234</span><br><span class=\"line\">→ AT+ PSWD?</span><br></pre></td></tr></table></figure></p>\n<p>设置主从模式<br>串口调试助手A，将蓝牙A配置为主机模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ROLE=1</span><br><span class=\"line\">→ AT+ ROLE?</span><br></pre></td></tr></table></figure></p>\n<p>串口调试助手B，将蓝牙B配置为从机模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ROLE=0</span><br></pre></td></tr></table></figure></p>\n<p>设置波特率9600，无校验位，1停止位<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ UART:9600,0,0</span><br><span class=\"line\">→ AT+ UART?</span><br></pre></td></tr></table></figure></p>\n<p>设置连接模式<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ CMODE=0</span><br><span class=\"line\">→ AT+ CMODE?</span><br></pre></td></tr></table></figure></p>\n<p>查询蓝牙地址，并相互绑定，注意把地址的冒号换成逗号<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">→ AT+ ADDR?</span><br><span class=\"line\">→ AT+ BIND=98d3,32,307440</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"结果\"><a href=\"#结果\" class=\"headerlink\" title=\"结果\"></a>结果</h2><p>查看端口<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ls /dev/tty*</span><br></pre></td></tr></table></figure></p>\n<p>运行<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ python run.py --serial /dev/ttyUSB0</span><br></pre></td></tr></table></figure></p>\n<p><img src=\"/2019/04/24/简单手势分类器/02.png\" width=\"600\" height=\"300\"><br><img src=\"/2019/04/24/简单手势分类器/01.png\" width=\"600\" height=\"300\"></p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>【Python+OpenCV】目标跟踪-背景分割器：KNN、MOG2和GMG - CSDN博客<br><a href=\"https://blog.csdn.net/lwplwf/article/details/73551648\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/lwplwf/article/details/73551648</a></li>\n<li>Tensorflow+树莓派，自制“猜拳神器” - Lauyeed的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/Lauyeed/article/details/79345685\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/Lauyeed/article/details/79345685</a></li>\n<li>蓝牙模块HC-05使用说明_图文_百度文库<br><a href=\"http://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq\" target=\"_blank\" rel=\"noopener\">http://wenku.baidu.com/link?url=tDhQ1eN2RBFS4-iA9dFZuuYUUb21nx3ZpahLARbDaesVM0HkHMeiLc0NzfR7W6NVqc5F57p0x8t6c_3T3JN4ne9NCEB540mwEYV5kLpFSfq</a></li>\n<li>AttributeError: module ‘serial’ has no attribute ‘Serial’ - m0_37827405的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/m0_37827405/article/details/80879678\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/m0_37827405/article/details/80879678</a></li>\n</ul>\n</the>"},{"title":"桌面冰球机器人","date":"2019-06-06T16:48:20.000Z","_content":"\n## 说明\n* 桌上冰球机器人 opencv3 + arduino mega2560  \nhttps://blog.csdn.net/x_a_little_story/article/details/88747280\n\n在闲鱼上面发现这个机器人感觉得很有趣，如果使用强化学习做人机对战是一个很好的项目。  \n查到了资料发现代码模型都很全，就按开源项目的设计和代码在端午小假期DIY了一个。  \n目前还是个人工智障，主要有以下问题待解决：\n* 笔记本性能不够，帧数最多只到9，反应速度不够快；\n* 电机没有加Y轴，所以理论上只能防守；\n* 机械结构上做了一些trick，比如倾斜“场地”和封死机器人的“球门”；\n* 算法上还是常规几何推理的方法，并没有想好怎么使用RL，大概可以参考一下gym里的breakout？\n\n## Demo\n<div align=center>\n<img src = \"桌面冰球机器人\\001.gif\" width=600 height=350>\n</div>\n\n## 参考资料\n感谢故里草木深和JJulio两位前辈提供的资料。  \n\n* 桌上冰球机器人 opencv3 + arduino mega2560  \nhttps://blog.csdn.net/x_a_little_story/article/details/88747280\n* JJulio/AHRobot: Air Hockey Robot Project  \nhttps://github.com/JJulio/AHRobot\n\n","source":"_posts/桌面冰球机器人.md","raw":"---\ntitle: 桌面冰球机器人\ndate: 2019-06-07 00:48:20\ntags:\n  - opencv\n  - arduino\n---\n\n## 说明\n* 桌上冰球机器人 opencv3 + arduino mega2560  \nhttps://blog.csdn.net/x_a_little_story/article/details/88747280\n\n在闲鱼上面发现这个机器人感觉得很有趣，如果使用强化学习做人机对战是一个很好的项目。  \n查到了资料发现代码模型都很全，就按开源项目的设计和代码在端午小假期DIY了一个。  \n目前还是个人工智障，主要有以下问题待解决：\n* 笔记本性能不够，帧数最多只到9，反应速度不够快；\n* 电机没有加Y轴，所以理论上只能防守；\n* 机械结构上做了一些trick，比如倾斜“场地”和封死机器人的“球门”；\n* 算法上还是常规几何推理的方法，并没有想好怎么使用RL，大概可以参考一下gym里的breakout？\n\n## Demo\n<div align=center>\n<img src = \"桌面冰球机器人\\001.gif\" width=600 height=350>\n</div>\n\n## 参考资料\n感谢故里草木深和JJulio两位前辈提供的资料。  \n\n* 桌上冰球机器人 opencv3 + arduino mega2560  \nhttps://blog.csdn.net/x_a_little_story/article/details/88747280\n* JJulio/AHRobot: Air Hockey Robot Project  \nhttps://github.com/JJulio/AHRobot\n\n","slug":"桌面冰球机器人","published":1,"updated":"2019-06-23T07:09:39.782Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm752001crsvjo1gqugcd","content":"<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><ul>\n<li>桌上冰球机器人 opencv3 + arduino mega2560<br><a href=\"https://blog.csdn.net/x_a_little_story/article/details/88747280\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/x_a_little_story/article/details/88747280</a></li>\n</ul>\n<p>在闲鱼上面发现这个机器人感觉得很有趣，如果使用强化学习做人机对战是一个很好的项目。<br>查到了资料发现代码模型都很全，就按开源项目的设计和代码在端午小假期DIY了一个。<br>目前还是个人工智障，主要有以下问题待解决：</p>\n<ul>\n<li>笔记本性能不够，帧数最多只到9，反应速度不够快；</li>\n<li>电机没有加Y轴，所以理论上只能防守；</li>\n<li>机械结构上做了一些trick，比如倾斜“场地”和封死机器人的“球门”；</li>\n<li>算法上还是常规几何推理的方法，并没有想好怎么使用RL，大概可以参考一下gym里的breakout？</li>\n</ul>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><div align=\"center\">\n<img src=\"/2019/06/07/桌面冰球机器人/001.gif\" width=\"600\" height=\"350\">\n</div>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>感谢故里草木深和JJulio两位前辈提供的资料。  </p>\n<ul>\n<li>桌上冰球机器人 opencv3 + arduino mega2560<br><a href=\"https://blog.csdn.net/x_a_little_story/article/details/88747280\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/x_a_little_story/article/details/88747280</a></li>\n<li>JJulio/AHRobot: Air Hockey Robot Project<br><a href=\"https://github.com/JJulio/AHRobot\" target=\"_blank\" rel=\"noopener\">https://github.com/JJulio/AHRobot</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"说明\"><a href=\"#说明\" class=\"headerlink\" title=\"说明\"></a>说明</h2><ul>\n<li>桌上冰球机器人 opencv3 + arduino mega2560<br><a href=\"https://blog.csdn.net/x_a_little_story/article/details/88747280\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/x_a_little_story/article/details/88747280</a></li>\n</ul>\n<p>在闲鱼上面发现这个机器人感觉得很有趣，如果使用强化学习做人机对战是一个很好的项目。<br>查到了资料发现代码模型都很全，就按开源项目的设计和代码在端午小假期DIY了一个。<br>目前还是个人工智障，主要有以下问题待解决：</p>\n<ul>\n<li>笔记本性能不够，帧数最多只到9，反应速度不够快；</li>\n<li>电机没有加Y轴，所以理论上只能防守；</li>\n<li>机械结构上做了一些trick，比如倾斜“场地”和封死机器人的“球门”；</li>\n<li>算法上还是常规几何推理的方法，并没有想好怎么使用RL，大概可以参考一下gym里的breakout？</li>\n</ul>\n<h2 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h2><div align=\"center\">\n<img src=\"/2019/06/07/桌面冰球机器人/001.gif\" width=\"600\" height=\"350\">\n</div>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p>感谢故里草木深和JJulio两位前辈提供的资料。  </p>\n<ul>\n<li>桌上冰球机器人 opencv3 + arduino mega2560<br><a href=\"https://blog.csdn.net/x_a_little_story/article/details/88747280\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/x_a_little_story/article/details/88747280</a></li>\n<li>JJulio/AHRobot: Air Hockey Robot Project<br><a href=\"https://github.com/JJulio/AHRobot\" target=\"_blank\" rel=\"noopener\">https://github.com/JJulio/AHRobot</a></li>\n</ul>\n"},{"title":"象棋残局机器人一：摄像头标定","date":"2019-05-25T08:44:09.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n廉价摄像头会给图像带来很多畸变，硬件解决方法是买个无畸变的摄像头，软件解决方案是找到摄像机畸变参数以及摄像机的内部参数和外部参数，对畸变图像进行修复。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n<div align=center>\n<img src=\"象棋残局机器人一：摄像头标定\\001.jpg\" width=600 height=400>\n</div>\n\n## 原理\n* 相机标定(Camera calibration) - honyniu的专栏 - CSDN博客  \nhttps://blog.csdn.net/honyniu/article/details/51004397\n* 张正友相机标定Opencv实现以及标定流程&&标定结果评价&&图像矫正流程解析（附标定程序和棋盘图） - 牧野的博客 - CSDN博客  \nhttps://blog.csdn.net/dcrmg/article/details/52939318\n\n\n## 流程\n1. 准备棋盘格标定图片；\n2. 对每一张标定图片，执行棋盘格检测，提取角点信息；\n3. 相机标定；\n4. 对标定结果进行评价；\n5. 查看标定效果\n\n### 准备标定图片\n标定图片需要使用标定板在不同位置、不同角度、不同姿态下拍摄，最少需要3张，以10~20张为宜。标定板需要是黑白相间的矩形构成的棋盘图，制作精度要求较高。\n\n\n### 对每一张图片，提取角点信息\n读取每一张标定图片，执行cv2.findChessboardCorners棋盘格检测函数，提取角点信息corners；  \n我们需要最大精度的角点检测，使用cv2.cornerSubPix()，将角点的重心传给这个函数进行修正，它可以提供亚像素级别的角点检测；\n在棋盘标定图上绘制找到的内角点；\n\n``` python\ndef read_sample(self, image_path):\n    for fname in image_path:\n        img = cv2.imread(fname)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        # 找到棋盘格角点\n        ret, corners = cv2.findChessboardCorners(gray, (w,h),None)\n        # 如果找到足够点对，将其存储起来\n        if ret == True:\n            cv2.cornerSubPix(gray,corners,(11,11),(-1,-1), self.criteria)\n            self.objpoints.append(self.objp)\n            self.imgpoints.append(corners)\n            # 将角点在图像上显示\n            cv2.drawChessboardCorners(img, (w,h), corners, ret)\n            cv2.imshow('findCorners',img)\n            cv2.waitKey(1)\n    cv2.destroyAllWindows()\n```\n<div align=center>\n<img src = \"象棋残局机器人一：摄像头标定/003.png\" width=600 height=400>\n</div>\n\n### 相机标定\n获取到棋盘标定图的内角点图像坐标之后，就可以使用cv2.calibrateCamera函数进行标定，计算相机内参和外参系数；\n``` python\ndef calibrate(self):\n    # 标定\n    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera( self.objpoints, self.imgpoints, self.image_shape[::-1], None, None)\n    '''\n    mtx   - 摄像机内矩阵\n    dist  - 进一步扭曲\n    rvecs - 旋转向量\n    tvecs - 平移向量\n    '''\n    print(\"mtx:\", mtx)\n    print(\"dist:\", dist)\n```\n\n### 查看标定效果\n利用求得的内参数矩阵和畸变系数，可以对图像进行畸变的矫正\n``` python\ndef test(self, image_path):\n    # 去畸变\n    img2 = cv2.imread(image_path)\n    h, w = img2.shape[:2]\n    # undistort\n    dst = cv2.undistort(img2, self.calibrate_mtx, self.calibrate_dist, None, self.calibrate_mtx)\n    cv2.imshow('img', img2)\n    cv2.imshow('dst', dst)\n```\n<div align=center>\n<img src = \"象棋残局机器人一：摄像头标定/002.png\" width=600 height=400>\n</div>\n\n## 参考资料\n\n* 使用OpenCV进行标定（Python） - sylvester的博客 - CSDN博客  \nhttps://blog.csdn.net/u010128736/article/details/52875137\n\n","source":"_posts/象棋残局机器人一：摄像头标定.md","raw":"---\ntitle: 象棋残局机器人一：摄像头标定\ndate: 2019-05-25 16:44:09\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n廉价摄像头会给图像带来很多畸变，硬件解决方法是买个无畸变的摄像头，软件解决方案是找到摄像机畸变参数以及摄像机的内部参数和外部参数，对畸变图像进行修复。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n<div align=center>\n<img src=\"象棋残局机器人一：摄像头标定\\001.jpg\" width=600 height=400>\n</div>\n\n## 原理\n* 相机标定(Camera calibration) - honyniu的专栏 - CSDN博客  \nhttps://blog.csdn.net/honyniu/article/details/51004397\n* 张正友相机标定Opencv实现以及标定流程&&标定结果评价&&图像矫正流程解析（附标定程序和棋盘图） - 牧野的博客 - CSDN博客  \nhttps://blog.csdn.net/dcrmg/article/details/52939318\n\n\n## 流程\n1. 准备棋盘格标定图片；\n2. 对每一张标定图片，执行棋盘格检测，提取角点信息；\n3. 相机标定；\n4. 对标定结果进行评价；\n5. 查看标定效果\n\n### 准备标定图片\n标定图片需要使用标定板在不同位置、不同角度、不同姿态下拍摄，最少需要3张，以10~20张为宜。标定板需要是黑白相间的矩形构成的棋盘图，制作精度要求较高。\n\n\n### 对每一张图片，提取角点信息\n读取每一张标定图片，执行cv2.findChessboardCorners棋盘格检测函数，提取角点信息corners；  \n我们需要最大精度的角点检测，使用cv2.cornerSubPix()，将角点的重心传给这个函数进行修正，它可以提供亚像素级别的角点检测；\n在棋盘标定图上绘制找到的内角点；\n\n``` python\ndef read_sample(self, image_path):\n    for fname in image_path:\n        img = cv2.imread(fname)\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        # 找到棋盘格角点\n        ret, corners = cv2.findChessboardCorners(gray, (w,h),None)\n        # 如果找到足够点对，将其存储起来\n        if ret == True:\n            cv2.cornerSubPix(gray,corners,(11,11),(-1,-1), self.criteria)\n            self.objpoints.append(self.objp)\n            self.imgpoints.append(corners)\n            # 将角点在图像上显示\n            cv2.drawChessboardCorners(img, (w,h), corners, ret)\n            cv2.imshow('findCorners',img)\n            cv2.waitKey(1)\n    cv2.destroyAllWindows()\n```\n<div align=center>\n<img src = \"象棋残局机器人一：摄像头标定/003.png\" width=600 height=400>\n</div>\n\n### 相机标定\n获取到棋盘标定图的内角点图像坐标之后，就可以使用cv2.calibrateCamera函数进行标定，计算相机内参和外参系数；\n``` python\ndef calibrate(self):\n    # 标定\n    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera( self.objpoints, self.imgpoints, self.image_shape[::-1], None, None)\n    '''\n    mtx   - 摄像机内矩阵\n    dist  - 进一步扭曲\n    rvecs - 旋转向量\n    tvecs - 平移向量\n    '''\n    print(\"mtx:\", mtx)\n    print(\"dist:\", dist)\n```\n\n### 查看标定效果\n利用求得的内参数矩阵和畸变系数，可以对图像进行畸变的矫正\n``` python\ndef test(self, image_path):\n    # 去畸变\n    img2 = cv2.imread(image_path)\n    h, w = img2.shape[:2]\n    # undistort\n    dst = cv2.undistort(img2, self.calibrate_mtx, self.calibrate_dist, None, self.calibrate_mtx)\n    cv2.imshow('img', img2)\n    cv2.imshow('dst', dst)\n```\n<div align=center>\n<img src = \"象棋残局机器人一：摄像头标定/002.png\" width=600 height=400>\n</div>\n\n## 参考资料\n\n* 使用OpenCV进行标定（Python） - sylvester的博客 - CSDN博客  \nhttps://blog.csdn.net/u010128736/article/details/52875137\n\n","slug":"象棋残局机器人一：摄像头标定","published":1,"updated":"2019-06-23T07:09:39.790Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm753001ersvjoz9npopo","content":"<p><strong> 象棋残局机器人一：摄像头标定：</strong> <excerpt in index | 首页摘要><br>廉价摄像头会给图像带来很多畸变，硬件解决方法是买个无畸变的摄像头，软件解决方案是找到摄像机畸变参数以及摄像机的内部参数和外部参数，对畸变图像进行修复。<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/001.jpg\" width=\"600\" height=\"400\">\n</div>\n\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><ul>\n<li>相机标定(Camera calibration) - honyniu的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/honyniu/article/details/51004397\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/honyniu/article/details/51004397</a></li>\n<li>张正友相机标定Opencv实现以及标定流程&amp;&amp;标定结果评价&amp;&amp;图像矫正流程解析（附标定程序和棋盘图） - 牧野的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/dcrmg/article/details/52939318\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dcrmg/article/details/52939318</a></li>\n</ul>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><ol>\n<li>准备棋盘格标定图片；</li>\n<li>对每一张标定图片，执行棋盘格检测，提取角点信息；</li>\n<li>相机标定；</li>\n<li>对标定结果进行评价；</li>\n<li>查看标定效果</li>\n</ol>\n<h3 id=\"准备标定图片\"><a href=\"#准备标定图片\" class=\"headerlink\" title=\"准备标定图片\"></a>准备标定图片</h3><p>标定图片需要使用标定板在不同位置、不同角度、不同姿态下拍摄，最少需要3张，以10~20张为宜。标定板需要是黑白相间的矩形构成的棋盘图，制作精度要求较高。</p>\n<h3 id=\"对每一张图片，提取角点信息\"><a href=\"#对每一张图片，提取角点信息\" class=\"headerlink\" title=\"对每一张图片，提取角点信息\"></a>对每一张图片，提取角点信息</h3><p>读取每一张标定图片，执行cv2.findChessboardCorners棋盘格检测函数，提取角点信息corners；<br>我们需要最大精度的角点检测，使用cv2.cornerSubPix()，将角点的重心传给这个函数进行修正，它可以提供亚像素级别的角点检测；<br>在棋盘标定图上绘制找到的内角点；</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">read_sample</span><span class=\"params\">(self, image_path)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> fname <span class=\"keyword\">in</span> image_path:</span><br><span class=\"line\">        img = cv2.imread(fname)</span><br><span class=\"line\">        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">        <span class=\"comment\"># 找到棋盘格角点</span></span><br><span class=\"line\">        ret, corners = cv2.findChessboardCorners(gray, (w,h),<span class=\"literal\">None</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 如果找到足够点对，将其存储起来</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">            cv2.cornerSubPix(gray,corners,(<span class=\"number\">11</span>,<span class=\"number\">11</span>),(<span class=\"number\">-1</span>,<span class=\"number\">-1</span>), self.criteria)</span><br><span class=\"line\">            self.objpoints.append(self.objp)</span><br><span class=\"line\">            self.imgpoints.append(corners)</span><br><span class=\"line\">            <span class=\"comment\"># 将角点在图像上显示</span></span><br><span class=\"line\">            cv2.drawChessboardCorners(img, (w,h), corners, ret)</span><br><span class=\"line\">            cv2.imshow(<span class=\"string\">'findCorners'</span>,img)</span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/003.png\" width=\"600\" height=\"400\">\n</div>\n\n<h3 id=\"相机标定\"><a href=\"#相机标定\" class=\"headerlink\" title=\"相机标定\"></a>相机标定</h3><p>获取到棋盘标定图的内角点图像坐标之后，就可以使用cv2.calibrateCamera函数进行标定，计算相机内参和外参系数；<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calibrate</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 标定</span></span><br><span class=\"line\">    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera( self.objpoints, self.imgpoints, self.image_shape[::<span class=\"number\">-1</span>], <span class=\"literal\">None</span>, <span class=\"literal\">None</span>)</span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    mtx   - 摄像机内矩阵</span></span><br><span class=\"line\"><span class=\"string\">    dist  - 进一步扭曲</span></span><br><span class=\"line\"><span class=\"string\">    rvecs - 旋转向量</span></span><br><span class=\"line\"><span class=\"string\">    tvecs - 平移向量</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    print(<span class=\"string\">\"mtx:\"</span>, mtx)</span><br><span class=\"line\">    print(<span class=\"string\">\"dist:\"</span>, dist)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"查看标定效果\"><a href=\"#查看标定效果\" class=\"headerlink\" title=\"查看标定效果\"></a>查看标定效果</h3><p>利用求得的内参数矩阵和畸变系数，可以对图像进行畸变的矫正<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">(self, image_path)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 去畸变</span></span><br><span class=\"line\">    img2 = cv2.imread(image_path)</span><br><span class=\"line\">    h, w = img2.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\">    <span class=\"comment\"># undistort</span></span><br><span class=\"line\">    dst = cv2.undistort(img2, self.calibrate_mtx, self.calibrate_dist, <span class=\"literal\">None</span>, self.calibrate_mtx)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'img'</span>, img2)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'dst'</span>, dst)</span><br></pre></td></tr></table></figure></p>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/002.png\" width=\"600\" height=\"400\">\n</div>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>使用OpenCV进行标定（Python） - sylvester的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/u010128736/article/details/52875137\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010128736/article/details/52875137</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 象棋残局机器人一：摄像头标定：</strong> <excerpt in index | 首页摘要><br>廉价摄像头会给图像带来很多畸变，硬件解决方法是买个无畸变的摄像头，软件解决方案是找到摄像机畸变参数以及摄像机的内部参数和外部参数，对畸变图像进行修复。<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/001.jpg\" width=\"600\" height=\"400\">\n</div>\n\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><ul>\n<li>相机标定(Camera calibration) - honyniu的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/honyniu/article/details/51004397\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/honyniu/article/details/51004397</a></li>\n<li>张正友相机标定Opencv实现以及标定流程&amp;&amp;标定结果评价&amp;&amp;图像矫正流程解析（附标定程序和棋盘图） - 牧野的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/dcrmg/article/details/52939318\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/dcrmg/article/details/52939318</a></li>\n</ul>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><ol>\n<li>准备棋盘格标定图片；</li>\n<li>对每一张标定图片，执行棋盘格检测，提取角点信息；</li>\n<li>相机标定；</li>\n<li>对标定结果进行评价；</li>\n<li>查看标定效果</li>\n</ol>\n<h3 id=\"准备标定图片\"><a href=\"#准备标定图片\" class=\"headerlink\" title=\"准备标定图片\"></a>准备标定图片</h3><p>标定图片需要使用标定板在不同位置、不同角度、不同姿态下拍摄，最少需要3张，以10~20张为宜。标定板需要是黑白相间的矩形构成的棋盘图，制作精度要求较高。</p>\n<h3 id=\"对每一张图片，提取角点信息\"><a href=\"#对每一张图片，提取角点信息\" class=\"headerlink\" title=\"对每一张图片，提取角点信息\"></a>对每一张图片，提取角点信息</h3><p>读取每一张标定图片，执行cv2.findChessboardCorners棋盘格检测函数，提取角点信息corners；<br>我们需要最大精度的角点检测，使用cv2.cornerSubPix()，将角点的重心传给这个函数进行修正，它可以提供亚像素级别的角点检测；<br>在棋盘标定图上绘制找到的内角点；</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">read_sample</span><span class=\"params\">(self, image_path)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> fname <span class=\"keyword\">in</span> image_path:</span><br><span class=\"line\">        img = cv2.imread(fname)</span><br><span class=\"line\">        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">        <span class=\"comment\"># 找到棋盘格角点</span></span><br><span class=\"line\">        ret, corners = cv2.findChessboardCorners(gray, (w,h),<span class=\"literal\">None</span>)</span><br><span class=\"line\">        <span class=\"comment\"># 如果找到足够点对，将其存储起来</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> ret == <span class=\"literal\">True</span>:</span><br><span class=\"line\">            cv2.cornerSubPix(gray,corners,(<span class=\"number\">11</span>,<span class=\"number\">11</span>),(<span class=\"number\">-1</span>,<span class=\"number\">-1</span>), self.criteria)</span><br><span class=\"line\">            self.objpoints.append(self.objp)</span><br><span class=\"line\">            self.imgpoints.append(corners)</span><br><span class=\"line\">            <span class=\"comment\"># 将角点在图像上显示</span></span><br><span class=\"line\">            cv2.drawChessboardCorners(img, (w,h), corners, ret)</span><br><span class=\"line\">            cv2.imshow(<span class=\"string\">'findCorners'</span>,img)</span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">1</span>)</span><br><span class=\"line\">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/003.png\" width=\"600\" height=\"400\">\n</div>\n\n<h3 id=\"相机标定\"><a href=\"#相机标定\" class=\"headerlink\" title=\"相机标定\"></a>相机标定</h3><p>获取到棋盘标定图的内角点图像坐标之后，就可以使用cv2.calibrateCamera函数进行标定，计算相机内参和外参系数；<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">calibrate</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 标定</span></span><br><span class=\"line\">    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera( self.objpoints, self.imgpoints, self.image_shape[::<span class=\"number\">-1</span>], <span class=\"literal\">None</span>, <span class=\"literal\">None</span>)</span><br><span class=\"line\">    <span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">    mtx   - 摄像机内矩阵</span></span><br><span class=\"line\"><span class=\"string\">    dist  - 进一步扭曲</span></span><br><span class=\"line\"><span class=\"string\">    rvecs - 旋转向量</span></span><br><span class=\"line\"><span class=\"string\">    tvecs - 平移向量</span></span><br><span class=\"line\"><span class=\"string\">    '''</span></span><br><span class=\"line\">    print(<span class=\"string\">\"mtx:\"</span>, mtx)</span><br><span class=\"line\">    print(<span class=\"string\">\"dist:\"</span>, dist)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"查看标定效果\"><a href=\"#查看标定效果\" class=\"headerlink\" title=\"查看标定效果\"></a>查看标定效果</h3><p>利用求得的内参数矩阵和畸变系数，可以对图像进行畸变的矫正<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">(self, image_path)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 去畸变</span></span><br><span class=\"line\">    img2 = cv2.imread(image_path)</span><br><span class=\"line\">    h, w = img2.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\">    <span class=\"comment\"># undistort</span></span><br><span class=\"line\">    dst = cv2.undistort(img2, self.calibrate_mtx, self.calibrate_dist, <span class=\"literal\">None</span>, self.calibrate_mtx)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'img'</span>, img2)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'dst'</span>, dst)</span><br></pre></td></tr></table></figure></p>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人一：摄像头标定/002.png\" width=\"600\" height=\"400\">\n</div>\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>使用OpenCV进行标定（Python） - sylvester的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/u010128736/article/details/52875137\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/u010128736/article/details/52875137</a></li>\n</ul>\n</the>"},{"title":"象棋残局机器人","date":"2019-05-05T15:08:30.000Z","_content":"\n# 准备\n\n## python\n* Home - Anaconda https://www.anaconda.com/  \n* Visual Studio Code - Code Editing. Redefined https://code.visualstudio.com/  \n\n```python\nimport cv2\nimport numpy\nimport tkinter as tk\nimport serial \n```\n\n## Strategy\n* 图搜索：极大极小搜索、Alpha-Beta剪枝、迭代加深、A*、IDA*\n* 强化学习：MCTS、AlphaZero\n\n## Armbot\n* 越疆科技DOBOT https://cn.dobot.cc/\n\n## Vision\n* OpenCV: OpenCV-Python Tutorials https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html\n* spmallick/learnopencv: Learn OpenCV : C++ and Python Examples https://github.com/spmallick/learnopencv\n``` bash\n> conda create -n your_env_name python=3.6\n> activate your_env_name\n> pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple\n> pip install opencv-contrib-python\n```\n\n\n\n# Demo\n\n\n* hikey970 棋面识别  \n<div align=center>\n<img src='象棋残局机器人/demo1.gif' width=600 height=400>\n</div>\n\n* 开局  \n<div align=center>\n<img src='象棋残局机器人/demo3.gif' width=600 height=400>\n</div>\n\n* 人机对弈  \n<div align=center>\n<img src='象棋残局机器人/demo2.gif' width=600 height=400>\n</div>\n\n","source":"_posts/象棋残局机器人.md","raw":"---\ntitle: 象棋残局机器人\ndate: 2019-05-05 23:08:30\ntags:\n  - python\n  - opencv\n  - alphazero\n---\n\n# 准备\n\n## python\n* Home - Anaconda https://www.anaconda.com/  \n* Visual Studio Code - Code Editing. Redefined https://code.visualstudio.com/  \n\n```python\nimport cv2\nimport numpy\nimport tkinter as tk\nimport serial \n```\n\n## Strategy\n* 图搜索：极大极小搜索、Alpha-Beta剪枝、迭代加深、A*、IDA*\n* 强化学习：MCTS、AlphaZero\n\n## Armbot\n* 越疆科技DOBOT https://cn.dobot.cc/\n\n## Vision\n* OpenCV: OpenCV-Python Tutorials https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html\n* spmallick/learnopencv: Learn OpenCV : C++ and Python Examples https://github.com/spmallick/learnopencv\n``` bash\n> conda create -n your_env_name python=3.6\n> activate your_env_name\n> pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple\n> pip install opencv-contrib-python\n```\n\n\n\n# Demo\n\n\n* hikey970 棋面识别  \n<div align=center>\n<img src='象棋残局机器人/demo1.gif' width=600 height=400>\n</div>\n\n* 开局  \n<div align=center>\n<img src='象棋残局机器人/demo3.gif' width=600 height=400>\n</div>\n\n* 人机对弈  \n<div align=center>\n<img src='象棋残局机器人/demo2.gif' width=600 height=400>\n</div>\n\n","slug":"象棋残局机器人","published":1,"updated":"2019-06-23T07:09:39.787Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm755001grsvjff5ukdcm","content":"<h1 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h1><h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li>Home - Anaconda <a href=\"https://www.anaconda.com/\" target=\"_blank\" rel=\"noopener\">https://www.anaconda.com/</a>  </li>\n<li>Visual Studio Code - Code Editing. Redefined <a href=\"https://code.visualstudio.com/\" target=\"_blank\" rel=\"noopener\">https://code.visualstudio.com/</a>  </li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter <span class=\"keyword\">as</span> tk</span><br><span class=\"line\"><span class=\"keyword\">import</span> serial</span><br></pre></td></tr></table></figure>\n<h2 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h2><ul>\n<li>图搜索：极大极小搜索、Alpha-Beta剪枝、迭代加深、A<em>、IDA</em></li>\n<li>强化学习：MCTS、AlphaZero</li>\n</ul>\n<h2 id=\"Armbot\"><a href=\"#Armbot\" class=\"headerlink\" title=\"Armbot\"></a>Armbot</h2><ul>\n<li>越疆科技DOBOT <a href=\"https://cn.dobot.cc/\" target=\"_blank\" rel=\"noopener\">https://cn.dobot.cc/</a></li>\n</ul>\n<h2 id=\"Vision\"><a href=\"#Vision\" class=\"headerlink\" title=\"Vision\"></a>Vision</h2><ul>\n<li>OpenCV: OpenCV-Python Tutorials <a href=\"https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html\" target=\"_blank\" rel=\"noopener\">https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html</a></li>\n<li>spmallick/learnopencv: Learn OpenCV : C++ and Python Examples <a href=\"https://github.com/spmallick/learnopencv\" target=\"_blank\" rel=\"noopener\">https://github.com/spmallick/learnopencv</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; conda create -n your_env_name python=3.6</span><br><span class=\"line\">&gt; activate your_env_name</span><br><span class=\"line\">&gt; pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class=\"line\">&gt; pip install opencv-contrib-python</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h1 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h1><ul>\n<li><p>hikey970 棋面识别  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo1.gif\" width=\"600\" height=\"400\">\n</div>\n</li>\n<li><p>开局  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo3.gif\" width=\"600\" height=\"400\">\n</div>\n</li>\n<li><p>人机对弈  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo2.gif\" width=\"600\" height=\"400\">\n</div>\n\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h1><h2 id=\"python\"><a href=\"#python\" class=\"headerlink\" title=\"python\"></a>python</h2><ul>\n<li>Home - Anaconda <a href=\"https://www.anaconda.com/\" target=\"_blank\" rel=\"noopener\">https://www.anaconda.com/</a>  </li>\n<li>Visual Studio Code - Code Editing. Redefined <a href=\"https://code.visualstudio.com/\" target=\"_blank\" rel=\"noopener\">https://code.visualstudio.com/</a>  </li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy</span><br><span class=\"line\"><span class=\"keyword\">import</span> tkinter <span class=\"keyword\">as</span> tk</span><br><span class=\"line\"><span class=\"keyword\">import</span> serial</span><br></pre></td></tr></table></figure>\n<h2 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h2><ul>\n<li>图搜索：极大极小搜索、Alpha-Beta剪枝、迭代加深、A<em>、IDA</em></li>\n<li>强化学习：MCTS、AlphaZero</li>\n</ul>\n<h2 id=\"Armbot\"><a href=\"#Armbot\" class=\"headerlink\" title=\"Armbot\"></a>Armbot</h2><ul>\n<li>越疆科技DOBOT <a href=\"https://cn.dobot.cc/\" target=\"_blank\" rel=\"noopener\">https://cn.dobot.cc/</a></li>\n</ul>\n<h2 id=\"Vision\"><a href=\"#Vision\" class=\"headerlink\" title=\"Vision\"></a>Vision</h2><ul>\n<li>OpenCV: OpenCV-Python Tutorials <a href=\"https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html\" target=\"_blank\" rel=\"noopener\">https://docs.opencv.org/4.0.0/d6/d00/tutorial_py_root.html</a></li>\n<li>spmallick/learnopencv: Learn OpenCV : C++ and Python Examples <a href=\"https://github.com/spmallick/learnopencv\" target=\"_blank\" rel=\"noopener\">https://github.com/spmallick/learnopencv</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&gt; conda create -n your_env_name python=3.6</span><br><span class=\"line\">&gt; activate your_env_name</span><br><span class=\"line\">&gt; pip install opencv-python -i https://pypi.tuna.tsinghua.edu.cn/simple</span><br><span class=\"line\">&gt; pip install opencv-contrib-python</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h1 id=\"Demo\"><a href=\"#Demo\" class=\"headerlink\" title=\"Demo\"></a>Demo</h1><ul>\n<li><p>hikey970 棋面识别  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo1.gif\" width=\"600\" height=\"400\">\n</div>\n</li>\n<li><p>开局  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo3.gif\" width=\"600\" height=\"400\">\n</div>\n</li>\n<li><p>人机对弈  </p>\n<div align=\"center\">\n<img src=\"/2019/05/05/象棋残局机器人/demo2.gif\" width=\"600\" height=\"400\">\n</div>\n\n</li>\n</ul>\n"},{"title":"象棋残局机器人二：投射变换","date":"2019-05-25T15:34:15.000Z","_content":"\n## 图片的几何变换\n* 缩放\n``` bash\nimg = cv2.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\ndstHeight = int(height*0.5)\ndstWidth = int(width*0.5)\n# cv2.resize()\n# dst = cv2.resize(img, (dstWidth, dstHeight))\n# 最近邻域插值\ndstImage = np.zeros((dstHeight, dstWidth), np.uint8)\nfor i in range(0, dstHeight):\n    for j in range(0, dstWidth):\n        iNew = int(i * height * 1.0 / dstHeight)\n        jNew = int(j * width * 1.0 / dstWidth)\n        dstImage[i, j] = img(iNew, jNew)\ncv2.imshow(\"img\", dstImage)\n# 双线性插值 \n# 像素关系重采样 \n# 立方插值\ncv2.waitKey(0)\n```\n* 剪切\n``` bash\n# 图片坐标\n# x: 0-width\n# y: 0-height\nimg = cv2.imread(\"tmp.png\", 1)\ndatImage = img[100:200, 100:300]\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 位移\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# cv2.warpAffine()\nmatShift = np.float32([[1,0,100], [0,1,200]]) # 2行3列\ndstImage = cv2.warpAffine(img, matShift, (width, height))\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 镜像\n``` bash\nxImg  = cv.flip(img,1,dst=None)  #水平镜像\nxImg1 = cv.flip(img,0,dst=None)  #垂直镜像\nxImg2 = cv.flip(img,-1,dst=None) #对角镜像\n```\n* 仿射变换\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# src 3p -> dst 3p\nmatSrc = np.float32([[0,0], [0,height-1], [width-1, 0]])\nmatDst = np.float32([[50,50], [300,height-200], [width-300, 100]])\n# 获得仿射变换矩阵\nmatAffine = cv2.getAffineTransform(matSrc, matDst)\ndstImage = cv2.warpAffine(img, matAffine, (width, height))\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 旋转\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# 获得旋转矩阵\nmatRotate = cv2.getRotationMatrix2D((int(width/2), int(height/2)), 45, 0.5)\ndstImage = cv2.warpAffine(img, matRotate, (width, height))\ncv2.imshow(\"img2\", dstImage)\ncv2.waitKey(0)\n```\n## 仿射变换就是特殊的透射变换\n\n* 透射变换\n``` bash\nmatSrc = np.float32(points)\nmatDst = np.float32([[0,0],[0,399],[99, 0],[99,399]])\nmatPers = cv2.getPerspectiveTransform(matSrc, matDst)\ndstImage = cv2.warpPerspective(img, matPers, (width, height))\n```\n\n<div align=center>\n<img src='象棋残局机器人二：透射变换\\001.jpg' width=600 height=300>\n</div>\n\n利用透射变换这一操作，从而将棋面的图像从背景中抽离转化成易于处理的形式。\n\n\n## 参考资料\n\n* 仿射变换和透射变换 - outthinker - 博客园  \nhttps://www.cnblogs.com/zf-blog/p/7813227.html\n\n* 4.1 图像特效介绍 - YouTube  \nhttps://www.youtube.com/watch?v=Ih2iamhLvxE&list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&index=36\n","source":"_posts/象棋残局机器人二：透射变换.md","raw":"---\ntitle: 象棋残局机器人二：投射变换\ndate: 2019-05-25 23:34:15\ntags:\n  - opencv\n---\n\n## 图片的几何变换\n* 缩放\n``` bash\nimg = cv2.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\ndstHeight = int(height*0.5)\ndstWidth = int(width*0.5)\n# cv2.resize()\n# dst = cv2.resize(img, (dstWidth, dstHeight))\n# 最近邻域插值\ndstImage = np.zeros((dstHeight, dstWidth), np.uint8)\nfor i in range(0, dstHeight):\n    for j in range(0, dstWidth):\n        iNew = int(i * height * 1.0 / dstHeight)\n        jNew = int(j * width * 1.0 / dstWidth)\n        dstImage[i, j] = img(iNew, jNew)\ncv2.imshow(\"img\", dstImage)\n# 双线性插值 \n# 像素关系重采样 \n# 立方插值\ncv2.waitKey(0)\n```\n* 剪切\n``` bash\n# 图片坐标\n# x: 0-width\n# y: 0-height\nimg = cv2.imread(\"tmp.png\", 1)\ndatImage = img[100:200, 100:300]\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 位移\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# cv2.warpAffine()\nmatShift = np.float32([[1,0,100], [0,1,200]]) # 2行3列\ndstImage = cv2.warpAffine(img, matShift, (width, height))\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 镜像\n``` bash\nxImg  = cv.flip(img,1,dst=None)  #水平镜像\nxImg1 = cv.flip(img,0,dst=None)  #垂直镜像\nxImg2 = cv.flip(img,-1,dst=None) #对角镜像\n```\n* 仿射变换\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# src 3p -> dst 3p\nmatSrc = np.float32([[0,0], [0,height-1], [width-1, 0]])\nmatDst = np.float32([[50,50], [300,height-200], [width-300, 100]])\n# 获得仿射变换矩阵\nmatAffine = cv2.getAffineTransform(matSrc, matDst)\ndstImage = cv2.warpAffine(img, matAffine, (width, height))\ncv2.imshow(\"img\", dstImage)\ncv2.waitKey(0)\n```\n* 旋转\n``` bash\nimg = cv.imread(\"tmp.png\", 1)\nheight, width, _ = img.shape  # (height, width, mode)\n# 获得旋转矩阵\nmatRotate = cv2.getRotationMatrix2D((int(width/2), int(height/2)), 45, 0.5)\ndstImage = cv2.warpAffine(img, matRotate, (width, height))\ncv2.imshow(\"img2\", dstImage)\ncv2.waitKey(0)\n```\n## 仿射变换就是特殊的透射变换\n\n* 透射变换\n``` bash\nmatSrc = np.float32(points)\nmatDst = np.float32([[0,0],[0,399],[99, 0],[99,399]])\nmatPers = cv2.getPerspectiveTransform(matSrc, matDst)\ndstImage = cv2.warpPerspective(img, matPers, (width, height))\n```\n\n<div align=center>\n<img src='象棋残局机器人二：透射变换\\001.jpg' width=600 height=300>\n</div>\n\n利用透射变换这一操作，从而将棋面的图像从背景中抽离转化成易于处理的形式。\n\n\n## 参考资料\n\n* 仿射变换和透射变换 - outthinker - 博客园  \nhttps://www.cnblogs.com/zf-blog/p/7813227.html\n\n* 4.1 图像特效介绍 - YouTube  \nhttps://www.youtube.com/watch?v=Ih2iamhLvxE&list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&index=36\n","slug":"象棋残局机器人二：透射变换","published":1,"updated":"2019-06-23T07:09:39.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm756001irsvjhqahgogm","content":"<h2 id=\"图片的几何变换\"><a href=\"#图片的几何变换\" class=\"headerlink\" title=\"图片的几何变换\"></a>图片的几何变换</h2><ul>\n<li><p>缩放</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv2.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\">dstHeight = int(height*0.5)</span><br><span class=\"line\">dstWidth = int(width*0.5)</span><br><span class=\"line\"><span class=\"comment\"># cv2.resize()</span></span><br><span class=\"line\"><span class=\"comment\"># dst = cv2.resize(img, (dstWidth, dstHeight))</span></span><br><span class=\"line\"><span class=\"comment\"># 最近邻域插值</span></span><br><span class=\"line\">dstImage = np.zeros((dstHeight, dstWidth), np.uint8)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, dstHeight):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(0, dstWidth):</span><br><span class=\"line\">        iNew = int(i * height * 1.0 / dstHeight)</span><br><span class=\"line\">        jNew = int(j * width * 1.0 / dstWidth)</span><br><span class=\"line\">        dstImage[i, j] = img(iNew, jNew)</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\"><span class=\"comment\"># 双线性插值 </span></span><br><span class=\"line\"><span class=\"comment\"># 像素关系重采样 </span></span><br><span class=\"line\"><span class=\"comment\"># 立方插值</span></span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>剪切</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 图片坐标</span></span><br><span class=\"line\"><span class=\"comment\"># x: 0-width</span></span><br><span class=\"line\"><span class=\"comment\"># y: 0-height</span></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">datImage = img[100:200, 100:300]</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>位移</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.warpAffine()</span></span><br><span class=\"line\">matShift = np.float32([[1,0,100], [0,1,200]]) <span class=\"comment\"># 2行3列</span></span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matShift, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>镜像</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xImg  = cv.flip(img,1,dst=None)  <span class=\"comment\">#水平镜像</span></span><br><span class=\"line\">xImg1 = cv.flip(img,0,dst=None)  <span class=\"comment\">#垂直镜像</span></span><br><span class=\"line\">xImg2 = cv.flip(img,-1,dst=None) <span class=\"comment\">#对角镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>仿射变换</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># src 3p -&gt; dst 3p</span></span><br><span class=\"line\">matSrc = np.float32([[0,0], [0,height-1], [width-1, 0]])</span><br><span class=\"line\">matDst = np.float32([[50,50], [300,height-200], [width-300, 100]])</span><br><span class=\"line\"><span class=\"comment\"># 获得仿射变换矩阵</span></span><br><span class=\"line\">matAffine = cv2.getAffineTransform(matSrc, matDst)</span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matAffine, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>旋转</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># 获得旋转矩阵</span></span><br><span class=\"line\">matRotate = cv2.getRotationMatrix2D((int(width/2), int(height/2)), 45, 0.5)</span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matRotate, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img2\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"仿射变换就是特殊的透射变换\"><a href=\"#仿射变换就是特殊的透射变换\" class=\"headerlink\" title=\"仿射变换就是特殊的透射变换\"></a>仿射变换就是特殊的透射变换</h2><ul>\n<li>透射变换<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">matSrc = np.float32(points)</span><br><span class=\"line\">matDst = np.float32([[0,0],[0,399],[99, 0],[99,399]])</span><br><span class=\"line\">matPers = cv2.getPerspectiveTransform(matSrc, matDst)</span><br><span class=\"line\">dstImage = cv2.warpPerspective(img, matPers, (width, height))</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人二：透射变换/001.jpg\" width=\"600\" height=\"300\">\n</div>\n\n<p>利用透射变换这一操作，从而将棋面的图像从背景中抽离转化成易于处理的形式。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><p>仿射变换和透射变换 - outthinker - 博客园<br><a href=\"https://www.cnblogs.com/zf-blog/p/7813227.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zf-blog/p/7813227.html</a></p>\n</li>\n<li><p>4.1 图像特效介绍 - YouTube<br><a href=\"https://www.youtube.com/watch?v=Ih2iamhLvxE&amp;list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&amp;index=36\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=Ih2iamhLvxE&amp;list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&amp;index=36</a></p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"图片的几何变换\"><a href=\"#图片的几何变换\" class=\"headerlink\" title=\"图片的几何变换\"></a>图片的几何变换</h2><ul>\n<li><p>缩放</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv2.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\">dstHeight = int(height*0.5)</span><br><span class=\"line\">dstWidth = int(width*0.5)</span><br><span class=\"line\"><span class=\"comment\"># cv2.resize()</span></span><br><span class=\"line\"><span class=\"comment\"># dst = cv2.resize(img, (dstWidth, dstHeight))</span></span><br><span class=\"line\"><span class=\"comment\"># 最近邻域插值</span></span><br><span class=\"line\">dstImage = np.zeros((dstHeight, dstWidth), np.uint8)</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(0, dstHeight):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(0, dstWidth):</span><br><span class=\"line\">        iNew = int(i * height * 1.0 / dstHeight)</span><br><span class=\"line\">        jNew = int(j * width * 1.0 / dstWidth)</span><br><span class=\"line\">        dstImage[i, j] = img(iNew, jNew)</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\"><span class=\"comment\"># 双线性插值 </span></span><br><span class=\"line\"><span class=\"comment\"># 像素关系重采样 </span></span><br><span class=\"line\"><span class=\"comment\"># 立方插值</span></span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>剪切</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 图片坐标</span></span><br><span class=\"line\"><span class=\"comment\"># x: 0-width</span></span><br><span class=\"line\"><span class=\"comment\"># y: 0-height</span></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">datImage = img[100:200, 100:300]</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>位移</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.warpAffine()</span></span><br><span class=\"line\">matShift = np.float32([[1,0,100], [0,1,200]]) <span class=\"comment\"># 2行3列</span></span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matShift, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>镜像</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xImg  = cv.flip(img,1,dst=None)  <span class=\"comment\">#水平镜像</span></span><br><span class=\"line\">xImg1 = cv.flip(img,0,dst=None)  <span class=\"comment\">#垂直镜像</span></span><br><span class=\"line\">xImg2 = cv.flip(img,-1,dst=None) <span class=\"comment\">#对角镜像</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>仿射变换</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># src 3p -&gt; dst 3p</span></span><br><span class=\"line\">matSrc = np.float32([[0,0], [0,height-1], [width-1, 0]])</span><br><span class=\"line\">matDst = np.float32([[50,50], [300,height-200], [width-300, 100]])</span><br><span class=\"line\"><span class=\"comment\"># 获得仿射变换矩阵</span></span><br><span class=\"line\">matAffine = cv2.getAffineTransform(matSrc, matDst)</span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matAffine, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>旋转</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = cv.imread(<span class=\"string\">\"tmp.png\"</span>, 1)</span><br><span class=\"line\">height, width, _ = img.shape  <span class=\"comment\"># (height, width, mode)</span></span><br><span class=\"line\"><span class=\"comment\"># 获得旋转矩阵</span></span><br><span class=\"line\">matRotate = cv2.getRotationMatrix2D((int(width/2), int(height/2)), 45, 0.5)</span><br><span class=\"line\">dstImage = cv2.warpAffine(img, matRotate, (width, height))</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"img2\"</span>, dstImage)</span><br><span class=\"line\">cv2.waitKey(0)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"仿射变换就是特殊的透射变换\"><a href=\"#仿射变换就是特殊的透射变换\" class=\"headerlink\" title=\"仿射变换就是特殊的透射变换\"></a>仿射变换就是特殊的透射变换</h2><ul>\n<li>透射变换<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">matSrc = np.float32(points)</span><br><span class=\"line\">matDst = np.float32([[0,0],[0,399],[99, 0],[99,399]])</span><br><span class=\"line\">matPers = cv2.getPerspectiveTransform(matSrc, matDst)</span><br><span class=\"line\">dstImage = cv2.warpPerspective(img, matPers, (width, height))</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<div align=\"center\">\n<img src=\"/2019/05/25/象棋残局机器人二：透射变换/001.jpg\" width=\"600\" height=\"300\">\n</div>\n\n<p>利用透射变换这一操作，从而将棋面的图像从背景中抽离转化成易于处理的形式。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><p>仿射变换和透射变换 - outthinker - 博客园<br><a href=\"https://www.cnblogs.com/zf-blog/p/7813227.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/zf-blog/p/7813227.html</a></p>\n</li>\n<li><p>4.1 图像特效介绍 - YouTube<br><a href=\"https://www.youtube.com/watch?v=Ih2iamhLvxE&amp;list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&amp;index=36\" target=\"_blank\" rel=\"noopener\">https://www.youtube.com/watch?v=Ih2iamhLvxE&amp;list=PLsYXQooxlb1pE21-dgEf-VdsArdqSvuEW&amp;index=36</a></p>\n</li>\n</ul>\n"},{"title":"象棋残局机器人三：分类模型retrain","date":"2019-05-28T16:27:39.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n基于InceptionV3和mobileNet模型重新训练自己的图片分类模型。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 迁移学习\n\n图片分类模型往往有数以万计的参数，而从头开始训练需要大量的带标签训练数据、强大的算力和更多时间，利用迁移学习，可以在前人优秀图片分类模型的基础上，非常快捷有效地重新训练出新的图像分类器。  \n通常来说，迁移学习的策略有两种。\n* Finetuning（微调）  \n包括在基础数据集上使用预训练网络，并在目标数据集上训练所有层。\n* Freeze and Train（冻结和训练）  \n包括仅冻结并训练最后一层，其他层不变（权重不更新）；也可以冻结前几层，微调其他层，这是由于有些证据表明CNN的前几层有纹理滤镜和彩色斑点。\n\n## 流程\n1. predo.py，准备自己要分类的图片训练样本；\n2. retrain.py，下载inception v3/mobileNet模型及训练图片分类器；\n3. label_image.py，测试模型预测结果。\n\n### 预处理\n``` python\nimport os\nimport cv2\n\npath = \"./data\"\nfiles = os.listdir(path) \n# print(files)\nfor f in files: \n    print(f)\n    cnt = 0\n    data_list = os.listdir(path+'/'+f)\n    # print(data_list[:4])\n    for data in data_list:\n        data_file_path = path+'/'+f+'/'+data \n        # img = cv2.imread(data_file_path)\n        # img_resize = cv2.resize(img, (300, 300))\n        # cv2.imwrite(path+'/'+f+'/'+\"{:04d}.jpg\".format(cnt), img_resize)\n        newname = path+'/'+f+'/'+\"{:04d}.jpg\".format(cnt)\n        os.rename(data_file_path, newname)\n        cnt += 1\n    #     if cnt == 2:\n    #         break\n    # break\n```\n\n### retrain\n* tensorflow/retrain.py at c565660e008cf666c582668cb0d0937ca86e71fb · tensorflow/tensorflow  \nhttps://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py\n\n源码分析  \n* TensorFlow学习笔记：Inception_v3源码分析 - 简书  \nhttps://www.jianshu.com/p/feecdcdef8a0\n``` bash\n# By default: Inception v3\npython retrain.py\n# mobileNet\npython retrain.py --image_dir ./daata --architecture mobilenet_1.0_224\n```\n可以提前下载模型文件到./tmp/imagenet文件夹下。\n* Google AI Blog: MobileNets: Open-Source Models for Efficient On-Device Vision  \nhttps://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html\n\n### 测试\n``` python\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport re\nimport shutil\n\nlines = tf.gfile.GFile('./tmp/output_labels.txt').readlines()\nuid_to_human = {}\n#一行一行读取数据\nfor uid,line in enumerate(lines) :\n    #去掉换行符\n    line=line.strip('\\n')\n    uid_to_human[uid] = line\n \ndef id_to_string(node_id):\n    if node_id not in uid_to_human:\n        return ''\n    return uid_to_human[node_id]\n \n#创建一个图来存放google训练好的模型\nwith tf.gfile.FastGFile('./tmp/output_graph.pb', 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf.import_graph_def(graph_def, name='')\n \nwith tf.Session() as sess:\n    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n    #遍历目录\n    for root,dirs,files in os.walk('./test/'):\n        # print(\"root[-1]:\", root[-1]) # 类别\n        # print(\"files:\", files)\n        \n        for file in files:\n            print(root+\"/\"+file)\n            #载入图片\n            image_data = tf.gfile.FastGFile(root+\"/\"+file, 'rb').read()\n            predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})#图片格式是jpg格式\n            predictions = np.squeeze(predictions)#把结果转为1维数据\n \n            #打印图片路径及名称\n            image_path = os.path.join(root,file)\n            # print(image_path)\n            # #显示图片\n            # img=Image.open(image_path)\n            # plt.imshow(img)\n            # plt.axis('off')\n            # plt.show()\n \n            # 打印结果\n            top_k = predictions.argsort()[::-1]\n            # print(top_k)\n            for node_id in top_k:     \n                # 获取分类名称\n                human_string = id_to_string(node_id)\n                # 获取该分类的置信度\n                score = predictions[node_id]\n                print('%s (score = %.5f)' % (human_string, score))\n            \n            # 将识别错误文件保存到bad文件夹\n            if id_to_string(top_k[0]) != root[-1]:\n                old_path = root + \"/\" + file\n                name, _ = file.split('.')\n                new_path = r'./bad' + '/' + name + '_' + id_to_string(top_k[0]) + '_' + str(predictions[top_k[0]]) +'.jpg' \n                shutil.copyfile(old_path, new_path)\n\n```\n\n## 问题汇总\n### 1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\n\n* TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph. · Issue #12250 · tensorflow/tensorflow  \nhttps://github.com/tensorflow/tensorflow/issues/12250\n\n打印图的参数名称\n``` python\ntensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]\nprint(tensor_name_list)\n```\n修改输入为第一个tensor的名称\n``` python\n# inceptionV3\n# image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n# predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data}) #图片格式是jpg格式\n# predictions = np.squeeze(predictions) #把结果转为1维数据\n\n# mobileNet\nimage_data = tf.gfile.FastGFile(image_path, 'rb').read()\nimage_data = sess.run(tf.expand_dims(tf.image.resize_images(\n    tf.image.decode_jpeg(image_data), [128, 128], method=np.random.randint(0,3)), 0))\npredictions = sess.run(softmax_tensor, {'input:0': image_data}) #图片格式是jpg格式\npredictions = np.squeeze(predictions) #把结果转为1维数据\n```\n### 2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒\n对于棋子分类任务来说，输入是一张28*28的3通道图片，无论使用InceptionV3还是mobileNet_128模型都过于“厚重”，最终手写一个小的卷积网络，通过两层卷积+两层全连接来实现棋子分类。\n<div align=center>\n<img src='象棋残局机器人三：分类模型retrain\\001.png' width=600 height=300>\n</div>\n<div align=center>\n<img src='象棋残局机器人三：分类模型retrain\\002.png' width=600 height=300>\n</div>\n\n\n## 参考资料\n\n* 浅谈迁移学习图像分类 - weixin_33805743的博客 - CSDN博客  \nhttps://blog.csdn.net/weixin_33805743/article/details/87426423\n\n","source":"_posts/象棋残局机器人三：分类模型retrain.md","raw":"---\ntitle: 象棋残局机器人三：分类模型retrain\ndate: 2019-05-29 00:27:39\ntags:\n  - tensorflow\n  - 迁移学习\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n基于InceptionV3和mobileNet模型重新训练自己的图片分类模型。\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 迁移学习\n\n图片分类模型往往有数以万计的参数，而从头开始训练需要大量的带标签训练数据、强大的算力和更多时间，利用迁移学习，可以在前人优秀图片分类模型的基础上，非常快捷有效地重新训练出新的图像分类器。  \n通常来说，迁移学习的策略有两种。\n* Finetuning（微调）  \n包括在基础数据集上使用预训练网络，并在目标数据集上训练所有层。\n* Freeze and Train（冻结和训练）  \n包括仅冻结并训练最后一层，其他层不变（权重不更新）；也可以冻结前几层，微调其他层，这是由于有些证据表明CNN的前几层有纹理滤镜和彩色斑点。\n\n## 流程\n1. predo.py，准备自己要分类的图片训练样本；\n2. retrain.py，下载inception v3/mobileNet模型及训练图片分类器；\n3. label_image.py，测试模型预测结果。\n\n### 预处理\n``` python\nimport os\nimport cv2\n\npath = \"./data\"\nfiles = os.listdir(path) \n# print(files)\nfor f in files: \n    print(f)\n    cnt = 0\n    data_list = os.listdir(path+'/'+f)\n    # print(data_list[:4])\n    for data in data_list:\n        data_file_path = path+'/'+f+'/'+data \n        # img = cv2.imread(data_file_path)\n        # img_resize = cv2.resize(img, (300, 300))\n        # cv2.imwrite(path+'/'+f+'/'+\"{:04d}.jpg\".format(cnt), img_resize)\n        newname = path+'/'+f+'/'+\"{:04d}.jpg\".format(cnt)\n        os.rename(data_file_path, newname)\n        cnt += 1\n    #     if cnt == 2:\n    #         break\n    # break\n```\n\n### retrain\n* tensorflow/retrain.py at c565660e008cf666c582668cb0d0937ca86e71fb · tensorflow/tensorflow  \nhttps://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py\n\n源码分析  \n* TensorFlow学习笔记：Inception_v3源码分析 - 简书  \nhttps://www.jianshu.com/p/feecdcdef8a0\n``` bash\n# By default: Inception v3\npython retrain.py\n# mobileNet\npython retrain.py --image_dir ./daata --architecture mobilenet_1.0_224\n```\n可以提前下载模型文件到./tmp/imagenet文件夹下。\n* Google AI Blog: MobileNets: Open-Source Models for Efficient On-Device Vision  \nhttps://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html\n\n### 测试\n``` python\nimport tensorflow as tf\nimport os\nimport numpy as np\nimport re\nimport shutil\n\nlines = tf.gfile.GFile('./tmp/output_labels.txt').readlines()\nuid_to_human = {}\n#一行一行读取数据\nfor uid,line in enumerate(lines) :\n    #去掉换行符\n    line=line.strip('\\n')\n    uid_to_human[uid] = line\n \ndef id_to_string(node_id):\n    if node_id not in uid_to_human:\n        return ''\n    return uid_to_human[node_id]\n \n#创建一个图来存放google训练好的模型\nwith tf.gfile.FastGFile('./tmp/output_graph.pb', 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf.import_graph_def(graph_def, name='')\n \nwith tf.Session() as sess:\n    softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n    #遍历目录\n    for root,dirs,files in os.walk('./test/'):\n        # print(\"root[-1]:\", root[-1]) # 类别\n        # print(\"files:\", files)\n        \n        for file in files:\n            print(root+\"/\"+file)\n            #载入图片\n            image_data = tf.gfile.FastGFile(root+\"/\"+file, 'rb').read()\n            predictions = sess.run(softmax_tensor,{'DecodeJpeg/contents:0': image_data})#图片格式是jpg格式\n            predictions = np.squeeze(predictions)#把结果转为1维数据\n \n            #打印图片路径及名称\n            image_path = os.path.join(root,file)\n            # print(image_path)\n            # #显示图片\n            # img=Image.open(image_path)\n            # plt.imshow(img)\n            # plt.axis('off')\n            # plt.show()\n \n            # 打印结果\n            top_k = predictions.argsort()[::-1]\n            # print(top_k)\n            for node_id in top_k:     \n                # 获取分类名称\n                human_string = id_to_string(node_id)\n                # 获取该分类的置信度\n                score = predictions[node_id]\n                print('%s (score = %.5f)' % (human_string, score))\n            \n            # 将识别错误文件保存到bad文件夹\n            if id_to_string(top_k[0]) != root[-1]:\n                old_path = root + \"/\" + file\n                name, _ = file.split('.')\n                new_path = r'./bad' + '/' + name + '_' + id_to_string(top_k[0]) + '_' + str(predictions[top_k[0]]) +'.jpg' \n                shutil.copyfile(old_path, new_path)\n\n```\n\n## 问题汇总\n### 1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph.\n\n* TypeError: Cannot interpret feed_dict key as Tensor: The name 'DecodeJpeg/contents:0' refers to a Tensor which does not exist. The operation, 'DecodeJpeg/contents', does not exist in the graph. · Issue #12250 · tensorflow/tensorflow  \nhttps://github.com/tensorflow/tensorflow/issues/12250\n\n打印图的参数名称\n``` python\ntensor_name_list = [tensor.name for tensor in tf.get_default_graph().as_graph_def().node]\nprint(tensor_name_list)\n```\n修改输入为第一个tensor的名称\n``` python\n# inceptionV3\n# image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n# predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data}) #图片格式是jpg格式\n# predictions = np.squeeze(predictions) #把结果转为1维数据\n\n# mobileNet\nimage_data = tf.gfile.FastGFile(image_path, 'rb').read()\nimage_data = sess.run(tf.expand_dims(tf.image.resize_images(\n    tf.image.decode_jpeg(image_data), [128, 128], method=np.random.randint(0,3)), 0))\npredictions = sess.run(softmax_tensor, {'input:0': image_data}) #图片格式是jpg格式\npredictions = np.squeeze(predictions) #把结果转为1维数据\n```\n### 2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒\n对于棋子分类任务来说，输入是一张28*28的3通道图片，无论使用InceptionV3还是mobileNet_128模型都过于“厚重”，最终手写一个小的卷积网络，通过两层卷积+两层全连接来实现棋子分类。\n<div align=center>\n<img src='象棋残局机器人三：分类模型retrain\\001.png' width=600 height=300>\n</div>\n<div align=center>\n<img src='象棋残局机器人三：分类模型retrain\\002.png' width=600 height=300>\n</div>\n\n\n## 参考资料\n\n* 浅谈迁移学习图像分类 - weixin_33805743的博客 - CSDN博客  \nhttps://blog.csdn.net/weixin_33805743/article/details/87426423\n\n","slug":"象棋残局机器人三：分类模型retrain","published":1,"updated":"2019-06-23T07:09:39.793Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm758001krsvjn74ah9zz","content":"<p><strong> 象棋残局机器人三：分类模型retrain：</strong> <excerpt in index | 首页摘要><br>基于InceptionV3和mobileNet模型重新训练自己的图片分类模型。<br><a id=\"more\"></a></excerpt></p>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h2><p>图片分类模型往往有数以万计的参数，而从头开始训练需要大量的带标签训练数据、强大的算力和更多时间，利用迁移学习，可以在前人优秀图片分类模型的基础上，非常快捷有效地重新训练出新的图像分类器。<br>通常来说，迁移学习的策略有两种。</p>\n<ul>\n<li>Finetuning（微调）<br>包括在基础数据集上使用预训练网络，并在目标数据集上训练所有层。</li>\n<li>Freeze and Train（冻结和训练）<br>包括仅冻结并训练最后一层，其他层不变（权重不更新）；也可以冻结前几层，微调其他层，这是由于有些证据表明CNN的前几层有纹理滤镜和彩色斑点。</li>\n</ul>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><ol>\n<li>predo.py，准备自己要分类的图片训练样本；</li>\n<li>retrain.py，下载inception v3/mobileNet模型及训练图片分类器；</li>\n<li>label_image.py，测试模型预测结果。</li>\n</ol>\n<h3 id=\"预处理\"><a href=\"#预处理\" class=\"headerlink\" title=\"预处理\"></a>预处理</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">path = <span class=\"string\">\"./data\"</span></span><br><span class=\"line\">files = os.listdir(path) </span><br><span class=\"line\"><span class=\"comment\"># print(files)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> files: </span><br><span class=\"line\">    print(f)</span><br><span class=\"line\">    cnt = <span class=\"number\">0</span></span><br><span class=\"line\">    data_list = os.listdir(path+<span class=\"string\">'/'</span>+f)</span><br><span class=\"line\">    <span class=\"comment\"># print(data_list[:4])</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> data_list:</span><br><span class=\"line\">        data_file_path = path+<span class=\"string\">'/'</span>+f+<span class=\"string\">'/'</span>+data </span><br><span class=\"line\">        <span class=\"comment\"># img = cv2.imread(data_file_path)</span></span><br><span class=\"line\">        <span class=\"comment\"># img_resize = cv2.resize(img, (300, 300))</span></span><br><span class=\"line\">        <span class=\"comment\"># cv2.imwrite(path+'/'+f+'/'+\"&#123;:04d&#125;.jpg\".format(cnt), img_resize)</span></span><br><span class=\"line\">        newname = path+<span class=\"string\">'/'</span>+f+<span class=\"string\">'/'</span>+<span class=\"string\">\"&#123;:04d&#125;.jpg\"</span>.format(cnt)</span><br><span class=\"line\">        os.rename(data_file_path, newname)</span><br><span class=\"line\">        cnt += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\">#     if cnt == 2:</span></span><br><span class=\"line\">    <span class=\"comment\">#         break</span></span><br><span class=\"line\">    <span class=\"comment\"># break</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"retrain\"><a href=\"#retrain\" class=\"headerlink\" title=\"retrain\"></a>retrain</h3><ul>\n<li>tensorflow/retrain.py at c565660e008cf666c582668cb0d0937ca86e71fb · tensorflow/tensorflow<br><a href=\"https://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py</a></li>\n</ul>\n<p>源码分析  </p>\n<ul>\n<li>TensorFlow学习笔记：Inception_v3源码分析 - 简书<br><a href=\"https://www.jianshu.com/p/feecdcdef8a0\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/feecdcdef8a0</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># By default: Inception v3</span></span><br><span class=\"line\">python retrain.py</span><br><span class=\"line\"><span class=\"comment\"># mobileNet</span></span><br><span class=\"line\">python retrain.py --image_dir ./daata --architecture mobilenet_1.0_224</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>可以提前下载模型文件到./tmp/imagenet文件夹下。</p>\n<ul>\n<li>Google AI Blog: MobileNets: Open-Source Models for Efficient On-Device Vision<br><a href=\"https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html\" target=\"_blank\" rel=\"noopener\">https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html</a></li>\n</ul>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> shutil</span><br><span class=\"line\"></span><br><span class=\"line\">lines = tf.gfile.GFile(<span class=\"string\">'./tmp/output_labels.txt'</span>).readlines()</span><br><span class=\"line\">uid_to_human = &#123;&#125;</span><br><span class=\"line\"><span class=\"comment\">#一行一行读取数据</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> uid,line <span class=\"keyword\">in</span> enumerate(lines) :</span><br><span class=\"line\">    <span class=\"comment\">#去掉换行符</span></span><br><span class=\"line\">    line=line.strip(<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">    uid_to_human[uid] = line</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">id_to_string</span><span class=\"params\">(node_id)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> node_id <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> uid_to_human:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">''</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> uid_to_human[node_id]</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#创建一个图来存放google训练好的模型</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.gfile.FastGFile(<span class=\"string\">'./tmp/output_graph.pb'</span>, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    graph_def = tf.GraphDef()</span><br><span class=\"line\">    graph_def.ParseFromString(f.read())</span><br><span class=\"line\">    tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    softmax_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'final_result:0'</span>)</span><br><span class=\"line\">    <span class=\"comment\">#遍历目录</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> root,dirs,files <span class=\"keyword\">in</span> os.walk(<span class=\"string\">'./test/'</span>):</span><br><span class=\"line\">        <span class=\"comment\"># print(\"root[-1]:\", root[-1]) # 类别</span></span><br><span class=\"line\">        <span class=\"comment\"># print(\"files:\", files)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">            print(root+<span class=\"string\">\"/\"</span>+file)</span><br><span class=\"line\">            <span class=\"comment\">#载入图片</span></span><br><span class=\"line\">            image_data = tf.gfile.FastGFile(root+<span class=\"string\">\"/\"</span>+file, <span class=\"string\">'rb'</span>).read()</span><br><span class=\"line\">            predictions = sess.run(softmax_tensor,&#123;<span class=\"string\">'DecodeJpeg/contents:0'</span>: image_data&#125;)<span class=\"comment\">#图片格式是jpg格式</span></span><br><span class=\"line\">            predictions = np.squeeze(predictions)<span class=\"comment\">#把结果转为1维数据</span></span><br><span class=\"line\"> </span><br><span class=\"line\">            <span class=\"comment\">#打印图片路径及名称</span></span><br><span class=\"line\">            image_path = os.path.join(root,file)</span><br><span class=\"line\">            <span class=\"comment\"># print(image_path)</span></span><br><span class=\"line\">            <span class=\"comment\"># #显示图片</span></span><br><span class=\"line\">            <span class=\"comment\"># img=Image.open(image_path)</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.imshow(img)</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.axis('off')</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.show()</span></span><br><span class=\"line\"> </span><br><span class=\"line\">            <span class=\"comment\"># 打印结果</span></span><br><span class=\"line\">            top_k = predictions.argsort()[::<span class=\"number\">-1</span>]</span><br><span class=\"line\">            <span class=\"comment\"># print(top_k)</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> node_id <span class=\"keyword\">in</span> top_k:     </span><br><span class=\"line\">                <span class=\"comment\"># 获取分类名称</span></span><br><span class=\"line\">                human_string = id_to_string(node_id)</span><br><span class=\"line\">                <span class=\"comment\"># 获取该分类的置信度</span></span><br><span class=\"line\">                score = predictions[node_id]</span><br><span class=\"line\">                print(<span class=\"string\">'%s (score = %.5f)'</span> % (human_string, score))</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 将识别错误文件保存到bad文件夹</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> id_to_string(top_k[<span class=\"number\">0</span>]) != root[<span class=\"number\">-1</span>]:</span><br><span class=\"line\">                old_path = root + <span class=\"string\">\"/\"</span> + file</span><br><span class=\"line\">                name, _ = file.split(<span class=\"string\">'.'</span>)</span><br><span class=\"line\">                new_path = <span class=\"string\">r'./bad'</span> + <span class=\"string\">'/'</span> + name + <span class=\"string\">'_'</span> + id_to_string(top_k[<span class=\"number\">0</span>]) + <span class=\"string\">'_'</span> + str(predictions[top_k[<span class=\"number\">0</span>]]) +<span class=\"string\">'.jpg'</span> </span><br><span class=\"line\">                shutil.copyfile(old_path, new_path)</span><br></pre></td></tr></table></figure>\n<h2 id=\"问题汇总\"><a href=\"#问题汇总\" class=\"headerlink\" title=\"问题汇总\"></a>问题汇总</h2><h3 id=\"1-使用mobileNet时-TypeError-Cannot-interpret-feed-dict-key-as-Tensor-The-name-‘DecodeJpeg-contents-0’-refers-to-a-Tensor-which-does-not-exist-The-operation-‘DecodeJpeg-contents’-does-not-exist-in-the-graph\"><a href=\"#1-使用mobileNet时-TypeError-Cannot-interpret-feed-dict-key-as-Tensor-The-name-‘DecodeJpeg-contents-0’-refers-to-a-Tensor-which-does-not-exist-The-operation-‘DecodeJpeg-contents’-does-not-exist-in-the-graph\" class=\"headerlink\" title=\"1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph.\"></a>1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph.</h3><ul>\n<li>TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph. · Issue #12250 · tensorflow/tensorflow<br><a href=\"https://github.com/tensorflow/tensorflow/issues/12250\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/issues/12250</a></li>\n</ul>\n<p>打印图的参数名称<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor_name_list = [tensor.name <span class=\"keyword\">for</span> tensor <span class=\"keyword\">in</span> tf.get_default_graph().as_graph_def().node]</span><br><span class=\"line\">print(tensor_name_list)</span><br></pre></td></tr></table></figure></p>\n<p>修改输入为第一个tensor的名称<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># inceptionV3</span></span><br><span class=\"line\"><span class=\"comment\"># image_data = tf.gfile.FastGFile(image_path, 'rb').read()</span></span><br><span class=\"line\"><span class=\"comment\"># predictions = sess.run(softmax_tensor, &#123;'DecodeJpeg/contents:0': image_data&#125;) #图片格式是jpg格式</span></span><br><span class=\"line\"><span class=\"comment\"># predictions = np.squeeze(predictions) #把结果转为1维数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mobileNet</span></span><br><span class=\"line\">image_data = tf.gfile.FastGFile(image_path, <span class=\"string\">'rb'</span>).read()</span><br><span class=\"line\">image_data = sess.run(tf.expand_dims(tf.image.resize_images(</span><br><span class=\"line\">    tf.image.decode_jpeg(image_data), [<span class=\"number\">128</span>, <span class=\"number\">128</span>], method=np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">3</span>)), <span class=\"number\">0</span>))</span><br><span class=\"line\">predictions = sess.run(softmax_tensor, &#123;<span class=\"string\">'input:0'</span>: image_data&#125;) <span class=\"comment\">#图片格式是jpg格式</span></span><br><span class=\"line\">predictions = np.squeeze(predictions) <span class=\"comment\">#把结果转为1维数据</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-分类速度太慢：-0-8s一张图，32个棋子大概需要20多秒\"><a href=\"#2-分类速度太慢：-0-8s一张图，32个棋子大概需要20多秒\" class=\"headerlink\" title=\"2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒\"></a>2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒</h3><p>对于棋子分类任务来说，输入是一张28*28的3通道图片，无论使用InceptionV3还是mobileNet_128模型都过于“厚重”，最终手写一个小的卷积网络，通过两层卷积+两层全连接来实现棋子分类。</p>\n<div align=\"center\">\n<img src=\"/2019/05/29/象棋残局机器人三：分类模型retrain/001.png\" width=\"600\" height=\"300\">\n</div>\n<div align=\"center\">\n<img src=\"/2019/05/29/象棋残局机器人三：分类模型retrain/002.png\" width=\"600\" height=\"300\">\n</div>\n\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>浅谈迁移学习图像分类 - weixin_33805743的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_33805743/article/details/87426423\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_33805743/article/details/87426423</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 象棋残局机器人三：分类模型retrain：</strong> <excerpt in index | 首页摘要><br>基于InceptionV3和mobileNet模型重新训练自己的图片分类模型。<br></excerpt></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"迁移学习\"><a href=\"#迁移学习\" class=\"headerlink\" title=\"迁移学习\"></a>迁移学习</h2><p>图片分类模型往往有数以万计的参数，而从头开始训练需要大量的带标签训练数据、强大的算力和更多时间，利用迁移学习，可以在前人优秀图片分类模型的基础上，非常快捷有效地重新训练出新的图像分类器。<br>通常来说，迁移学习的策略有两种。</p>\n<ul>\n<li>Finetuning（微调）<br>包括在基础数据集上使用预训练网络，并在目标数据集上训练所有层。</li>\n<li>Freeze and Train（冻结和训练）<br>包括仅冻结并训练最后一层，其他层不变（权重不更新）；也可以冻结前几层，微调其他层，这是由于有些证据表明CNN的前几层有纹理滤镜和彩色斑点。</li>\n</ul>\n<h2 id=\"流程\"><a href=\"#流程\" class=\"headerlink\" title=\"流程\"></a>流程</h2><ol>\n<li>predo.py，准备自己要分类的图片训练样本；</li>\n<li>retrain.py，下载inception v3/mobileNet模型及训练图片分类器；</li>\n<li>label_image.py，测试模型预测结果。</li>\n</ol>\n<h3 id=\"预处理\"><a href=\"#预处理\" class=\"headerlink\" title=\"预处理\"></a>预处理</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">path = <span class=\"string\">\"./data\"</span></span><br><span class=\"line\">files = os.listdir(path) </span><br><span class=\"line\"><span class=\"comment\"># print(files)</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> files: </span><br><span class=\"line\">    print(f)</span><br><span class=\"line\">    cnt = <span class=\"number\">0</span></span><br><span class=\"line\">    data_list = os.listdir(path+<span class=\"string\">'/'</span>+f)</span><br><span class=\"line\">    <span class=\"comment\"># print(data_list[:4])</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> data <span class=\"keyword\">in</span> data_list:</span><br><span class=\"line\">        data_file_path = path+<span class=\"string\">'/'</span>+f+<span class=\"string\">'/'</span>+data </span><br><span class=\"line\">        <span class=\"comment\"># img = cv2.imread(data_file_path)</span></span><br><span class=\"line\">        <span class=\"comment\"># img_resize = cv2.resize(img, (300, 300))</span></span><br><span class=\"line\">        <span class=\"comment\"># cv2.imwrite(path+'/'+f+'/'+\"&#123;:04d&#125;.jpg\".format(cnt), img_resize)</span></span><br><span class=\"line\">        newname = path+<span class=\"string\">'/'</span>+f+<span class=\"string\">'/'</span>+<span class=\"string\">\"&#123;:04d&#125;.jpg\"</span>.format(cnt)</span><br><span class=\"line\">        os.rename(data_file_path, newname)</span><br><span class=\"line\">        cnt += <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"comment\">#     if cnt == 2:</span></span><br><span class=\"line\">    <span class=\"comment\">#         break</span></span><br><span class=\"line\">    <span class=\"comment\"># break</span></span><br></pre></td></tr></table></figure>\n<h3 id=\"retrain\"><a href=\"#retrain\" class=\"headerlink\" title=\"retrain\"></a>retrain</h3><ul>\n<li>tensorflow/retrain.py at c565660e008cf666c582668cb0d0937ca86e71fb · tensorflow/tensorflow<br><a href=\"https://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/blob/c565660e008cf666c582668cb0d0937ca86e71fb/tensorflow/examples/image_retraining/retrain.py</a></li>\n</ul>\n<p>源码分析  </p>\n<ul>\n<li>TensorFlow学习笔记：Inception_v3源码分析 - 简书<br><a href=\"https://www.jianshu.com/p/feecdcdef8a0\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/feecdcdef8a0</a><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># By default: Inception v3</span></span><br><span class=\"line\">python retrain.py</span><br><span class=\"line\"><span class=\"comment\"># mobileNet</span></span><br><span class=\"line\">python retrain.py --image_dir ./daata --architecture mobilenet_1.0_224</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>可以提前下载模型文件到./tmp/imagenet文件夹下。</p>\n<ul>\n<li>Google AI Blog: MobileNets: Open-Source Models for Efficient On-Device Vision<br><a href=\"https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html\" target=\"_blank\" rel=\"noopener\">https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html</a></li>\n</ul>\n<h3 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"><span class=\"keyword\">import</span> os</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> re</span><br><span class=\"line\"><span class=\"keyword\">import</span> shutil</span><br><span class=\"line\"></span><br><span class=\"line\">lines = tf.gfile.GFile(<span class=\"string\">'./tmp/output_labels.txt'</span>).readlines()</span><br><span class=\"line\">uid_to_human = &#123;&#125;</span><br><span class=\"line\"><span class=\"comment\">#一行一行读取数据</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> uid,line <span class=\"keyword\">in</span> enumerate(lines) :</span><br><span class=\"line\">    <span class=\"comment\">#去掉换行符</span></span><br><span class=\"line\">    line=line.strip(<span class=\"string\">'\\n'</span>)</span><br><span class=\"line\">    uid_to_human[uid] = line</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">id_to_string</span><span class=\"params\">(node_id)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> node_id <span class=\"keyword\">not</span> <span class=\"keyword\">in</span> uid_to_human:</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"string\">''</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> uid_to_human[node_id]</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"comment\">#创建一个图来存放google训练好的模型</span></span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.gfile.FastGFile(<span class=\"string\">'./tmp/output_graph.pb'</span>, <span class=\"string\">'rb'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    graph_def = tf.GraphDef()</span><br><span class=\"line\">    graph_def.ParseFromString(f.read())</span><br><span class=\"line\">    tf.import_graph_def(graph_def, name=<span class=\"string\">''</span>)</span><br><span class=\"line\"> </span><br><span class=\"line\"><span class=\"keyword\">with</span> tf.Session() <span class=\"keyword\">as</span> sess:</span><br><span class=\"line\">    softmax_tensor = sess.graph.get_tensor_by_name(<span class=\"string\">'final_result:0'</span>)</span><br><span class=\"line\">    <span class=\"comment\">#遍历目录</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> root,dirs,files <span class=\"keyword\">in</span> os.walk(<span class=\"string\">'./test/'</span>):</span><br><span class=\"line\">        <span class=\"comment\"># print(\"root[-1]:\", root[-1]) # 类别</span></span><br><span class=\"line\">        <span class=\"comment\"># print(\"files:\", files)</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">for</span> file <span class=\"keyword\">in</span> files:</span><br><span class=\"line\">            print(root+<span class=\"string\">\"/\"</span>+file)</span><br><span class=\"line\">            <span class=\"comment\">#载入图片</span></span><br><span class=\"line\">            image_data = tf.gfile.FastGFile(root+<span class=\"string\">\"/\"</span>+file, <span class=\"string\">'rb'</span>).read()</span><br><span class=\"line\">            predictions = sess.run(softmax_tensor,&#123;<span class=\"string\">'DecodeJpeg/contents:0'</span>: image_data&#125;)<span class=\"comment\">#图片格式是jpg格式</span></span><br><span class=\"line\">            predictions = np.squeeze(predictions)<span class=\"comment\">#把结果转为1维数据</span></span><br><span class=\"line\"> </span><br><span class=\"line\">            <span class=\"comment\">#打印图片路径及名称</span></span><br><span class=\"line\">            image_path = os.path.join(root,file)</span><br><span class=\"line\">            <span class=\"comment\"># print(image_path)</span></span><br><span class=\"line\">            <span class=\"comment\"># #显示图片</span></span><br><span class=\"line\">            <span class=\"comment\"># img=Image.open(image_path)</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.imshow(img)</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.axis('off')</span></span><br><span class=\"line\">            <span class=\"comment\"># plt.show()</span></span><br><span class=\"line\"> </span><br><span class=\"line\">            <span class=\"comment\"># 打印结果</span></span><br><span class=\"line\">            top_k = predictions.argsort()[::<span class=\"number\">-1</span>]</span><br><span class=\"line\">            <span class=\"comment\"># print(top_k)</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> node_id <span class=\"keyword\">in</span> top_k:     </span><br><span class=\"line\">                <span class=\"comment\"># 获取分类名称</span></span><br><span class=\"line\">                human_string = id_to_string(node_id)</span><br><span class=\"line\">                <span class=\"comment\"># 获取该分类的置信度</span></span><br><span class=\"line\">                score = predictions[node_id]</span><br><span class=\"line\">                print(<span class=\"string\">'%s (score = %.5f)'</span> % (human_string, score))</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"comment\"># 将识别错误文件保存到bad文件夹</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> id_to_string(top_k[<span class=\"number\">0</span>]) != root[<span class=\"number\">-1</span>]:</span><br><span class=\"line\">                old_path = root + <span class=\"string\">\"/\"</span> + file</span><br><span class=\"line\">                name, _ = file.split(<span class=\"string\">'.'</span>)</span><br><span class=\"line\">                new_path = <span class=\"string\">r'./bad'</span> + <span class=\"string\">'/'</span> + name + <span class=\"string\">'_'</span> + id_to_string(top_k[<span class=\"number\">0</span>]) + <span class=\"string\">'_'</span> + str(predictions[top_k[<span class=\"number\">0</span>]]) +<span class=\"string\">'.jpg'</span> </span><br><span class=\"line\">                shutil.copyfile(old_path, new_path)</span><br></pre></td></tr></table></figure>\n<h2 id=\"问题汇总\"><a href=\"#问题汇总\" class=\"headerlink\" title=\"问题汇总\"></a>问题汇总</h2><h3 id=\"1-使用mobileNet时-TypeError-Cannot-interpret-feed-dict-key-as-Tensor-The-name-‘DecodeJpeg-contents-0’-refers-to-a-Tensor-which-does-not-exist-The-operation-‘DecodeJpeg-contents’-does-not-exist-in-the-graph\"><a href=\"#1-使用mobileNet时-TypeError-Cannot-interpret-feed-dict-key-as-Tensor-The-name-‘DecodeJpeg-contents-0’-refers-to-a-Tensor-which-does-not-exist-The-operation-‘DecodeJpeg-contents’-does-not-exist-in-the-graph\" class=\"headerlink\" title=\"1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph.\"></a>1. 使用mobileNet时 TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph.</h3><ul>\n<li>TypeError: Cannot interpret feed_dict key as Tensor: The name ‘DecodeJpeg/contents:0’ refers to a Tensor which does not exist. The operation, ‘DecodeJpeg/contents’, does not exist in the graph. · Issue #12250 · tensorflow/tensorflow<br><a href=\"https://github.com/tensorflow/tensorflow/issues/12250\" target=\"_blank\" rel=\"noopener\">https://github.com/tensorflow/tensorflow/issues/12250</a></li>\n</ul>\n<p>打印图的参数名称<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tensor_name_list = [tensor.name <span class=\"keyword\">for</span> tensor <span class=\"keyword\">in</span> tf.get_default_graph().as_graph_def().node]</span><br><span class=\"line\">print(tensor_name_list)</span><br></pre></td></tr></table></figure></p>\n<p>修改输入为第一个tensor的名称<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># inceptionV3</span></span><br><span class=\"line\"><span class=\"comment\"># image_data = tf.gfile.FastGFile(image_path, 'rb').read()</span></span><br><span class=\"line\"><span class=\"comment\"># predictions = sess.run(softmax_tensor, &#123;'DecodeJpeg/contents:0': image_data&#125;) #图片格式是jpg格式</span></span><br><span class=\"line\"><span class=\"comment\"># predictions = np.squeeze(predictions) #把结果转为1维数据</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># mobileNet</span></span><br><span class=\"line\">image_data = tf.gfile.FastGFile(image_path, <span class=\"string\">'rb'</span>).read()</span><br><span class=\"line\">image_data = sess.run(tf.expand_dims(tf.image.resize_images(</span><br><span class=\"line\">    tf.image.decode_jpeg(image_data), [<span class=\"number\">128</span>, <span class=\"number\">128</span>], method=np.random.randint(<span class=\"number\">0</span>,<span class=\"number\">3</span>)), <span class=\"number\">0</span>))</span><br><span class=\"line\">predictions = sess.run(softmax_tensor, &#123;<span class=\"string\">'input:0'</span>: image_data&#125;) <span class=\"comment\">#图片格式是jpg格式</span></span><br><span class=\"line\">predictions = np.squeeze(predictions) <span class=\"comment\">#把结果转为1维数据</span></span><br></pre></td></tr></table></figure></p>\n<h3 id=\"2-分类速度太慢：-0-8s一张图，32个棋子大概需要20多秒\"><a href=\"#2-分类速度太慢：-0-8s一张图，32个棋子大概需要20多秒\" class=\"headerlink\" title=\"2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒\"></a>2. 分类速度太慢： 0.8s一张图，32个棋子大概需要20多秒</h3><p>对于棋子分类任务来说，输入是一张28*28的3通道图片，无论使用InceptionV3还是mobileNet_128模型都过于“厚重”，最终手写一个小的卷积网络，通过两层卷积+两层全连接来实现棋子分类。</p>\n<div align=\"center\">\n<img src=\"/2019/05/29/象棋残局机器人三：分类模型retrain/001.png\" width=\"600\" height=\"300\">\n</div>\n<div align=\"center\">\n<img src=\"/2019/05/29/象棋残局机器人三：分类模型retrain/002.png\" width=\"600\" height=\"300\">\n</div>\n\n\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>浅谈迁移学习图像分类 - weixin_33805743的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/weixin_33805743/article/details/87426423\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_33805743/article/details/87426423</a></li>\n</ul>\n</the>"},{"title":"门禁python多进程练习","date":"2019-05-16T12:33:16.000Z","_content":"\n\n``` bash\nimport multiprocessing as mp\n\ndef task(a):\n    pass\n\nif __name__ == \"__main__\":\n    p1 = mp.Process(target=task, args=(1,))\n    p1.start()\n    p1.join()\n```\n\n\n\n\n\n\n\n``` bash\nimport tkinter as tk\n\nroot = tk.Tk()\n\ndef func_loop():\n    func()\n    root.after(1, func_loop)\n\nroot.loopmain()\n```\n\n\n* [译]深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks) - Shuzi_rank - 博客园 </br>https://www.cnblogs.com/shuzirank/p/7141017.html","source":"_posts/门禁python多进程练习.md","raw":"---\ntitle: 门禁python多进程练习\ndate: 2019-05-16 20:33:16\ntags:\n  - python\n---\n\n\n``` bash\nimport multiprocessing as mp\n\ndef task(a):\n    pass\n\nif __name__ == \"__main__\":\n    p1 = mp.Process(target=task, args=(1,))\n    p1.start()\n    p1.join()\n```\n\n\n\n\n\n\n\n``` bash\nimport tkinter as tk\n\nroot = tk.Tk()\n\ndef func_loop():\n    func()\n    root.after(1, func_loop)\n\nroot.loopmain()\n```\n\n\n* [译]深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks) - Shuzi_rank - 博客园 </br>https://www.cnblogs.com/shuzirank/p/7141017.html","slug":"门禁python多进程练习","published":1,"updated":"2019-05-19T11:35:42.286Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm759001mrsvj6ig9i98q","content":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import multiprocessing as mp</span><br><span class=\"line\"></span><br><span class=\"line\">def task(a):</span><br><span class=\"line\">    pass</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    p1 = mp.Process(target=task, args=(1,))</span><br><span class=\"line\">    p1.start()</span><br><span class=\"line\">    p1.join()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import tkinter as tk</span><br><span class=\"line\"></span><br><span class=\"line\">root = tk.Tk()</span><br><span class=\"line\"></span><br><span class=\"line\">def func_loop():</span><br><span class=\"line\">    func()</span><br><span class=\"line\">    root.after(1, func_loop)</span><br><span class=\"line\"></span><br><span class=\"line\">root.loopmain()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[译]深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks) - Shuzi_rank - 博客园 &lt;/br&gt;<a href=\"https://www.cnblogs.com/shuzirank/p/7141017.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shuzirank/p/7141017.html</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import multiprocessing as mp</span><br><span class=\"line\"></span><br><span class=\"line\">def task(a):</span><br><span class=\"line\">    pass</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">\"__main__\"</span>:</span><br><span class=\"line\">    p1 = mp.Process(target=task, args=(1,))</span><br><span class=\"line\">    p1.start()</span><br><span class=\"line\">    p1.join()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import tkinter as tk</span><br><span class=\"line\"></span><br><span class=\"line\">root = tk.Tk()</span><br><span class=\"line\"></span><br><span class=\"line\">def func_loop():</span><br><span class=\"line\">    func()</span><br><span class=\"line\">    root.after(1, func_loop)</span><br><span class=\"line\"></span><br><span class=\"line\">root.loopmain()</span><br></pre></td></tr></table></figure>\n<ul>\n<li>[译]深度神经网络的多任务学习概览(An Overview of Multi-task Learning in Deep Neural Networks) - Shuzi_rank - 博客园 &lt;/br&gt;<a href=\"https://www.cnblogs.com/shuzirank/p/7141017.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/shuzirank/p/7141017.html</a></li>\n</ul>\n"},{"title":"象棋残局机器人五：象棋棋子分类模型","date":"2019-06-05T07:50:47.000Z","_content":"\n\n\n\n## 问题记录\n\n### 1. 采集图像分辨率低导致分类错误\n\n小伙伴的电脑摄像头采集视频流默认长宽比是16:9，显示的图片会自动在上下方补充两道黑条，并被发现无法通过cap.set(CAP_PROP_FRAME_HEIGHT，480)函数解决这个问题。  \n这个问题导致采集图像的实际分辨率为640:360，所以采集的棋子照片中棋子比较模糊，同样的问题在重新调整摄像头位置没有调整好焦距时也会发生。\n<div align=center>\n<img src='象棋残局机器人五：象棋棋子分类模型\\001.jpg' width=600 height=400>\n</div>\n默认分辨率是640*480，通过调高分辨率解决。  \n\n``` bash\nimg = img[60:400,:,:]\nimg = cv2.resize(img, (640, 480))\n```\n\n### 2. 对于一些场景可以调整摄像头参数\n特别注意有些摄像头参数设置后会保存，一旦修改后无法恢复到初始值，所以不要随意设置参数或在设置前注意记录摄像头参数的初始值。  \n获取摄像头参数\n``` bash\ncapture.get(CAP_PROP_FRAME_WIDTH)\ncapture.get(CAP_PROP_FRAME_HEIGHT)\ncapture.get(CAP_PROP_FPS)\ncapture.get(CAP_PROP_BRIGHTNESS)\ncapture.get(CAP_PROP_CONTRAST)\ncapture.get(CAP_PROP_SATURATION)\ncapture.get(CAP_PROP_HUE)\ncapture.get(CAP_PROP_EXPOSURE)\n```\n设置摄像头参数  \n``` bash\ncapture.set(CAP_PROP_FRAME_WIDTH, 1080) #宽度 \ncapture.set(CAP_PROP_FRAME_HEIGHT, 960) #高度\ncapture.set(CAP_PROP_FPS, 30)           #帧率 帧/秒\ncapture.set(CAP_PROP_BRIGHTNESS, 1)     #亮度 1\ncapture.set(CAP_PROP_CONTRAST,40)       #对比度 40\ncapture.set(CAP_PROP_SATURATION, 50)    #饱和度 50\ncapture.set(CAP_PROP_HUE, 50)           #色调 50\ncapture.set(CAP_PROP_EXPOSURE, -6)      #曝光 50\n```\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/象棋残局机器人五：象棋棋子分类模型.md","raw":"---\ntitle: 象棋残局机器人五：象棋棋子分类模型\ndate: 2019-06-05 15:50:47\ntags:\n---\n\n\n\n\n## 问题记录\n\n### 1. 采集图像分辨率低导致分类错误\n\n小伙伴的电脑摄像头采集视频流默认长宽比是16:9，显示的图片会自动在上下方补充两道黑条，并被发现无法通过cap.set(CAP_PROP_FRAME_HEIGHT，480)函数解决这个问题。  \n这个问题导致采集图像的实际分辨率为640:360，所以采集的棋子照片中棋子比较模糊，同样的问题在重新调整摄像头位置没有调整好焦距时也会发生。\n<div align=center>\n<img src='象棋残局机器人五：象棋棋子分类模型\\001.jpg' width=600 height=400>\n</div>\n默认分辨率是640*480，通过调高分辨率解决。  \n\n``` bash\nimg = img[60:400,:,:]\nimg = cv2.resize(img, (640, 480))\n```\n\n### 2. 对于一些场景可以调整摄像头参数\n特别注意有些摄像头参数设置后会保存，一旦修改后无法恢复到初始值，所以不要随意设置参数或在设置前注意记录摄像头参数的初始值。  \n获取摄像头参数\n``` bash\ncapture.get(CAP_PROP_FRAME_WIDTH)\ncapture.get(CAP_PROP_FRAME_HEIGHT)\ncapture.get(CAP_PROP_FPS)\ncapture.get(CAP_PROP_BRIGHTNESS)\ncapture.get(CAP_PROP_CONTRAST)\ncapture.get(CAP_PROP_SATURATION)\ncapture.get(CAP_PROP_HUE)\ncapture.get(CAP_PROP_EXPOSURE)\n```\n设置摄像头参数  \n``` bash\ncapture.set(CAP_PROP_FRAME_WIDTH, 1080) #宽度 \ncapture.set(CAP_PROP_FRAME_HEIGHT, 960) #高度\ncapture.set(CAP_PROP_FPS, 30)           #帧率 帧/秒\ncapture.set(CAP_PROP_BRIGHTNESS, 1)     #亮度 1\ncapture.set(CAP_PROP_CONTRAST,40)       #对比度 40\ncapture.set(CAP_PROP_SATURATION, 50)    #饱和度 50\ncapture.set(CAP_PROP_HUE, 50)           #色调 50\ncapture.set(CAP_PROP_EXPOSURE, -6)      #曝光 50\n```\n\n\n\n\n\n\n\n\n\n\n","slug":"象棋残局机器人五：象棋棋子分类模型","published":1,"updated":"2019-06-08T01:32:09.509Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm75b001orsvje3tlnlkk","content":"<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"1-采集图像分辨率低导致分类错误\"><a href=\"#1-采集图像分辨率低导致分类错误\" class=\"headerlink\" title=\"1. 采集图像分辨率低导致分类错误\"></a>1. 采集图像分辨率低导致分类错误</h3><p>小伙伴的电脑摄像头采集视频流默认长宽比是16:9，显示的图片会自动在上下方补充两道黑条，并被发现无法通过cap.set(CAP_PROP_FRAME_HEIGHT，480)函数解决这个问题。<br>这个问题导致采集图像的实际分辨率为640:360，所以采集的棋子照片中棋子比较模糊，同样的问题在重新调整摄像头位置没有调整好焦距时也会发生。</p>\n<p><div align=\"center\">\n<img src=\"/2019/06/05/象棋残局机器人五：象棋棋子分类模型/001.jpg\" width=\"600\" height=\"400\">\n</div><br>默认分辨率是640*480，通过调高分辨率解决。  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = img[60:400,:,:]</span><br><span class=\"line\">img = cv2.resize(img, (640, 480))</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-对于一些场景可以调整摄像头参数\"><a href=\"#2-对于一些场景可以调整摄像头参数\" class=\"headerlink\" title=\"2. 对于一些场景可以调整摄像头参数\"></a>2. 对于一些场景可以调整摄像头参数</h3><p>特别注意有些摄像头参数设置后会保存，一旦修改后无法恢复到初始值，所以不要随意设置参数或在设置前注意记录摄像头参数的初始值。<br>获取摄像头参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">capture.get(CAP_PROP_FRAME_WIDTH)</span><br><span class=\"line\">capture.get(CAP_PROP_FRAME_HEIGHT)</span><br><span class=\"line\">capture.get(CAP_PROP_FPS)</span><br><span class=\"line\">capture.get(CAP_PROP_BRIGHTNESS)</span><br><span class=\"line\">capture.get(CAP_PROP_CONTRAST)</span><br><span class=\"line\">capture.get(CAP_PROP_SATURATION)</span><br><span class=\"line\">capture.get(CAP_PROP_HUE)</span><br><span class=\"line\">capture.get(CAP_PROP_EXPOSURE)</span><br></pre></td></tr></table></figure></p>\n<p>设置摄像头参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">capture.set(CAP_PROP_FRAME_WIDTH, 1080) <span class=\"comment\">#宽度 </span></span><br><span class=\"line\">capture.set(CAP_PROP_FRAME_HEIGHT, 960) <span class=\"comment\">#高度</span></span><br><span class=\"line\">capture.set(CAP_PROP_FPS, 30)           <span class=\"comment\">#帧率 帧/秒</span></span><br><span class=\"line\">capture.set(CAP_PROP_BRIGHTNESS, 1)     <span class=\"comment\">#亮度 1</span></span><br><span class=\"line\">capture.set(CAP_PROP_CONTRAST,40)       <span class=\"comment\">#对比度 40</span></span><br><span class=\"line\">capture.set(CAP_PROP_SATURATION, 50)    <span class=\"comment\">#饱和度 50</span></span><br><span class=\"line\">capture.set(CAP_PROP_HUE, 50)           <span class=\"comment\">#色调 50</span></span><br><span class=\"line\">capture.set(CAP_PROP_EXPOSURE, -6)      <span class=\"comment\">#曝光 50</span></span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"问题记录\"><a href=\"#问题记录\" class=\"headerlink\" title=\"问题记录\"></a>问题记录</h2><h3 id=\"1-采集图像分辨率低导致分类错误\"><a href=\"#1-采集图像分辨率低导致分类错误\" class=\"headerlink\" title=\"1. 采集图像分辨率低导致分类错误\"></a>1. 采集图像分辨率低导致分类错误</h3><p>小伙伴的电脑摄像头采集视频流默认长宽比是16:9，显示的图片会自动在上下方补充两道黑条，并被发现无法通过cap.set(CAP_PROP_FRAME_HEIGHT，480)函数解决这个问题。<br>这个问题导致采集图像的实际分辨率为640:360，所以采集的棋子照片中棋子比较模糊，同样的问题在重新调整摄像头位置没有调整好焦距时也会发生。</p>\n<p><div align=\"center\">\n<img src=\"/2019/06/05/象棋残局机器人五：象棋棋子分类模型/001.jpg\" width=\"600\" height=\"400\">\n</div><br>默认分辨率是640*480，通过调高分辨率解决。  </p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">img = img[60:400,:,:]</span><br><span class=\"line\">img = cv2.resize(img, (640, 480))</span><br></pre></td></tr></table></figure>\n<h3 id=\"2-对于一些场景可以调整摄像头参数\"><a href=\"#2-对于一些场景可以调整摄像头参数\" class=\"headerlink\" title=\"2. 对于一些场景可以调整摄像头参数\"></a>2. 对于一些场景可以调整摄像头参数</h3><p>特别注意有些摄像头参数设置后会保存，一旦修改后无法恢复到初始值，所以不要随意设置参数或在设置前注意记录摄像头参数的初始值。<br>获取摄像头参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">capture.get(CAP_PROP_FRAME_WIDTH)</span><br><span class=\"line\">capture.get(CAP_PROP_FRAME_HEIGHT)</span><br><span class=\"line\">capture.get(CAP_PROP_FPS)</span><br><span class=\"line\">capture.get(CAP_PROP_BRIGHTNESS)</span><br><span class=\"line\">capture.get(CAP_PROP_CONTRAST)</span><br><span class=\"line\">capture.get(CAP_PROP_SATURATION)</span><br><span class=\"line\">capture.get(CAP_PROP_HUE)</span><br><span class=\"line\">capture.get(CAP_PROP_EXPOSURE)</span><br></pre></td></tr></table></figure></p>\n<p>设置摄像头参数<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">capture.set(CAP_PROP_FRAME_WIDTH, 1080) <span class=\"comment\">#宽度 </span></span><br><span class=\"line\">capture.set(CAP_PROP_FRAME_HEIGHT, 960) <span class=\"comment\">#高度</span></span><br><span class=\"line\">capture.set(CAP_PROP_FPS, 30)           <span class=\"comment\">#帧率 帧/秒</span></span><br><span class=\"line\">capture.set(CAP_PROP_BRIGHTNESS, 1)     <span class=\"comment\">#亮度 1</span></span><br><span class=\"line\">capture.set(CAP_PROP_CONTRAST,40)       <span class=\"comment\">#对比度 40</span></span><br><span class=\"line\">capture.set(CAP_PROP_SATURATION, 50)    <span class=\"comment\">#饱和度 50</span></span><br><span class=\"line\">capture.set(CAP_PROP_HUE, 50)           <span class=\"comment\">#色调 50</span></span><br><span class=\"line\">capture.set(CAP_PROP_EXPOSURE, -6)      <span class=\"comment\">#曝光 50</span></span><br></pre></td></tr></table></figure></p>\n"},{"title":"象棋残局机器人四：策略","date":"2019-06-04T06:47:59.000Z","_content":"关于下棋策略的方案，尝试使用了象棋引擎binghewusi和cyclone，最终选择开源项目cczero。\n\n\n\n## 象棋引擎\n* 中国象棋程序《象棋旋风》 </br>http://www.xqbase.com/league/xqcyclone.htm\n* 中国象棋程序《兵河五四》 </br>http://www.xqbase.com/league/bhws.htm\n\n\n### 中国象棋通用引擎协议\n不管是Windows还是UNIX平台，能被界面调用的引擎都必须是编译过的可执行文件，它跟界面之间通过“标准输入”和“标准输出”(即C/C++语言中的stdin和stdout)通道来通讯。如果引擎从Windows平台移植到UNIX平台，那么需要重新编译源代码(管道操作的程序也需要作适当修改)，或使用跨平台接口。\n\n* 中国象棋电脑应用规范(五)：中国象棋通用引擎协议</br>http://www.xqbase.com/protocol/cchess_ucci.htm\n\nFEN格式串最初的棋局表示:\n``` bash\nrnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w - - 0 1\n```\n小写表示黑方，大写表示红方  \n* 中国象棋电脑应用规范(三)：FEN文件格式 </br>http://www.xqbase.com/protocol/cchess_fen.htm  \n\n调用象棋引擎，输入FEN格式串表的当前局面，获得当前局面策略，输出的策略是一个ICCS坐标格式的四位字符串\n``` bash\nimport subprocess\nimport time\nclass Strategy:\n    exepath = r\".\\strategy.exe\"\n\n    def __init__(self):\n        self.p = subprocess.Popen(self.exepath, stdin=subprocess.PIPE,stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        ret = self.p.stdout.readline()\n\n    def get_move(self, position = \"rCbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/4C2C1/9/RNBAKABNR\", \n                 player = \"b\", times = 1000, depth = 8, show_thinking = 1):   \n        \n        com = \"position fen \" + position + \" \" + player + \" - - 0 1\\r\\n\"\n        self.p.stdin.write(com.encode('GBK'))\n        # com = 'go depth ' + str(depth) + ' time 20000\\r\\n'\n        com = 'go depth ' + str(depth) + '\\r\\n'\n        self.p.stdin.write(com.encode('GBK'))\n        self.p.stdin.flush()\n\n        while True:\n            ret = self.p.stdout.readline()\n            if show_thinking:\n                print(ret)\n            if ret.decode()[:8] == 'bestmove':\n                ans = ret.decode()[9:13]\n                break\n        # print(\"ans\", ans)\n        return ans\n\nif __name__ == '__main__':\n    ai = Strategy()\n    situation = \"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/2C4C1/9/RNBAKABNR\"\n    move = ai.get_move(position=situation, show_thinking = True)\n    print(move)\n\n```\n棋盘标记\n<div align=center>\n<img src='象棋残局机器人四：策略\\001.png' width=300 height=300>\n</div>\n\n\n\n\n## 开源项目cczero\n\n众所周知，Deep Mind公司先后推出了Alpha Go, AlphaGo Zero 和 AlphaZero 三个棋类算法：AlphaGo吊打李世石、柯洁；AlphaGo Zero不用人类知识从零学起吊打AlphaGo；AlphaZero又分别在围棋、国际象棋和将棋领域取得了最高水平。cczero项目移植了AlphaZero算法。  \nDeepMind用了5000个TPU才能在很短的时间内训练完成，cczero也需要巨大的计算资源才能使其征服中国象棋打败当今最强象棋程序，其开放跑谱教程，鼓励参与者贡献CPU/GPU时间，使这个项目变得越来越强。    \ncczero项目为开源项目，引擎和权重永久免费，项目交流群为706396552。\n\n* 中国象棋Zero</br> https://cczero.org/\n* NeymarL/ChineseChess-AlphaZero: Implement AlphaZero/AlphaGo Zero methods on Chinese chess. </br>https://github.com/NeymarL/ChineseChess-AlphaZero\n* 下载cczero最新权重 </br>https://cczero.org/api/models\n\n\n调用cczero主要代码\n``` bash\nplay = PlayWithHuman(config)\n# play.start(human_first)\nplay.env.reset(init_state=\"r8/3k5/9/9/9/9/9/9/4A4/3AK4\")\nplay.load_model()\nplay.pipe = play.model.get_pipes()\nplay.ai = CChessPlayer(play.config, search_tree=defaultdict(VisitState), pipes=play.pipe,\n                        enable_resign=False, debugging=False)\nhuman_first = not args.ai_move_first\nplay.human_move_first = human_first\nmove = ai.get_move(position=situation, show_thinking = True)\n```\n\n\n## 参考资料\n* AlphaZero实践——中国象棋（附论文翻译） - 知乎</br> https://zhuanlan.zhihu.com/p/34433581\n\n","source":"_posts/象棋残局机器人四：策略.md","raw":"---\ntitle: 象棋残局机器人四：策略\ndate: 2019-06-04 14:47:59\ntags:\n  - AlphaZero\n---\n关于下棋策略的方案，尝试使用了象棋引擎binghewusi和cyclone，最终选择开源项目cczero。\n\n\n\n## 象棋引擎\n* 中国象棋程序《象棋旋风》 </br>http://www.xqbase.com/league/xqcyclone.htm\n* 中国象棋程序《兵河五四》 </br>http://www.xqbase.com/league/bhws.htm\n\n\n### 中国象棋通用引擎协议\n不管是Windows还是UNIX平台，能被界面调用的引擎都必须是编译过的可执行文件，它跟界面之间通过“标准输入”和“标准输出”(即C/C++语言中的stdin和stdout)通道来通讯。如果引擎从Windows平台移植到UNIX平台，那么需要重新编译源代码(管道操作的程序也需要作适当修改)，或使用跨平台接口。\n\n* 中国象棋电脑应用规范(五)：中国象棋通用引擎协议</br>http://www.xqbase.com/protocol/cchess_ucci.htm\n\nFEN格式串最初的棋局表示:\n``` bash\nrnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w - - 0 1\n```\n小写表示黑方，大写表示红方  \n* 中国象棋电脑应用规范(三)：FEN文件格式 </br>http://www.xqbase.com/protocol/cchess_fen.htm  \n\n调用象棋引擎，输入FEN格式串表的当前局面，获得当前局面策略，输出的策略是一个ICCS坐标格式的四位字符串\n``` bash\nimport subprocess\nimport time\nclass Strategy:\n    exepath = r\".\\strategy.exe\"\n\n    def __init__(self):\n        self.p = subprocess.Popen(self.exepath, stdin=subprocess.PIPE,stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        ret = self.p.stdout.readline()\n\n    def get_move(self, position = \"rCbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/4C2C1/9/RNBAKABNR\", \n                 player = \"b\", times = 1000, depth = 8, show_thinking = 1):   \n        \n        com = \"position fen \" + position + \" \" + player + \" - - 0 1\\r\\n\"\n        self.p.stdin.write(com.encode('GBK'))\n        # com = 'go depth ' + str(depth) + ' time 20000\\r\\n'\n        com = 'go depth ' + str(depth) + '\\r\\n'\n        self.p.stdin.write(com.encode('GBK'))\n        self.p.stdin.flush()\n\n        while True:\n            ret = self.p.stdout.readline()\n            if show_thinking:\n                print(ret)\n            if ret.decode()[:8] == 'bestmove':\n                ans = ret.decode()[9:13]\n                break\n        # print(\"ans\", ans)\n        return ans\n\nif __name__ == '__main__':\n    ai = Strategy()\n    situation = \"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/2C4C1/9/RNBAKABNR\"\n    move = ai.get_move(position=situation, show_thinking = True)\n    print(move)\n\n```\n棋盘标记\n<div align=center>\n<img src='象棋残局机器人四：策略\\001.png' width=300 height=300>\n</div>\n\n\n\n\n## 开源项目cczero\n\n众所周知，Deep Mind公司先后推出了Alpha Go, AlphaGo Zero 和 AlphaZero 三个棋类算法：AlphaGo吊打李世石、柯洁；AlphaGo Zero不用人类知识从零学起吊打AlphaGo；AlphaZero又分别在围棋、国际象棋和将棋领域取得了最高水平。cczero项目移植了AlphaZero算法。  \nDeepMind用了5000个TPU才能在很短的时间内训练完成，cczero也需要巨大的计算资源才能使其征服中国象棋打败当今最强象棋程序，其开放跑谱教程，鼓励参与者贡献CPU/GPU时间，使这个项目变得越来越强。    \ncczero项目为开源项目，引擎和权重永久免费，项目交流群为706396552。\n\n* 中国象棋Zero</br> https://cczero.org/\n* NeymarL/ChineseChess-AlphaZero: Implement AlphaZero/AlphaGo Zero methods on Chinese chess. </br>https://github.com/NeymarL/ChineseChess-AlphaZero\n* 下载cczero最新权重 </br>https://cczero.org/api/models\n\n\n调用cczero主要代码\n``` bash\nplay = PlayWithHuman(config)\n# play.start(human_first)\nplay.env.reset(init_state=\"r8/3k5/9/9/9/9/9/9/4A4/3AK4\")\nplay.load_model()\nplay.pipe = play.model.get_pipes()\nplay.ai = CChessPlayer(play.config, search_tree=defaultdict(VisitState), pipes=play.pipe,\n                        enable_resign=False, debugging=False)\nhuman_first = not args.ai_move_first\nplay.human_move_first = human_first\nmove = ai.get_move(position=situation, show_thinking = True)\n```\n\n\n## 参考资料\n* AlphaZero实践——中国象棋（附论文翻译） - 知乎</br> https://zhuanlan.zhihu.com/p/34433581\n\n","slug":"象棋残局机器人四：策略","published":1,"updated":"2019-06-27T18:05:34.416Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm75c001rrsvj2prfmv7n","content":"<p>关于下棋策略的方案，尝试使用了象棋引擎binghewusi和cyclone，最终选择开源项目cczero。</p>\n<h2 id=\"象棋引擎\"><a href=\"#象棋引擎\" class=\"headerlink\" title=\"象棋引擎\"></a>象棋引擎</h2><ul>\n<li>中国象棋程序《象棋旋风》 &lt;/br&gt;<a href=\"http://www.xqbase.com/league/xqcyclone.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/league/xqcyclone.htm</a></li>\n<li>中国象棋程序《兵河五四》 &lt;/br&gt;<a href=\"http://www.xqbase.com/league/bhws.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/league/bhws.htm</a></li>\n</ul>\n<h3 id=\"中国象棋通用引擎协议\"><a href=\"#中国象棋通用引擎协议\" class=\"headerlink\" title=\"中国象棋通用引擎协议\"></a>中国象棋通用引擎协议</h3><p>不管是Windows还是UNIX平台，能被界面调用的引擎都必须是编译过的可执行文件，它跟界面之间通过“标准输入”和“标准输出”(即C/C++语言中的stdin和stdout)通道来通讯。如果引擎从Windows平台移植到UNIX平台，那么需要重新编译源代码(管道操作的程序也需要作适当修改)，或使用跨平台接口。</p>\n<ul>\n<li>中国象棋电脑应用规范(五)：中国象棋通用引擎协议&lt;/br&gt;<a href=\"http://www.xqbase.com/protocol/cchess_ucci.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/protocol/cchess_ucci.htm</a></li>\n</ul>\n<p>FEN格式串最初的棋局表示:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w - - 0 1</span><br></pre></td></tr></table></figure></p>\n<p>小写表示黑方，大写表示红方  </p>\n<ul>\n<li>中国象棋电脑应用规范(三)：FEN文件格式 &lt;/br&gt;<a href=\"http://www.xqbase.com/protocol/cchess_fen.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/protocol/cchess_fen.htm</a>  </li>\n</ul>\n<p>调用象棋引擎，输入FEN格式串表的当前局面，获得当前局面策略，输出的策略是一个ICCS坐标格式的四位字符串<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import subprocess</span><br><span class=\"line\">import time</span><br><span class=\"line\">class Strategy:</span><br><span class=\"line\">    exepath = r<span class=\"string\">\".\\strategy.exe\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        self.p = subprocess.Popen(self.exepath, stdin=subprocess.PIPE,stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\"line\">        ret = self.p.stdout.readline()</span><br><span class=\"line\"></span><br><span class=\"line\">    def get_move(self, position = <span class=\"string\">\"rCbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/4C2C1/9/RNBAKABNR\"</span>, </span><br><span class=\"line\">                 player = <span class=\"string\">\"b\"</span>, <span class=\"built_in\">times</span> = 1000, depth = 8, show_thinking = 1):   </span><br><span class=\"line\">        </span><br><span class=\"line\">        com = <span class=\"string\">\"position fen \"</span> + position + <span class=\"string\">\" \"</span> + player + <span class=\"string\">\" - - 0 1\\r\\n\"</span></span><br><span class=\"line\">        self.p.stdin.write(com.encode(<span class=\"string\">'GBK'</span>))</span><br><span class=\"line\">        <span class=\"comment\"># com = 'go depth ' + str(depth) + ' time 20000\\r\\n'</span></span><br><span class=\"line\">        com = <span class=\"string\">'go depth '</span> + str(depth) + <span class=\"string\">'\\r\\n'</span></span><br><span class=\"line\">        self.p.stdin.write(com.encode(<span class=\"string\">'GBK'</span>))</span><br><span class=\"line\">        self.p.stdin.flush()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">while</span> True:</span><br><span class=\"line\">            ret = self.p.stdout.readline()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> show_thinking:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(ret)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> ret.decode()[:8] == <span class=\"string\">'bestmove'</span>:</span><br><span class=\"line\">                ans = ret.decode()[9:13]</span><br><span class=\"line\">                <span class=\"built_in\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># print(\"ans\", ans)</span></span><br><span class=\"line\">        <span class=\"built_in\">return</span> ans</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    ai = Strategy()</span><br><span class=\"line\">    situation = <span class=\"string\">\"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/2C4C1/9/RNBAKABNR\"</span></span><br><span class=\"line\">    move = ai.get_move(position=situation, show_thinking = True)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(move)</span><br></pre></td></tr></table></figure></p>\n<p>棋盘标记</p>\n<div align=\"center\">\n<img src=\"/2019/06/04/象棋残局机器人四：策略/001.png\" width=\"300\" height=\"300\">\n</div>\n\n\n\n\n<h2 id=\"开源项目cczero\"><a href=\"#开源项目cczero\" class=\"headerlink\" title=\"开源项目cczero\"></a>开源项目cczero</h2><p>众所周知，Deep Mind公司先后推出了Alpha Go, AlphaGo Zero 和 AlphaZero 三个棋类算法：AlphaGo吊打李世石、柯洁；AlphaGo Zero不用人类知识从零学起吊打AlphaGo；AlphaZero又分别在围棋、国际象棋和将棋领域取得了最高水平。cczero项目移植了AlphaZero算法。<br>DeepMind用了5000个TPU才能在很短的时间内训练完成，cczero也需要巨大的计算资源才能使其征服中国象棋打败当今最强象棋程序，其开放跑谱教程，鼓励参与者贡献CPU/GPU时间，使这个项目变得越来越强。<br>cczero项目为开源项目，引擎和权重永久免费，项目交流群为706396552。</p>\n<ul>\n<li>中国象棋Zero&lt;/br&gt; <a href=\"https://cczero.org/\" target=\"_blank\" rel=\"noopener\">https://cczero.org/</a></li>\n<li>NeymarL/ChineseChess-AlphaZero: Implement AlphaZero/AlphaGo Zero methods on Chinese chess. &lt;/br&gt;<a href=\"https://github.com/NeymarL/ChineseChess-AlphaZero\" target=\"_blank\" rel=\"noopener\">https://github.com/NeymarL/ChineseChess-AlphaZero</a></li>\n<li>下载cczero最新权重 &lt;/br&gt;<a href=\"https://cczero.org/api/models\" target=\"_blank\" rel=\"noopener\">https://cczero.org/api/models</a></li>\n</ul>\n<p>调用cczero主要代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">play = PlayWithHuman(config)</span><br><span class=\"line\"><span class=\"comment\"># play.start(human_first)</span></span><br><span class=\"line\">play.env.reset(init_state=<span class=\"string\">\"r8/3k5/9/9/9/9/9/9/4A4/3AK4\"</span>)</span><br><span class=\"line\">play.load_model()</span><br><span class=\"line\">play.pipe = play.model.get_pipes()</span><br><span class=\"line\">play.ai = CChessPlayer(play.config, search_tree=defaultdict(VisitState), pipes=play.pipe,</span><br><span class=\"line\">                        enable_resign=False, debugging=False)</span><br><span class=\"line\">human_first = not args.ai_move_first</span><br><span class=\"line\">play.human_move_first = human_first</span><br><span class=\"line\">move = ai.get_move(position=situation, show_thinking = True)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>AlphaZero实践——中国象棋（附论文翻译） - 知乎&lt;/br&gt; <a href=\"https://zhuanlan.zhihu.com/p/34433581\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/34433581</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>关于下棋策略的方案，尝试使用了象棋引擎binghewusi和cyclone，最终选择开源项目cczero。</p>\n<h2 id=\"象棋引擎\"><a href=\"#象棋引擎\" class=\"headerlink\" title=\"象棋引擎\"></a>象棋引擎</h2><ul>\n<li>中国象棋程序《象棋旋风》 &lt;/br&gt;<a href=\"http://www.xqbase.com/league/xqcyclone.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/league/xqcyclone.htm</a></li>\n<li>中国象棋程序《兵河五四》 &lt;/br&gt;<a href=\"http://www.xqbase.com/league/bhws.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/league/bhws.htm</a></li>\n</ul>\n<h3 id=\"中国象棋通用引擎协议\"><a href=\"#中国象棋通用引擎协议\" class=\"headerlink\" title=\"中国象棋通用引擎协议\"></a>中国象棋通用引擎协议</h3><p>不管是Windows还是UNIX平台，能被界面调用的引擎都必须是编译过的可执行文件，它跟界面之间通过“标准输入”和“标准输出”(即C/C++语言中的stdin和stdout)通道来通讯。如果引擎从Windows平台移植到UNIX平台，那么需要重新编译源代码(管道操作的程序也需要作适当修改)，或使用跨平台接口。</p>\n<ul>\n<li>中国象棋电脑应用规范(五)：中国象棋通用引擎协议&lt;/br&gt;<a href=\"http://www.xqbase.com/protocol/cchess_ucci.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/protocol/cchess_ucci.htm</a></li>\n</ul>\n<p>FEN格式串最初的棋局表示:<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/1C5C1/9/RNBAKABNR w - - 0 1</span><br></pre></td></tr></table></figure></p>\n<p>小写表示黑方，大写表示红方  </p>\n<ul>\n<li>中国象棋电脑应用规范(三)：FEN文件格式 &lt;/br&gt;<a href=\"http://www.xqbase.com/protocol/cchess_fen.htm\" target=\"_blank\" rel=\"noopener\">http://www.xqbase.com/protocol/cchess_fen.htm</a>  </li>\n</ul>\n<p>调用象棋引擎，输入FEN格式串表的当前局面，获得当前局面策略，输出的策略是一个ICCS坐标格式的四位字符串<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import subprocess</span><br><span class=\"line\">import time</span><br><span class=\"line\">class Strategy:</span><br><span class=\"line\">    exepath = r<span class=\"string\">\".\\strategy.exe\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    def __init__(self):</span><br><span class=\"line\">        self.p = subprocess.Popen(self.exepath, stdin=subprocess.PIPE,stdout=subprocess.PIPE, stderr=subprocess.PIPE)</span><br><span class=\"line\">        ret = self.p.stdout.readline()</span><br><span class=\"line\"></span><br><span class=\"line\">    def get_move(self, position = <span class=\"string\">\"rCbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/4C2C1/9/RNBAKABNR\"</span>, </span><br><span class=\"line\">                 player = <span class=\"string\">\"b\"</span>, <span class=\"built_in\">times</span> = 1000, depth = 8, show_thinking = 1):   </span><br><span class=\"line\">        </span><br><span class=\"line\">        com = <span class=\"string\">\"position fen \"</span> + position + <span class=\"string\">\" \"</span> + player + <span class=\"string\">\" - - 0 1\\r\\n\"</span></span><br><span class=\"line\">        self.p.stdin.write(com.encode(<span class=\"string\">'GBK'</span>))</span><br><span class=\"line\">        <span class=\"comment\"># com = 'go depth ' + str(depth) + ' time 20000\\r\\n'</span></span><br><span class=\"line\">        com = <span class=\"string\">'go depth '</span> + str(depth) + <span class=\"string\">'\\r\\n'</span></span><br><span class=\"line\">        self.p.stdin.write(com.encode(<span class=\"string\">'GBK'</span>))</span><br><span class=\"line\">        self.p.stdin.flush()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">while</span> True:</span><br><span class=\"line\">            ret = self.p.stdout.readline()</span><br><span class=\"line\">            <span class=\"keyword\">if</span> show_thinking:</span><br><span class=\"line\">                <span class=\"built_in\">print</span>(ret)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> ret.decode()[:8] == <span class=\"string\">'bestmove'</span>:</span><br><span class=\"line\">                ans = ret.decode()[9:13]</span><br><span class=\"line\">                <span class=\"built_in\">break</span></span><br><span class=\"line\">        <span class=\"comment\"># print(\"ans\", ans)</span></span><br><span class=\"line\">        <span class=\"built_in\">return</span> ans</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    ai = Strategy()</span><br><span class=\"line\">    situation = <span class=\"string\">\"rnbakabnr/9/1c5c1/p1p1p1p1p/9/9/P1P1P1P1P/2C4C1/9/RNBAKABNR\"</span></span><br><span class=\"line\">    move = ai.get_move(position=situation, show_thinking = True)</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(move)</span><br></pre></td></tr></table></figure></p>\n<p>棋盘标记</p>\n<div align=\"center\">\n<img src=\"/2019/06/04/象棋残局机器人四：策略/001.png\" width=\"300\" height=\"300\">\n</div>\n\n\n\n\n<h2 id=\"开源项目cczero\"><a href=\"#开源项目cczero\" class=\"headerlink\" title=\"开源项目cczero\"></a>开源项目cczero</h2><p>众所周知，Deep Mind公司先后推出了Alpha Go, AlphaGo Zero 和 AlphaZero 三个棋类算法：AlphaGo吊打李世石、柯洁；AlphaGo Zero不用人类知识从零学起吊打AlphaGo；AlphaZero又分别在围棋、国际象棋和将棋领域取得了最高水平。cczero项目移植了AlphaZero算法。<br>DeepMind用了5000个TPU才能在很短的时间内训练完成，cczero也需要巨大的计算资源才能使其征服中国象棋打败当今最强象棋程序，其开放跑谱教程，鼓励参与者贡献CPU/GPU时间，使这个项目变得越来越强。<br>cczero项目为开源项目，引擎和权重永久免费，项目交流群为706396552。</p>\n<ul>\n<li>中国象棋Zero&lt;/br&gt; <a href=\"https://cczero.org/\" target=\"_blank\" rel=\"noopener\">https://cczero.org/</a></li>\n<li>NeymarL/ChineseChess-AlphaZero: Implement AlphaZero/AlphaGo Zero methods on Chinese chess. &lt;/br&gt;<a href=\"https://github.com/NeymarL/ChineseChess-AlphaZero\" target=\"_blank\" rel=\"noopener\">https://github.com/NeymarL/ChineseChess-AlphaZero</a></li>\n<li>下载cczero最新权重 &lt;/br&gt;<a href=\"https://cczero.org/api/models\" target=\"_blank\" rel=\"noopener\">https://cczero.org/api/models</a></li>\n</ul>\n<p>调用cczero主要代码<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">play = PlayWithHuman(config)</span><br><span class=\"line\"><span class=\"comment\"># play.start(human_first)</span></span><br><span class=\"line\">play.env.reset(init_state=<span class=\"string\">\"r8/3k5/9/9/9/9/9/9/4A4/3AK4\"</span>)</span><br><span class=\"line\">play.load_model()</span><br><span class=\"line\">play.pipe = play.model.get_pipes()</span><br><span class=\"line\">play.ai = CChessPlayer(play.config, search_tree=defaultdict(VisitState), pipes=play.pipe,</span><br><span class=\"line\">                        enable_resign=False, debugging=False)</span><br><span class=\"line\">human_first = not args.ai_move_first</span><br><span class=\"line\">play.human_move_first = human_first</span><br><span class=\"line\">move = ai.get_move(position=situation, show_thinking = True)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li>AlphaZero实践——中国象棋（附论文翻译） - 知乎&lt;/br&gt; <a href=\"https://zhuanlan.zhihu.com/p/34433581\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/34433581</a></li>\n</ul>\n"},{"title":"门禁ubuntu配置$hadow$ocks,又可以刷脸开门了","date":"2019-04-27T15:30:03.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n* Shadowsocks - A secure socks5 proxy </br>http://shadowsocks.org/en/index.html\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n### 安装\n``` bash\n$ sudo apt-get install python-pip\n$ sudo pip install shadowsocks\n$ sudo apt-get install software-properties-common -y\n$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y\n$ sudo apt-get update\n$ sudo apt install shadowsocks-libev\n```\n### 配置\n``` bash\n$ sudo vim /etc/shadowsocks-libev.json\n    \n    {\n        \"server\":\"xx.xx.xx.xx\",\n        \"server_port\":2080,\n        \"local_address\": \"127.0.0.1\",\n        \"local_port\":1080,\n        \"password\":\"xxxxxxxx\",\n        \"timeout\":300,\n        \"method\":\"chacha20-ietf-poly1305\",\n        \"workers\": 2,\n        \"fast_open\": false\n    }\n```\n### 运行\n``` bash\n$ ss-local -c /etc/shadowsocks-libev.json\n```\n### 设置全局代理\n系统设置 -> 网络 -> 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080，然后点击应用到整个系统，输入密码即可。\n### 设置浏览器代理\n直接搜索proxy，找到设置后根据实际情况设置，不要使用系统代理设置\n### 设置开机自启\n``` bash\n$ cd /etc/init.d\n```\n创建开机启动服务\n``` bash\n$ sudo vim shadowsocks\n\n    #!/bin/bash\n    /usr/bin/ss-local -c /etc/shadowsocks-libev.json\n    exit  0\n```\n报“missing LSB tags and overrides”错，在#!/bin/bash下面添加\n``` bash\n    ### BEGIN INIT INFO\n    # Provides: OSSEC HIDS\n    # Required-Start: $network $remote_fs $syslog $time\n    # Required-Stop:\n    # Default-Start: 2 3 4 5\n    # Default-Stop: 0 1 6\n    # Short-Description: OSSEC HIDS\n    ### END INIT INFO\n```\n赋予可执行权限\n``` bash\n$ sudo chmod +x shadowsocks\n```\n设置开机自启动\n``` bash\n$ sudo update-rc.d shadowsocks defaults 100\n```\n\n\n\n\n","source":"_posts/门禁ubuntu配置-hadow-ocks-又可以刷脸开门了.md","raw":"---\ntitle: '门禁ubuntu配置$hadow$ocks,又可以刷脸开门了'\ndate: 2019-04-27 23:30:03\ntags:\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n* Shadowsocks - A secure socks5 proxy </br>http://shadowsocks.org/en/index.html\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n### 安装\n``` bash\n$ sudo apt-get install python-pip\n$ sudo pip install shadowsocks\n$ sudo apt-get install software-properties-common -y\n$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y\n$ sudo apt-get update\n$ sudo apt install shadowsocks-libev\n```\n### 配置\n``` bash\n$ sudo vim /etc/shadowsocks-libev.json\n    \n    {\n        \"server\":\"xx.xx.xx.xx\",\n        \"server_port\":2080,\n        \"local_address\": \"127.0.0.1\",\n        \"local_port\":1080,\n        \"password\":\"xxxxxxxx\",\n        \"timeout\":300,\n        \"method\":\"chacha20-ietf-poly1305\",\n        \"workers\": 2,\n        \"fast_open\": false\n    }\n```\n### 运行\n``` bash\n$ ss-local -c /etc/shadowsocks-libev.json\n```\n### 设置全局代理\n系统设置 -> 网络 -> 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080，然后点击应用到整个系统，输入密码即可。\n### 设置浏览器代理\n直接搜索proxy，找到设置后根据实际情况设置，不要使用系统代理设置\n### 设置开机自启\n``` bash\n$ cd /etc/init.d\n```\n创建开机启动服务\n``` bash\n$ sudo vim shadowsocks\n\n    #!/bin/bash\n    /usr/bin/ss-local -c /etc/shadowsocks-libev.json\n    exit  0\n```\n报“missing LSB tags and overrides”错，在#!/bin/bash下面添加\n``` bash\n    ### BEGIN INIT INFO\n    # Provides: OSSEC HIDS\n    # Required-Start: $network $remote_fs $syslog $time\n    # Required-Stop:\n    # Default-Start: 2 3 4 5\n    # Default-Stop: 0 1 6\n    # Short-Description: OSSEC HIDS\n    ### END INIT INFO\n```\n赋予可执行权限\n``` bash\n$ sudo chmod +x shadowsocks\n```\n设置开机自启动\n``` bash\n$ sudo update-rc.d shadowsocks defaults 100\n```\n\n\n\n\n","slug":"门禁ubuntu配置-hadow-ocks-又可以刷脸开门了","published":1,"updated":"2019-05-16T12:01:16.477Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm75d001srsvjuxwbwqd2","content":"<p><strong> 门禁ubuntu配置$hadow$ocks,又可以刷脸开门了：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>Shadowsocks - A secure socks5 proxy &lt;/br&gt;<a href=\"http://shadowsocks.org/en/index.html\" target=\"_blank\" rel=\"noopener\">http://shadowsocks.org/en/index.html</a></li>\n</ul>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-pip</span><br><span class=\"line\">$ sudo pip install shadowsocks</span><br><span class=\"line\">$ sudo apt-get install software-properties-common -y</span><br><span class=\"line\">$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y</span><br><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt install shadowsocks-libev</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/shadowsocks-libev.json</span><br><span class=\"line\">    </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"string\">\"server\"</span>:<span class=\"string\">\"xx.xx.xx.xx\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"server_port\"</span>:2080,</span><br><span class=\"line\">        <span class=\"string\">\"local_address\"</span>: <span class=\"string\">\"127.0.0.1\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"local_port\"</span>:1080,</span><br><span class=\"line\">        <span class=\"string\">\"password\"</span>:<span class=\"string\">\"xxxxxxxx\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"timeout\"</span>:300,</span><br><span class=\"line\">        <span class=\"string\">\"method\"</span>:<span class=\"string\">\"chacha20-ietf-poly1305\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"workers\"</span>: 2,</span><br><span class=\"line\">        <span class=\"string\">\"fast_open\"</span>: <span class=\"literal\">false</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ss-local -c /etc/shadowsocks-libev.json</span><br></pre></td></tr></table></figure>\n<h3 id=\"设置全局代理\"><a href=\"#设置全局代理\" class=\"headerlink\" title=\"设置全局代理\"></a>设置全局代理</h3><p>系统设置 -&gt; 网络 -&gt; 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080，然后点击应用到整个系统，输入密码即可。</p>\n<h3 id=\"设置浏览器代理\"><a href=\"#设置浏览器代理\" class=\"headerlink\" title=\"设置浏览器代理\"></a>设置浏览器代理</h3><p>直接搜索proxy，找到设置后根据实际情况设置，不要使用系统代理设置</p>\n<h3 id=\"设置开机自启\"><a href=\"#设置开机自启\" class=\"headerlink\" title=\"设置开机自启\"></a>设置开机自启</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /etc/init.d</span><br></pre></td></tr></table></figure>\n<p>创建开机启动服务<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim shadowsocks</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">    /usr/bin/ss-local -c /etc/shadowsocks-libev.json</span><br><span class=\"line\">    <span class=\"built_in\">exit</span>  0</span><br></pre></td></tr></table></figure></p>\n<p>报“missing LSB tags and overrides”错，在#!/bin/bash下面添加<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### BEGIN INIT INFO</span></span><br><span class=\"line\"><span class=\"comment\"># Provides: OSSEC HIDS</span></span><br><span class=\"line\"><span class=\"comment\"># Required-Start: $network $remote_fs $syslog $time</span></span><br><span class=\"line\"><span class=\"comment\"># Required-Stop:</span></span><br><span class=\"line\"><span class=\"comment\"># Default-Start: 2 3 4 5</span></span><br><span class=\"line\"><span class=\"comment\"># Default-Stop: 0 1 6</span></span><br><span class=\"line\"><span class=\"comment\"># Short-Description: OSSEC HIDS</span></span><br><span class=\"line\"><span class=\"comment\">### END INIT INFO</span></span><br></pre></td></tr></table></figure></p>\n<p>赋予可执行权限<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo chmod +x shadowsocks</span><br></pre></td></tr></table></figure></p>\n<p>设置开机自启动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo update-rc.d shadowsocks defaults 100</span><br></pre></td></tr></table></figure></p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 门禁ubuntu配置$hadow$ocks,又可以刷脸开门了：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>Shadowsocks - A secure socks5 proxy &lt;/br&gt;<a href=\"http://shadowsocks.org/en/index.html\" target=\"_blank\" rel=\"noopener\">http://shadowsocks.org/en/index.html</a></li>\n</ul>","more":"<the rest of contents | 余下全文>\n\n\n<h3 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install python-pip</span><br><span class=\"line\">$ sudo pip install shadowsocks</span><br><span class=\"line\">$ sudo apt-get install software-properties-common -y</span><br><span class=\"line\">$ sudo add-apt-repository ppa:max-c-lv/shadowsocks-libev -y</span><br><span class=\"line\">$ sudo apt-get update</span><br><span class=\"line\">$ sudo apt install shadowsocks-libev</span><br></pre></td></tr></table></figure>\n<h3 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/shadowsocks-libev.json</span><br><span class=\"line\">    </span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"string\">\"server\"</span>:<span class=\"string\">\"xx.xx.xx.xx\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"server_port\"</span>:2080,</span><br><span class=\"line\">        <span class=\"string\">\"local_address\"</span>: <span class=\"string\">\"127.0.0.1\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"local_port\"</span>:1080,</span><br><span class=\"line\">        <span class=\"string\">\"password\"</span>:<span class=\"string\">\"xxxxxxxx\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"timeout\"</span>:300,</span><br><span class=\"line\">        <span class=\"string\">\"method\"</span>:<span class=\"string\">\"chacha20-ietf-poly1305\"</span>,</span><br><span class=\"line\">        <span class=\"string\">\"workers\"</span>: 2,</span><br><span class=\"line\">        <span class=\"string\">\"fast_open\"</span>: <span class=\"literal\">false</span></span><br><span class=\"line\">    &#125;</span><br></pre></td></tr></table></figure>\n<h3 id=\"运行\"><a href=\"#运行\" class=\"headerlink\" title=\"运行\"></a>运行</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ ss-local -c /etc/shadowsocks-libev.json</span><br></pre></td></tr></table></figure>\n<h3 id=\"设置全局代理\"><a href=\"#设置全局代理\" class=\"headerlink\" title=\"设置全局代理\"></a>设置全局代理</h3><p>系统设置 -&gt; 网络 -&gt; 网络代理，方法选择手动，然后设置Socks主机127.0.0.1， 后面端口这是1080，然后点击应用到整个系统，输入密码即可。</p>\n<h3 id=\"设置浏览器代理\"><a href=\"#设置浏览器代理\" class=\"headerlink\" title=\"设置浏览器代理\"></a>设置浏览器代理</h3><p>直接搜索proxy，找到设置后根据实际情况设置，不要使用系统代理设置</p>\n<h3 id=\"设置开机自启\"><a href=\"#设置开机自启\" class=\"headerlink\" title=\"设置开机自启\"></a>设置开机自启</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /etc/init.d</span><br></pre></td></tr></table></figure>\n<p>创建开机启动服务<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim shadowsocks</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#!/bin/bash</span></span><br><span class=\"line\">    /usr/bin/ss-local -c /etc/shadowsocks-libev.json</span><br><span class=\"line\">    <span class=\"built_in\">exit</span>  0</span><br></pre></td></tr></table></figure></p>\n<p>报“missing LSB tags and overrides”错，在#!/bin/bash下面添加<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">### BEGIN INIT INFO</span></span><br><span class=\"line\"><span class=\"comment\"># Provides: OSSEC HIDS</span></span><br><span class=\"line\"><span class=\"comment\"># Required-Start: $network $remote_fs $syslog $time</span></span><br><span class=\"line\"><span class=\"comment\"># Required-Stop:</span></span><br><span class=\"line\"><span class=\"comment\"># Default-Start: 2 3 4 5</span></span><br><span class=\"line\"><span class=\"comment\"># Default-Stop: 0 1 6</span></span><br><span class=\"line\"><span class=\"comment\"># Short-Description: OSSEC HIDS</span></span><br><span class=\"line\"><span class=\"comment\">### END INIT INFO</span></span><br></pre></td></tr></table></figure></p>\n<p>赋予可执行权限<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo chmod +x shadowsocks</span><br></pre></td></tr></table></figure></p>\n<p>设置开机自启动<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo update-rc.d shadowsocks defaults 100</span><br></pre></td></tr></table></figure></p>\n</the>"},{"title":"门禁人脸检测和识别二：人脸关键点检测","date":"2019-06-27T17:57:02.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n\n* dlib人脸关键点代码解析 - 知乎 https://zhuanlan.zhihu.com/p/56195986\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n","source":"_posts/门禁人脸检测和识别二：人脸关键点检测.md","raw":"---\ntitle: 门禁人脸检测和识别二：人脸关键点检测\ndate: 2019-06-28 01:57:02\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n* dlib人脸关键点代码解析 - 知乎 https://zhuanlan.zhihu.com/p/56195986\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n","slug":"门禁人脸检测和识别二：人脸关键点检测","published":1,"updated":"2019-07-01T05:48:01.312Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm75f001ursvj8ei9nltn","content":"<p><strong> 门禁人脸检测和识别二：人脸关键点检测：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>dlib人脸关键点代码解析 - 知乎 <a href=\"https://zhuanlan.zhihu.com/p/56195986\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/56195986</a></li>\n</ul>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n</the>","site":{"data":{}},"excerpt":"<p><strong> 门禁人脸检测和识别二：人脸关键点检测：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<ul>\n<li>dlib人脸关键点代码解析 - 知乎 <a href=\"https://zhuanlan.zhihu.com/p/56195986\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/56195986</a></li>\n</ul>","more":"<the rest of contents | 余下全文>\n\n\n</the>"},{"title":"门禁人脸检测和识别","date":"2019-06-25T10:08:41.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n<img src=\"门禁人脸检测和识别\\demo.gif\">\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 人脸检测\n\n### OpenCV库\n* ### 基于haar特征和adaboost分类器的人脸检测\nHaar分类器 = Haar-like特征 + 积分图方法 + AdaBoost +级联；  \nHaar分类器算法的要点如下：  \n①　使用Haar-like特征做检测。  \n②　使用积分图（Integral Image）对Haar-like特征求值进行加速。  \n③　使用AdaBoost算法训练区分人脸和非人脸的强分类器。  \n④　使用筛选式级联把强分类器级联到一起，提高准确率。 \n``` python\nfaceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n\ndef detectFaceOpenCVHaar(faceCascade, frame, inHeight=300, inWidth=0):\n    frameOpenCVHaar = frame.copy()\n    frameHeight = frameOpenCVHaar.shape[0]\n    frameWidth = frameOpenCVHaar.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight) * inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameOpenCVHaarSmall = cv2.resize(frameOpenCVHaar, (inWidth, inHeight))\n    frameGray = cv2.cvtColor(frameOpenCVHaarSmall, cv2.COLOR_BGR2GRAY)\n\n    faces = faceCascade.detectMultiScale(frameGray)\n    bboxes = []\n    for (x, y, w, h) in faces:\n        x1 = x\n        y1 = y\n        x2 = x + w\n        y2 = y + h\n        cvRect = [int(x1 * scaleWidth), int(y1 * scaleHeight),\n                  int(x2 * scaleWidth), int(y2 * scaleHeight)]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameOpenCVHaar, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0),\n                      int(round(frameHeight / 150)), 4)\n    return frameOpenCVHaar, bboxes\n```\n\n* ### 基于DNN的人脸检测\n在OpenCV3.3版本发布中把DNN模块从扩展模块移到了OpenCV正式发布模块中，OpenCV做了近一步扩展支持所有主流的深度学习框架训练生成与导出模型数据加载。 \n``` python \ndef detectFaceOpenCVDnn(net, frame):\n    frameOpencvDnn = frame.copy()\n    frameHeight = frameOpencvDnn.shape[0]\n    frameWidth = frameOpencvDnn.shape[1]\n    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n\n    net.setInput(blob)\n    detections = net.forward()\n    bboxes = []\n    for i in range(detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n        if confidence > conf_threshold:\n            x1 = int(detections[0, 0, i, 3] * frameWidth)\n            y1 = int(detections[0, 0, i, 4] * frameHeight)\n            x2 = int(detections[0, 0, i, 5] * frameWidth)\n            y2 = int(detections[0, 0, i, 6] * frameHeight)\n            bboxes.append([x1, y1, x2, y2])\n            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n    return frameOpencvDnn, bboxes\n```\nopenCV人脸检测的实例中，DNN模块支持两个框架的模型：   \n若为caffe模型，则使用readNetFromCaffe，需要用到.prototxt格式的配置文件和.caffemodel格式的模型文件；  \n``` python\n# 1. FP16 version of the original caffe implementation ( 5.4 MB )\nmodelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\nconfigFile = \"models/deploy.prototxt\"\nnet = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n```\n若为tensorflow模型，则使用readNetFromTensorflow，需要用到.pbtxt格式的配置文件和.pb格式的模型文件。\n``` python\n# 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )\nmodelFile = \"models/opencv_face_detector_uint8.pb\"\nconfigFile = \"models/opencv_face_detector.pbtxt\"\nnet = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n```\n\n### Dlib库\nDlib 是一个十分优秀好用的机器学习库，其源码均由 C++ 实现，并提供了 Python 接口，可广泛适用于很多场景。  \n> * dlib C++ Library  \n> http://dlib.net/ \n\n* ### 基于HOG特征和线性分类器的人脸检测\n采用经典的HOG(Histogram of Oriented Gradients)特征结合线性分类器、图像金字塔(image pyramid)及滑窗检测机制(sliding window detection scheme)实现的人脸检测器。\n``` python\nhogFaceDetector = dlib.get_frontal_face_detector()\n\ndef detectFaceDlibHog(detector, frame, inHeight=300, inWidth=0):\n\n    frameDlibHog = frame.copy()\n    frameHeight = frameDlibHog.shape[0]\n    frameWidth = frameDlibHog.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight)*inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameDlibHogSmall = cv2.resize(frameDlibHog, (inWidth, inHeight))\n\n    frameDlibHogSmall = cv2.cvtColor(frameDlibHogSmall, cv2.COLOR_BGR2RGB)\n    faceRects = detector(frameDlibHogSmall, 0)\n    print(frameWidth, frameHeight, inWidth, inHeight)\n    bboxes = []\n    for faceRect in faceRects:\n\n        cvRect = [int(faceRect.left()*scaleWidth), int(faceRect.top()*scaleHeight),\n                  int(faceRect.right()*scaleWidth), int(faceRect.bottom()*scaleHeight) ]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameDlibHog, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n    return frameDlibHog, bboxes\n```\n\n* ### 基于CNN的人脸检测\n采用预训练的CNN模型进行图片中的人脸检测。  \n基于CNN模型比基于HOG特征模型的人脸检测准确度更高，但是需要更多的计算资源，即在GPU上运行才可有较好的运行速率。\n\n``` python\ndnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\")\n\ndef detectFaceDlibMMOD(detector, frame, inHeight=300, inWidth=0):\n\n    frameDlibMMOD = frame.copy()\n    frameHeight = frameDlibMMOD.shape[0]\n    frameWidth = frameDlibMMOD.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight)*inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameDlibMMODSmall = cv2.resize(frameDlibMMOD, (inWidth, inHeight))\n\n    frameDlibMMODSmall = cv2.cvtColor(frameDlibMMODSmall, cv2.COLOR_BGR2RGB)\n    faceRects = detector(frameDlibMMODSmall, 0)\n\n    print(frameWidth, frameHeight, inWidth, inHeight)\n    bboxes = []\n    for faceRect in faceRects:\n        cvRect = [int(faceRect.rect.left()*scaleWidth), int(faceRect.rect.top()*scaleHeight),\n                  int(faceRect.rect.right()*scaleWidth), int(faceRect.rect.bottom()*scaleHeight) ]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameDlibMMOD, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n    return frameDlibMMOD, bboxes\n```\n\n\n\n## 参考\n* Face Detection - OpenCV, Dlib and Deep Learning | Learn OpenCV  \nhttps://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\n\n\n\n\n\n\n\n\n\n","source":"_posts/门禁人脸检测和识别.md","raw":"---\ntitle: 门禁人脸检测和识别\ndate: 2019-06-25 18:08:41\ntags:\n  - opencv\n  - python\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n<img src=\"门禁人脸检测和识别\\demo.gif\">\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## 人脸检测\n\n### OpenCV库\n* ### 基于haar特征和adaboost分类器的人脸检测\nHaar分类器 = Haar-like特征 + 积分图方法 + AdaBoost +级联；  \nHaar分类器算法的要点如下：  \n①　使用Haar-like特征做检测。  \n②　使用积分图（Integral Image）对Haar-like特征求值进行加速。  \n③　使用AdaBoost算法训练区分人脸和非人脸的强分类器。  \n④　使用筛选式级联把强分类器级联到一起，提高准确率。 \n``` python\nfaceCascade = cv2.CascadeClassifier('./haarcascade_frontalface_default.xml')\n\ndef detectFaceOpenCVHaar(faceCascade, frame, inHeight=300, inWidth=0):\n    frameOpenCVHaar = frame.copy()\n    frameHeight = frameOpenCVHaar.shape[0]\n    frameWidth = frameOpenCVHaar.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight) * inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameOpenCVHaarSmall = cv2.resize(frameOpenCVHaar, (inWidth, inHeight))\n    frameGray = cv2.cvtColor(frameOpenCVHaarSmall, cv2.COLOR_BGR2GRAY)\n\n    faces = faceCascade.detectMultiScale(frameGray)\n    bboxes = []\n    for (x, y, w, h) in faces:\n        x1 = x\n        y1 = y\n        x2 = x + w\n        y2 = y + h\n        cvRect = [int(x1 * scaleWidth), int(y1 * scaleHeight),\n                  int(x2 * scaleWidth), int(y2 * scaleHeight)]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameOpenCVHaar, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0),\n                      int(round(frameHeight / 150)), 4)\n    return frameOpenCVHaar, bboxes\n```\n\n* ### 基于DNN的人脸检测\n在OpenCV3.3版本发布中把DNN模块从扩展模块移到了OpenCV正式发布模块中，OpenCV做了近一步扩展支持所有主流的深度学习框架训练生成与导出模型数据加载。 \n``` python \ndef detectFaceOpenCVDnn(net, frame):\n    frameOpencvDnn = frame.copy()\n    frameHeight = frameOpencvDnn.shape[0]\n    frameWidth = frameOpencvDnn.shape[1]\n    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], False, False)\n\n    net.setInput(blob)\n    detections = net.forward()\n    bboxes = []\n    for i in range(detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n        if confidence > conf_threshold:\n            x1 = int(detections[0, 0, i, 3] * frameWidth)\n            y1 = int(detections[0, 0, i, 4] * frameHeight)\n            x2 = int(detections[0, 0, i, 5] * frameWidth)\n            y2 = int(detections[0, 0, i, 6] * frameHeight)\n            bboxes.append([x1, y1, x2, y2])\n            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n    return frameOpencvDnn, bboxes\n```\nopenCV人脸检测的实例中，DNN模块支持两个框架的模型：   \n若为caffe模型，则使用readNetFromCaffe，需要用到.prototxt格式的配置文件和.caffemodel格式的模型文件；  \n``` python\n# 1. FP16 version of the original caffe implementation ( 5.4 MB )\nmodelFile = \"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\nconfigFile = \"models/deploy.prototxt\"\nnet = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n```\n若为tensorflow模型，则使用readNetFromTensorflow，需要用到.pbtxt格式的配置文件和.pb格式的模型文件。\n``` python\n# 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )\nmodelFile = \"models/opencv_face_detector_uint8.pb\"\nconfigFile = \"models/opencv_face_detector.pbtxt\"\nnet = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n```\n\n### Dlib库\nDlib 是一个十分优秀好用的机器学习库，其源码均由 C++ 实现，并提供了 Python 接口，可广泛适用于很多场景。  \n> * dlib C++ Library  \n> http://dlib.net/ \n\n* ### 基于HOG特征和线性分类器的人脸检测\n采用经典的HOG(Histogram of Oriented Gradients)特征结合线性分类器、图像金字塔(image pyramid)及滑窗检测机制(sliding window detection scheme)实现的人脸检测器。\n``` python\nhogFaceDetector = dlib.get_frontal_face_detector()\n\ndef detectFaceDlibHog(detector, frame, inHeight=300, inWidth=0):\n\n    frameDlibHog = frame.copy()\n    frameHeight = frameDlibHog.shape[0]\n    frameWidth = frameDlibHog.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight)*inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameDlibHogSmall = cv2.resize(frameDlibHog, (inWidth, inHeight))\n\n    frameDlibHogSmall = cv2.cvtColor(frameDlibHogSmall, cv2.COLOR_BGR2RGB)\n    faceRects = detector(frameDlibHogSmall, 0)\n    print(frameWidth, frameHeight, inWidth, inHeight)\n    bboxes = []\n    for faceRect in faceRects:\n\n        cvRect = [int(faceRect.left()*scaleWidth), int(faceRect.top()*scaleHeight),\n                  int(faceRect.right()*scaleWidth), int(faceRect.bottom()*scaleHeight) ]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameDlibHog, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n    return frameDlibHog, bboxes\n```\n\n* ### 基于CNN的人脸检测\n采用预训练的CNN模型进行图片中的人脸检测。  \n基于CNN模型比基于HOG特征模型的人脸检测准确度更高，但是需要更多的计算资源，即在GPU上运行才可有较好的运行速率。\n\n``` python\ndnnFaceDetector = dlib.cnn_face_detection_model_v1(\"./mmod_human_face_detector.dat\")\n\ndef detectFaceDlibMMOD(detector, frame, inHeight=300, inWidth=0):\n\n    frameDlibMMOD = frame.copy()\n    frameHeight = frameDlibMMOD.shape[0]\n    frameWidth = frameDlibMMOD.shape[1]\n    if not inWidth:\n        inWidth = int((frameWidth / frameHeight)*inHeight)\n\n    scaleHeight = frameHeight / inHeight\n    scaleWidth = frameWidth / inWidth\n\n    frameDlibMMODSmall = cv2.resize(frameDlibMMOD, (inWidth, inHeight))\n\n    frameDlibMMODSmall = cv2.cvtColor(frameDlibMMODSmall, cv2.COLOR_BGR2RGB)\n    faceRects = detector(frameDlibMMODSmall, 0)\n\n    print(frameWidth, frameHeight, inWidth, inHeight)\n    bboxes = []\n    for faceRect in faceRects:\n        cvRect = [int(faceRect.rect.left()*scaleWidth), int(faceRect.rect.top()*scaleHeight),\n                  int(faceRect.rect.right()*scaleWidth), int(faceRect.rect.bottom()*scaleHeight) ]\n        bboxes.append(cvRect)\n        cv2.rectangle(frameDlibMMOD, (cvRect[0], cvRect[1]), (cvRect[2], cvRect[3]), (0, 255, 0), int(round(frameHeight/150)), 4)\n    return frameDlibMMOD, bboxes\n```\n\n\n\n## 参考\n* Face Detection - OpenCV, Dlib and Deep Learning | Learn OpenCV  \nhttps://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\n\n\n\n\n\n\n\n\n\n","slug":"门禁人脸检测和识别","published":1,"updated":"2019-06-28T02:25:25.883Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm75g001wrsvjjv7m7b84","content":"<p><strong> 门禁人脸检测和识别：</strong> <excerpt in index | 首页摘要><br><img src=\"/2019/06/25/门禁人脸检测和识别/demo.gif\"></excerpt></p>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n<h2 id=\"人脸检测\"><a href=\"#人脸检测\" class=\"headerlink\" title=\"人脸检测\"></a>人脸检测</h2><h3 id=\"OpenCV库\"><a href=\"#OpenCV库\" class=\"headerlink\" title=\"OpenCV库\"></a>OpenCV库</h3><ul>\n<li><h3 id=\"基于haar特征和adaboost分类器的人脸检测\"><a href=\"#基于haar特征和adaboost分类器的人脸检测\" class=\"headerlink\" title=\"基于haar特征和adaboost分类器的人脸检测\"></a>基于haar特征和adaboost分类器的人脸检测</h3><p>Haar分类器 = Haar-like特征 + 积分图方法 + AdaBoost +级联；<br>Haar分类器算法的要点如下：<br>①　使用Haar-like特征做检测。<br>②　使用积分图（Integral Image）对Haar-like特征求值进行加速。<br>③　使用AdaBoost算法训练区分人脸和非人脸的强分类器。<br>④　使用筛选式级联把强分类器级联到一起，提高准确率。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">faceCascade = cv2.CascadeClassifier(<span class=\"string\">'./haarcascade_frontalface_default.xml'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceOpenCVHaar</span><span class=\"params\">(faceCascade, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">    frameOpenCVHaar = frame.copy()</span><br><span class=\"line\">    frameHeight = frameOpenCVHaar.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameOpenCVHaar.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight) * inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameOpenCVHaarSmall = cv2.resize(frameOpenCVHaar, (inWidth, inHeight))</span><br><span class=\"line\">    frameGray = cv2.cvtColor(frameOpenCVHaarSmall, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">    faces = faceCascade.detectMultiScale(frameGray)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">        x1 = x</span><br><span class=\"line\">        y1 = y</span><br><span class=\"line\">        x2 = x + w</span><br><span class=\"line\">        y2 = y + h</span><br><span class=\"line\">        cvRect = [int(x1 * scaleWidth), int(y1 * scaleHeight),</span><br><span class=\"line\">                  int(x2 * scaleWidth), int(y2 * scaleHeight)]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameOpenCVHaar, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>),</span><br><span class=\"line\">                      int(round(frameHeight / <span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameOpenCVHaar, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n<li><h3 id=\"基于DNN的人脸检测\"><a href=\"#基于DNN的人脸检测\" class=\"headerlink\" title=\"基于DNN的人脸检测\"></a>基于DNN的人脸检测</h3><p>在OpenCV3.3版本发布中把DNN模块从扩展模块移到了OpenCV正式发布模块中，OpenCV做了近一步扩展支持所有主流的深度学习框架训练生成与导出模型数据加载。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceOpenCVDnn</span><span class=\"params\">(net, frame)</span>:</span></span><br><span class=\"line\">    frameOpencvDnn = frame.copy()</span><br><span class=\"line\">    frameHeight = frameOpencvDnn.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameOpencvDnn.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    blob = cv2.dnn.blobFromImage(frameOpencvDnn, <span class=\"number\">1.0</span>, (<span class=\"number\">300</span>, <span class=\"number\">300</span>), [<span class=\"number\">104</span>, <span class=\"number\">117</span>, <span class=\"number\">123</span>], <span class=\"literal\">False</span>, <span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    net.setInput(blob)</span><br><span class=\"line\">    detections = net.forward()</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(detections.shape[<span class=\"number\">2</span>]):</span><br><span class=\"line\">        confidence = detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">2</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> confidence &gt; conf_threshold:</span><br><span class=\"line\">            x1 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">3</span>] * frameWidth)</span><br><span class=\"line\">            y1 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">4</span>] * frameHeight)</span><br><span class=\"line\">            x2 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">5</span>] * frameWidth)</span><br><span class=\"line\">            y2 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">6</span>] * frameHeight)</span><br><span class=\"line\">            bboxes.append([x1, y1, x2, y2])</span><br><span class=\"line\">            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">8</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameOpencvDnn, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>openCV人脸检测的实例中，DNN模块支持两个框架的模型：<br>若为caffe模型，则使用readNetFromCaffe，需要用到.prototxt格式的配置文件和.caffemodel格式的模型文件；<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. FP16 version of the original caffe implementation ( 5.4 MB )</span></span><br><span class=\"line\">modelFile = <span class=\"string\">\"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"</span></span><br><span class=\"line\">configFile = <span class=\"string\">\"models/deploy.prototxt\"</span></span><br><span class=\"line\">net = cv2.dnn.readNetFromCaffe(configFile, modelFile)</span><br></pre></td></tr></table></figure></p>\n<p>若为tensorflow模型，则使用readNetFromTensorflow，需要用到.pbtxt格式的配置文件和.pb格式的模型文件。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )</span></span><br><span class=\"line\">modelFile = <span class=\"string\">\"models/opencv_face_detector_uint8.pb\"</span></span><br><span class=\"line\">configFile = <span class=\"string\">\"models/opencv_face_detector.pbtxt\"</span></span><br><span class=\"line\">net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Dlib库\"><a href=\"#Dlib库\" class=\"headerlink\" title=\"Dlib库\"></a>Dlib库</h3><p>Dlib 是一个十分优秀好用的机器学习库，其源码均由 C++ 实现，并提供了 Python 接口，可广泛适用于很多场景。  </p>\n<blockquote>\n<ul>\n<li>dlib C++ Library<br><a href=\"http://dlib.net/\" target=\"_blank\" rel=\"noopener\">http://dlib.net/</a> </li>\n</ul>\n</blockquote>\n<ul>\n<li><h3 id=\"基于HOG特征和线性分类器的人脸检测\"><a href=\"#基于HOG特征和线性分类器的人脸检测\" class=\"headerlink\" title=\"基于HOG特征和线性分类器的人脸检测\"></a>基于HOG特征和线性分类器的人脸检测</h3><p>采用经典的HOG(Histogram of Oriented Gradients)特征结合线性分类器、图像金字塔(image pyramid)及滑窗检测机制(sliding window detection scheme)实现的人脸检测器。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hogFaceDetector = dlib.get_frontal_face_detector()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceDlibHog</span><span class=\"params\">(detector, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHog = frame.copy()</span><br><span class=\"line\">    frameHeight = frameDlibHog.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameDlibHog.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight)*inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHogSmall = cv2.resize(frameDlibHog, (inWidth, inHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHogSmall = cv2.cvtColor(frameDlibHogSmall, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    faceRects = detector(frameDlibHogSmall, <span class=\"number\">0</span>)</span><br><span class=\"line\">    print(frameWidth, frameHeight, inWidth, inHeight)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> faceRect <span class=\"keyword\">in</span> faceRects:</span><br><span class=\"line\"></span><br><span class=\"line\">        cvRect = [int(faceRect.left()*scaleWidth), int(faceRect.top()*scaleHeight),</span><br><span class=\"line\">                  int(faceRect.right()*scaleWidth), int(faceRect.bottom()*scaleHeight) ]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameDlibHog, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameDlibHog, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n<li><h3 id=\"基于CNN的人脸检测\"><a href=\"#基于CNN的人脸检测\" class=\"headerlink\" title=\"基于CNN的人脸检测\"></a>基于CNN的人脸检测</h3><p>采用预训练的CNN模型进行图片中的人脸检测。<br>基于CNN模型比基于HOG特征模型的人脸检测准确度更高，但是需要更多的计算资源，即在GPU上运行才可有较好的运行速率。</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnnFaceDetector = dlib.cnn_face_detection_model_v1(<span class=\"string\">\"./mmod_human_face_detector.dat\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceDlibMMOD</span><span class=\"params\">(detector, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMOD = frame.copy()</span><br><span class=\"line\">    frameHeight = frameDlibMMOD.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameDlibMMOD.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight)*inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMODSmall = cv2.resize(frameDlibMMOD, (inWidth, inHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMODSmall = cv2.cvtColor(frameDlibMMODSmall, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    faceRects = detector(frameDlibMMODSmall, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(frameWidth, frameHeight, inWidth, inHeight)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> faceRect <span class=\"keyword\">in</span> faceRects:</span><br><span class=\"line\">        cvRect = [int(faceRect.rect.left()*scaleWidth), int(faceRect.rect.top()*scaleHeight),</span><br><span class=\"line\">                  int(faceRect.rect.right()*scaleWidth), int(faceRect.rect.bottom()*scaleHeight) ]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameDlibMMOD, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameDlibMMOD, bboxes</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>Face Detection - OpenCV, Dlib and Deep Learning | Learn OpenCV<br><a href=\"https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 门禁人脸检测和识别：</strong> <excerpt in index | 首页摘要><br><img src=\"/2019/06/25/门禁人脸检测和识别/demo.gif\"></excerpt></p>","more":"<the rest of contents | 余下全文>\n\n\n<h2 id=\"人脸检测\"><a href=\"#人脸检测\" class=\"headerlink\" title=\"人脸检测\"></a>人脸检测</h2><h3 id=\"OpenCV库\"><a href=\"#OpenCV库\" class=\"headerlink\" title=\"OpenCV库\"></a>OpenCV库</h3><ul>\n<li><h3 id=\"基于haar特征和adaboost分类器的人脸检测\"><a href=\"#基于haar特征和adaboost分类器的人脸检测\" class=\"headerlink\" title=\"基于haar特征和adaboost分类器的人脸检测\"></a>基于haar特征和adaboost分类器的人脸检测</h3><p>Haar分类器 = Haar-like特征 + 积分图方法 + AdaBoost +级联；<br>Haar分类器算法的要点如下：<br>①　使用Haar-like特征做检测。<br>②　使用积分图（Integral Image）对Haar-like特征求值进行加速。<br>③　使用AdaBoost算法训练区分人脸和非人脸的强分类器。<br>④　使用筛选式级联把强分类器级联到一起，提高准确率。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">faceCascade = cv2.CascadeClassifier(<span class=\"string\">'./haarcascade_frontalface_default.xml'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceOpenCVHaar</span><span class=\"params\">(faceCascade, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\">    frameOpenCVHaar = frame.copy()</span><br><span class=\"line\">    frameHeight = frameOpenCVHaar.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameOpenCVHaar.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight) * inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameOpenCVHaarSmall = cv2.resize(frameOpenCVHaar, (inWidth, inHeight))</span><br><span class=\"line\">    frameGray = cv2.cvtColor(frameOpenCVHaarSmall, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">    faces = faceCascade.detectMultiScale(frameGray)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> (x, y, w, h) <span class=\"keyword\">in</span> faces:</span><br><span class=\"line\">        x1 = x</span><br><span class=\"line\">        y1 = y</span><br><span class=\"line\">        x2 = x + w</span><br><span class=\"line\">        y2 = y + h</span><br><span class=\"line\">        cvRect = [int(x1 * scaleWidth), int(y1 * scaleHeight),</span><br><span class=\"line\">                  int(x2 * scaleWidth), int(y2 * scaleHeight)]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameOpenCVHaar, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>),</span><br><span class=\"line\">                      int(round(frameHeight / <span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameOpenCVHaar, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n<li><h3 id=\"基于DNN的人脸检测\"><a href=\"#基于DNN的人脸检测\" class=\"headerlink\" title=\"基于DNN的人脸检测\"></a>基于DNN的人脸检测</h3><p>在OpenCV3.3版本发布中把DNN模块从扩展模块移到了OpenCV正式发布模块中，OpenCV做了近一步扩展支持所有主流的深度学习框架训练生成与导出模型数据加载。 </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceOpenCVDnn</span><span class=\"params\">(net, frame)</span>:</span></span><br><span class=\"line\">    frameOpencvDnn = frame.copy()</span><br><span class=\"line\">    frameHeight = frameOpencvDnn.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameOpencvDnn.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    blob = cv2.dnn.blobFromImage(frameOpencvDnn, <span class=\"number\">1.0</span>, (<span class=\"number\">300</span>, <span class=\"number\">300</span>), [<span class=\"number\">104</span>, <span class=\"number\">117</span>, <span class=\"number\">123</span>], <span class=\"literal\">False</span>, <span class=\"literal\">False</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    net.setInput(blob)</span><br><span class=\"line\">    detections = net.forward()</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(detections.shape[<span class=\"number\">2</span>]):</span><br><span class=\"line\">        confidence = detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">2</span>]</span><br><span class=\"line\">        <span class=\"keyword\">if</span> confidence &gt; conf_threshold:</span><br><span class=\"line\">            x1 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">3</span>] * frameWidth)</span><br><span class=\"line\">            y1 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">4</span>] * frameHeight)</span><br><span class=\"line\">            x2 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">5</span>] * frameWidth)</span><br><span class=\"line\">            y2 = int(detections[<span class=\"number\">0</span>, <span class=\"number\">0</span>, i, <span class=\"number\">6</span>] * frameHeight)</span><br><span class=\"line\">            bboxes.append([x1, y1, x2, y2])</span><br><span class=\"line\">            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">8</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameOpencvDnn, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>openCV人脸检测的实例中，DNN模块支持两个框架的模型：<br>若为caffe模型，则使用readNetFromCaffe，需要用到.prototxt格式的配置文件和.caffemodel格式的模型文件；<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 1. FP16 version of the original caffe implementation ( 5.4 MB )</span></span><br><span class=\"line\">modelFile = <span class=\"string\">\"models/res10_300x300_ssd_iter_140000_fp16.caffemodel\"</span></span><br><span class=\"line\">configFile = <span class=\"string\">\"models/deploy.prototxt\"</span></span><br><span class=\"line\">net = cv2.dnn.readNetFromCaffe(configFile, modelFile)</span><br></pre></td></tr></table></figure></p>\n<p>若为tensorflow模型，则使用readNetFromTensorflow，需要用到.pbtxt格式的配置文件和.pb格式的模型文件。<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 2. 8 bit Quantized version using Tensorflow ( 2.7 MB )</span></span><br><span class=\"line\">modelFile = <span class=\"string\">\"models/opencv_face_detector_uint8.pb\"</span></span><br><span class=\"line\">configFile = <span class=\"string\">\"models/opencv_face_detector.pbtxt\"</span></span><br><span class=\"line\">net = cv2.dnn.readNetFromTensorflow(modelFile, configFile)</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"Dlib库\"><a href=\"#Dlib库\" class=\"headerlink\" title=\"Dlib库\"></a>Dlib库</h3><p>Dlib 是一个十分优秀好用的机器学习库，其源码均由 C++ 实现，并提供了 Python 接口，可广泛适用于很多场景。  </p>\n<blockquote>\n<ul>\n<li>dlib C++ Library<br><a href=\"http://dlib.net/\" target=\"_blank\" rel=\"noopener\">http://dlib.net/</a> </li>\n</ul>\n</blockquote>\n<ul>\n<li><h3 id=\"基于HOG特征和线性分类器的人脸检测\"><a href=\"#基于HOG特征和线性分类器的人脸检测\" class=\"headerlink\" title=\"基于HOG特征和线性分类器的人脸检测\"></a>基于HOG特征和线性分类器的人脸检测</h3><p>采用经典的HOG(Histogram of Oriented Gradients)特征结合线性分类器、图像金字塔(image pyramid)及滑窗检测机制(sliding window detection scheme)实现的人脸检测器。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">hogFaceDetector = dlib.get_frontal_face_detector()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceDlibHog</span><span class=\"params\">(detector, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHog = frame.copy()</span><br><span class=\"line\">    frameHeight = frameDlibHog.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameDlibHog.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight)*inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHogSmall = cv2.resize(frameDlibHog, (inWidth, inHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibHogSmall = cv2.cvtColor(frameDlibHogSmall, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    faceRects = detector(frameDlibHogSmall, <span class=\"number\">0</span>)</span><br><span class=\"line\">    print(frameWidth, frameHeight, inWidth, inHeight)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> faceRect <span class=\"keyword\">in</span> faceRects:</span><br><span class=\"line\"></span><br><span class=\"line\">        cvRect = [int(faceRect.left()*scaleWidth), int(faceRect.top()*scaleHeight),</span><br><span class=\"line\">                  int(faceRect.right()*scaleWidth), int(faceRect.bottom()*scaleHeight) ]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameDlibHog, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameDlibHog, bboxes</span><br></pre></td></tr></table></figure>\n</li>\n<li><h3 id=\"基于CNN的人脸检测\"><a href=\"#基于CNN的人脸检测\" class=\"headerlink\" title=\"基于CNN的人脸检测\"></a>基于CNN的人脸检测</h3><p>采用预训练的CNN模型进行图片中的人脸检测。<br>基于CNN模型比基于HOG特征模型的人脸检测准确度更高，但是需要更多的计算资源，即在GPU上运行才可有较好的运行速率。</p>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dnnFaceDetector = dlib.cnn_face_detection_model_v1(<span class=\"string\">\"./mmod_human_face_detector.dat\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">detectFaceDlibMMOD</span><span class=\"params\">(detector, frame, inHeight=<span class=\"number\">300</span>, inWidth=<span class=\"number\">0</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMOD = frame.copy()</span><br><span class=\"line\">    frameHeight = frameDlibMMOD.shape[<span class=\"number\">0</span>]</span><br><span class=\"line\">    frameWidth = frameDlibMMOD.shape[<span class=\"number\">1</span>]</span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> inWidth:</span><br><span class=\"line\">        inWidth = int((frameWidth / frameHeight)*inHeight)</span><br><span class=\"line\"></span><br><span class=\"line\">    scaleHeight = frameHeight / inHeight</span><br><span class=\"line\">    scaleWidth = frameWidth / inWidth</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMODSmall = cv2.resize(frameDlibMMOD, (inWidth, inHeight))</span><br><span class=\"line\"></span><br><span class=\"line\">    frameDlibMMODSmall = cv2.cvtColor(frameDlibMMODSmall, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">    faceRects = detector(frameDlibMMODSmall, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    print(frameWidth, frameHeight, inWidth, inHeight)</span><br><span class=\"line\">    bboxes = []</span><br><span class=\"line\">    <span class=\"keyword\">for</span> faceRect <span class=\"keyword\">in</span> faceRects:</span><br><span class=\"line\">        cvRect = [int(faceRect.rect.left()*scaleWidth), int(faceRect.rect.top()*scaleHeight),</span><br><span class=\"line\">                  int(faceRect.rect.right()*scaleWidth), int(faceRect.rect.bottom()*scaleHeight) ]</span><br><span class=\"line\">        bboxes.append(cvRect)</span><br><span class=\"line\">        cv2.rectangle(frameDlibMMOD, (cvRect[<span class=\"number\">0</span>], cvRect[<span class=\"number\">1</span>]), (cvRect[<span class=\"number\">2</span>], cvRect[<span class=\"number\">3</span>]), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">0</span>), int(round(frameHeight/<span class=\"number\">150</span>)), <span class=\"number\">4</span>)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> frameDlibMMOD, bboxes</span><br></pre></td></tr></table></figure>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><ul>\n<li>Face Detection - OpenCV, Dlib and Deep Learning | Learn OpenCV<br><a href=\"https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/face-detection-opencv-dlib-and-deep-learning-c-python/</a></li>\n</ul>\n</the>"},{"title":"OpenCV学习笔记二：图像处理","date":"2019-06-22T13:58:29.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要> \n\n粗略搬运，仅作个人笔记参考，有时间再美化，搬运自\n* [OpenCV-Python] OpenCV 中的图像处理 部分 IV (一) - _Undo - 博客园  \nhttps://www.cnblogs.com/Undo-self-blog/p/8434906.html \n\n颜色空间转化  \n图像平滑  \n形态学转换\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 颜色空间转化\n* cv2.cvtColor()\n* cv2.inRange() \n\ncv2.cvtColor(input_image ，flag)，其中 flag就是转换类型。  \n对于 BGR↔Gray 的转换，我们要使用的 flag 就是 cv2.COLOR_BGR2GRAY。  \n同样对于 BGR↔HSV 的转换，我们用的 flag 就是 cv2.COLOR_BGR2HSV。  \n\n\n## 几何变换\n* cv2.warpAffine\n* cv2.warpPerspective\n* cv2.getPerspectiveTransform\n\n### 扩展缩放\n* cv2.resize()\n\n### 平移\n### 旋转\n### 仿射变换\n### 透视变换\n\n\n```python\nimport cv2\nimport numpy as np\nimg=cv2.imread('./images/lena.jpg')\n# 下面的 None 本应该是输出图像的尺寸，但是因为后边我们设置了缩放因子\n# 因此这里为 None\nres=cv2.resize(img,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n#OR\n# 这里呢，我们直接设置输出图像的尺寸，所以不用设置缩放因子\nheight,width=img.shape[:2]\nres=cv2.resize(img,(2*width,2*height),interpolation=cv2.INTER_CUBIC)\nwhile(1):\n    cv2.imshow('res',res)\n    cv2.imshow('img',img)\n    if cv2.waitKey(1) & 0xFF == 27:\n        break\ncv2.destroyAllWindows()\n# Resize(src, dst, interpolation=CV_INTER_LINEAR)\n\n```\n\n## 图像平滑\n\n### 2D卷积\nOpenCV 提供的函数 cv.filter2D() 可以让我们对一幅图像进行卷积操作。下面我们将对一幅图像使用平均滤波器。下面是一个 5x5 的平均滤波器核：\n$$K=\\frac{1}{25}\\left[\\begin{array}{ccccc}{1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1}\\end{array}\\right]$$\n操作如下：将核放在图像的一个像素 A 上，求与核对应的图像上 25（5x5）个像素的和，在取平均数，用这个平均数替代像素 A 的值。重复以上操作直到将图像的每一个像素值都更新一边。代码如下:  \n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nkernel = np.ones((5,5),np.float32)/25\ndst = cv2.filter2D(img, -1, kernel)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(dst),plt.title('Averaging')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_4_0.png)\n\n\n### 图像模糊（图像平滑）\n使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。OpenCV 提供了四种模糊技术。  \n\n### 平均\n　　这是由一个归一化卷积框完成的。他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完这个任务。可以同看查看文档了解更多卷积框的细节。我们需要设定卷积框的宽和高。下面是一个 3x3 的归一化卷积框：\n　　　　　$$　K =  \\frac{1}{9} \\begin{bmatrix} 1 & 1 & 1  \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$$\n注意：如果你不想使用归一化卷积框，你应该使用 cv2.boxFilter()，这时要传入参数 normalize=False。\n下面与第一部分一样的一个例子：\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\nblur = cv2.blur(img,(5,5))\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_6_0.png)\n\n\n### 高斯模糊\n　　现在把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。我们需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X，Y 方向的标准差。如果我们只指定了 X 方向的的标准差，Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音。\n如果你愿意的话，你也可以使用函数 cv2.getGaussianKernel() 自己构建一个高斯核。\n如果要使用高斯模糊的话，上边的代码应该写成：\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\n#0 是指根据窗口大小（ 5,5 ）来计算高斯函数标准差\nblur = cv2.GaussianBlur(img,(5,5),0)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_8_0.png)\n\n\n### 中值模糊\n顾名思义就是用与卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围（也可以使他本身）的值来取代他。他能有效的去除噪声。卷积核的大小也应该是一个奇数。\n在这个例子中，我们给原始图像加上 50% 的噪声然后再使用中值模糊。\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\nmedian = cv2.medianBlur(img,5)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_10_0.png)\n\n\n### 双边滤波\n\n函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音。但是这种操作与其他滤波器相比会比较慢。我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界。因此边界也会别模糊掉，而这正不是我们想要。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大。\n\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n#cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)\n#d – Diameter of each pixel neighborhood that is used during filtering.\n# If it is non-positive, it is computed from sigmaSpace\n#9 邻域直径，两个 75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差\nblur = cv2.bilateralFilter(img,9,75,75)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_12_0.png)\n\n\n## 形态学转换\n形态学操作是根据图像形状进行的简单操作。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等。\n\n\n### 腐蚀\n\n就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。这是怎么做到的呢？卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。  \n这会产生什么影响呢？根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等。\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/j.png', 1)\nkernel = np.ones((5,5),np.uint8)\nerosion = cv2.erode(img,kernel,iterations = 1)\n\nplt.imshow(erosion)\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_15_0.png)\n\n\n### 膨胀\n\n与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体。\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/j.png', 1)\nkernel = np.ones((5,5),np.uint8)\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\nplt.imshow(dilation)\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_17_0.png)\n\n\n### 开运算\n先进性腐蚀再进行膨胀就叫做开运算。就像我们上面介绍的那样，它被用来去除噪声。这里我们用到的函数是 cv2.morphologyEx()。\n\n### 闭运算\n先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。\n\n### 形态学梯度\n其实就是一幅图像膨胀与腐蚀的差别。结果看上去就像前景物体的轮廓。\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/OpenCV学习笔记二：图像处理.md","raw":"---\ntitle: OpenCV学习笔记二：图像处理\ndate: 2019-06-22 21:58:29\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要> \n\n粗略搬运，仅作个人笔记参考，有时间再美化，搬运自\n* [OpenCV-Python] OpenCV 中的图像处理 部分 IV (一) - _Undo - 博客园  \nhttps://www.cnblogs.com/Undo-self-blog/p/8434906.html \n\n颜色空间转化  \n图像平滑  \n形态学转换\n<!-- more -->\n<The rest of contents | 余下全文>\n\n## 颜色空间转化\n* cv2.cvtColor()\n* cv2.inRange() \n\ncv2.cvtColor(input_image ，flag)，其中 flag就是转换类型。  \n对于 BGR↔Gray 的转换，我们要使用的 flag 就是 cv2.COLOR_BGR2GRAY。  \n同样对于 BGR↔HSV 的转换，我们用的 flag 就是 cv2.COLOR_BGR2HSV。  \n\n\n## 几何变换\n* cv2.warpAffine\n* cv2.warpPerspective\n* cv2.getPerspectiveTransform\n\n### 扩展缩放\n* cv2.resize()\n\n### 平移\n### 旋转\n### 仿射变换\n### 透视变换\n\n\n```python\nimport cv2\nimport numpy as np\nimg=cv2.imread('./images/lena.jpg')\n# 下面的 None 本应该是输出图像的尺寸，但是因为后边我们设置了缩放因子\n# 因此这里为 None\nres=cv2.resize(img,None,fx=2,fy=2,interpolation=cv2.INTER_CUBIC)\n#OR\n# 这里呢，我们直接设置输出图像的尺寸，所以不用设置缩放因子\nheight,width=img.shape[:2]\nres=cv2.resize(img,(2*width,2*height),interpolation=cv2.INTER_CUBIC)\nwhile(1):\n    cv2.imshow('res',res)\n    cv2.imshow('img',img)\n    if cv2.waitKey(1) & 0xFF == 27:\n        break\ncv2.destroyAllWindows()\n# Resize(src, dst, interpolation=CV_INTER_LINEAR)\n\n```\n\n## 图像平滑\n\n### 2D卷积\nOpenCV 提供的函数 cv.filter2D() 可以让我们对一幅图像进行卷积操作。下面我们将对一幅图像使用平均滤波器。下面是一个 5x5 的平均滤波器核：\n$$K=\\frac{1}{25}\\left[\\begin{array}{ccccc}{1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1}\\end{array}\\right]$$\n操作如下：将核放在图像的一个像素 A 上，求与核对应的图像上 25（5x5）个像素的和，在取平均数，用这个平均数替代像素 A 的值。重复以上操作直到将图像的每一个像素值都更新一边。代码如下:  \n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nkernel = np.ones((5,5),np.float32)/25\ndst = cv2.filter2D(img, -1, kernel)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(dst),plt.title('Averaging')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_4_0.png)\n\n\n### 图像模糊（图像平滑）\n使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。OpenCV 提供了四种模糊技术。  \n\n### 平均\n　　这是由一个归一化卷积框完成的。他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完这个任务。可以同看查看文档了解更多卷积框的细节。我们需要设定卷积框的宽和高。下面是一个 3x3 的归一化卷积框：\n　　　　　$$　K =  \\frac{1}{9} \\begin{bmatrix} 1 & 1 & 1  \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}$$\n注意：如果你不想使用归一化卷积框，你应该使用 cv2.boxFilter()，这时要传入参数 normalize=False。\n下面与第一部分一样的一个例子：\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\nblur = cv2.blur(img,(5,5))\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_6_0.png)\n\n\n### 高斯模糊\n　　现在把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。我们需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X，Y 方向的标准差。如果我们只指定了 X 方向的的标准差，Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音。\n如果你愿意的话，你也可以使用函数 cv2.getGaussianKernel() 自己构建一个高斯核。\n如果要使用高斯模糊的话，上边的代码应该写成：\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\n#0 是指根据窗口大小（ 5,5 ）来计算高斯函数标准差\nblur = cv2.GaussianBlur(img,(5,5),0)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_8_0.png)\n\n\n### 中值模糊\n顾名思义就是用与卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围（也可以使他本身）的值来取代他。他能有效的去除噪声。卷积核的大小也应该是一个奇数。\n在这个例子中，我们给原始图像加上 50% 的噪声然后再使用中值模糊。\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\n\nmedian = cv2.medianBlur(img,5)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_10_0.png)\n\n\n### 双边滤波\n\n函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音。但是这种操作与其他滤波器相比会比较慢。我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界。因此边界也会别模糊掉，而这正不是我们想要。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大。\n\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/opencv-logo.png')\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n#cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)\n#d – Diameter of each pixel neighborhood that is used during filtering.\n# If it is non-positive, it is computed from sigmaSpace\n#9 邻域直径，两个 75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差\nblur = cv2.bilateralFilter(img,9,75,75)\n\nplt.subplot(121),plt.imshow(img),plt.title('Original')\nplt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(blur),plt.title('Blurred')\nplt.xticks([]), plt.yticks([])\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_12_0.png)\n\n\n## 形态学转换\n形态学操作是根据图像形状进行的简单操作。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等。\n\n\n### 腐蚀\n\n就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。这是怎么做到的呢？卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。  \n这会产生什么影响呢？根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等。\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/j.png', 1)\nkernel = np.ones((5,5),np.uint8)\nerosion = cv2.erode(img,kernel,iterations = 1)\n\nplt.imshow(erosion)\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_15_0.png)\n\n\n### 膨胀\n\n与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体。\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\nimg = cv2.imread('./images/j.png', 1)\nkernel = np.ones((5,5),np.uint8)\ndilation = cv2.dilate(img,kernel,iterations = 1)\n\nplt.imshow(dilation)\nplt.show()\n```\n\n\n![png](./OpenCV学习笔记二：图像处理/output_17_0.png)\n\n\n### 开运算\n先进性腐蚀再进行膨胀就叫做开运算。就像我们上面介绍的那样，它被用来去除噪声。这里我们用到的函数是 cv2.morphologyEx()。\n\n### 闭运算\n先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。\n\n### 形态学梯度\n其实就是一幅图像膨胀与腐蚀的差别。结果看上去就像前景物体的轮廓。\n\n\n\n\n\n\n\n\n\n\n","slug":"OpenCV学习笔记二：图像处理","published":1,"updated":"2019-06-23T07:09:39.749Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76b003wrsvj1c45f9up","content":"<p><strong> OpenCV学习笔记二：图像处理：</strong> <excerpt in index | 首页摘要> </excerpt></p>\n<p>粗略搬运，仅作个人笔记参考，有时间再美化，搬运自</p>\n<ul>\n<li>[OpenCV-Python] OpenCV 中的图像处理 部分 IV (一) - _Undo - 博客园<br><a href=\"https://www.cnblogs.com/Undo-self-blog/p/8434906.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Undo-self-blog/p/8434906.html</a> </li>\n</ul>\n<p>颜色空间转化<br>图像平滑<br>形态学转换<br><a id=\"more\"></a></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"颜色空间转化\"><a href=\"#颜色空间转化\" class=\"headerlink\" title=\"颜色空间转化\"></a>颜色空间转化</h2><ul>\n<li>cv2.cvtColor()</li>\n<li>cv2.inRange() </li>\n</ul>\n<p>cv2.cvtColor(input_image ，flag)，其中 flag就是转换类型。<br>对于 BGR↔Gray 的转换，我们要使用的 flag 就是 cv2.COLOR_BGR2GRAY。<br>同样对于 BGR↔HSV 的转换，我们用的 flag 就是 cv2.COLOR_BGR2HSV。  </p>\n<h2 id=\"几何变换\"><a href=\"#几何变换\" class=\"headerlink\" title=\"几何变换\"></a>几何变换</h2><ul>\n<li>cv2.warpAffine</li>\n<li>cv2.warpPerspective</li>\n<li>cv2.getPerspectiveTransform</li>\n</ul>\n<h3 id=\"扩展缩放\"><a href=\"#扩展缩放\" class=\"headerlink\" title=\"扩展缩放\"></a>扩展缩放</h3><ul>\n<li>cv2.resize()</li>\n</ul>\n<h3 id=\"平移\"><a href=\"#平移\" class=\"headerlink\" title=\"平移\"></a>平移</h3><h3 id=\"旋转\"><a href=\"#旋转\" class=\"headerlink\" title=\"旋转\"></a>旋转</h3><h3 id=\"仿射变换\"><a href=\"#仿射变换\" class=\"headerlink\" title=\"仿射变换\"></a>仿射变换</h3><h3 id=\"透视变换\"><a href=\"#透视变换\" class=\"headerlink\" title=\"透视变换\"></a>透视变换</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">img=cv2.imread(<span class=\"string\">'./images/lena.jpg'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 下面的 None 本应该是输出图像的尺寸，但是因为后边我们设置了缩放因子</span></span><br><span class=\"line\"><span class=\"comment\"># 因此这里为 None</span></span><br><span class=\"line\">res=cv2.resize(img,<span class=\"literal\">None</span>,fx=<span class=\"number\">2</span>,fy=<span class=\"number\">2</span>,interpolation=cv2.INTER_CUBIC)</span><br><span class=\"line\"><span class=\"comment\">#OR</span></span><br><span class=\"line\"><span class=\"comment\"># 这里呢，我们直接设置输出图像的尺寸，所以不用设置缩放因子</span></span><br><span class=\"line\">height,width=img.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\">res=cv2.resize(img,(<span class=\"number\">2</span>*width,<span class=\"number\">2</span>*height),interpolation=cv2.INTER_CUBIC)</span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"number\">1</span>):</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'res'</span>,res)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'img'</span>,img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) &amp; <span class=\"number\">0xFF</span> == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">cv2.destroyAllWindows()</span><br><span class=\"line\"><span class=\"comment\"># Resize(src, dst, interpolation=CV_INTER_LINEAR)</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"图像平滑\"><a href=\"#图像平滑\" class=\"headerlink\" title=\"图像平滑\"></a>图像平滑</h2><h3 id=\"2D卷积\"><a href=\"#2D卷积\" class=\"headerlink\" title=\"2D卷积\"></a>2D卷积</h3><p>OpenCV 提供的函数 cv.filter2D() 可以让我们对一幅图像进行卷积操作。下面我们将对一幅图像使用平均滤波器。下面是一个 5x5 的平均滤波器核：</p>\n<script type=\"math/tex; mode=display\">K=\\frac{1}{25}\\left[\\begin{array}{ccccc}{1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1}\\end{array}\\right]</script><p>操作如下：将核放在图像的一个像素 A 上，求与核对应的图像上 25（5x5）个像素的和，在取平均数，用这个平均数替代像素 A 的值。重复以上操作直到将图像的每一个像素值都更新一边。代码如下:  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\"></span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.float32)/<span class=\"number\">25</span></span><br><span class=\"line\">dst = cv2.filter2D(img, <span class=\"number\">-1</span>, kernel)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(dst),plt.title(<span class=\"string\">'Averaging'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_4_0.png\" alt=\"png\"></p>\n<h3 id=\"图像模糊（图像平滑）\"><a href=\"#图像模糊（图像平滑）\" class=\"headerlink\" title=\"图像模糊（图像平滑）\"></a>图像模糊（图像平滑）</h3><p>使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。OpenCV 提供了四种模糊技术。  </p>\n<h3 id=\"平均\"><a href=\"#平均\" class=\"headerlink\" title=\"平均\"></a>平均</h3><p>　　这是由一个归一化卷积框完成的。他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完这个任务。可以同看查看文档了解更多卷积框的细节。我们需要设定卷积框的宽和高。下面是一个 3x3 的归一化卷积框：<br>　　　　　<script type=\"math/tex\">K =  \\frac{1}{9} \\begin{bmatrix} 1 & 1 & 1  \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}</script><br>注意：如果你不想使用归一化卷积框，你应该使用 cv2.boxFilter()，这时要传入参数 normalize=False。<br>下面与第一部分一样的一个例子：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">blur = cv2.blur(img,(<span class=\"number\">5</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_6_0.png\" alt=\"png\"></p>\n<h3 id=\"高斯模糊\"><a href=\"#高斯模糊\" class=\"headerlink\" title=\"高斯模糊\"></a>高斯模糊</h3><p>　　现在把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。我们需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X，Y 方向的标准差。如果我们只指定了 X 方向的的标准差，Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音。<br>如果你愿意的话，你也可以使用函数 cv2.getGaussianKernel() 自己构建一个高斯核。<br>如果要使用高斯模糊的话，上边的代码应该写成：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#0 是指根据窗口大小（ 5,5 ）来计算高斯函数标准差</span></span><br><span class=\"line\">blur = cv2.GaussianBlur(img,(<span class=\"number\">5</span>,<span class=\"number\">5</span>),<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_8_0.png\" alt=\"png\"></p>\n<h3 id=\"中值模糊\"><a href=\"#中值模糊\" class=\"headerlink\" title=\"中值模糊\"></a>中值模糊</h3><p>顾名思义就是用与卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围（也可以使他本身）的值来取代他。他能有效的去除噪声。卷积核的大小也应该是一个奇数。<br>在这个例子中，我们给原始图像加上 50% 的噪声然后再使用中值模糊。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">median = cv2.medianBlur(img,<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_10_0.png\" alt=\"png\"></p>\n<h3 id=\"双边滤波\"><a href=\"#双边滤波\" class=\"headerlink\" title=\"双边滤波\"></a>双边滤波</h3><p>函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音。但是这种操作与其他滤波器相比会比较慢。我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界。因此边界也会别模糊掉，而这正不是我们想要。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)</span></span><br><span class=\"line\"><span class=\"comment\">#d – Diameter of each pixel neighborhood that is used during filtering.</span></span><br><span class=\"line\"><span class=\"comment\"># If it is non-positive, it is computed from sigmaSpace</span></span><br><span class=\"line\"><span class=\"comment\">#9 邻域直径，两个 75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差</span></span><br><span class=\"line\">blur = cv2.bilateralFilter(img,<span class=\"number\">9</span>,<span class=\"number\">75</span>,<span class=\"number\">75</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_12_0.png\" alt=\"png\"></p>\n<h2 id=\"形态学转换\"><a href=\"#形态学转换\" class=\"headerlink\" title=\"形态学转换\"></a>形态学转换</h2><p>形态学操作是根据图像形状进行的简单操作。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等。</p>\n<h3 id=\"腐蚀\"><a href=\"#腐蚀\" class=\"headerlink\" title=\"腐蚀\"></a>腐蚀</h3><p>就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。这是怎么做到的呢？卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。<br>这会产生什么影响呢？根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/j.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.uint8)</span><br><span class=\"line\">erosion = cv2.erode(img,kernel,iterations = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(erosion)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_15_0.png\" alt=\"png\"></p>\n<h3 id=\"膨胀\"><a href=\"#膨胀\" class=\"headerlink\" title=\"膨胀\"></a>膨胀</h3><p>与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/j.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.uint8)</span><br><span class=\"line\">dilation = cv2.dilate(img,kernel,iterations = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(dilation)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_17_0.png\" alt=\"png\"></p>\n<h3 id=\"开运算\"><a href=\"#开运算\" class=\"headerlink\" title=\"开运算\"></a>开运算</h3><p>先进性腐蚀再进行膨胀就叫做开运算。就像我们上面介绍的那样，它被用来去除噪声。这里我们用到的函数是 cv2.morphologyEx()。</p>\n<h3 id=\"闭运算\"><a href=\"#闭运算\" class=\"headerlink\" title=\"闭运算\"></a>闭运算</h3><p>先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。</p>\n<h3 id=\"形态学梯度\"><a href=\"#形态学梯度\" class=\"headerlink\" title=\"形态学梯度\"></a>形态学梯度</h3><p>其实就是一幅图像膨胀与腐蚀的差别。结果看上去就像前景物体的轮廓。</p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> OpenCV学习笔记二：图像处理：</strong> <excerpt in index | 首页摘要> </excerpt></p>\n<p>粗略搬运，仅作个人笔记参考，有时间再美化，搬运自</p>\n<ul>\n<li>[OpenCV-Python] OpenCV 中的图像处理 部分 IV (一) - _Undo - 博客园<br><a href=\"https://www.cnblogs.com/Undo-self-blog/p/8434906.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/Undo-self-blog/p/8434906.html</a> </li>\n</ul>\n<p>颜色空间转化<br>图像平滑<br>形态学转换<br></p>","more":"<p></p>\n<the rest of contents | 余下全文>\n\n<h2 id=\"颜色空间转化\"><a href=\"#颜色空间转化\" class=\"headerlink\" title=\"颜色空间转化\"></a>颜色空间转化</h2><ul>\n<li>cv2.cvtColor()</li>\n<li>cv2.inRange() </li>\n</ul>\n<p>cv2.cvtColor(input_image ，flag)，其中 flag就是转换类型。<br>对于 BGR↔Gray 的转换，我们要使用的 flag 就是 cv2.COLOR_BGR2GRAY。<br>同样对于 BGR↔HSV 的转换，我们用的 flag 就是 cv2.COLOR_BGR2HSV。  </p>\n<h2 id=\"几何变换\"><a href=\"#几何变换\" class=\"headerlink\" title=\"几何变换\"></a>几何变换</h2><ul>\n<li>cv2.warpAffine</li>\n<li>cv2.warpPerspective</li>\n<li>cv2.getPerspectiveTransform</li>\n</ul>\n<h3 id=\"扩展缩放\"><a href=\"#扩展缩放\" class=\"headerlink\" title=\"扩展缩放\"></a>扩展缩放</h3><ul>\n<li>cv2.resize()</li>\n</ul>\n<h3 id=\"平移\"><a href=\"#平移\" class=\"headerlink\" title=\"平移\"></a>平移</h3><h3 id=\"旋转\"><a href=\"#旋转\" class=\"headerlink\" title=\"旋转\"></a>旋转</h3><h3 id=\"仿射变换\"><a href=\"#仿射变换\" class=\"headerlink\" title=\"仿射变换\"></a>仿射变换</h3><h3 id=\"透视变换\"><a href=\"#透视变换\" class=\"headerlink\" title=\"透视变换\"></a>透视变换</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">img=cv2.imread(<span class=\"string\">'./images/lena.jpg'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 下面的 None 本应该是输出图像的尺寸，但是因为后边我们设置了缩放因子</span></span><br><span class=\"line\"><span class=\"comment\"># 因此这里为 None</span></span><br><span class=\"line\">res=cv2.resize(img,<span class=\"literal\">None</span>,fx=<span class=\"number\">2</span>,fy=<span class=\"number\">2</span>,interpolation=cv2.INTER_CUBIC)</span><br><span class=\"line\"><span class=\"comment\">#OR</span></span><br><span class=\"line\"><span class=\"comment\"># 这里呢，我们直接设置输出图像的尺寸，所以不用设置缩放因子</span></span><br><span class=\"line\">height,width=img.shape[:<span class=\"number\">2</span>]</span><br><span class=\"line\">res=cv2.resize(img,(<span class=\"number\">2</span>*width,<span class=\"number\">2</span>*height),interpolation=cv2.INTER_CUBIC)</span><br><span class=\"line\"><span class=\"keyword\">while</span>(<span class=\"number\">1</span>):</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'res'</span>,res)</span><br><span class=\"line\">    cv2.imshow(<span class=\"string\">'img'</span>,img)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> cv2.waitKey(<span class=\"number\">1</span>) &amp; <span class=\"number\">0xFF</span> == <span class=\"number\">27</span>:</span><br><span class=\"line\">        <span class=\"keyword\">break</span></span><br><span class=\"line\">cv2.destroyAllWindows()</span><br><span class=\"line\"><span class=\"comment\"># Resize(src, dst, interpolation=CV_INTER_LINEAR)</span></span><br></pre></td></tr></table></figure>\n<h2 id=\"图像平滑\"><a href=\"#图像平滑\" class=\"headerlink\" title=\"图像平滑\"></a>图像平滑</h2><h3 id=\"2D卷积\"><a href=\"#2D卷积\" class=\"headerlink\" title=\"2D卷积\"></a>2D卷积</h3><p>OpenCV 提供的函数 cv.filter2D() 可以让我们对一幅图像进行卷积操作。下面我们将对一幅图像使用平均滤波器。下面是一个 5x5 的平均滤波器核：</p>\n<script type=\"math/tex; mode=display\">K=\\frac{1}{25}\\left[\\begin{array}{ccccc}{1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1} \\\\ {1} & {1} & {1} & {1} & {1}\\end{array}\\right]</script><p>操作如下：将核放在图像的一个像素 A 上，求与核对应的图像上 25（5x5）个像素的和，在取平均数，用这个平均数替代像素 A 的值。重复以上操作直到将图像的每一个像素值都更新一边。代码如下:  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\"></span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.float32)/<span class=\"number\">25</span></span><br><span class=\"line\">dst = cv2.filter2D(img, <span class=\"number\">-1</span>, kernel)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(dst),plt.title(<span class=\"string\">'Averaging'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_4_0.png\" alt=\"png\"></p>\n<h3 id=\"图像模糊（图像平滑）\"><a href=\"#图像模糊（图像平滑）\" class=\"headerlink\" title=\"图像模糊（图像平滑）\"></a>图像模糊（图像平滑）</h3><p>使用低通滤波器可以达到图像模糊的目的。这对与去除噪音很有帮助。其实就是去除图像中的高频成分（比如：噪音，边界）。所以边界也会被模糊一点。（当然，也有一些模糊技术不会模糊掉边界）。OpenCV 提供了四种模糊技术。  </p>\n<h3 id=\"平均\"><a href=\"#平均\" class=\"headerlink\" title=\"平均\"></a>平均</h3><p>　　这是由一个归一化卷积框完成的。他只是用卷积框覆盖区域所有像素的平均值来代替中心元素。可以使用函数 cv2.blur() 和 cv2.boxFilter() 来完这个任务。可以同看查看文档了解更多卷积框的细节。我们需要设定卷积框的宽和高。下面是一个 3x3 的归一化卷积框：<br>　　　　　<script type=\"math/tex\">K =  \\frac{1}{9} \\begin{bmatrix} 1 & 1 & 1  \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1 \\end{bmatrix}</script><br>注意：如果你不想使用归一化卷积框，你应该使用 cv2.boxFilter()，这时要传入参数 normalize=False。<br>下面与第一部分一样的一个例子：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">blur = cv2.blur(img,(<span class=\"number\">5</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_6_0.png\" alt=\"png\"></p>\n<h3 id=\"高斯模糊\"><a href=\"#高斯模糊\" class=\"headerlink\" title=\"高斯模糊\"></a>高斯模糊</h3><p>　　现在把卷积核换成高斯核（简单来说，方框不变，将原来每个方框的值是相等的，现在里面的值是符合高斯分布的，方框中心的值最大，其余方框根据距离中心元素的距离递减，构成一个高斯小山包。原来的求平均数现在变成求加权平均数，全就是方框里的值）。实现的函数是 cv2.GaussianBlur()。我们需要指定高斯核的宽和高（必须是奇数）。以及高斯函数沿 X，Y 方向的标准差。如果我们只指定了 X 方向的的标准差，Y 方向也会取相同值。如果两个标准差都是 0，那么函数会根据核函数的大小自己计算。高斯滤波可以有效的从图像中去除高斯噪音。<br>如果你愿意的话，你也可以使用函数 cv2.getGaussianKernel() 自己构建一个高斯核。<br>如果要使用高斯模糊的话，上边的代码应该写成：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#0 是指根据窗口大小（ 5,5 ）来计算高斯函数标准差</span></span><br><span class=\"line\">blur = cv2.GaussianBlur(img,(<span class=\"number\">5</span>,<span class=\"number\">5</span>),<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_8_0.png\" alt=\"png\"></p>\n<h3 id=\"中值模糊\"><a href=\"#中值模糊\" class=\"headerlink\" title=\"中值模糊\"></a>中值模糊</h3><p>顾名思义就是用与卷积框对应像素的中值来替代中心像素的值。这个滤波器经常用来去除椒盐噪声。前面的滤波器都是用计算得到的一个新值来取代中心像素的值，而中值滤波是用中心像素周围（也可以使他本身）的值来取代他。他能有效的去除噪声。卷积核的大小也应该是一个奇数。<br>在这个例子中，我们给原始图像加上 50% 的噪声然后再使用中值模糊。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">median = cv2.medianBlur(img,<span class=\"number\">5</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_10_0.png\" alt=\"png\"></p>\n<h3 id=\"双边滤波\"><a href=\"#双边滤波\" class=\"headerlink\" title=\"双边滤波\"></a>双边滤波</h3><p>函数 cv2.bilateralFilter() 能在保持边界清晰的情况下有效的去除噪音。但是这种操作与其他滤波器相比会比较慢。我们已经知道高斯滤波器是求中心点邻近区域像素的高斯加权平均值。这种高斯滤波器只考虑像素之间的空间关系，而不会考虑像素值之间的关系（像素的相似度）。所以这种方法不会考虑一个像素是否位于边界。因此边界也会别模糊掉，而这正不是我们想要。双边滤波在同时使用空间高斯权重和灰度值相似性高斯权重。空间高斯函数确保只有邻近区域的像素对中心点有影响，灰度值相似性高斯函数确保只有与中心像素灰度值相近的才会被用来做模糊运算。所以这种方法会确保边界不会被模糊掉，因为边界处的灰度值变化比较大。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>)</span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#cv2.bilateralFilter(src, d, sigmaColor, sigmaSpace)</span></span><br><span class=\"line\"><span class=\"comment\">#d – Diameter of each pixel neighborhood that is used during filtering.</span></span><br><span class=\"line\"><span class=\"comment\"># If it is non-positive, it is computed from sigmaSpace</span></span><br><span class=\"line\"><span class=\"comment\">#9 邻域直径，两个 75 分别是空间高斯函数标准差，灰度值相似性高斯函数标准差</span></span><br><span class=\"line\">blur = cv2.bilateralFilter(img,<span class=\"number\">9</span>,<span class=\"number\">75</span>,<span class=\"number\">75</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">121</span>),plt.imshow(img),plt.title(<span class=\"string\">'Original'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.subplot(<span class=\"number\">122</span>),plt.imshow(blur),plt.title(<span class=\"string\">'Blurred'</span>)</span><br><span class=\"line\">plt.xticks([]), plt.yticks([])</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_12_0.png\" alt=\"png\"></p>\n<h2 id=\"形态学转换\"><a href=\"#形态学转换\" class=\"headerlink\" title=\"形态学转换\"></a>形态学转换</h2><p>形态学操作是根据图像形状进行的简单操作。一般情况下对二值化图像进行的操作。需要输入两个参数，一个是原始图像，第二个被称为结构化元素或核，它是用来决定操作的性质的。两个基本的形态学操作是腐蚀和膨胀。他们的变体构成了开运算，闭运算，梯度等。</p>\n<h3 id=\"腐蚀\"><a href=\"#腐蚀\" class=\"headerlink\" title=\"腐蚀\"></a>腐蚀</h3><p>就像土壤侵蚀一样，这个操作会把前景物体的边界腐蚀掉（但是前景仍然是白色）。这是怎么做到的呢？卷积核沿着图像滑动，如果与卷积核对应的原图像的所有像素值都是 1，那么中心元素就保持原来的像素值，否则就变为零。<br>这会产生什么影响呢？根据卷积核的大小靠近前景的所有像素都会被腐蚀掉（变为 0），所以前景物体会变小，整幅图像的白色区域会减少。这对于去除白噪声很有用，也可以用来断开两个连在一块的物体等。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/j.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.uint8)</span><br><span class=\"line\">erosion = cv2.erode(img,kernel,iterations = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(erosion)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_15_0.png\" alt=\"png\"></p>\n<h3 id=\"膨胀\"><a href=\"#膨胀\" class=\"headerlink\" title=\"膨胀\"></a>膨胀</h3><p>与腐蚀相反，与卷积核对应的原图像的像素值中只要有一个是 1，中心元素的像素值就是 1。所以这个操作会增加图像中的白色区域（前景）。一般在去噪声时先用腐蚀再用膨胀。因为腐蚀在去掉白噪声的同时，也会使前景对象变小。所以我们再对他进行膨胀。这时噪声已经被去除了，不会再回来了，但是前景还在并会增加。膨胀也可以用来连接两个分开的物体。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/j.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">kernel = np.ones((<span class=\"number\">5</span>,<span class=\"number\">5</span>),np.uint8)</span><br><span class=\"line\">dilation = cv2.dilate(img,kernel,iterations = <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(dilation)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/22/OpenCV学习笔记二：图像处理/./OpenCV学习笔记二：图像处理/output_17_0.png\" alt=\"png\"></p>\n<h3 id=\"开运算\"><a href=\"#开运算\" class=\"headerlink\" title=\"开运算\"></a>开运算</h3><p>先进性腐蚀再进行膨胀就叫做开运算。就像我们上面介绍的那样，它被用来去除噪声。这里我们用到的函数是 cv2.morphologyEx()。</p>\n<h3 id=\"闭运算\"><a href=\"#闭运算\" class=\"headerlink\" title=\"闭运算\"></a>闭运算</h3><p>先膨胀再腐蚀。它经常被用来填充前景物体中的小洞，或者前景物体上的小黑点。</p>\n<h3 id=\"形态学梯度\"><a href=\"#形态学梯度\" class=\"headerlink\" title=\"形态学梯度\"></a>形态学梯度</h3><p>其实就是一幅图像膨胀与腐蚀的差别。结果看上去就像前景物体的轮廓。</p>\n</the>"},{"title":"OpenCV学习笔记四：目标检测与识别","date":"2019-06-22T16:29:31.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要> \n\n### 目标检测和识别\n传统目标检测算法中的技术：  \n* 梯度直方图（Histogram of Oriented Gradient， HOG）  \n* 图像金字塔（image pyramid）  \n* 滑动窗口（sliding window）  \n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n与特征检测算法不同，这些算法是互补的。如在梯度直方图（HOG）中会使用滑动窗口技术。\n\n### HOG\n* Histogram of Oriented Gradients | Learn OpenCV  \nhttps://www.learnopencv.com/histogram-of-oriented-gradients/  \n\nHOG，全称方向梯度直方图，是一个特征描述符，它基于梯度来计算直方图。\n\n步骤：  \n1）图像预处理  \n包括伽马矫正和灰度化，可选步骤。\n为了减少光照因素的影响，首先需要将整个图像进行规范化（归一化）。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以，这种压缩处理能够有效地降低图像局部的阴影和光照变化；   \n因为颜色信息作用不大，通常先转化为灰度图。 \n\n2）计算每个像素点的梯度  \n计算图像横坐标和纵坐标方向的梯度，并据此计算每个像素位置的梯度方向值；求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。  \n图像中像素点$(x,y)$的梯度为：  \n$$G_x(x,y) = H(x+1,y) - H(x-1,y) $$\n$$G_y(x,y) = H(x,y+1) - H(x,y-1) $$\n其中$G_x(x,y)$,$G_y(x,y)$,$H(x,y)$分别表示图像中像素点$(x,y)$处的水平方向梯度、垂直方向梯度和像素值。像素点$(x,y)$处的梯度幅度和梯度方向分别为：  \n$$G(x,y) = \\sqrt{G_x(x,y)^2 + G_y(x,y)^2} $$\n$$\\alpha(x,y) = \\tan^{-1}{(\\frac{G_y(x,y)}{G_x(x,y)})} $$  \n最常用的方法是：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly，最后用以上公式计算该像素点的梯度大小和方向。  \n\n3）计算梯度直方图  \n梯度直方图是在一个8*8的cell里面计算的。那么在8*8的cell里面就会有8*8*2=128个值，其中2包括了梯度强度和梯度方向。通过统计形成梯度直方图，128个值将会变成9个值，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。  \n\n首先将0-180度分成9个bins，分别是0，20，40...160；然后根据梯度方向值的大小，将每一个像素点的梯度幅度值分配到相应的bin上；最终得到如下图所示的直方图，一个长度为9的数组。  \n<img alt=\"HOG02\" src=\"OpenCV学习笔记四：目标检测与识别/hog02.jpg\">\n从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。   \n\nbin值的具体计算方法如下例： \n<img alt=\"HOG01\" src=\"OpenCV学习笔记四：目标检测与识别/hog01.jpg\">  \n先看两个蓝色圈圈。因为蓝圈的方向是80度，大小是2，所以该点就投给80这个bin；  \n再看两个红色圈圈。因为红色圈圈的方向是10，大小是4，因为10距离0点为10，距离20点为也为10，那么有一半的大小是投给0这个bin，还有一半的大小投给20这个bin。  \n\n4）块内归一化梯度直方图  \n归一化的目的是降低光照的影响。  \n归一化的方法是向量的每一个值除以向量的模长。  \n\n5）收集HOG特征  \n将检测窗口中所有重叠的块进行HOG特征的收集，并将它们结合成最终的特征向量供分类使用。  \n一个图像的HOG特征维数计算:  \n对于一个$64\\times128$大小的图像，按照$16\\times16$的大小提取block，将会有7个水平位置和15个竖直位可以取得，所以一共有$7\\times15=105$个block，所以我们整合所有block的vector，形成一个大的一维vector的大小将会是$36\\times105=3780$。\n\n### OpenCV HOGDescriptor \n\n* 窗口大小 winSize(64,128)\n* 块大小 blockSize(16,16)\n* 块滑动增量 blockStride(8,8)\n* 胞元大小 cellSize(8,8)\n* 梯度方向数 nbins(9) \n\n在确定了上述的参数后，就可以计算出一个HOG描述子的维度了。\n\n\n``` cpp\nsize_t HOGDescriptor::getDescriptorSize() const\n{\n    CV_Assert(blockSize.width % cellSize.width == 0 &&\n        blockSize.height % cellSize.height == 0);\n    CV_Assert((winSize.width - blockSize.width) % blockStride.width == 0 &&\n        (winSize.height - blockSize.height) % blockStride.height == 0 );\n    return (size_t)nbins*\n        (blockSize.width/cellSize.width)*\n        (blockSize.height/cellSize.height)*\n        ((winSize.width - blockSize.width)/blockStride.width + 1)*\n        ((winSize.height - blockSize.height)/blockStride.height + 1);\n}\n```\n\n\n``` python\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nplt.figure(figsize=(10,10))\n\n# 确定某矩形是否完全包含在另一个矩形中\ndef is_inside(o, i):\n    ox, oy, ow, oh = o\n    ix, iy, iw, ih = i\n    return ox > ix and oy > iy and ox+ow < ix+iw and oy + oh < iy + ih\n\n# 绘制矩形来框住检测到的人\ndef draw_person(image, person):\n    x, y, w, h = person\n    cv2.rectangle(img, (x, y), (x+w, y + h), (0, 255, 255), 2)\n\n\n# 导入图像，\nimg = cv2.imread(\"./images/run.jpg\")\n# 实例化HOGDescriptor对象，作为检测人的检测器\nhog = cv2.HOGDescriptor()\n# 设置线性SVM分类器的系数\nhog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n\n# 该和人脸算法不一样，不需要在使用目标检测方法前将原始图像转换为灰度形式\n# 该方法返回一个与矩形相关的数组，用户可用该数组在图形上绘制形状\n# 若图形上的矩形存在有包含与被包含的关系，说明检测出现了错误\n# 被包含的图形应该被丢弃，此过程由is_inside来实现\n# 在输入图像中检测不同大小的对象。检测到的对象作为列表返回\nfound, w = hog.detectMultiScale(img)\n\nfound_filtered = []\n\n# 遍历检测结果，丢弃不含有检测目标区域的矩形。\nfor ri, r in enumerate(found):\n    for qi, q in enumerate(found):\n        if ri != qi and is_inside(r, q):\n            break\n        else:\n            found_filtered.append(r)\n\nfor person in found_filtered:\n    draw_person(img, person)\n\n# cv2.imshow(\"people detection\", img)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记四：目标检测与识别/output_4_0.png\">\n\n\n```python\nimport cv2\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(10,10))\n\nclass Hog_descriptor():\n    def __init__(self, img, cell_size=16, bin_size=9):\n        self.img = img\n        self.img = np.sqrt(img / np.max(img))\n        self.img = img * 255\n        self.cell_size = cell_size\n        self.bin_size = bin_size\n        self.angle_unit = int(360 / self.bin_size)\n        assert type(self.bin_size) == int, \"bin_size should be integer,\"\n        assert type(self.cell_size) == int, \"cell_size should be integer,\"\n        assert type(self.angle_unit) == int, \"bin_size should be divisible by 360\"\n\n    def extract(self):\n        height, width = self.img.shape\n        gradient_magnitude, gradient_angle = self.global_gradient()\n        gradient_magnitude = abs(gradient_magnitude)\n        cell_gradient_vector = np.zeros((int(height / self.cell_size), int(width / self.cell_size), self.bin_size))\n        for i in range(cell_gradient_vector.shape[0]):\n            for j in range(cell_gradient_vector.shape[1]):\n                cell_magnitude = gradient_magnitude[i * self.cell_size:(i + 1) * self.cell_size,\n                                 j * self.cell_size:(j + 1) * self.cell_size]\n                cell_angle = gradient_angle[i * self.cell_size:(i + 1) * self.cell_size,\n                             j * self.cell_size:(j + 1) * self.cell_size]\n                cell_gradient_vector[i][j] = self.cell_gradient(cell_magnitude, cell_angle)\n\n        hog_image = self.render_gradient(np.zeros([height, width]), cell_gradient_vector)\n        hog_vector = []\n        for i in range(cell_gradient_vector.shape[0] - 1):\n            for j in range(cell_gradient_vector.shape[1] - 1):\n                block_vector = []\n                block_vector.extend(cell_gradient_vector[i][j])\n                block_vector.extend(cell_gradient_vector[i][j + 1])\n                block_vector.extend(cell_gradient_vector[i + 1][j])\n                block_vector.extend(cell_gradient_vector[i + 1][j + 1])\n                mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector))\n                magnitude = mag(block_vector)\n                if magnitude != 0:\n                    normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector]\n                    block_vector = normalize(block_vector, magnitude)\n                hog_vector.append(block_vector)\n        return hog_vector, hog_image\n\n    def global_gradient(self):\n        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, 1, 0, ksize=5)\n        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, 0, 1, ksize=5)\n        gradient_magnitude = cv2.addWeighted(gradient_values_x, 0.5, gradient_values_y, 0.5, 0)\n        gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=True)\n        return gradient_magnitude, gradient_angle\n\n    def cell_gradient(self, cell_magnitude, cell_angle):\n        orientation_centers = [0] * self.bin_size\n        for i in range(cell_magnitude.shape[0]):\n            for j in range(cell_magnitude.shape[1]):\n                gradient_strength = cell_magnitude[i][j]\n                gradient_angle = cell_angle[i][j]\n                min_angle, max_angle, mod = self.get_closest_bins(gradient_angle)\n                orientation_centers[min_angle] += (gradient_strength * (1 - (mod / self.angle_unit)))\n                orientation_centers[max_angle] += (gradient_strength * (mod / self.angle_unit))\n        return orientation_centers\n\n    def get_closest_bins(self, gradient_angle):\n        idx = int(gradient_angle / self.angle_unit)\n        mod = gradient_angle % self.angle_unit\n        return idx, (idx + 1) % self.bin_size, mod\n\n    def render_gradient(self, image, cell_gradient):\n        cell_width = self.cell_size / 2\n        max_mag = np.array(cell_gradient).max()\n        for x in range(cell_gradient.shape[0]):\n            for y in range(cell_gradient.shape[1]):\n                cell_grad = cell_gradient[x][y]\n                cell_grad /= max_mag\n                angle = 0\n                angle_gap = self.angle_unit\n                for magnitude in cell_grad:\n                    angle_radian = math.radians(angle)\n                    x1 = int(x * self.cell_size + magnitude * cell_width * math.cos(angle_radian))\n                    y1 = int(y * self.cell_size + magnitude * cell_width * math.sin(angle_radian))\n                    x2 = int(x * self.cell_size - magnitude * cell_width * math.cos(angle_radian))\n                    y2 = int(y * self.cell_size - magnitude * cell_width * math.sin(angle_radian))\n                    cv2.line(image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude)))\n                    angle += angle_gap\n        return image\n\nimg = cv2.imread('./images/car.jpg', cv2.IMREAD_GRAYSCALE)\n# img = cv2.resize(img, (128, 64))\nhog = Hog_descriptor(img, cell_size=8, bin_size=9)\nvector, image = hog.extract()\nprint(np.array(vector).shape)\nplt.imshow(image, cmap=plt.cm.gray)\nplt.show()\n```\n\n\n<img src=\"OpenCV学习笔记四：目标检测与识别/output_5_1.png\">\n\n\n### 图像金字塔\n图像金字塔是图像的多尺度表示。  \n\n构建图像金字塔：  \n1 - 获取图像  \n2 - 使用任意尺度的参数来调整（缩小）图像大小  \n3 - 平滑图像（使用高斯模糊）  \n4 - 如果图像比最小尺寸还大，则从第一步重复该过程。  \n\n### 滑动窗口\n\n滑动窗口通过扫描较大图像的较小区域来解决定位问题，进而在同一图像的不同尺度下重复扫描。  \n\n该技术需将图像分解成多个部分，然后丢掉那些不太可能包含对象的部分，并对可能区域进行分类。  \n\n### 非极大抑制\n\n非极大值抑制（Non-maximum suppression, NMS）释义为抑制不是极大值的元素，搜索局部的极大值。  \n\n如在对象检测中，滑动窗口经提取特征 --> 分类器分类识别后，每个窗口都会得到一个分类和分数，但滑动窗口会导致很多窗口与其他窗口存在包含或大部分交叉的情况，这时就需要用到 NMS 来选取那些邻域里分数最高（某类对象的概率最大），并抑制这些分数低的窗口。 \n\n也可理解为：目标检测的过程中，同一目标位置上会产生大量的候选框，这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框。  \n\n### 使用HOG+SVM做行人检测\n\n参考2005年CVPR论文，使用HOG+SVM做行人检测\n论文链接：  \n* Histograms of Oriented Gradients for Human Detection   \nhttps://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf\n\n工作流程：首先对输入的图片进行预处理，然后计算像素点的梯度值，然后形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行高维的vector）放到SVM里进行监督学习，从而实现行人的检测。  \n![Histograms of Oriented Gradients for Human Detection](./OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png)\n\n\n### INRIA数据集\n\nINRIA数据集官方页面：  \n* http://pascal.inrialpes.fr/data/human/\n\n整理版本：  \n* INRIA数据集 - baiyu33的博客 - CSDN博客   \nhttps://blog.csdn.net/baiyu33/article/details/51762368\n\n### HardExample\n\n用分类器对样本进行分类，把其中错误分类的样本(hard negative)放入负样本集合再继续训练分类器。  \n\n难例(或叫做难样本，Hard Example，Hard Negative，Hard Instance)是指利用第一次训练的分类器在负样本原图(肯定没有人体)上进行行人检测时所有检测到的矩形框，这些矩形框区域很明显都是误报，把这些误报的矩形框保存为图片，加入到初始的负样本集合中，重新进行SVM的训练，可显著减少误报。这种方法叫做自举法(Bootstrap)，自举法首先使用初始负样本集来训练一个模型，然后收集被这个初始模型错误分类的负样本来形成一个负样本难例集。用此负样本难例集训练新的模型，此过程可以重复多次。\n\n\n### OHEM\n在线难例挖掘（online hard example miniing）  \n选取loss较大(检测结果与label差异较大)的部分进行训练。  \n\n\n### 基于深度学习的方法\n\n* RCNN \n* Fast-RCNN\n* YOLO\n* SSD\n\n\n### 参考资料\n* OpenCV 学习笔记 07 目标检测与识别 - 耕毅 - 博客园  \nhttps://www.cnblogs.com/gengyi/p/10555622.html\n","source":"_posts/OpenCV学习笔记四：目标检测与识别.md","raw":"---\ntitle: OpenCV学习笔记四：目标检测与识别\ndate: 2019-06-23 00:29:31\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要> \n\n### 目标检测和识别\n传统目标检测算法中的技术：  \n* 梯度直方图（Histogram of Oriented Gradient， HOG）  \n* 图像金字塔（image pyramid）  \n* 滑动窗口（sliding window）  \n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n与特征检测算法不同，这些算法是互补的。如在梯度直方图（HOG）中会使用滑动窗口技术。\n\n### HOG\n* Histogram of Oriented Gradients | Learn OpenCV  \nhttps://www.learnopencv.com/histogram-of-oriented-gradients/  \n\nHOG，全称方向梯度直方图，是一个特征描述符，它基于梯度来计算直方图。\n\n步骤：  \n1）图像预处理  \n包括伽马矫正和灰度化，可选步骤。\n为了减少光照因素的影响，首先需要将整个图像进行规范化（归一化）。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以，这种压缩处理能够有效地降低图像局部的阴影和光照变化；   \n因为颜色信息作用不大，通常先转化为灰度图。 \n\n2）计算每个像素点的梯度  \n计算图像横坐标和纵坐标方向的梯度，并据此计算每个像素位置的梯度方向值；求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。  \n图像中像素点$(x,y)$的梯度为：  \n$$G_x(x,y) = H(x+1,y) - H(x-1,y) $$\n$$G_y(x,y) = H(x,y+1) - H(x,y-1) $$\n其中$G_x(x,y)$,$G_y(x,y)$,$H(x,y)$分别表示图像中像素点$(x,y)$处的水平方向梯度、垂直方向梯度和像素值。像素点$(x,y)$处的梯度幅度和梯度方向分别为：  \n$$G(x,y) = \\sqrt{G_x(x,y)^2 + G_y(x,y)^2} $$\n$$\\alpha(x,y) = \\tan^{-1}{(\\frac{G_y(x,y)}{G_x(x,y)})} $$  \n最常用的方法是：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly，最后用以上公式计算该像素点的梯度大小和方向。  \n\n3）计算梯度直方图  \n梯度直方图是在一个8*8的cell里面计算的。那么在8*8的cell里面就会有8*8*2=128个值，其中2包括了梯度强度和梯度方向。通过统计形成梯度直方图，128个值将会变成9个值，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。  \n\n首先将0-180度分成9个bins，分别是0，20，40...160；然后根据梯度方向值的大小，将每一个像素点的梯度幅度值分配到相应的bin上；最终得到如下图所示的直方图，一个长度为9的数组。  \n<img alt=\"HOG02\" src=\"OpenCV学习笔记四：目标检测与识别/hog02.jpg\">\n从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。   \n\nbin值的具体计算方法如下例： \n<img alt=\"HOG01\" src=\"OpenCV学习笔记四：目标检测与识别/hog01.jpg\">  \n先看两个蓝色圈圈。因为蓝圈的方向是80度，大小是2，所以该点就投给80这个bin；  \n再看两个红色圈圈。因为红色圈圈的方向是10，大小是4，因为10距离0点为10，距离20点为也为10，那么有一半的大小是投给0这个bin，还有一半的大小投给20这个bin。  \n\n4）块内归一化梯度直方图  \n归一化的目的是降低光照的影响。  \n归一化的方法是向量的每一个值除以向量的模长。  \n\n5）收集HOG特征  \n将检测窗口中所有重叠的块进行HOG特征的收集，并将它们结合成最终的特征向量供分类使用。  \n一个图像的HOG特征维数计算:  \n对于一个$64\\times128$大小的图像，按照$16\\times16$的大小提取block，将会有7个水平位置和15个竖直位可以取得，所以一共有$7\\times15=105$个block，所以我们整合所有block的vector，形成一个大的一维vector的大小将会是$36\\times105=3780$。\n\n### OpenCV HOGDescriptor \n\n* 窗口大小 winSize(64,128)\n* 块大小 blockSize(16,16)\n* 块滑动增量 blockStride(8,8)\n* 胞元大小 cellSize(8,8)\n* 梯度方向数 nbins(9) \n\n在确定了上述的参数后，就可以计算出一个HOG描述子的维度了。\n\n\n``` cpp\nsize_t HOGDescriptor::getDescriptorSize() const\n{\n    CV_Assert(blockSize.width % cellSize.width == 0 &&\n        blockSize.height % cellSize.height == 0);\n    CV_Assert((winSize.width - blockSize.width) % blockStride.width == 0 &&\n        (winSize.height - blockSize.height) % blockStride.height == 0 );\n    return (size_t)nbins*\n        (blockSize.width/cellSize.width)*\n        (blockSize.height/cellSize.height)*\n        ((winSize.width - blockSize.width)/blockStride.width + 1)*\n        ((winSize.height - blockSize.height)/blockStride.height + 1);\n}\n```\n\n\n``` python\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\n\nplt.figure(figsize=(10,10))\n\n# 确定某矩形是否完全包含在另一个矩形中\ndef is_inside(o, i):\n    ox, oy, ow, oh = o\n    ix, iy, iw, ih = i\n    return ox > ix and oy > iy and ox+ow < ix+iw and oy + oh < iy + ih\n\n# 绘制矩形来框住检测到的人\ndef draw_person(image, person):\n    x, y, w, h = person\n    cv2.rectangle(img, (x, y), (x+w, y + h), (0, 255, 255), 2)\n\n\n# 导入图像，\nimg = cv2.imread(\"./images/run.jpg\")\n# 实例化HOGDescriptor对象，作为检测人的检测器\nhog = cv2.HOGDescriptor()\n# 设置线性SVM分类器的系数\nhog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n\n# 该和人脸算法不一样，不需要在使用目标检测方法前将原始图像转换为灰度形式\n# 该方法返回一个与矩形相关的数组，用户可用该数组在图形上绘制形状\n# 若图形上的矩形存在有包含与被包含的关系，说明检测出现了错误\n# 被包含的图形应该被丢弃，此过程由is_inside来实现\n# 在输入图像中检测不同大小的对象。检测到的对象作为列表返回\nfound, w = hog.detectMultiScale(img)\n\nfound_filtered = []\n\n# 遍历检测结果，丢弃不含有检测目标区域的矩形。\nfor ri, r in enumerate(found):\n    for qi, q in enumerate(found):\n        if ri != qi and is_inside(r, q):\n            break\n        else:\n            found_filtered.append(r)\n\nfor person in found_filtered:\n    draw_person(img, person)\n\n# cv2.imshow(\"people detection\", img)\n# cv2.waitKey(0)\n# cv2.destroyAllWindows()\nplt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记四：目标检测与识别/output_4_0.png\">\n\n\n```python\nimport cv2\nimport numpy as np\nimport math\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(10,10))\n\nclass Hog_descriptor():\n    def __init__(self, img, cell_size=16, bin_size=9):\n        self.img = img\n        self.img = np.sqrt(img / np.max(img))\n        self.img = img * 255\n        self.cell_size = cell_size\n        self.bin_size = bin_size\n        self.angle_unit = int(360 / self.bin_size)\n        assert type(self.bin_size) == int, \"bin_size should be integer,\"\n        assert type(self.cell_size) == int, \"cell_size should be integer,\"\n        assert type(self.angle_unit) == int, \"bin_size should be divisible by 360\"\n\n    def extract(self):\n        height, width = self.img.shape\n        gradient_magnitude, gradient_angle = self.global_gradient()\n        gradient_magnitude = abs(gradient_magnitude)\n        cell_gradient_vector = np.zeros((int(height / self.cell_size), int(width / self.cell_size), self.bin_size))\n        for i in range(cell_gradient_vector.shape[0]):\n            for j in range(cell_gradient_vector.shape[1]):\n                cell_magnitude = gradient_magnitude[i * self.cell_size:(i + 1) * self.cell_size,\n                                 j * self.cell_size:(j + 1) * self.cell_size]\n                cell_angle = gradient_angle[i * self.cell_size:(i + 1) * self.cell_size,\n                             j * self.cell_size:(j + 1) * self.cell_size]\n                cell_gradient_vector[i][j] = self.cell_gradient(cell_magnitude, cell_angle)\n\n        hog_image = self.render_gradient(np.zeros([height, width]), cell_gradient_vector)\n        hog_vector = []\n        for i in range(cell_gradient_vector.shape[0] - 1):\n            for j in range(cell_gradient_vector.shape[1] - 1):\n                block_vector = []\n                block_vector.extend(cell_gradient_vector[i][j])\n                block_vector.extend(cell_gradient_vector[i][j + 1])\n                block_vector.extend(cell_gradient_vector[i + 1][j])\n                block_vector.extend(cell_gradient_vector[i + 1][j + 1])\n                mag = lambda vector: math.sqrt(sum(i ** 2 for i in vector))\n                magnitude = mag(block_vector)\n                if magnitude != 0:\n                    normalize = lambda block_vector, magnitude: [element / magnitude for element in block_vector]\n                    block_vector = normalize(block_vector, magnitude)\n                hog_vector.append(block_vector)\n        return hog_vector, hog_image\n\n    def global_gradient(self):\n        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, 1, 0, ksize=5)\n        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, 0, 1, ksize=5)\n        gradient_magnitude = cv2.addWeighted(gradient_values_x, 0.5, gradient_values_y, 0.5, 0)\n        gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=True)\n        return gradient_magnitude, gradient_angle\n\n    def cell_gradient(self, cell_magnitude, cell_angle):\n        orientation_centers = [0] * self.bin_size\n        for i in range(cell_magnitude.shape[0]):\n            for j in range(cell_magnitude.shape[1]):\n                gradient_strength = cell_magnitude[i][j]\n                gradient_angle = cell_angle[i][j]\n                min_angle, max_angle, mod = self.get_closest_bins(gradient_angle)\n                orientation_centers[min_angle] += (gradient_strength * (1 - (mod / self.angle_unit)))\n                orientation_centers[max_angle] += (gradient_strength * (mod / self.angle_unit))\n        return orientation_centers\n\n    def get_closest_bins(self, gradient_angle):\n        idx = int(gradient_angle / self.angle_unit)\n        mod = gradient_angle % self.angle_unit\n        return idx, (idx + 1) % self.bin_size, mod\n\n    def render_gradient(self, image, cell_gradient):\n        cell_width = self.cell_size / 2\n        max_mag = np.array(cell_gradient).max()\n        for x in range(cell_gradient.shape[0]):\n            for y in range(cell_gradient.shape[1]):\n                cell_grad = cell_gradient[x][y]\n                cell_grad /= max_mag\n                angle = 0\n                angle_gap = self.angle_unit\n                for magnitude in cell_grad:\n                    angle_radian = math.radians(angle)\n                    x1 = int(x * self.cell_size + magnitude * cell_width * math.cos(angle_radian))\n                    y1 = int(y * self.cell_size + magnitude * cell_width * math.sin(angle_radian))\n                    x2 = int(x * self.cell_size - magnitude * cell_width * math.cos(angle_radian))\n                    y2 = int(y * self.cell_size - magnitude * cell_width * math.sin(angle_radian))\n                    cv2.line(image, (y1, x1), (y2, x2), int(255 * math.sqrt(magnitude)))\n                    angle += angle_gap\n        return image\n\nimg = cv2.imread('./images/car.jpg', cv2.IMREAD_GRAYSCALE)\n# img = cv2.resize(img, (128, 64))\nhog = Hog_descriptor(img, cell_size=8, bin_size=9)\nvector, image = hog.extract()\nprint(np.array(vector).shape)\nplt.imshow(image, cmap=plt.cm.gray)\nplt.show()\n```\n\n\n<img src=\"OpenCV学习笔记四：目标检测与识别/output_5_1.png\">\n\n\n### 图像金字塔\n图像金字塔是图像的多尺度表示。  \n\n构建图像金字塔：  \n1 - 获取图像  \n2 - 使用任意尺度的参数来调整（缩小）图像大小  \n3 - 平滑图像（使用高斯模糊）  \n4 - 如果图像比最小尺寸还大，则从第一步重复该过程。  \n\n### 滑动窗口\n\n滑动窗口通过扫描较大图像的较小区域来解决定位问题，进而在同一图像的不同尺度下重复扫描。  \n\n该技术需将图像分解成多个部分，然后丢掉那些不太可能包含对象的部分，并对可能区域进行分类。  \n\n### 非极大抑制\n\n非极大值抑制（Non-maximum suppression, NMS）释义为抑制不是极大值的元素，搜索局部的极大值。  \n\n如在对象检测中，滑动窗口经提取特征 --> 分类器分类识别后，每个窗口都会得到一个分类和分数，但滑动窗口会导致很多窗口与其他窗口存在包含或大部分交叉的情况，这时就需要用到 NMS 来选取那些邻域里分数最高（某类对象的概率最大），并抑制这些分数低的窗口。 \n\n也可理解为：目标检测的过程中，同一目标位置上会产生大量的候选框，这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框。  \n\n### 使用HOG+SVM做行人检测\n\n参考2005年CVPR论文，使用HOG+SVM做行人检测\n论文链接：  \n* Histograms of Oriented Gradients for Human Detection   \nhttps://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf\n\n工作流程：首先对输入的图片进行预处理，然后计算像素点的梯度值，然后形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行高维的vector）放到SVM里进行监督学习，从而实现行人的检测。  \n![Histograms of Oriented Gradients for Human Detection](./OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png)\n\n\n### INRIA数据集\n\nINRIA数据集官方页面：  \n* http://pascal.inrialpes.fr/data/human/\n\n整理版本：  \n* INRIA数据集 - baiyu33的博客 - CSDN博客   \nhttps://blog.csdn.net/baiyu33/article/details/51762368\n\n### HardExample\n\n用分类器对样本进行分类，把其中错误分类的样本(hard negative)放入负样本集合再继续训练分类器。  \n\n难例(或叫做难样本，Hard Example，Hard Negative，Hard Instance)是指利用第一次训练的分类器在负样本原图(肯定没有人体)上进行行人检测时所有检测到的矩形框，这些矩形框区域很明显都是误报，把这些误报的矩形框保存为图片，加入到初始的负样本集合中，重新进行SVM的训练，可显著减少误报。这种方法叫做自举法(Bootstrap)，自举法首先使用初始负样本集来训练一个模型，然后收集被这个初始模型错误分类的负样本来形成一个负样本难例集。用此负样本难例集训练新的模型，此过程可以重复多次。\n\n\n### OHEM\n在线难例挖掘（online hard example miniing）  \n选取loss较大(检测结果与label差异较大)的部分进行训练。  \n\n\n### 基于深度学习的方法\n\n* RCNN \n* Fast-RCNN\n* YOLO\n* SSD\n\n\n### 参考资料\n* OpenCV 学习笔记 07 目标检测与识别 - 耕毅 - 博客园  \nhttps://www.cnblogs.com/gengyi/p/10555622.html\n","slug":"OpenCV学习笔记四：目标检测与识别","published":1,"updated":"2019-06-23T07:09:39.752Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76d003xrsvjuuaocv3s","content":"<p><strong> OpenCV学习笔记四：目标检测与识别：</strong> <excerpt in index | 首页摘要> </excerpt></p>\n<h3 id=\"目标检测和识别\"><a href=\"#目标检测和识别\" class=\"headerlink\" title=\"目标检测和识别\"></a>目标检测和识别</h3><p>传统目标检测算法中的技术：  </p>\n<ul>\n<li>梯度直方图（Histogram of Oriented Gradient， HOG）  </li>\n<li>图像金字塔（image pyramid）  </li>\n<li>滑动窗口（sliding window）  </li>\n</ul>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n<p>与特征检测算法不同，这些算法是互补的。如在梯度直方图（HOG）中会使用滑动窗口技术。</p>\n<h3 id=\"HOG\"><a href=\"#HOG\" class=\"headerlink\" title=\"HOG\"></a>HOG</h3><ul>\n<li>Histogram of Oriented Gradients | Learn OpenCV<br><a href=\"https://www.learnopencv.com/histogram-of-oriented-gradients/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/histogram-of-oriented-gradients/</a>  </li>\n</ul>\n<p>HOG，全称方向梯度直方图，是一个特征描述符，它基于梯度来计算直方图。</p>\n<p>步骤：<br>1）图像预处理<br>包括伽马矫正和灰度化，可选步骤。<br>为了减少光照因素的影响，首先需要将整个图像进行规范化（归一化）。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以，这种压缩处理能够有效地降低图像局部的阴影和光照变化；<br>因为颜色信息作用不大，通常先转化为灰度图。 </p>\n<p>2）计算每个像素点的梯度<br>计算图像横坐标和纵坐标方向的梯度，并据此计算每个像素位置的梯度方向值；求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。<br>图像中像素点$(x,y)$的梯度为：  </p>\n<script type=\"math/tex; mode=display\">G_x(x,y) = H(x+1,y) - H(x-1,y)</script><script type=\"math/tex; mode=display\">G_y(x,y) = H(x,y+1) - H(x,y-1)</script><p>其中$G_x(x,y)$,$G_y(x,y)$,$H(x,y)$分别表示图像中像素点$(x,y)$处的水平方向梯度、垂直方向梯度和像素值。像素点$(x,y)$处的梯度幅度和梯度方向分别为：  </p>\n<script type=\"math/tex; mode=display\">G(x,y) = \\sqrt{G_x(x,y)^2 + G_y(x,y)^2}</script><script type=\"math/tex; mode=display\">\\alpha(x,y) = \\tan^{-1}{(\\frac{G_y(x,y)}{G_x(x,y)})}</script><p>最常用的方法是：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly，最后用以上公式计算该像素点的梯度大小和方向。  </p>\n<p>3）计算梯度直方图<br>梯度直方图是在一个8<em>8的cell里面计算的。那么在8</em>8的cell里面就会有8<em>8</em>2=128个值，其中2包括了梯度强度和梯度方向。通过统计形成梯度直方图，128个值将会变成9个值，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。  </p>\n<p>首先将0-180度分成9个bins，分别是0，20，40…160；然后根据梯度方向值的大小，将每一个像素点的梯度幅度值分配到相应的bin上；最终得到如下图所示的直方图，一个长度为9的数组。<br><img alt=\"HOG02\" src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog02.jpg\"><br>从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。   </p>\n<p>bin值的具体计算方法如下例：<br><img alt=\"HOG01\" src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog01.jpg\"><br>先看两个蓝色圈圈。因为蓝圈的方向是80度，大小是2，所以该点就投给80这个bin；<br>再看两个红色圈圈。因为红色圈圈的方向是10，大小是4，因为10距离0点为10，距离20点为也为10，那么有一半的大小是投给0这个bin，还有一半的大小投给20这个bin。  </p>\n<p>4）块内归一化梯度直方图<br>归一化的目的是降低光照的影响。<br>归一化的方法是向量的每一个值除以向量的模长。  </p>\n<p>5）收集HOG特征<br>将检测窗口中所有重叠的块进行HOG特征的收集，并将它们结合成最终的特征向量供分类使用。<br>一个图像的HOG特征维数计算:<br>对于一个$64\\times128$大小的图像，按照$16\\times16$的大小提取block，将会有7个水平位置和15个竖直位可以取得，所以一共有$7\\times15=105$个block，所以我们整合所有block的vector，形成一个大的一维vector的大小将会是$36\\times105=3780$。</p>\n<h3 id=\"OpenCV-HOGDescriptor\"><a href=\"#OpenCV-HOGDescriptor\" class=\"headerlink\" title=\"OpenCV HOGDescriptor\"></a>OpenCV HOGDescriptor</h3><ul>\n<li>窗口大小 winSize(64,128)</li>\n<li>块大小 blockSize(16,16)</li>\n<li>块滑动增量 blockStride(8,8)</li>\n<li>胞元大小 cellSize(8,8)</li>\n<li>梯度方向数 nbins(9) </li>\n</ul>\n<p>在确定了上述的参数后，就可以计算出一个HOG描述子的维度了。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">size_t</span> HOGDescriptor::getDescriptorSize() <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    CV_Assert(blockSize.width % cellSize.width == <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        blockSize.height % cellSize.height == <span class=\"number\">0</span>);</span><br><span class=\"line\">    CV_Assert((winSize.width - blockSize.width) % blockStride.width == <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        (winSize.height - blockSize.height) % blockStride.height == <span class=\"number\">0</span> );</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"keyword\">size_t</span>)nbins*</span><br><span class=\"line\">        (blockSize.width/cellSize.width)*</span><br><span class=\"line\">        (blockSize.height/cellSize.height)*</span><br><span class=\"line\">        ((winSize.width - blockSize.width)/blockStride.width + <span class=\"number\">1</span>)*</span><br><span class=\"line\">        ((winSize.height - blockSize.height)/blockStride.height + <span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 确定某矩形是否完全包含在另一个矩形中</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">is_inside</span><span class=\"params\">(o, i)</span>:</span></span><br><span class=\"line\">    ox, oy, ow, oh = o</span><br><span class=\"line\">    ix, iy, iw, ih = i</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ox &gt; ix <span class=\"keyword\">and</span> oy &gt; iy <span class=\"keyword\">and</span> ox+ow &lt; ix+iw <span class=\"keyword\">and</span> oy + oh &lt; iy + ih</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制矩形来框住检测到的人</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_person</span><span class=\"params\">(image, person)</span>:</span></span><br><span class=\"line\">    x, y, w, h = person</span><br><span class=\"line\">    cv2.rectangle(img, (x, y), (x+w, y + h), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入图像，</span></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">\"./images/run.jpg\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># 实例化HOGDescriptor对象，作为检测人的检测器</span></span><br><span class=\"line\">hog = cv2.HOGDescriptor()</span><br><span class=\"line\"><span class=\"comment\"># 设置线性SVM分类器的系数</span></span><br><span class=\"line\">hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该和人脸算法不一样，不需要在使用目标检测方法前将原始图像转换为灰度形式</span></span><br><span class=\"line\"><span class=\"comment\"># 该方法返回一个与矩形相关的数组，用户可用该数组在图形上绘制形状</span></span><br><span class=\"line\"><span class=\"comment\"># 若图形上的矩形存在有包含与被包含的关系，说明检测出现了错误</span></span><br><span class=\"line\"><span class=\"comment\"># 被包含的图形应该被丢弃，此过程由is_inside来实现</span></span><br><span class=\"line\"><span class=\"comment\"># 在输入图像中检测不同大小的对象。检测到的对象作为列表返回</span></span><br><span class=\"line\">found, w = hog.detectMultiScale(img)</span><br><span class=\"line\"></span><br><span class=\"line\">found_filtered = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历检测结果，丢弃不含有检测目标区域的矩形。</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ri, r <span class=\"keyword\">in</span> enumerate(found):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> qi, q <span class=\"keyword\">in</span> enumerate(found):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> ri != qi <span class=\"keyword\">and</span> is_inside(r, q):</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            found_filtered.append(r)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> person <span class=\"keyword\">in</span> found_filtered:</span><br><span class=\"line\">    draw_person(img, person)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cv2.imshow(\"people detection\", img)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.waitKey(0)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.destroyAllWindows()</span></span><br><span class=\"line\">plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_4_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Hog_descriptor</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, img, cell_size=<span class=\"number\">16</span>, bin_size=<span class=\"number\">9</span>)</span>:</span></span><br><span class=\"line\">        self.img = img</span><br><span class=\"line\">        self.img = np.sqrt(img / np.max(img))</span><br><span class=\"line\">        self.img = img * <span class=\"number\">255</span></span><br><span class=\"line\">        self.cell_size = cell_size</span><br><span class=\"line\">        self.bin_size = bin_size</span><br><span class=\"line\">        self.angle_unit = int(<span class=\"number\">360</span> / self.bin_size)</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.bin_size) == int, <span class=\"string\">\"bin_size should be integer,\"</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.cell_size) == int, <span class=\"string\">\"cell_size should be integer,\"</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.angle_unit) == int, <span class=\"string\">\"bin_size should be divisible by 360\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">extract</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        height, width = self.img.shape</span><br><span class=\"line\">        gradient_magnitude, gradient_angle = self.global_gradient()</span><br><span class=\"line\">        gradient_magnitude = abs(gradient_magnitude)</span><br><span class=\"line\">        cell_gradient_vector = np.zeros((int(height / self.cell_size), int(width / self.cell_size), self.bin_size))</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                cell_magnitude = gradient_magnitude[i * self.cell_size:(i + <span class=\"number\">1</span>) * self.cell_size,</span><br><span class=\"line\">                                 j * self.cell_size:(j + <span class=\"number\">1</span>) * self.cell_size]</span><br><span class=\"line\">                cell_angle = gradient_angle[i * self.cell_size:(i + <span class=\"number\">1</span>) * self.cell_size,</span><br><span class=\"line\">                             j * self.cell_size:(j + <span class=\"number\">1</span>) * self.cell_size]</span><br><span class=\"line\">                cell_gradient_vector[i][j] = self.cell_gradient(cell_magnitude, cell_angle)</span><br><span class=\"line\"></span><br><span class=\"line\">        hog_image = self.render_gradient(np.zeros([height, width]), cell_gradient_vector)</span><br><span class=\"line\">        hog_vector = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">0</span>] - <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">1</span>] - <span class=\"number\">1</span>):</span><br><span class=\"line\">                block_vector = []</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i][j])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i][j + <span class=\"number\">1</span>])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i + <span class=\"number\">1</span>][j])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i + <span class=\"number\">1</span>][j + <span class=\"number\">1</span>])</span><br><span class=\"line\">                mag = <span class=\"keyword\">lambda</span> vector: math.sqrt(sum(i ** <span class=\"number\">2</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> vector))</span><br><span class=\"line\">                magnitude = mag(block_vector)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> magnitude != <span class=\"number\">0</span>:</span><br><span class=\"line\">                    normalize = <span class=\"keyword\">lambda</span> block_vector, magnitude: [element / magnitude <span class=\"keyword\">for</span> element <span class=\"keyword\">in</span> block_vector]</span><br><span class=\"line\">                    block_vector = normalize(block_vector, magnitude)</span><br><span class=\"line\">                hog_vector.append(block_vector)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> hog_vector, hog_image</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">global_gradient</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, <span class=\"number\">1</span>, <span class=\"number\">0</span>, ksize=<span class=\"number\">5</span>)</span><br><span class=\"line\">        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, <span class=\"number\">0</span>, <span class=\"number\">1</span>, ksize=<span class=\"number\">5</span>)</span><br><span class=\"line\">        gradient_magnitude = cv2.addWeighted(gradient_values_x, <span class=\"number\">0.5</span>, gradient_values_y, <span class=\"number\">0.5</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">        gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> gradient_magnitude, gradient_angle</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cell_gradient</span><span class=\"params\">(self, cell_magnitude, cell_angle)</span>:</span></span><br><span class=\"line\">        orientation_centers = [<span class=\"number\">0</span>] * self.bin_size</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_magnitude.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_magnitude.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                gradient_strength = cell_magnitude[i][j]</span><br><span class=\"line\">                gradient_angle = cell_angle[i][j]</span><br><span class=\"line\">                min_angle, max_angle, mod = self.get_closest_bins(gradient_angle)</span><br><span class=\"line\">                orientation_centers[min_angle] += (gradient_strength * (<span class=\"number\">1</span> - (mod / self.angle_unit)))</span><br><span class=\"line\">                orientation_centers[max_angle] += (gradient_strength * (mod / self.angle_unit))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> orientation_centers</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_closest_bins</span><span class=\"params\">(self, gradient_angle)</span>:</span></span><br><span class=\"line\">        idx = int(gradient_angle / self.angle_unit)</span><br><span class=\"line\">        mod = gradient_angle % self.angle_unit</span><br><span class=\"line\">        <span class=\"keyword\">return</span> idx, (idx + <span class=\"number\">1</span>) % self.bin_size, mod</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">render_gradient</span><span class=\"params\">(self, image, cell_gradient)</span>:</span></span><br><span class=\"line\">        cell_width = self.cell_size / <span class=\"number\">2</span></span><br><span class=\"line\">        max_mag = np.array(cell_gradient).max()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(cell_gradient.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> range(cell_gradient.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                cell_grad = cell_gradient[x][y]</span><br><span class=\"line\">                cell_grad /= max_mag</span><br><span class=\"line\">                angle = <span class=\"number\">0</span></span><br><span class=\"line\">                angle_gap = self.angle_unit</span><br><span class=\"line\">                <span class=\"keyword\">for</span> magnitude <span class=\"keyword\">in</span> cell_grad:</span><br><span class=\"line\">                    angle_radian = math.radians(angle)</span><br><span class=\"line\">                    x1 = int(x * self.cell_size + magnitude * cell_width * math.cos(angle_radian))</span><br><span class=\"line\">                    y1 = int(y * self.cell_size + magnitude * cell_width * math.sin(angle_radian))</span><br><span class=\"line\">                    x2 = int(x * self.cell_size - magnitude * cell_width * math.cos(angle_radian))</span><br><span class=\"line\">                    y2 = int(y * self.cell_size - magnitude * cell_width * math.sin(angle_radian))</span><br><span class=\"line\">                    cv2.line(image, (y1, x1), (y2, x2), int(<span class=\"number\">255</span> * math.sqrt(magnitude)))</span><br><span class=\"line\">                    angle += angle_gap</span><br><span class=\"line\">        <span class=\"keyword\">return</span> image</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/car.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"><span class=\"comment\"># img = cv2.resize(img, (128, 64))</span></span><br><span class=\"line\">hog = Hog_descriptor(img, cell_size=<span class=\"number\">8</span>, bin_size=<span class=\"number\">9</span>)</span><br><span class=\"line\">vector, image = hog.extract()</span><br><span class=\"line\">print(np.array(vector).shape)</span><br><span class=\"line\">plt.imshow(image, cmap=plt.cm.gray)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_5_1.png\"></p>\n<h3 id=\"图像金字塔\"><a href=\"#图像金字塔\" class=\"headerlink\" title=\"图像金字塔\"></a>图像金字塔</h3><p>图像金字塔是图像的多尺度表示。  </p>\n<p>构建图像金字塔：<br>1 - 获取图像<br>2 - 使用任意尺度的参数来调整（缩小）图像大小<br>3 - 平滑图像（使用高斯模糊）<br>4 - 如果图像比最小尺寸还大，则从第一步重复该过程。  </p>\n<h3 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h3><p>滑动窗口通过扫描较大图像的较小区域来解决定位问题，进而在同一图像的不同尺度下重复扫描。  </p>\n<p>该技术需将图像分解成多个部分，然后丢掉那些不太可能包含对象的部分，并对可能区域进行分类。  </p>\n<h3 id=\"非极大抑制\"><a href=\"#非极大抑制\" class=\"headerlink\" title=\"非极大抑制\"></a>非极大抑制</h3><p>非极大值抑制（Non-maximum suppression, NMS）释义为抑制不是极大值的元素，搜索局部的极大值。  </p>\n<p>如在对象检测中，滑动窗口经提取特征 —&gt; 分类器分类识别后，每个窗口都会得到一个分类和分数，但滑动窗口会导致很多窗口与其他窗口存在包含或大部分交叉的情况，这时就需要用到 NMS 来选取那些邻域里分数最高（某类对象的概率最大），并抑制这些分数低的窗口。 </p>\n<p>也可理解为：目标检测的过程中，同一目标位置上会产生大量的候选框，这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框。  </p>\n<h3 id=\"使用HOG-SVM做行人检测\"><a href=\"#使用HOG-SVM做行人检测\" class=\"headerlink\" title=\"使用HOG+SVM做行人检测\"></a>使用HOG+SVM做行人检测</h3><p>参考2005年CVPR论文，使用HOG+SVM做行人检测<br>论文链接：  </p>\n<ul>\n<li>Histograms of Oriented Gradients for Human Detection<br><a href=\"https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf\" target=\"_blank\" rel=\"noopener\">https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf</a></li>\n</ul>\n<p>工作流程：首先对输入的图片进行预处理，然后计算像素点的梯度值，然后形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行高维的vector）放到SVM里进行监督学习，从而实现行人的检测。<br><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/./OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png\" alt=\"Histograms of Oriented Gradients for Human Detection\"></p>\n<h3 id=\"INRIA数据集\"><a href=\"#INRIA数据集\" class=\"headerlink\" title=\"INRIA数据集\"></a>INRIA数据集</h3><p>INRIA数据集官方页面：  </p>\n<ul>\n<li><a href=\"http://pascal.inrialpes.fr/data/human/\" target=\"_blank\" rel=\"noopener\">http://pascal.inrialpes.fr/data/human/</a></li>\n</ul>\n<p>整理版本：  </p>\n<ul>\n<li>INRIA数据集 - baiyu33的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/baiyu33/article/details/51762368\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baiyu33/article/details/51762368</a></li>\n</ul>\n<h3 id=\"HardExample\"><a href=\"#HardExample\" class=\"headerlink\" title=\"HardExample\"></a>HardExample</h3><p>用分类器对样本进行分类，把其中错误分类的样本(hard negative)放入负样本集合再继续训练分类器。  </p>\n<p>难例(或叫做难样本，Hard Example，Hard Negative，Hard Instance)是指利用第一次训练的分类器在负样本原图(肯定没有人体)上进行行人检测时所有检测到的矩形框，这些矩形框区域很明显都是误报，把这些误报的矩形框保存为图片，加入到初始的负样本集合中，重新进行SVM的训练，可显著减少误报。这种方法叫做自举法(Bootstrap)，自举法首先使用初始负样本集来训练一个模型，然后收集被这个初始模型错误分类的负样本来形成一个负样本难例集。用此负样本难例集训练新的模型，此过程可以重复多次。</p>\n<h3 id=\"OHEM\"><a href=\"#OHEM\" class=\"headerlink\" title=\"OHEM\"></a>OHEM</h3><p>在线难例挖掘（online hard example miniing）<br>选取loss较大(检测结果与label差异较大)的部分进行训练。  </p>\n<h3 id=\"基于深度学习的方法\"><a href=\"#基于深度学习的方法\" class=\"headerlink\" title=\"基于深度学习的方法\"></a>基于深度学习的方法</h3><ul>\n<li>RCNN </li>\n<li>Fast-RCNN</li>\n<li>YOLO</li>\n<li>SSD</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li>OpenCV 学习笔记 07 目标检测与识别 - 耕毅 - 博客园<br><a href=\"https://www.cnblogs.com/gengyi/p/10555622.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gengyi/p/10555622.html</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> OpenCV学习笔记四：目标检测与识别：</strong> <excerpt in index | 首页摘要> </excerpt></p>\n<h3 id=\"目标检测和识别\"><a href=\"#目标检测和识别\" class=\"headerlink\" title=\"目标检测和识别\"></a>目标检测和识别</h3><p>传统目标检测算法中的技术：  </p>\n<ul>\n<li>梯度直方图（Histogram of Oriented Gradient， HOG）  </li>\n<li>图像金字塔（image pyramid）  </li>\n<li>滑动窗口（sliding window）  </li>\n</ul>","more":"<the rest of contents | 余下全文>\n\n<p>与特征检测算法不同，这些算法是互补的。如在梯度直方图（HOG）中会使用滑动窗口技术。</p>\n<h3 id=\"HOG\"><a href=\"#HOG\" class=\"headerlink\" title=\"HOG\"></a>HOG</h3><ul>\n<li>Histogram of Oriented Gradients | Learn OpenCV<br><a href=\"https://www.learnopencv.com/histogram-of-oriented-gradients/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/histogram-of-oriented-gradients/</a>  </li>\n</ul>\n<p>HOG，全称方向梯度直方图，是一个特征描述符，它基于梯度来计算直方图。</p>\n<p>步骤：<br>1）图像预处理<br>包括伽马矫正和灰度化，可选步骤。<br>为了减少光照因素的影响，首先需要将整个图像进行规范化（归一化）。在图像的纹理强度中，局部的表层曝光贡献的比重较大，所以，这种压缩处理能够有效地降低图像局部的阴影和光照变化；<br>因为颜色信息作用不大，通常先转化为灰度图。 </p>\n<p>2）计算每个像素点的梯度<br>计算图像横坐标和纵坐标方向的梯度，并据此计算每个像素位置的梯度方向值；求导操作不仅能够捕获轮廓，人影和一些纹理信息，还能进一步弱化光照的影响。<br>图像中像素点$(x,y)$的梯度为：  </p>\n<script type=\"math/tex; mode=display\">G_x(x,y) = H(x+1,y) - H(x-1,y)</script><script type=\"math/tex; mode=display\">G_y(x,y) = H(x,y+1) - H(x,y-1)</script><p>其中$G_x(x,y)$,$G_y(x,y)$,$H(x,y)$分别表示图像中像素点$(x,y)$处的水平方向梯度、垂直方向梯度和像素值。像素点$(x,y)$处的梯度幅度和梯度方向分别为：  </p>\n<script type=\"math/tex; mode=display\">G(x,y) = \\sqrt{G_x(x,y)^2 + G_y(x,y)^2}</script><script type=\"math/tex; mode=display\">\\alpha(x,y) = \\tan^{-1}{(\\frac{G_y(x,y)}{G_x(x,y)})}</script><p>最常用的方法是：首先用[-1,0,1]梯度算子对原图像做卷积运算，得到x方向（水平方向，以向右为正方向）的梯度分量gradscalx，然后用[1,0,-1]T梯度算子对原图像做卷积运算，得到y方向（竖直方向，以向上为正方向）的梯度分量gradscaly，最后用以上公式计算该像素点的梯度大小和方向。  </p>\n<p>3）计算梯度直方图<br>梯度直方图是在一个8<em>8的cell里面计算的。那么在8</em>8的cell里面就会有8<em>8</em>2=128个值，其中2包括了梯度强度和梯度方向。通过统计形成梯度直方图，128个值将会变成9个值，大大降低了计算量，同时又对光照等环境变化更加地鲁棒。  </p>\n<p>首先将0-180度分成9个bins，分别是0，20，40…160；然后根据梯度方向值的大小，将每一个像素点的梯度幅度值分配到相应的bin上；最终得到如下图所示的直方图，一个长度为9的数组。<br><img alt=\"HOG02\" src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog02.jpg\"><br>从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。   </p>\n<p>bin值的具体计算方法如下例：<br><img alt=\"HOG01\" src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/hog01.jpg\"><br>先看两个蓝色圈圈。因为蓝圈的方向是80度，大小是2，所以该点就投给80这个bin；<br>再看两个红色圈圈。因为红色圈圈的方向是10，大小是4，因为10距离0点为10，距离20点为也为10，那么有一半的大小是投给0这个bin，还有一半的大小投给20这个bin。  </p>\n<p>4）块内归一化梯度直方图<br>归一化的目的是降低光照的影响。<br>归一化的方法是向量的每一个值除以向量的模长。  </p>\n<p>5）收集HOG特征<br>将检测窗口中所有重叠的块进行HOG特征的收集，并将它们结合成最终的特征向量供分类使用。<br>一个图像的HOG特征维数计算:<br>对于一个$64\\times128$大小的图像，按照$16\\times16$的大小提取block，将会有7个水平位置和15个竖直位可以取得，所以一共有$7\\times15=105$个block，所以我们整合所有block的vector，形成一个大的一维vector的大小将会是$36\\times105=3780$。</p>\n<h3 id=\"OpenCV-HOGDescriptor\"><a href=\"#OpenCV-HOGDescriptor\" class=\"headerlink\" title=\"OpenCV HOGDescriptor\"></a>OpenCV HOGDescriptor</h3><ul>\n<li>窗口大小 winSize(64,128)</li>\n<li>块大小 blockSize(16,16)</li>\n<li>块滑动增量 blockStride(8,8)</li>\n<li>胞元大小 cellSize(8,8)</li>\n<li>梯度方向数 nbins(9) </li>\n</ul>\n<p>在确定了上述的参数后，就可以计算出一个HOG描述子的维度了。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">size_t</span> HOGDescriptor::getDescriptorSize() <span class=\"keyword\">const</span></span><br><span class=\"line\">&#123;</span><br><span class=\"line\">    CV_Assert(blockSize.width % cellSize.width == <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        blockSize.height % cellSize.height == <span class=\"number\">0</span>);</span><br><span class=\"line\">    CV_Assert((winSize.width - blockSize.width) % blockStride.width == <span class=\"number\">0</span> &amp;&amp;</span><br><span class=\"line\">        (winSize.height - blockSize.height) % blockStride.height == <span class=\"number\">0</span> );</span><br><span class=\"line\">    <span class=\"keyword\">return</span> (<span class=\"keyword\">size_t</span>)nbins*</span><br><span class=\"line\">        (blockSize.width/cellSize.width)*</span><br><span class=\"line\">        (blockSize.height/cellSize.height)*</span><br><span class=\"line\">        ((winSize.width - blockSize.width)/blockStride.width + <span class=\"number\">1</span>)*</span><br><span class=\"line\">        ((winSize.height - blockSize.height)/blockStride.height + <span class=\"number\">1</span>);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 确定某矩形是否完全包含在另一个矩形中</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">is_inside</span><span class=\"params\">(o, i)</span>:</span></span><br><span class=\"line\">    ox, oy, ow, oh = o</span><br><span class=\"line\">    ix, iy, iw, ih = i</span><br><span class=\"line\">    <span class=\"keyword\">return</span> ox &gt; ix <span class=\"keyword\">and</span> oy &gt; iy <span class=\"keyword\">and</span> ox+ow &lt; ix+iw <span class=\"keyword\">and</span> oy + oh &lt; iy + ih</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 绘制矩形来框住检测到的人</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_person</span><span class=\"params\">(image, person)</span>:</span></span><br><span class=\"line\">    x, y, w, h = person</span><br><span class=\"line\">    cv2.rectangle(img, (x, y), (x+w, y + h), (<span class=\"number\">0</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>), <span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入图像，</span></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">\"./images/run.jpg\"</span>)</span><br><span class=\"line\"><span class=\"comment\"># 实例化HOGDescriptor对象，作为检测人的检测器</span></span><br><span class=\"line\">hog = cv2.HOGDescriptor()</span><br><span class=\"line\"><span class=\"comment\"># 设置线性SVM分类器的系数</span></span><br><span class=\"line\">hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 该和人脸算法不一样，不需要在使用目标检测方法前将原始图像转换为灰度形式</span></span><br><span class=\"line\"><span class=\"comment\"># 该方法返回一个与矩形相关的数组，用户可用该数组在图形上绘制形状</span></span><br><span class=\"line\"><span class=\"comment\"># 若图形上的矩形存在有包含与被包含的关系，说明检测出现了错误</span></span><br><span class=\"line\"><span class=\"comment\"># 被包含的图形应该被丢弃，此过程由is_inside来实现</span></span><br><span class=\"line\"><span class=\"comment\"># 在输入图像中检测不同大小的对象。检测到的对象作为列表返回</span></span><br><span class=\"line\">found, w = hog.detectMultiScale(img)</span><br><span class=\"line\"></span><br><span class=\"line\">found_filtered = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历检测结果，丢弃不含有检测目标区域的矩形。</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> ri, r <span class=\"keyword\">in</span> enumerate(found):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> qi, q <span class=\"keyword\">in</span> enumerate(found):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> ri != qi <span class=\"keyword\">and</span> is_inside(r, q):</span><br><span class=\"line\">            <span class=\"keyword\">break</span></span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            found_filtered.append(r)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> person <span class=\"keyword\">in</span> found_filtered:</span><br><span class=\"line\">    draw_person(img, person)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cv2.imshow(\"people detection\", img)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.waitKey(0)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.destroyAllWindows()</span></span><br><span class=\"line\">plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_4_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Hog_descriptor</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, img, cell_size=<span class=\"number\">16</span>, bin_size=<span class=\"number\">9</span>)</span>:</span></span><br><span class=\"line\">        self.img = img</span><br><span class=\"line\">        self.img = np.sqrt(img / np.max(img))</span><br><span class=\"line\">        self.img = img * <span class=\"number\">255</span></span><br><span class=\"line\">        self.cell_size = cell_size</span><br><span class=\"line\">        self.bin_size = bin_size</span><br><span class=\"line\">        self.angle_unit = int(<span class=\"number\">360</span> / self.bin_size)</span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.bin_size) == int, <span class=\"string\">\"bin_size should be integer,\"</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.cell_size) == int, <span class=\"string\">\"cell_size should be integer,\"</span></span><br><span class=\"line\">        <span class=\"keyword\">assert</span> type(self.angle_unit) == int, <span class=\"string\">\"bin_size should be divisible by 360\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">extract</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        height, width = self.img.shape</span><br><span class=\"line\">        gradient_magnitude, gradient_angle = self.global_gradient()</span><br><span class=\"line\">        gradient_magnitude = abs(gradient_magnitude)</span><br><span class=\"line\">        cell_gradient_vector = np.zeros((int(height / self.cell_size), int(width / self.cell_size), self.bin_size))</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                cell_magnitude = gradient_magnitude[i * self.cell_size:(i + <span class=\"number\">1</span>) * self.cell_size,</span><br><span class=\"line\">                                 j * self.cell_size:(j + <span class=\"number\">1</span>) * self.cell_size]</span><br><span class=\"line\">                cell_angle = gradient_angle[i * self.cell_size:(i + <span class=\"number\">1</span>) * self.cell_size,</span><br><span class=\"line\">                             j * self.cell_size:(j + <span class=\"number\">1</span>) * self.cell_size]</span><br><span class=\"line\">                cell_gradient_vector[i][j] = self.cell_gradient(cell_magnitude, cell_angle)</span><br><span class=\"line\"></span><br><span class=\"line\">        hog_image = self.render_gradient(np.zeros([height, width]), cell_gradient_vector)</span><br><span class=\"line\">        hog_vector = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">0</span>] - <span class=\"number\">1</span>):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_gradient_vector.shape[<span class=\"number\">1</span>] - <span class=\"number\">1</span>):</span><br><span class=\"line\">                block_vector = []</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i][j])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i][j + <span class=\"number\">1</span>])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i + <span class=\"number\">1</span>][j])</span><br><span class=\"line\">                block_vector.extend(cell_gradient_vector[i + <span class=\"number\">1</span>][j + <span class=\"number\">1</span>])</span><br><span class=\"line\">                mag = <span class=\"keyword\">lambda</span> vector: math.sqrt(sum(i ** <span class=\"number\">2</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> vector))</span><br><span class=\"line\">                magnitude = mag(block_vector)</span><br><span class=\"line\">                <span class=\"keyword\">if</span> magnitude != <span class=\"number\">0</span>:</span><br><span class=\"line\">                    normalize = <span class=\"keyword\">lambda</span> block_vector, magnitude: [element / magnitude <span class=\"keyword\">for</span> element <span class=\"keyword\">in</span> block_vector]</span><br><span class=\"line\">                    block_vector = normalize(block_vector, magnitude)</span><br><span class=\"line\">                hog_vector.append(block_vector)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> hog_vector, hog_image</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">global_gradient</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, <span class=\"number\">1</span>, <span class=\"number\">0</span>, ksize=<span class=\"number\">5</span>)</span><br><span class=\"line\">        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, <span class=\"number\">0</span>, <span class=\"number\">1</span>, ksize=<span class=\"number\">5</span>)</span><br><span class=\"line\">        gradient_magnitude = cv2.addWeighted(gradient_values_x, <span class=\"number\">0.5</span>, gradient_values_y, <span class=\"number\">0.5</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">        gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=<span class=\"literal\">True</span>)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> gradient_magnitude, gradient_angle</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">cell_gradient</span><span class=\"params\">(self, cell_magnitude, cell_angle)</span>:</span></span><br><span class=\"line\">        orientation_centers = [<span class=\"number\">0</span>] * self.bin_size</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(cell_magnitude.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(cell_magnitude.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                gradient_strength = cell_magnitude[i][j]</span><br><span class=\"line\">                gradient_angle = cell_angle[i][j]</span><br><span class=\"line\">                min_angle, max_angle, mod = self.get_closest_bins(gradient_angle)</span><br><span class=\"line\">                orientation_centers[min_angle] += (gradient_strength * (<span class=\"number\">1</span> - (mod / self.angle_unit)))</span><br><span class=\"line\">                orientation_centers[max_angle] += (gradient_strength * (mod / self.angle_unit))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> orientation_centers</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">get_closest_bins</span><span class=\"params\">(self, gradient_angle)</span>:</span></span><br><span class=\"line\">        idx = int(gradient_angle / self.angle_unit)</span><br><span class=\"line\">        mod = gradient_angle % self.angle_unit</span><br><span class=\"line\">        <span class=\"keyword\">return</span> idx, (idx + <span class=\"number\">1</span>) % self.bin_size, mod</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">render_gradient</span><span class=\"params\">(self, image, cell_gradient)</span>:</span></span><br><span class=\"line\">        cell_width = self.cell_size / <span class=\"number\">2</span></span><br><span class=\"line\">        max_mag = np.array(cell_gradient).max()</span><br><span class=\"line\">        <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(cell_gradient.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">            <span class=\"keyword\">for</span> y <span class=\"keyword\">in</span> range(cell_gradient.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">                cell_grad = cell_gradient[x][y]</span><br><span class=\"line\">                cell_grad /= max_mag</span><br><span class=\"line\">                angle = <span class=\"number\">0</span></span><br><span class=\"line\">                angle_gap = self.angle_unit</span><br><span class=\"line\">                <span class=\"keyword\">for</span> magnitude <span class=\"keyword\">in</span> cell_grad:</span><br><span class=\"line\">                    angle_radian = math.radians(angle)</span><br><span class=\"line\">                    x1 = int(x * self.cell_size + magnitude * cell_width * math.cos(angle_radian))</span><br><span class=\"line\">                    y1 = int(y * self.cell_size + magnitude * cell_width * math.sin(angle_radian))</span><br><span class=\"line\">                    x2 = int(x * self.cell_size - magnitude * cell_width * math.cos(angle_radian))</span><br><span class=\"line\">                    y2 = int(y * self.cell_size - magnitude * cell_width * math.sin(angle_radian))</span><br><span class=\"line\">                    cv2.line(image, (y1, x1), (y2, x2), int(<span class=\"number\">255</span> * math.sqrt(magnitude)))</span><br><span class=\"line\">                    angle += angle_gap</span><br><span class=\"line\">        <span class=\"keyword\">return</span> image</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/car.jpg'</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"><span class=\"comment\"># img = cv2.resize(img, (128, 64))</span></span><br><span class=\"line\">hog = Hog_descriptor(img, cell_size=<span class=\"number\">8</span>, bin_size=<span class=\"number\">9</span>)</span><br><span class=\"line\">vector, image = hog.extract()</span><br><span class=\"line\">print(np.array(vector).shape)</span><br><span class=\"line\">plt.imshow(image, cmap=plt.cm.gray)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/output_5_1.png\"></p>\n<h3 id=\"图像金字塔\"><a href=\"#图像金字塔\" class=\"headerlink\" title=\"图像金字塔\"></a>图像金字塔</h3><p>图像金字塔是图像的多尺度表示。  </p>\n<p>构建图像金字塔：<br>1 - 获取图像<br>2 - 使用任意尺度的参数来调整（缩小）图像大小<br>3 - 平滑图像（使用高斯模糊）<br>4 - 如果图像比最小尺寸还大，则从第一步重复该过程。  </p>\n<h3 id=\"滑动窗口\"><a href=\"#滑动窗口\" class=\"headerlink\" title=\"滑动窗口\"></a>滑动窗口</h3><p>滑动窗口通过扫描较大图像的较小区域来解决定位问题，进而在同一图像的不同尺度下重复扫描。  </p>\n<p>该技术需将图像分解成多个部分，然后丢掉那些不太可能包含对象的部分，并对可能区域进行分类。  </p>\n<h3 id=\"非极大抑制\"><a href=\"#非极大抑制\" class=\"headerlink\" title=\"非极大抑制\"></a>非极大抑制</h3><p>非极大值抑制（Non-maximum suppression, NMS）释义为抑制不是极大值的元素，搜索局部的极大值。  </p>\n<p>如在对象检测中，滑动窗口经提取特征 —&gt; 分类器分类识别后，每个窗口都会得到一个分类和分数，但滑动窗口会导致很多窗口与其他窗口存在包含或大部分交叉的情况，这时就需要用到 NMS 来选取那些邻域里分数最高（某类对象的概率最大），并抑制这些分数低的窗口。 </p>\n<p>也可理解为：目标检测的过程中，同一目标位置上会产生大量的候选框，这些候选框相互之间可能会有重叠，此时我们需要利用非极大值抑制找到最佳的目标边界框，消除冗余的边界框。  </p>\n<h3 id=\"使用HOG-SVM做行人检测\"><a href=\"#使用HOG-SVM做行人检测\" class=\"headerlink\" title=\"使用HOG+SVM做行人检测\"></a>使用HOG+SVM做行人检测</h3><p>参考2005年CVPR论文，使用HOG+SVM做行人检测<br>论文链接：  </p>\n<ul>\n<li>Histograms of Oriented Gradients for Human Detection<br><a href=\"https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf\" target=\"_blank\" rel=\"noopener\">https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf</a></li>\n</ul>\n<p>工作流程：首先对输入的图片进行预处理，然后计算像素点的梯度值，然后形成梯度直方图，然后对blocks进行normalize，最后收集到HOG feature（其实是一行高维的vector）放到SVM里进行监督学习，从而实现行人的检测。<br><img src=\"/2019/06/23/OpenCV学习笔记四：目标检测与识别/./OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png\" alt=\"Histograms of Oriented Gradients for Human Detection\"></p>\n<h3 id=\"INRIA数据集\"><a href=\"#INRIA数据集\" class=\"headerlink\" title=\"INRIA数据集\"></a>INRIA数据集</h3><p>INRIA数据集官方页面：  </p>\n<ul>\n<li><a href=\"http://pascal.inrialpes.fr/data/human/\" target=\"_blank\" rel=\"noopener\">http://pascal.inrialpes.fr/data/human/</a></li>\n</ul>\n<p>整理版本：  </p>\n<ul>\n<li>INRIA数据集 - baiyu33的博客 - CSDN博客<br><a href=\"https://blog.csdn.net/baiyu33/article/details/51762368\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/baiyu33/article/details/51762368</a></li>\n</ul>\n<h3 id=\"HardExample\"><a href=\"#HardExample\" class=\"headerlink\" title=\"HardExample\"></a>HardExample</h3><p>用分类器对样本进行分类，把其中错误分类的样本(hard negative)放入负样本集合再继续训练分类器。  </p>\n<p>难例(或叫做难样本，Hard Example，Hard Negative，Hard Instance)是指利用第一次训练的分类器在负样本原图(肯定没有人体)上进行行人检测时所有检测到的矩形框，这些矩形框区域很明显都是误报，把这些误报的矩形框保存为图片，加入到初始的负样本集合中，重新进行SVM的训练，可显著减少误报。这种方法叫做自举法(Bootstrap)，自举法首先使用初始负样本集来训练一个模型，然后收集被这个初始模型错误分类的负样本来形成一个负样本难例集。用此负样本难例集训练新的模型，此过程可以重复多次。</p>\n<h3 id=\"OHEM\"><a href=\"#OHEM\" class=\"headerlink\" title=\"OHEM\"></a>OHEM</h3><p>在线难例挖掘（online hard example miniing）<br>选取loss较大(检测结果与label差异较大)的部分进行训练。  </p>\n<h3 id=\"基于深度学习的方法\"><a href=\"#基于深度学习的方法\" class=\"headerlink\" title=\"基于深度学习的方法\"></a>基于深度学习的方法</h3><ul>\n<li>RCNN </li>\n<li>Fast-RCNN</li>\n<li>YOLO</li>\n<li>SSD</li>\n</ul>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li>OpenCV 学习笔记 07 目标检测与识别 - 耕毅 - 博客园<br><a href=\"https://www.cnblogs.com/gengyi/p/10555622.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gengyi/p/10555622.html</a></li>\n</ul>\n</the>"},{"title":"天猫精灵，开灯","date":"2019-04-20T13:20:13.000Z","_content":"\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n## 整体方案\n\n天猫精灵协议的对接是云服务器与云服务器的对接，并不支持与硬件设备的直接对接。下图展示了智能硬件的接入方式：用户的语音指令通过天猫精灵上传阿里云语音服务器通过解析后发送响应的协议到云服务器，然后控制云再与硬件设备进行沟通控制。\n<div align=center>\n<img src = \"天猫精灵，开灯/1.png\" width=600 height=300>\n</div>\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n采用花生壳内网穿透的方法，部署一台ubuntu 16.04作为服务器。使用Apache2搭建一个web服务器用于解析域名和php文本，为域名申请SSL证书，部署Apahce2下的https服务器，安装MySQL数据库用于http协议下频繁的数据存储和查询读取和OAuth2.0服务器的搭建。AliGenie平台通过OAuth2.0在不需要注册新设备用户的同时使用用户已有的账号获得智能硬件的认证系统的授权，使得天猫精灵能够访问智能硬件，然后完成指令的交互。\n<div align=center>\n<img src = \"天猫精灵，开灯/2.png\" width=600 height=300>\n</div>\n懒得搭服务器可以考虑下第三方平台，比如HomeAssistant、贝壳物联\n\n## 准备\n* 路由器\n* 实验室主机一台\n* 花生棒\n* esp8266\n* 天猫精灵\n\n## 花生棒设置\n访问https://b.oray.com/ \n内网穿透中增加两个映射\n映射一\n* 映射类型 HTTP80\n* 外网端口 80\n* 内网主机 192.168.1.241\n* 内网端口 80\n映射二\n* 映射类型 通用应用\n* 外网端口 动态端口号\n* 内网主机 192.168.1.241\n* 内网端口 443\n\n## 服务器部署\n### apache2+php7.0 web服务器的构建\n安装apathe\n``` bash\n$ sudo apt-get install apache2\n```\n安装php\n``` bash\n$ sudo apt-get install php\n```\n配置apache2支持php7\n``` bash\n$ sudo apt-get install libapache2-mod-php\n```\n重启一下apache2\n``` bash\n$ sudo service apache2 restart\n```\n\n配置DPO\n``` bash\n$ sudo apt-get install php7.0-mysql\n$ sudo phpenmod pdo_mysql\n$ sudo service apache2 restart\n```\n\n``` bash\n$ sudo vim /etc/php/7.0/mods-available/pdo.ini\n\n    ;extension=pdo.so\n```\n\n``` bash\n$ sudo vim /etc/php/7.0/apache2/php.ini\n\n    extension=/usr/lib/php/20151012/mysqli.so\n    extension=/usr/lib/php/20151012/mysqlnd.so\n    extension=/usr/lib/php/20151012/pdo.so\n    extension=/usr/lib/php/20151012/pdo_mysql.so\n```\n\n\n### 申请SSL证书\nSSL For Free工具官方网站\n* https://www.sslforfree.com/\n\n输入域名点击后面的Create Free SSL Certificate按钮获取，选择手工验证方式Manual Verification，点击Manually Verify Domain，根据提示的步骤进行，下载文件，然后对应添加文件夹，然后激活验证链接\n``` bash\n$ cd /var/www/html/\n$ sudo mkdir .well-known\n$ cd .well-known/\n$ sudo mkdir acme-challenge\n$ cd acme-challenge/\n$ sudo chmod 777 -R /var/www/html/\n```\n设置到期后通知邮箱，下载证书\n\n### 部署HTTPS服务器\n安装openssl\n``` bash\n$ sudo apt-get install openssl\n```\n开启SSL模块\n``` bash\n$ sudo a2enmod ssl\n```\n拷贝证书到相应目录，指定SSL证书\n\n``` bash\nSSLCertificateFile      /etc/ssl/certs/certificate.crt\nSSLCertificateKeyFile   /etc/ssl/private/private.key\nSSLCertificateChainFile /etc/ssl/private/ca_bundle.crt\n```\n\n``` bash\n$ sudo chmod 777 -R /etc/ssl/\n$ cd /etc/apache2/\n$ cat ports.conf\n    \n    # If you just change the port or add more ports here, you will likely also\n    # have to change the VirtualHost statement in\n    # /etc/apache2/sites-enabled/000-default.conf\n\n    Listen 80\n\n    <IfModule ssl_module>\n            Listen 443\n    </IfModule>\n\n    <IfModule mod_gnutls.c>\n            Listen 443\n    </IfModule>\n```\n建立软链\n``` bash\n$ sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/\n```\n修改default-ssl.conf\n``` bash\n$ sudo apt-get install vim\n$ sudo vim /etc/apache2/sites-available/default-ssl.conf\n\n    SSLProtocol all -SSLv2 -SSLv3\n    SSLCertificateFile      /etc/ssl/certs/certificate.crt\n    SSLCertificateKeyFile   /etc/ssl/private/private.key\n    SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt\n```\n\n通过a2ensite激活站点\n``` bash\n$ sudo a2ensite default-ssl.conf\n```\n重启apache\n``` bash\n$ sudo service apache2 restart\n```\n### 安装MySQL\n``` bash\n$ sudo apt-get install mysql-server mysql-client\n```\n下载安装oauth2-server\n``` bash\n$ cd /var/www/html/\n$ sudo apt-get install git\n$ git clone https://github.com/bshaffer/oauth2-server-php.git -b master\n```\n建立数据库\n``` bash\n$ mysql -u root -p\n```\n\n``` bash\nmysql> create database ilamp;\nmysql> use ilamp;\nmysql> CREATE TABLE `oauth_access_tokens` (\n         `access_token` VARCHAR(40) NOT NULL,\n         `client_id`    VARCHAR(80) NOT NULL,\n         `user_id`  VARCHAR(255),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         PRIMARY KEY (access_token));\nmysql>  CREATE TABLE `oauth_authorization_codes` (\n         `authorization_code` VARCHAR(40) NOT NULL,\n         `client_id` VARCHAR(80) NOT NULL,\n         `user_id` VARCHAR(255),\n         `redirect_uri` VARCHAR(2000),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         'id_token' VARCHAR(1000),\n         PRIMARY KEY (authorization_code));\nmysql>  CREATE TABLE 'oauth_clients' (\n         'client_id' VARCHAR(80) not null,\n         'client_secret' VARCHAR(80), \n         'redirect_uri' VARCHAR(2000),\n         'grant_types' VARCHAR(80),\n         'scope' VARCHAR(4000),\n         'user_id' VARCHAR(80), \n         PRIMARY KEY (client_id));\nmysql>  CREATE TABLE `oauth_refresh_tokens` ( \n         `refresh_token` VARCHAR(40) NOT NULL,\n         `client_id` VARCHAR(80) NOT NULL,\n         `user_id` VARCHAR(255),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         PRIMARY KEY (refresh_token));\nmysql> CREATE TABLE `oauth_users` (\n         `username` VARCHAR(255) NOT NULL,\n         `password` VARCHAR(2000),\n         `first_name` VARCHAR(255),\n         `last_name` VARCHAR(255),\n         PRIMARY KEY (username));\nmysql> CREATE TABLE `oauth_scopes` (\n         'scope' VARCHAR(80) not null,\n         'is_default' boolean,\n         PRIMARY KEY(scope));\nmysql> CREATE TABLE `oauth_jwt` (\n         'client_id' VARCHAR(80) not null,\n         'subject' VARCHAR(80),\n         'public_key' VARCHAR(2000) not null);\nmysql> show tables;\n+---------------------------+\n| Tables_in_ilamp           |\n+---------------------------+\n| oauth_access_tokens       |\n| oauth_authorization_codes |\n| oauth_clients             |\n| oauth_jwt                 |\n| oauth_refresh_tokens      |\n| oauth_scopes              |\n| oauth_users               |\n+---------------------------+\nmysql> insert into oauth_clients (client_id, client_secret, redirect_uri ) values (\"id\",\"psw\",\"https://open.bot.tmall.com/oauth/callback\");\n```\n\n## 天猫精灵新加技能\n\n登录开发者平台AliGenie - 语音开发者平台  https://open.aligenie.com/\n发布新技能。\n\n### 服务设置\nOAuth2\n* 账户授权连接: https://xxxx/authorize.php\n* ClientID: id\n* Client Secret: psw\n* 跳转 URL: https://open.bot.tmall.com/oauth/callback\n* Access Token URL: https://xxx/token.php\n* 厂商登出 URL: 暂无描述\n\n设备管理\n* 开发者网关地址: https://xxx/gate.php\n* 设备管理跳转连接: 暂无描述\n\n\n### 开机跳过用户登录\n打开 系统设置 中的 用户帐户;  \n打开用户帐户设置窗口后，点击右上角的\"解锁\"按钮;  \n将自动登录设置为“开启”。\n\n\n## 参考博客\n* esp8266对接天猫精灵（1）前言 - CSDN博客  \nhttps://blog.csdn.net/qq_35527832/article/details/79143899\n* 天猫精灵接入HomeAssistant  \nhttps://weibo.com/ttarticle/p/show?id=2309404195482120392395\n* GitHub - c1pher-cn/tmall-bot-x1: 天猫精灵智能家居技能对接homeassistant  \nhttps://github.com/c1pher-cn/tmall-bot-x1\n* 【新提醒】天猫精灵接入HomeAssistant【智能家居技能接入，非webhook调用】 - 『HomeAssistant』智能硬件讨论区 - 『瀚思彼岸』» 智能家居第一站 - Hassbian.com  \nhttps://bbs.hassbian.com/thread-1862-1-1.html\n* AliGenie开发者平台  \nhttp://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&id=332356&tagId=null\n","source":"_posts/天猫精灵，开灯.md","raw":"---\ntitle: 天猫精灵，开灯\ndate: 2019-04-20 21:20:13\ntags: \n  - 天猫精灵\n  - esp8266\n  - php\n  - mysql\n---\n\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n## 整体方案\n\n天猫精灵协议的对接是云服务器与云服务器的对接，并不支持与硬件设备的直接对接。下图展示了智能硬件的接入方式：用户的语音指令通过天猫精灵上传阿里云语音服务器通过解析后发送响应的协议到云服务器，然后控制云再与硬件设备进行沟通控制。\n<div align=center>\n<img src = \"天猫精灵，开灯/1.png\" width=600 height=300>\n</div>\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n采用花生壳内网穿透的方法，部署一台ubuntu 16.04作为服务器。使用Apache2搭建一个web服务器用于解析域名和php文本，为域名申请SSL证书，部署Apahce2下的https服务器，安装MySQL数据库用于http协议下频繁的数据存储和查询读取和OAuth2.0服务器的搭建。AliGenie平台通过OAuth2.0在不需要注册新设备用户的同时使用用户已有的账号获得智能硬件的认证系统的授权，使得天猫精灵能够访问智能硬件，然后完成指令的交互。\n<div align=center>\n<img src = \"天猫精灵，开灯/2.png\" width=600 height=300>\n</div>\n懒得搭服务器可以考虑下第三方平台，比如HomeAssistant、贝壳物联\n\n## 准备\n* 路由器\n* 实验室主机一台\n* 花生棒\n* esp8266\n* 天猫精灵\n\n## 花生棒设置\n访问https://b.oray.com/ \n内网穿透中增加两个映射\n映射一\n* 映射类型 HTTP80\n* 外网端口 80\n* 内网主机 192.168.1.241\n* 内网端口 80\n映射二\n* 映射类型 通用应用\n* 外网端口 动态端口号\n* 内网主机 192.168.1.241\n* 内网端口 443\n\n## 服务器部署\n### apache2+php7.0 web服务器的构建\n安装apathe\n``` bash\n$ sudo apt-get install apache2\n```\n安装php\n``` bash\n$ sudo apt-get install php\n```\n配置apache2支持php7\n``` bash\n$ sudo apt-get install libapache2-mod-php\n```\n重启一下apache2\n``` bash\n$ sudo service apache2 restart\n```\n\n配置DPO\n``` bash\n$ sudo apt-get install php7.0-mysql\n$ sudo phpenmod pdo_mysql\n$ sudo service apache2 restart\n```\n\n``` bash\n$ sudo vim /etc/php/7.0/mods-available/pdo.ini\n\n    ;extension=pdo.so\n```\n\n``` bash\n$ sudo vim /etc/php/7.0/apache2/php.ini\n\n    extension=/usr/lib/php/20151012/mysqli.so\n    extension=/usr/lib/php/20151012/mysqlnd.so\n    extension=/usr/lib/php/20151012/pdo.so\n    extension=/usr/lib/php/20151012/pdo_mysql.so\n```\n\n\n### 申请SSL证书\nSSL For Free工具官方网站\n* https://www.sslforfree.com/\n\n输入域名点击后面的Create Free SSL Certificate按钮获取，选择手工验证方式Manual Verification，点击Manually Verify Domain，根据提示的步骤进行，下载文件，然后对应添加文件夹，然后激活验证链接\n``` bash\n$ cd /var/www/html/\n$ sudo mkdir .well-known\n$ cd .well-known/\n$ sudo mkdir acme-challenge\n$ cd acme-challenge/\n$ sudo chmod 777 -R /var/www/html/\n```\n设置到期后通知邮箱，下载证书\n\n### 部署HTTPS服务器\n安装openssl\n``` bash\n$ sudo apt-get install openssl\n```\n开启SSL模块\n``` bash\n$ sudo a2enmod ssl\n```\n拷贝证书到相应目录，指定SSL证书\n\n``` bash\nSSLCertificateFile      /etc/ssl/certs/certificate.crt\nSSLCertificateKeyFile   /etc/ssl/private/private.key\nSSLCertificateChainFile /etc/ssl/private/ca_bundle.crt\n```\n\n``` bash\n$ sudo chmod 777 -R /etc/ssl/\n$ cd /etc/apache2/\n$ cat ports.conf\n    \n    # If you just change the port or add more ports here, you will likely also\n    # have to change the VirtualHost statement in\n    # /etc/apache2/sites-enabled/000-default.conf\n\n    Listen 80\n\n    <IfModule ssl_module>\n            Listen 443\n    </IfModule>\n\n    <IfModule mod_gnutls.c>\n            Listen 443\n    </IfModule>\n```\n建立软链\n``` bash\n$ sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/\n```\n修改default-ssl.conf\n``` bash\n$ sudo apt-get install vim\n$ sudo vim /etc/apache2/sites-available/default-ssl.conf\n\n    SSLProtocol all -SSLv2 -SSLv3\n    SSLCertificateFile      /etc/ssl/certs/certificate.crt\n    SSLCertificateKeyFile   /etc/ssl/private/private.key\n    SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt\n```\n\n通过a2ensite激活站点\n``` bash\n$ sudo a2ensite default-ssl.conf\n```\n重启apache\n``` bash\n$ sudo service apache2 restart\n```\n### 安装MySQL\n``` bash\n$ sudo apt-get install mysql-server mysql-client\n```\n下载安装oauth2-server\n``` bash\n$ cd /var/www/html/\n$ sudo apt-get install git\n$ git clone https://github.com/bshaffer/oauth2-server-php.git -b master\n```\n建立数据库\n``` bash\n$ mysql -u root -p\n```\n\n``` bash\nmysql> create database ilamp;\nmysql> use ilamp;\nmysql> CREATE TABLE `oauth_access_tokens` (\n         `access_token` VARCHAR(40) NOT NULL,\n         `client_id`    VARCHAR(80) NOT NULL,\n         `user_id`  VARCHAR(255),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         PRIMARY KEY (access_token));\nmysql>  CREATE TABLE `oauth_authorization_codes` (\n         `authorization_code` VARCHAR(40) NOT NULL,\n         `client_id` VARCHAR(80) NOT NULL,\n         `user_id` VARCHAR(255),\n         `redirect_uri` VARCHAR(2000),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         'id_token' VARCHAR(1000),\n         PRIMARY KEY (authorization_code));\nmysql>  CREATE TABLE 'oauth_clients' (\n         'client_id' VARCHAR(80) not null,\n         'client_secret' VARCHAR(80), \n         'redirect_uri' VARCHAR(2000),\n         'grant_types' VARCHAR(80),\n         'scope' VARCHAR(4000),\n         'user_id' VARCHAR(80), \n         PRIMARY KEY (client_id));\nmysql>  CREATE TABLE `oauth_refresh_tokens` ( \n         `refresh_token` VARCHAR(40) NOT NULL,\n         `client_id` VARCHAR(80) NOT NULL,\n         `user_id` VARCHAR(255),\n         `expires` TIMESTAMP NOT NULL,\n         `scope` VARCHAR(2000),\n         PRIMARY KEY (refresh_token));\nmysql> CREATE TABLE `oauth_users` (\n         `username` VARCHAR(255) NOT NULL,\n         `password` VARCHAR(2000),\n         `first_name` VARCHAR(255),\n         `last_name` VARCHAR(255),\n         PRIMARY KEY (username));\nmysql> CREATE TABLE `oauth_scopes` (\n         'scope' VARCHAR(80) not null,\n         'is_default' boolean,\n         PRIMARY KEY(scope));\nmysql> CREATE TABLE `oauth_jwt` (\n         'client_id' VARCHAR(80) not null,\n         'subject' VARCHAR(80),\n         'public_key' VARCHAR(2000) not null);\nmysql> show tables;\n+---------------------------+\n| Tables_in_ilamp           |\n+---------------------------+\n| oauth_access_tokens       |\n| oauth_authorization_codes |\n| oauth_clients             |\n| oauth_jwt                 |\n| oauth_refresh_tokens      |\n| oauth_scopes              |\n| oauth_users               |\n+---------------------------+\nmysql> insert into oauth_clients (client_id, client_secret, redirect_uri ) values (\"id\",\"psw\",\"https://open.bot.tmall.com/oauth/callback\");\n```\n\n## 天猫精灵新加技能\n\n登录开发者平台AliGenie - 语音开发者平台  https://open.aligenie.com/\n发布新技能。\n\n### 服务设置\nOAuth2\n* 账户授权连接: https://xxxx/authorize.php\n* ClientID: id\n* Client Secret: psw\n* 跳转 URL: https://open.bot.tmall.com/oauth/callback\n* Access Token URL: https://xxx/token.php\n* 厂商登出 URL: 暂无描述\n\n设备管理\n* 开发者网关地址: https://xxx/gate.php\n* 设备管理跳转连接: 暂无描述\n\n\n### 开机跳过用户登录\n打开 系统设置 中的 用户帐户;  \n打开用户帐户设置窗口后，点击右上角的\"解锁\"按钮;  \n将自动登录设置为“开启”。\n\n\n## 参考博客\n* esp8266对接天猫精灵（1）前言 - CSDN博客  \nhttps://blog.csdn.net/qq_35527832/article/details/79143899\n* 天猫精灵接入HomeAssistant  \nhttps://weibo.com/ttarticle/p/show?id=2309404195482120392395\n* GitHub - c1pher-cn/tmall-bot-x1: 天猫精灵智能家居技能对接homeassistant  \nhttps://github.com/c1pher-cn/tmall-bot-x1\n* 【新提醒】天猫精灵接入HomeAssistant【智能家居技能接入，非webhook调用】 - 『HomeAssistant』智能硬件讨论区 - 『瀚思彼岸』» 智能家居第一站 - Hassbian.com  \nhttps://bbs.hassbian.com/thread-1862-1-1.html\n* AliGenie开发者平台  \nhttp://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&id=332356&tagId=null\n","slug":"天猫精灵，开灯","published":1,"updated":"2019-06-27T09:34:31.912Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76e003zrsvjmn27e3he","content":"<p><strong> 天猫精灵，开灯：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"整体方案\"><a href=\"#整体方案\" class=\"headerlink\" title=\"整体方案\"></a>整体方案</h2><p>天猫精灵协议的对接是云服务器与云服务器的对接，并不支持与硬件设备的直接对接。下图展示了智能硬件的接入方式：用户的语音指令通过天猫精灵上传阿里云语音服务器通过解析后发送响应的协议到云服务器，然后控制云再与硬件设备进行沟通控制。</p>\n<div align=\"center\">\n<img src=\"/2019/04/20/天猫精灵，开灯/1.png\" width=\"600\" height=\"300\">\n</div>\n\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n<p>采用花生壳内网穿透的方法，部署一台ubuntu 16.04作为服务器。使用Apache2搭建一个web服务器用于解析域名和php文本，为域名申请SSL证书，部署Apahce2下的https服务器，安装MySQL数据库用于http协议下频繁的数据存储和查询读取和OAuth2.0服务器的搭建。AliGenie平台通过OAuth2.0在不需要注册新设备用户的同时使用用户已有的账号获得智能硬件的认证系统的授权，使得天猫精灵能够访问智能硬件，然后完成指令的交互。</p>\n<p><div align=\"center\">\n<img src=\"/2019/04/20/天猫精灵，开灯/2.png\" width=\"600\" height=\"300\">\n</div><br>懒得搭服务器可以考虑下第三方平台，比如HomeAssistant、贝壳物联</p>\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>路由器</li>\n<li>实验室主机一台</li>\n<li>花生棒</li>\n<li>esp8266</li>\n<li>天猫精灵</li>\n</ul>\n<h2 id=\"花生棒设置\"><a href=\"#花生棒设置\" class=\"headerlink\" title=\"花生棒设置\"></a>花生棒设置</h2><p>访问<a href=\"https://b.oray.com/\" target=\"_blank\" rel=\"noopener\">https://b.oray.com/</a><br>内网穿透中增加两个映射<br>映射一</p>\n<ul>\n<li>映射类型 HTTP80</li>\n<li>外网端口 80</li>\n<li>内网主机 192.168.1.241</li>\n<li>内网端口 80<br>映射二</li>\n<li>映射类型 通用应用</li>\n<li>外网端口 动态端口号</li>\n<li>内网主机 192.168.1.241</li>\n<li>内网端口 443</li>\n</ul>\n<h2 id=\"服务器部署\"><a href=\"#服务器部署\" class=\"headerlink\" title=\"服务器部署\"></a>服务器部署</h2><h3 id=\"apache2-php7-0-web服务器的构建\"><a href=\"#apache2-php7-0-web服务器的构建\" class=\"headerlink\" title=\"apache2+php7.0 web服务器的构建\"></a>apache2+php7.0 web服务器的构建</h3><p>安装apathe<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install apache2</span><br></pre></td></tr></table></figure></p>\n<p>安装php<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install php</span><br></pre></td></tr></table></figure></p>\n<p>配置apache2支持php7<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install libapache2-mod-php</span><br></pre></td></tr></table></figure></p>\n<p>重启一下apache2<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<p>配置DPO<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install php7.0-mysql</span><br><span class=\"line\">$ sudo phpenmod pdo_mysql</span><br><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/php/7.0/mods-available/pdo.ini</span><br><span class=\"line\"></span><br><span class=\"line\">    ;extension=pdo.so</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/php/7.0/apache2/php.ini</span><br><span class=\"line\"></span><br><span class=\"line\">    extension=/usr/lib/php/20151012/mysqli.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/mysqlnd.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/pdo.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/pdo_mysql.so</span><br></pre></td></tr></table></figure>\n<h3 id=\"申请SSL证书\"><a href=\"#申请SSL证书\" class=\"headerlink\" title=\"申请SSL证书\"></a>申请SSL证书</h3><p>SSL For Free工具官方网站</p>\n<ul>\n<li><a href=\"https://www.sslforfree.com/\" target=\"_blank\" rel=\"noopener\">https://www.sslforfree.com/</a></li>\n</ul>\n<p>输入域名点击后面的Create Free SSL Certificate按钮获取，选择手工验证方式Manual Verification，点击Manually Verify Domain，根据提示的步骤进行，下载文件，然后对应添加文件夹，然后激活验证链接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var/www/html/</span><br><span class=\"line\">$ sudo mkdir .well-known</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> .well-known/</span><br><span class=\"line\">$ sudo mkdir acme-challenge</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> acme-challenge/</span><br><span class=\"line\">$ sudo chmod 777 -R /var/www/html/</span><br></pre></td></tr></table></figure></p>\n<p>设置到期后通知邮箱，下载证书</p>\n<h3 id=\"部署HTTPS服务器\"><a href=\"#部署HTTPS服务器\" class=\"headerlink\" title=\"部署HTTPS服务器\"></a>部署HTTPS服务器</h3><p>安装openssl<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install openssl</span><br></pre></td></tr></table></figure></p>\n<p>开启SSL模块<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo a2enmod ssl</span><br></pre></td></tr></table></figure></p>\n<p>拷贝证书到相应目录，指定SSL证书</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SSLCertificateFile      /etc/ssl/certs/certificate.crt</span><br><span class=\"line\">SSLCertificateKeyFile   /etc/ssl/private/private.key</span><br><span class=\"line\">SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo chmod 777 -R /etc/ssl/</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /etc/apache2/</span><br><span class=\"line\">$ cat ports.conf</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># If you just change the port or add more ports here, you will likely also</span></span><br><span class=\"line\">    <span class=\"comment\"># have to change the VirtualHost statement in</span></span><br><span class=\"line\">    <span class=\"comment\"># /etc/apache2/sites-enabled/000-default.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Listen 80</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;IfModule ssl_module&gt;</span><br><span class=\"line\">            Listen 443</span><br><span class=\"line\">    &lt;/IfModule&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;IfModule mod_gnutls.c&gt;</span><br><span class=\"line\">            Listen 443</span><br><span class=\"line\">    &lt;/IfModule&gt;</span><br></pre></td></tr></table></figure>\n<p>建立软链<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/</span><br></pre></td></tr></table></figure></p>\n<p>修改default-ssl.conf<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install vim</span><br><span class=\"line\">$ sudo vim /etc/apache2/sites-available/default-ssl.conf</span><br><span class=\"line\"></span><br><span class=\"line\">    SSLProtocol all -SSLv2 -SSLv3</span><br><span class=\"line\">    SSLCertificateFile      /etc/ssl/certs/certificate.crt</span><br><span class=\"line\">    SSLCertificateKeyFile   /etc/ssl/private/private.key</span><br><span class=\"line\">    SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt</span><br></pre></td></tr></table></figure></p>\n<p>通过a2ensite激活站点<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo a2ensite default-ssl.conf</span><br></pre></td></tr></table></figure></p>\n<p>重启apache<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"安装MySQL\"><a href=\"#安装MySQL\" class=\"headerlink\" title=\"安装MySQL\"></a>安装MySQL</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install mysql-server mysql-client</span><br></pre></td></tr></table></figure>\n<p>下载安装oauth2-server<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var/www/html/</span><br><span class=\"line\">$ sudo apt-get install git</span><br><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/bshaffer/oauth2-server-php.git -b master</span><br></pre></td></tr></table></figure></p>\n<p>建立数据库<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mysql -u root -p</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; create database ilamp;</span><br><span class=\"line\">mysql&gt; use ilamp;</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_access_tokens` (</span><br><span class=\"line\">         `access_token` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id`    VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id`  VARCHAR(255),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         PRIMARY KEY (access_token));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE `oauth_authorization_codes` (</span><br><span class=\"line\">         `authorization_code` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id` VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id` VARCHAR(255),</span><br><span class=\"line\">         `redirect_uri` VARCHAR(2000),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         <span class=\"string\">'id_token'</span> VARCHAR(1000),</span><br><span class=\"line\">         PRIMARY KEY (authorization_code));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE <span class=\"string\">'oauth_clients'</span> (</span><br><span class=\"line\">         <span class=\"string\">'client_id'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'client_secret'</span> VARCHAR(80), </span><br><span class=\"line\">         <span class=\"string\">'redirect_uri'</span> VARCHAR(2000),</span><br><span class=\"line\">         <span class=\"string\">'grant_types'</span> VARCHAR(80),</span><br><span class=\"line\">         <span class=\"string\">'scope'</span> VARCHAR(4000),</span><br><span class=\"line\">         <span class=\"string\">'user_id'</span> VARCHAR(80), </span><br><span class=\"line\">         PRIMARY KEY (client_id));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE `oauth_refresh_tokens` ( </span><br><span class=\"line\">         `refresh_token` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id` VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id` VARCHAR(255),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         PRIMARY KEY (refresh_token));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_users` (</span><br><span class=\"line\">         `username` VARCHAR(255) NOT NULL,</span><br><span class=\"line\">         `password` VARCHAR(2000),</span><br><span class=\"line\">         `first_name` VARCHAR(255),</span><br><span class=\"line\">         `last_name` VARCHAR(255),</span><br><span class=\"line\">         PRIMARY KEY (username));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_scopes` (</span><br><span class=\"line\">         <span class=\"string\">'scope'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'is_default'</span> boolean,</span><br><span class=\"line\">         PRIMARY KEY(scope));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_jwt` (</span><br><span class=\"line\">         <span class=\"string\">'client_id'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'subject'</span> VARCHAR(80),</span><br><span class=\"line\">         <span class=\"string\">'public_key'</span> VARCHAR(2000) not null);</span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">| Tables_in_ilamp           |</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">| oauth_access_tokens       |</span><br><span class=\"line\">| oauth_authorization_codes |</span><br><span class=\"line\">| oauth_clients             |</span><br><span class=\"line\">| oauth_jwt                 |</span><br><span class=\"line\">| oauth_refresh_tokens      |</span><br><span class=\"line\">| oauth_scopes              |</span><br><span class=\"line\">| oauth_users               |</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">mysql&gt; insert into oauth_clients (client_id, client_secret, redirect_uri ) values (<span class=\"string\">\"id\"</span>,<span class=\"string\">\"psw\"</span>,<span class=\"string\">\"https://open.bot.tmall.com/oauth/callback\"</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"天猫精灵新加技能\"><a href=\"#天猫精灵新加技能\" class=\"headerlink\" title=\"天猫精灵新加技能\"></a>天猫精灵新加技能</h2><p>登录开发者平台AliGenie - 语音开发者平台  <a href=\"https://open.aligenie.com/\" target=\"_blank\" rel=\"noopener\">https://open.aligenie.com/</a><br>发布新技能。</p>\n<h3 id=\"服务设置\"><a href=\"#服务设置\" class=\"headerlink\" title=\"服务设置\"></a>服务设置</h3><p>OAuth2</p>\n<ul>\n<li>账户授权连接: <a href=\"https://xxxx/authorize.php\" target=\"_blank\" rel=\"noopener\">https://xxxx/authorize.php</a></li>\n<li>ClientID: id</li>\n<li>Client Secret: psw</li>\n<li>跳转 URL: <a href=\"https://open.bot.tmall.com/oauth/callback\" target=\"_blank\" rel=\"noopener\">https://open.bot.tmall.com/oauth/callback</a></li>\n<li>Access Token URL: <a href=\"https://xxx/token.php\" target=\"_blank\" rel=\"noopener\">https://xxx/token.php</a></li>\n<li>厂商登出 URL: 暂无描述</li>\n</ul>\n<p>设备管理</p>\n<ul>\n<li>开发者网关地址: <a href=\"https://xxx/gate.php\" target=\"_blank\" rel=\"noopener\">https://xxx/gate.php</a></li>\n<li>设备管理跳转连接: 暂无描述</li>\n</ul>\n<h3 id=\"开机跳过用户登录\"><a href=\"#开机跳过用户登录\" class=\"headerlink\" title=\"开机跳过用户登录\"></a>开机跳过用户登录</h3><p>打开 系统设置 中的 用户帐户;<br>打开用户帐户设置窗口后，点击右上角的”解锁”按钮;<br>将自动登录设置为“开启”。</p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>esp8266对接天猫精灵（1）前言 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_35527832/article/details/79143899\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_35527832/article/details/79143899</a></li>\n<li>天猫精灵接入HomeAssistant<br><a href=\"https://weibo.com/ttarticle/p/show?id=2309404195482120392395\" target=\"_blank\" rel=\"noopener\">https://weibo.com/ttarticle/p/show?id=2309404195482120392395</a></li>\n<li>GitHub - c1pher-cn/tmall-bot-x1: 天猫精灵智能家居技能对接homeassistant<br><a href=\"https://github.com/c1pher-cn/tmall-bot-x1\" target=\"_blank\" rel=\"noopener\">https://github.com/c1pher-cn/tmall-bot-x1</a></li>\n<li>【新提醒】天猫精灵接入HomeAssistant【智能家居技能接入，非webhook调用】 - 『HomeAssistant』智能硬件讨论区 - 『瀚思彼岸』» 智能家居第一站 - Hassbian.com<br><a href=\"https://bbs.hassbian.com/thread-1862-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.hassbian.com/thread-1862-1-1.html</a></li>\n<li>AliGenie开发者平台<br><a href=\"http://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&amp;id=332356&amp;tagId=null\" target=\"_blank\" rel=\"noopener\">http://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&amp;id=332356&amp;tagId=null</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 天猫精灵，开灯：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"整体方案\"><a href=\"#整体方案\" class=\"headerlink\" title=\"整体方案\"></a>整体方案</h2><p>天猫精灵协议的对接是云服务器与云服务器的对接，并不支持与硬件设备的直接对接。下图展示了智能硬件的接入方式：用户的语音指令通过天猫精灵上传阿里云语音服务器通过解析后发送响应的协议到云服务器，然后控制云再与硬件设备进行沟通控制。</p>\n<div align=\"center\">\n<img src=\"/2019/04/20/天猫精灵，开灯/1.png\" width=\"600\" height=\"300\">\n</div>","more":"<the rest of contents | 余下全文>\n\n<p>采用花生壳内网穿透的方法，部署一台ubuntu 16.04作为服务器。使用Apache2搭建一个web服务器用于解析域名和php文本，为域名申请SSL证书，部署Apahce2下的https服务器，安装MySQL数据库用于http协议下频繁的数据存储和查询读取和OAuth2.0服务器的搭建。AliGenie平台通过OAuth2.0在不需要注册新设备用户的同时使用用户已有的账号获得智能硬件的认证系统的授权，使得天猫精灵能够访问智能硬件，然后完成指令的交互。</p>\n<p><div align=\"center\">\n<img src=\"/2019/04/20/天猫精灵，开灯/2.png\" width=\"600\" height=\"300\">\n</div><br>懒得搭服务器可以考虑下第三方平台，比如HomeAssistant、贝壳物联</p>\n<h2 id=\"准备\"><a href=\"#准备\" class=\"headerlink\" title=\"准备\"></a>准备</h2><ul>\n<li>路由器</li>\n<li>实验室主机一台</li>\n<li>花生棒</li>\n<li>esp8266</li>\n<li>天猫精灵</li>\n</ul>\n<h2 id=\"花生棒设置\"><a href=\"#花生棒设置\" class=\"headerlink\" title=\"花生棒设置\"></a>花生棒设置</h2><p>访问<a href=\"https://b.oray.com/\" target=\"_blank\" rel=\"noopener\">https://b.oray.com/</a><br>内网穿透中增加两个映射<br>映射一</p>\n<ul>\n<li>映射类型 HTTP80</li>\n<li>外网端口 80</li>\n<li>内网主机 192.168.1.241</li>\n<li>内网端口 80<br>映射二</li>\n<li>映射类型 通用应用</li>\n<li>外网端口 动态端口号</li>\n<li>内网主机 192.168.1.241</li>\n<li>内网端口 443</li>\n</ul>\n<h2 id=\"服务器部署\"><a href=\"#服务器部署\" class=\"headerlink\" title=\"服务器部署\"></a>服务器部署</h2><h3 id=\"apache2-php7-0-web服务器的构建\"><a href=\"#apache2-php7-0-web服务器的构建\" class=\"headerlink\" title=\"apache2+php7.0 web服务器的构建\"></a>apache2+php7.0 web服务器的构建</h3><p>安装apathe<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install apache2</span><br></pre></td></tr></table></figure></p>\n<p>安装php<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install php</span><br></pre></td></tr></table></figure></p>\n<p>配置apache2支持php7<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install libapache2-mod-php</span><br></pre></td></tr></table></figure></p>\n<p>重启一下apache2<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<p>配置DPO<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install php7.0-mysql</span><br><span class=\"line\">$ sudo phpenmod pdo_mysql</span><br><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/php/7.0/mods-available/pdo.ini</span><br><span class=\"line\"></span><br><span class=\"line\">    ;extension=pdo.so</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo vim /etc/php/7.0/apache2/php.ini</span><br><span class=\"line\"></span><br><span class=\"line\">    extension=/usr/lib/php/20151012/mysqli.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/mysqlnd.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/pdo.so</span><br><span class=\"line\">    extension=/usr/lib/php/20151012/pdo_mysql.so</span><br></pre></td></tr></table></figure>\n<h3 id=\"申请SSL证书\"><a href=\"#申请SSL证书\" class=\"headerlink\" title=\"申请SSL证书\"></a>申请SSL证书</h3><p>SSL For Free工具官方网站</p>\n<ul>\n<li><a href=\"https://www.sslforfree.com/\" target=\"_blank\" rel=\"noopener\">https://www.sslforfree.com/</a></li>\n</ul>\n<p>输入域名点击后面的Create Free SSL Certificate按钮获取，选择手工验证方式Manual Verification，点击Manually Verify Domain，根据提示的步骤进行，下载文件，然后对应添加文件夹，然后激活验证链接<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var/www/html/</span><br><span class=\"line\">$ sudo mkdir .well-known</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> .well-known/</span><br><span class=\"line\">$ sudo mkdir acme-challenge</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> acme-challenge/</span><br><span class=\"line\">$ sudo chmod 777 -R /var/www/html/</span><br></pre></td></tr></table></figure></p>\n<p>设置到期后通知邮箱，下载证书</p>\n<h3 id=\"部署HTTPS服务器\"><a href=\"#部署HTTPS服务器\" class=\"headerlink\" title=\"部署HTTPS服务器\"></a>部署HTTPS服务器</h3><p>安装openssl<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install openssl</span><br></pre></td></tr></table></figure></p>\n<p>开启SSL模块<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo a2enmod ssl</span><br></pre></td></tr></table></figure></p>\n<p>拷贝证书到相应目录，指定SSL证书</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">SSLCertificateFile      /etc/ssl/certs/certificate.crt</span><br><span class=\"line\">SSLCertificateKeyFile   /etc/ssl/private/private.key</span><br><span class=\"line\">SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo chmod 777 -R /etc/ssl/</span><br><span class=\"line\">$ <span class=\"built_in\">cd</span> /etc/apache2/</span><br><span class=\"line\">$ cat ports.conf</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># If you just change the port or add more ports here, you will likely also</span></span><br><span class=\"line\">    <span class=\"comment\"># have to change the VirtualHost statement in</span></span><br><span class=\"line\">    <span class=\"comment\"># /etc/apache2/sites-enabled/000-default.conf</span></span><br><span class=\"line\"></span><br><span class=\"line\">    Listen 80</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;IfModule ssl_module&gt;</span><br><span class=\"line\">            Listen 443</span><br><span class=\"line\">    &lt;/IfModule&gt;</span><br><span class=\"line\"></span><br><span class=\"line\">    &lt;IfModule mod_gnutls.c&gt;</span><br><span class=\"line\">            Listen 443</span><br><span class=\"line\">    &lt;/IfModule&gt;</span><br></pre></td></tr></table></figure>\n<p>建立软链<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo ln -s /etc/apache2/sites-available/default-ssl.conf /etc/apache2/sites-enabled/</span><br></pre></td></tr></table></figure></p>\n<p>修改default-ssl.conf<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install vim</span><br><span class=\"line\">$ sudo vim /etc/apache2/sites-available/default-ssl.conf</span><br><span class=\"line\"></span><br><span class=\"line\">    SSLProtocol all -SSLv2 -SSLv3</span><br><span class=\"line\">    SSLCertificateFile      /etc/ssl/certs/certificate.crt</span><br><span class=\"line\">    SSLCertificateKeyFile   /etc/ssl/private/private.key</span><br><span class=\"line\">    SSLCertificateChainFile /etc/ssl/private/ca_bundle.crt</span><br></pre></td></tr></table></figure></p>\n<p>通过a2ensite激活站点<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo a2ensite default-ssl.conf</span><br></pre></td></tr></table></figure></p>\n<p>重启apache<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo service apache2 restart</span><br></pre></td></tr></table></figure></p>\n<h3 id=\"安装MySQL\"><a href=\"#安装MySQL\" class=\"headerlink\" title=\"安装MySQL\"></a>安装MySQL</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ sudo apt-get install mysql-server mysql-client</span><br></pre></td></tr></table></figure>\n<p>下载安装oauth2-server<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ <span class=\"built_in\">cd</span> /var/www/html/</span><br><span class=\"line\">$ sudo apt-get install git</span><br><span class=\"line\">$ git <span class=\"built_in\">clone</span> https://github.com/bshaffer/oauth2-server-php.git -b master</span><br></pre></td></tr></table></figure></p>\n<p>建立数据库<br><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ mysql -u root -p</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mysql&gt; create database ilamp;</span><br><span class=\"line\">mysql&gt; use ilamp;</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_access_tokens` (</span><br><span class=\"line\">         `access_token` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id`    VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id`  VARCHAR(255),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         PRIMARY KEY (access_token));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE `oauth_authorization_codes` (</span><br><span class=\"line\">         `authorization_code` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id` VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id` VARCHAR(255),</span><br><span class=\"line\">         `redirect_uri` VARCHAR(2000),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         <span class=\"string\">'id_token'</span> VARCHAR(1000),</span><br><span class=\"line\">         PRIMARY KEY (authorization_code));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE <span class=\"string\">'oauth_clients'</span> (</span><br><span class=\"line\">         <span class=\"string\">'client_id'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'client_secret'</span> VARCHAR(80), </span><br><span class=\"line\">         <span class=\"string\">'redirect_uri'</span> VARCHAR(2000),</span><br><span class=\"line\">         <span class=\"string\">'grant_types'</span> VARCHAR(80),</span><br><span class=\"line\">         <span class=\"string\">'scope'</span> VARCHAR(4000),</span><br><span class=\"line\">         <span class=\"string\">'user_id'</span> VARCHAR(80), </span><br><span class=\"line\">         PRIMARY KEY (client_id));</span><br><span class=\"line\">mysql&gt;  CREATE TABLE `oauth_refresh_tokens` ( </span><br><span class=\"line\">         `refresh_token` VARCHAR(40) NOT NULL,</span><br><span class=\"line\">         `client_id` VARCHAR(80) NOT NULL,</span><br><span class=\"line\">         `user_id` VARCHAR(255),</span><br><span class=\"line\">         `expires` TIMESTAMP NOT NULL,</span><br><span class=\"line\">         `scope` VARCHAR(2000),</span><br><span class=\"line\">         PRIMARY KEY (refresh_token));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_users` (</span><br><span class=\"line\">         `username` VARCHAR(255) NOT NULL,</span><br><span class=\"line\">         `password` VARCHAR(2000),</span><br><span class=\"line\">         `first_name` VARCHAR(255),</span><br><span class=\"line\">         `last_name` VARCHAR(255),</span><br><span class=\"line\">         PRIMARY KEY (username));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_scopes` (</span><br><span class=\"line\">         <span class=\"string\">'scope'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'is_default'</span> boolean,</span><br><span class=\"line\">         PRIMARY KEY(scope));</span><br><span class=\"line\">mysql&gt; CREATE TABLE `oauth_jwt` (</span><br><span class=\"line\">         <span class=\"string\">'client_id'</span> VARCHAR(80) not null,</span><br><span class=\"line\">         <span class=\"string\">'subject'</span> VARCHAR(80),</span><br><span class=\"line\">         <span class=\"string\">'public_key'</span> VARCHAR(2000) not null);</span><br><span class=\"line\">mysql&gt; show tables;</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">| Tables_in_ilamp           |</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">| oauth_access_tokens       |</span><br><span class=\"line\">| oauth_authorization_codes |</span><br><span class=\"line\">| oauth_clients             |</span><br><span class=\"line\">| oauth_jwt                 |</span><br><span class=\"line\">| oauth_refresh_tokens      |</span><br><span class=\"line\">| oauth_scopes              |</span><br><span class=\"line\">| oauth_users               |</span><br><span class=\"line\">+---------------------------+</span><br><span class=\"line\">mysql&gt; insert into oauth_clients (client_id, client_secret, redirect_uri ) values (<span class=\"string\">\"id\"</span>,<span class=\"string\">\"psw\"</span>,<span class=\"string\">\"https://open.bot.tmall.com/oauth/callback\"</span>);</span><br></pre></td></tr></table></figure>\n<h2 id=\"天猫精灵新加技能\"><a href=\"#天猫精灵新加技能\" class=\"headerlink\" title=\"天猫精灵新加技能\"></a>天猫精灵新加技能</h2><p>登录开发者平台AliGenie - 语音开发者平台  <a href=\"https://open.aligenie.com/\" target=\"_blank\" rel=\"noopener\">https://open.aligenie.com/</a><br>发布新技能。</p>\n<h3 id=\"服务设置\"><a href=\"#服务设置\" class=\"headerlink\" title=\"服务设置\"></a>服务设置</h3><p>OAuth2</p>\n<ul>\n<li>账户授权连接: <a href=\"https://xxxx/authorize.php\" target=\"_blank\" rel=\"noopener\">https://xxxx/authorize.php</a></li>\n<li>ClientID: id</li>\n<li>Client Secret: psw</li>\n<li>跳转 URL: <a href=\"https://open.bot.tmall.com/oauth/callback\" target=\"_blank\" rel=\"noopener\">https://open.bot.tmall.com/oauth/callback</a></li>\n<li>Access Token URL: <a href=\"https://xxx/token.php\" target=\"_blank\" rel=\"noopener\">https://xxx/token.php</a></li>\n<li>厂商登出 URL: 暂无描述</li>\n</ul>\n<p>设备管理</p>\n<ul>\n<li>开发者网关地址: <a href=\"https://xxx/gate.php\" target=\"_blank\" rel=\"noopener\">https://xxx/gate.php</a></li>\n<li>设备管理跳转连接: 暂无描述</li>\n</ul>\n<h3 id=\"开机跳过用户登录\"><a href=\"#开机跳过用户登录\" class=\"headerlink\" title=\"开机跳过用户登录\"></a>开机跳过用户登录</h3><p>打开 系统设置 中的 用户帐户;<br>打开用户帐户设置窗口后，点击右上角的”解锁”按钮;<br>将自动登录设置为“开启”。</p>\n<h2 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h2><ul>\n<li>esp8266对接天猫精灵（1）前言 - CSDN博客<br><a href=\"https://blog.csdn.net/qq_35527832/article/details/79143899\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_35527832/article/details/79143899</a></li>\n<li>天猫精灵接入HomeAssistant<br><a href=\"https://weibo.com/ttarticle/p/show?id=2309404195482120392395\" target=\"_blank\" rel=\"noopener\">https://weibo.com/ttarticle/p/show?id=2309404195482120392395</a></li>\n<li>GitHub - c1pher-cn/tmall-bot-x1: 天猫精灵智能家居技能对接homeassistant<br><a href=\"https://github.com/c1pher-cn/tmall-bot-x1\" target=\"_blank\" rel=\"noopener\">https://github.com/c1pher-cn/tmall-bot-x1</a></li>\n<li>【新提醒】天猫精灵接入HomeAssistant【智能家居技能接入，非webhook调用】 - 『HomeAssistant』智能硬件讨论区 - 『瀚思彼岸』» 智能家居第一站 - Hassbian.com<br><a href=\"https://bbs.hassbian.com/thread-1862-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.hassbian.com/thread-1862-1-1.html</a></li>\n<li>AliGenie开发者平台<br><a href=\"http://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&amp;id=332356&amp;tagId=null\" target=\"_blank\" rel=\"noopener\">http://doc-bot.tmall.com/support/hotProblemDetail.htm?spm=0.0.0.0.cTGpHI&amp;id=332356&amp;tagId=null</a></li>\n</ul>\n</the>"},{"title":"好玩的_基于视觉控制的无传感器机械臂","date":"2019-06-16T07:29:46.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n机械之心今天发布了计算机视觉领域顶级会议 CVPR 2019 入选论文《CRAVES: Controlling Robotic Arm with a Vision-based, Economic System》的解读，该论文由约翰霍普金斯大学、清华大学和北京大学王亦洲课题组共同合作完成。  \n\n论文提出了一种基于视觉的机械臂控制系统。仅借助一个额外的摄像头，系统使用深度卷积神经网络，实时估计机械臂的三维姿态，并通过强化学习训练的智能体输出控制信号。进而，系统可以实现控制机械臂到达空间中任意给定三维坐标。基于此，我们还实现了自动抓取骰子的任务。此外，姿态估计和强化学习的训练完全依赖在虚拟环境中生成的数据，不需要人为进行标注与监督。\n\n项目网站：https://craves.ai（含代码和数据）\n\n论文地址：https://arxiv.org/abs/1812.00725\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n简介\n\n如何赋予机器人视觉，让其在多变的环境中完成复杂的任务，近年来吸引了越来越多研究者的关注。然而，以往的研究大多使用昂贵的工业级机器人（价值一万美元以上），这无疑限制了一般的研究者进入这个领域。因此，本文希望通过低成本的硬件来搭建一个机器人研究和教育的平台，以降低相关领域研究的硬件门槛。\n\n我们选用了 OWI-535 机械臂，因为其：\n\n非常廉价，只需要 40 美元左右；\n\n易于获得，在淘宝网或亚马逊上就可以买到；\n\n非常流行，在 Youtube 上有大量用户上传相关的改装与操作的视频。\n\n与此同时，其缺点也非常明显：没有任何传感器，因此无法获得反馈信号并对其进行精确控制。但人可以通过观察机械臂，通过遥控器完成一些高级机械臂才能完成的任务, 例如叠筛子。如何用视觉算法像人一样对没有传感器的机械臂进行控制是本文关注的焦点。\n\n我们选择使用一个外部的 RGB 摄像头作为视觉传感器，实时估计机械臂的三维姿态，并生成反馈控制信号。系统框图如下图所示：\n\n\n\n系统首先读入输入 RGB 视频流中的一帧（图中绿色部分），将其输入到姿态估计网络当中（图中蓝色部分），还原机械臂的三维姿态信息。最后，由强化学习智能体构成的控制器（图中橙色部分）接收三维姿态信息，生成控制信号，控制机械臂的电机运动。\n\n本文的主要贡献包括：\n\n设计了一个低成本的、无传感器的机械臂系统的实现方案;\n\n提出了一种结合几何先验的半监督域适应方法, 实现机械臂位姿估计模块从虚拟到真实的迁移；\n\n提供了三个带标注的数据集和一个虚拟环境，以促进未来该领域研究的发展。\n\n下面将分别介绍数据集收集、姿态估计模块和实验结果。\n\n数据集收集\n\n因为获取带有精确标注的真实数据代价十分高昂，所以我们构建了一个虚拟环境来自动生成标注数据，用于训练。为了验证模型在真实场景的性能，我们额外收集了两个真实数据集，并进行了人工标注。三个数据集及虚拟环境均开放下载。\n\n第一个数据集是虚拟数据集（Virtual Dataset）。我们使用了虚幻 4 引擎及其插件 Unrealcv[2] 来进行场景的渲染和数据采集。在生成训练数据时，我们对摄像机的位置、场景光照和背景进行随机化，以增强网络在真实场景中的泛化能力。我们共采集了 5000 张图片作为训练数据。虚拟数据集的标注自动生成，包括三维姿态信息。\n\n第二个数据集是实验室数据集（Lab Dataset）。我们在实验室环境拍摄了机械臂的图片，标定了相机的内外参数和机械臂的三维姿态。实验室数据集由 500 张左右图片构成，只用于测试。\n\n第三个数据集是 YouTube 数据集。我们爬取了 YouTube 中 OWI-535 机械臂的相关视频，并进行了手工标注，由于相机内外参数未知，因此我们只标注了二维关键点的位置。YouTube 数据集由 500 张左右图片构成，只用于测试。\n\n数据集样例图片见下图：\n\n\n\n上两行：虚拟数据；第三行：实验室数据；最后一行：YouTube 数据\n\n可迁移的三维姿态估计\n\n机械臂三维姿态估计模块是系统的核心组成部分。其输入是 RGB 图像，输出是机械臂的三维姿态，也即各个转轴的角度。具体而言，其由两个子模块构成：第一个子模块是二维关键点估计神经网络，由输入图像还原出二维关键点坐标；第二个子模块依据二维关键点还原出三维姿态。\n\n二维关键点估计神经网络使用的是 Stacked Hourglass Network[1]，网络采用全卷积结构。我们预先定义好机械臂上的 17 个关键点，网络的输出是与其对应的 17 个通道的热点图。在预测时，我们取热点图上响应最明显的位置作为预测结果。\n\n获取了二维姿态后，第二个子模块进行三维还原。我们将机械臂建模为一个 4 个自由度的多刚体模型，因此 17 个关键点的位置满足一定的约束关系。我们通过在线的解一个优化方程，即最小化二维关键点的预测位置和三维模型重投影位置之间的误差，来获得机械臂各转轴角度的最优解。\n\n此外，我们提出了新的半监督域迁移算法。只使用虚拟数据进行训练的网络，在真实图片上的表现不够好，而采用了我们的算法之后，泛化性能有大幅度提升。下图展示了我们的域迁移算法框图。我们首先使用虚拟图片对神经网络进行预训练。之后，我们将没有标注过的真实图片送入网络，生成初始预测结果。由于域间的差异，初始预测结果可能会产生错误。我们基于初始预测结果进行三维重建，并将此结果投影回二维，就获得了优化后的关键点预测结果。由于在此过程中引入了机械臂刚性结构的强先验信息，所以优化后的预测结果会好于初始预测结果。最后，我们用真实图片及用这种方法生成的虚假标签来对神经网络进行微调。\n\n\n\n我们首先使用虚拟图片对神经网络进行预训练（图中绿色虚线）。然后，我们将没有标注过的真实图片送入网络，生成初始预测结果。接下来，基于初始预测结果进行三维重建，并将此结果投影回二维，获得优化后的关键点预测结果。最后对网络进行微调（图中蓝色部分）。\n\n实验结果\n\n二维关键点预测结果\n\n如下表所示，我们证明了在实验室环境下，我们提出的半监督域迁移算法（最后一行）相比于只使用虚拟数据训练的网络（第一行）性能有很大提升。且此方法优于其他的无监督域迁移算法，包括 CycleGAN[3] 等。参与对比的几种域迁移方法都以 Lab 数据集作为目标域。其在从未见过的 YouTube 数据上的准确率相对其他方法有更大提高，说明网络整体泛化能力获得提升。\n\n上表为不同迁移方法下得到的模型的二维关键点检测准确率。测试数据分别在虚拟数据集、实验室数据集、YouTube 数据集，其中 YouTube-vis 为只计算可见的关键点的结果。\n\n三维重建结果\n\n下图展示了三维重建的定性结果。上图是原始图片，下图是经过三维重建并渲染可视化的图片。可见，系统可以在复杂背景下对机械臂进行三维重建。实验室数据集上的定量结果表明，机械臂转角的重建误差约为 4.8 度。\n\n机械臂控制结果\n\n我们使用 DDPG 算法训练强化学习智能体，在虚拟环境中进行交互。智能体的输入是当前状态、目标状态和上一时刻的决策。输出是对 4 个电机马达的控制信号。我们在两个任务上进行了测试。\n\n第一个任务是 Reach，即让机械臂的前端达到特定目标点的正上方。这是机械臂的「基本功」。通过测量终止位置和目标位置之间的水平距离来评价结果的好坏。上图是我们的实验装置示意图，下方参考板上的 9 个黑色圆点即为目标位置。在这个任务上，我们达到了与人类控制相近的精度。\n\n\n\n在不同的视角、背景下也能很好地工作。\n\n\n\n第二个任务是夹取骰子，现阶段骰子的三维空间位置由人工测量给定。\n\n\n\n参考文献：\n\n[1] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision, 2016.\n\n[2] Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, Yizhou Wang, and Alan Yuille. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia, 2017.\n\n[3] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A.Efros. Unpaired image-to-image translation using cycleconsistent adversarial networks. In International Conference on Computer Vision, 2017.\n\n","source":"_posts/好玩的-基于视觉控制的无传感器机械臂.md","raw":"---\ntitle: 好玩的_基于视觉控制的无传感器机械臂\ndate: 2019-06-16 15:29:46\ntags:\n\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n机械之心今天发布了计算机视觉领域顶级会议 CVPR 2019 入选论文《CRAVES: Controlling Robotic Arm with a Vision-based, Economic System》的解读，该论文由约翰霍普金斯大学、清华大学和北京大学王亦洲课题组共同合作完成。  \n\n论文提出了一种基于视觉的机械臂控制系统。仅借助一个额外的摄像头，系统使用深度卷积神经网络，实时估计机械臂的三维姿态，并通过强化学习训练的智能体输出控制信号。进而，系统可以实现控制机械臂到达空间中任意给定三维坐标。基于此，我们还实现了自动抓取骰子的任务。此外，姿态估计和强化学习的训练完全依赖在虚拟环境中生成的数据，不需要人为进行标注与监督。\n\n项目网站：https://craves.ai（含代码和数据）\n\n论文地址：https://arxiv.org/abs/1812.00725\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n简介\n\n如何赋予机器人视觉，让其在多变的环境中完成复杂的任务，近年来吸引了越来越多研究者的关注。然而，以往的研究大多使用昂贵的工业级机器人（价值一万美元以上），这无疑限制了一般的研究者进入这个领域。因此，本文希望通过低成本的硬件来搭建一个机器人研究和教育的平台，以降低相关领域研究的硬件门槛。\n\n我们选用了 OWI-535 机械臂，因为其：\n\n非常廉价，只需要 40 美元左右；\n\n易于获得，在淘宝网或亚马逊上就可以买到；\n\n非常流行，在 Youtube 上有大量用户上传相关的改装与操作的视频。\n\n与此同时，其缺点也非常明显：没有任何传感器，因此无法获得反馈信号并对其进行精确控制。但人可以通过观察机械臂，通过遥控器完成一些高级机械臂才能完成的任务, 例如叠筛子。如何用视觉算法像人一样对没有传感器的机械臂进行控制是本文关注的焦点。\n\n我们选择使用一个外部的 RGB 摄像头作为视觉传感器，实时估计机械臂的三维姿态，并生成反馈控制信号。系统框图如下图所示：\n\n\n\n系统首先读入输入 RGB 视频流中的一帧（图中绿色部分），将其输入到姿态估计网络当中（图中蓝色部分），还原机械臂的三维姿态信息。最后，由强化学习智能体构成的控制器（图中橙色部分）接收三维姿态信息，生成控制信号，控制机械臂的电机运动。\n\n本文的主要贡献包括：\n\n设计了一个低成本的、无传感器的机械臂系统的实现方案;\n\n提出了一种结合几何先验的半监督域适应方法, 实现机械臂位姿估计模块从虚拟到真实的迁移；\n\n提供了三个带标注的数据集和一个虚拟环境，以促进未来该领域研究的发展。\n\n下面将分别介绍数据集收集、姿态估计模块和实验结果。\n\n数据集收集\n\n因为获取带有精确标注的真实数据代价十分高昂，所以我们构建了一个虚拟环境来自动生成标注数据，用于训练。为了验证模型在真实场景的性能，我们额外收集了两个真实数据集，并进行了人工标注。三个数据集及虚拟环境均开放下载。\n\n第一个数据集是虚拟数据集（Virtual Dataset）。我们使用了虚幻 4 引擎及其插件 Unrealcv[2] 来进行场景的渲染和数据采集。在生成训练数据时，我们对摄像机的位置、场景光照和背景进行随机化，以增强网络在真实场景中的泛化能力。我们共采集了 5000 张图片作为训练数据。虚拟数据集的标注自动生成，包括三维姿态信息。\n\n第二个数据集是实验室数据集（Lab Dataset）。我们在实验室环境拍摄了机械臂的图片，标定了相机的内外参数和机械臂的三维姿态。实验室数据集由 500 张左右图片构成，只用于测试。\n\n第三个数据集是 YouTube 数据集。我们爬取了 YouTube 中 OWI-535 机械臂的相关视频，并进行了手工标注，由于相机内外参数未知，因此我们只标注了二维关键点的位置。YouTube 数据集由 500 张左右图片构成，只用于测试。\n\n数据集样例图片见下图：\n\n\n\n上两行：虚拟数据；第三行：实验室数据；最后一行：YouTube 数据\n\n可迁移的三维姿态估计\n\n机械臂三维姿态估计模块是系统的核心组成部分。其输入是 RGB 图像，输出是机械臂的三维姿态，也即各个转轴的角度。具体而言，其由两个子模块构成：第一个子模块是二维关键点估计神经网络，由输入图像还原出二维关键点坐标；第二个子模块依据二维关键点还原出三维姿态。\n\n二维关键点估计神经网络使用的是 Stacked Hourglass Network[1]，网络采用全卷积结构。我们预先定义好机械臂上的 17 个关键点，网络的输出是与其对应的 17 个通道的热点图。在预测时，我们取热点图上响应最明显的位置作为预测结果。\n\n获取了二维姿态后，第二个子模块进行三维还原。我们将机械臂建模为一个 4 个自由度的多刚体模型，因此 17 个关键点的位置满足一定的约束关系。我们通过在线的解一个优化方程，即最小化二维关键点的预测位置和三维模型重投影位置之间的误差，来获得机械臂各转轴角度的最优解。\n\n此外，我们提出了新的半监督域迁移算法。只使用虚拟数据进行训练的网络，在真实图片上的表现不够好，而采用了我们的算法之后，泛化性能有大幅度提升。下图展示了我们的域迁移算法框图。我们首先使用虚拟图片对神经网络进行预训练。之后，我们将没有标注过的真实图片送入网络，生成初始预测结果。由于域间的差异，初始预测结果可能会产生错误。我们基于初始预测结果进行三维重建，并将此结果投影回二维，就获得了优化后的关键点预测结果。由于在此过程中引入了机械臂刚性结构的强先验信息，所以优化后的预测结果会好于初始预测结果。最后，我们用真实图片及用这种方法生成的虚假标签来对神经网络进行微调。\n\n\n\n我们首先使用虚拟图片对神经网络进行预训练（图中绿色虚线）。然后，我们将没有标注过的真实图片送入网络，生成初始预测结果。接下来，基于初始预测结果进行三维重建，并将此结果投影回二维，获得优化后的关键点预测结果。最后对网络进行微调（图中蓝色部分）。\n\n实验结果\n\n二维关键点预测结果\n\n如下表所示，我们证明了在实验室环境下，我们提出的半监督域迁移算法（最后一行）相比于只使用虚拟数据训练的网络（第一行）性能有很大提升。且此方法优于其他的无监督域迁移算法，包括 CycleGAN[3] 等。参与对比的几种域迁移方法都以 Lab 数据集作为目标域。其在从未见过的 YouTube 数据上的准确率相对其他方法有更大提高，说明网络整体泛化能力获得提升。\n\n上表为不同迁移方法下得到的模型的二维关键点检测准确率。测试数据分别在虚拟数据集、实验室数据集、YouTube 数据集，其中 YouTube-vis 为只计算可见的关键点的结果。\n\n三维重建结果\n\n下图展示了三维重建的定性结果。上图是原始图片，下图是经过三维重建并渲染可视化的图片。可见，系统可以在复杂背景下对机械臂进行三维重建。实验室数据集上的定量结果表明，机械臂转角的重建误差约为 4.8 度。\n\n机械臂控制结果\n\n我们使用 DDPG 算法训练强化学习智能体，在虚拟环境中进行交互。智能体的输入是当前状态、目标状态和上一时刻的决策。输出是对 4 个电机马达的控制信号。我们在两个任务上进行了测试。\n\n第一个任务是 Reach，即让机械臂的前端达到特定目标点的正上方。这是机械臂的「基本功」。通过测量终止位置和目标位置之间的水平距离来评价结果的好坏。上图是我们的实验装置示意图，下方参考板上的 9 个黑色圆点即为目标位置。在这个任务上，我们达到了与人类控制相近的精度。\n\n\n\n在不同的视角、背景下也能很好地工作。\n\n\n\n第二个任务是夹取骰子，现阶段骰子的三维空间位置由人工测量给定。\n\n\n\n参考文献：\n\n[1] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision, 2016.\n\n[2] Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, Yizhou Wang, and Alan Yuille. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia, 2017.\n\n[3] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A.Efros. Unpaired image-to-image translation using cycleconsistent adversarial networks. In International Conference on Computer Vision, 2017.\n\n","slug":"好玩的-基于视觉控制的无传感器机械臂","published":1,"updated":"2019-06-23T07:09:39.773Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76g0041rsvj4z4dywpl","content":"<p><strong> 好玩的_基于视觉控制的无传感器机械臂：</strong> <excerpt in index | 首页摘要><br>机械之心今天发布了计算机视觉领域顶级会议 CVPR 2019 入选论文《CRAVES: Controlling Robotic Arm with a Vision-based, Economic System》的解读，该论文由约翰霍普金斯大学、清华大学和北京大学王亦洲课题组共同合作完成。  </excerpt></p>\n<p>论文提出了一种基于视觉的机械臂控制系统。仅借助一个额外的摄像头，系统使用深度卷积神经网络，实时估计机械臂的三维姿态，并通过强化学习训练的智能体输出控制信号。进而，系统可以实现控制机械臂到达空间中任意给定三维坐标。基于此，我们还实现了自动抓取骰子的任务。此外，姿态估计和强化学习的训练完全依赖在虚拟环境中生成的数据，不需要人为进行标注与监督。</p>\n<p>项目网站：<a href=\"https://craves.ai（含代码和数据）\" target=\"_blank\" rel=\"noopener\">https://craves.ai（含代码和数据）</a></p>\n<p>论文地址：<a href=\"https://arxiv.org/abs/1812.00725\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1812.00725</a></p>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n<p>简介</p>\n<p>如何赋予机器人视觉，让其在多变的环境中完成复杂的任务，近年来吸引了越来越多研究者的关注。然而，以往的研究大多使用昂贵的工业级机器人（价值一万美元以上），这无疑限制了一般的研究者进入这个领域。因此，本文希望通过低成本的硬件来搭建一个机器人研究和教育的平台，以降低相关领域研究的硬件门槛。</p>\n<p>我们选用了 OWI-535 机械臂，因为其：</p>\n<p>非常廉价，只需要 40 美元左右；</p>\n<p>易于获得，在淘宝网或亚马逊上就可以买到；</p>\n<p>非常流行，在 Youtube 上有大量用户上传相关的改装与操作的视频。</p>\n<p>与此同时，其缺点也非常明显：没有任何传感器，因此无法获得反馈信号并对其进行精确控制。但人可以通过观察机械臂，通过遥控器完成一些高级机械臂才能完成的任务, 例如叠筛子。如何用视觉算法像人一样对没有传感器的机械臂进行控制是本文关注的焦点。</p>\n<p>我们选择使用一个外部的 RGB 摄像头作为视觉传感器，实时估计机械臂的三维姿态，并生成反馈控制信号。系统框图如下图所示：</p>\n<p>系统首先读入输入 RGB 视频流中的一帧（图中绿色部分），将其输入到姿态估计网络当中（图中蓝色部分），还原机械臂的三维姿态信息。最后，由强化学习智能体构成的控制器（图中橙色部分）接收三维姿态信息，生成控制信号，控制机械臂的电机运动。</p>\n<p>本文的主要贡献包括：</p>\n<p>设计了一个低成本的、无传感器的机械臂系统的实现方案;</p>\n<p>提出了一种结合几何先验的半监督域适应方法, 实现机械臂位姿估计模块从虚拟到真实的迁移；</p>\n<p>提供了三个带标注的数据集和一个虚拟环境，以促进未来该领域研究的发展。</p>\n<p>下面将分别介绍数据集收集、姿态估计模块和实验结果。</p>\n<p>数据集收集</p>\n<p>因为获取带有精确标注的真实数据代价十分高昂，所以我们构建了一个虚拟环境来自动生成标注数据，用于训练。为了验证模型在真实场景的性能，我们额外收集了两个真实数据集，并进行了人工标注。三个数据集及虚拟环境均开放下载。</p>\n<p>第一个数据集是虚拟数据集（Virtual Dataset）。我们使用了虚幻 4 引擎及其插件 Unrealcv[2] 来进行场景的渲染和数据采集。在生成训练数据时，我们对摄像机的位置、场景光照和背景进行随机化，以增强网络在真实场景中的泛化能力。我们共采集了 5000 张图片作为训练数据。虚拟数据集的标注自动生成，包括三维姿态信息。</p>\n<p>第二个数据集是实验室数据集（Lab Dataset）。我们在实验室环境拍摄了机械臂的图片，标定了相机的内外参数和机械臂的三维姿态。实验室数据集由 500 张左右图片构成，只用于测试。</p>\n<p>第三个数据集是 YouTube 数据集。我们爬取了 YouTube 中 OWI-535 机械臂的相关视频，并进行了手工标注，由于相机内外参数未知，因此我们只标注了二维关键点的位置。YouTube 数据集由 500 张左右图片构成，只用于测试。</p>\n<p>数据集样例图片见下图：</p>\n<p>上两行：虚拟数据；第三行：实验室数据；最后一行：YouTube 数据</p>\n<p>可迁移的三维姿态估计</p>\n<p>机械臂三维姿态估计模块是系统的核心组成部分。其输入是 RGB 图像，输出是机械臂的三维姿态，也即各个转轴的角度。具体而言，其由两个子模块构成：第一个子模块是二维关键点估计神经网络，由输入图像还原出二维关键点坐标；第二个子模块依据二维关键点还原出三维姿态。</p>\n<p>二维关键点估计神经网络使用的是 Stacked Hourglass Network[1]，网络采用全卷积结构。我们预先定义好机械臂上的 17 个关键点，网络的输出是与其对应的 17 个通道的热点图。在预测时，我们取热点图上响应最明显的位置作为预测结果。</p>\n<p>获取了二维姿态后，第二个子模块进行三维还原。我们将机械臂建模为一个 4 个自由度的多刚体模型，因此 17 个关键点的位置满足一定的约束关系。我们通过在线的解一个优化方程，即最小化二维关键点的预测位置和三维模型重投影位置之间的误差，来获得机械臂各转轴角度的最优解。</p>\n<p>此外，我们提出了新的半监督域迁移算法。只使用虚拟数据进行训练的网络，在真实图片上的表现不够好，而采用了我们的算法之后，泛化性能有大幅度提升。下图展示了我们的域迁移算法框图。我们首先使用虚拟图片对神经网络进行预训练。之后，我们将没有标注过的真实图片送入网络，生成初始预测结果。由于域间的差异，初始预测结果可能会产生错误。我们基于初始预测结果进行三维重建，并将此结果投影回二维，就获得了优化后的关键点预测结果。由于在此过程中引入了机械臂刚性结构的强先验信息，所以优化后的预测结果会好于初始预测结果。最后，我们用真实图片及用这种方法生成的虚假标签来对神经网络进行微调。</p>\n<p>我们首先使用虚拟图片对神经网络进行预训练（图中绿色虚线）。然后，我们将没有标注过的真实图片送入网络，生成初始预测结果。接下来，基于初始预测结果进行三维重建，并将此结果投影回二维，获得优化后的关键点预测结果。最后对网络进行微调（图中蓝色部分）。</p>\n<p>实验结果</p>\n<p>二维关键点预测结果</p>\n<p>如下表所示，我们证明了在实验室环境下，我们提出的半监督域迁移算法（最后一行）相比于只使用虚拟数据训练的网络（第一行）性能有很大提升。且此方法优于其他的无监督域迁移算法，包括 CycleGAN[3] 等。参与对比的几种域迁移方法都以 Lab 数据集作为目标域。其在从未见过的 YouTube 数据上的准确率相对其他方法有更大提高，说明网络整体泛化能力获得提升。</p>\n<p>上表为不同迁移方法下得到的模型的二维关键点检测准确率。测试数据分别在虚拟数据集、实验室数据集、YouTube 数据集，其中 YouTube-vis 为只计算可见的关键点的结果。</p>\n<p>三维重建结果</p>\n<p>下图展示了三维重建的定性结果。上图是原始图片，下图是经过三维重建并渲染可视化的图片。可见，系统可以在复杂背景下对机械臂进行三维重建。实验室数据集上的定量结果表明，机械臂转角的重建误差约为 4.8 度。</p>\n<p>机械臂控制结果</p>\n<p>我们使用 DDPG 算法训练强化学习智能体，在虚拟环境中进行交互。智能体的输入是当前状态、目标状态和上一时刻的决策。输出是对 4 个电机马达的控制信号。我们在两个任务上进行了测试。</p>\n<p>第一个任务是 Reach，即让机械臂的前端达到特定目标点的正上方。这是机械臂的「基本功」。通过测量终止位置和目标位置之间的水平距离来评价结果的好坏。上图是我们的实验装置示意图，下方参考板上的 9 个黑色圆点即为目标位置。在这个任务上，我们达到了与人类控制相近的精度。</p>\n<p>在不同的视角、背景下也能很好地工作。</p>\n<p>第二个任务是夹取骰子，现阶段骰子的三维空间位置由人工测量给定。</p>\n<p>参考文献：</p>\n<p>[1] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision, 2016.</p>\n<p>[2] Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, Yizhou Wang, and Alan Yuille. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia, 2017.</p>\n<p>[3] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A.Efros. Unpaired image-to-image translation using cycleconsistent adversarial networks. In International Conference on Computer Vision, 2017.</p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 好玩的_基于视觉控制的无传感器机械臂：</strong> <excerpt in index | 首页摘要><br>机械之心今天发布了计算机视觉领域顶级会议 CVPR 2019 入选论文《CRAVES: Controlling Robotic Arm with a Vision-based, Economic System》的解读，该论文由约翰霍普金斯大学、清华大学和北京大学王亦洲课题组共同合作完成。  </excerpt></p>\n<p>论文提出了一种基于视觉的机械臂控制系统。仅借助一个额外的摄像头，系统使用深度卷积神经网络，实时估计机械臂的三维姿态，并通过强化学习训练的智能体输出控制信号。进而，系统可以实现控制机械臂到达空间中任意给定三维坐标。基于此，我们还实现了自动抓取骰子的任务。此外，姿态估计和强化学习的训练完全依赖在虚拟环境中生成的数据，不需要人为进行标注与监督。</p>\n<p>项目网站：<a href=\"https://craves.ai（含代码和数据）\" target=\"_blank\" rel=\"noopener\">https://craves.ai（含代码和数据）</a></p>\n<p>论文地址：<a href=\"https://arxiv.org/abs/1812.00725\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1812.00725</a></p>","more":"<the rest of contents | 余下全文>\n\n\n<p>简介</p>\n<p>如何赋予机器人视觉，让其在多变的环境中完成复杂的任务，近年来吸引了越来越多研究者的关注。然而，以往的研究大多使用昂贵的工业级机器人（价值一万美元以上），这无疑限制了一般的研究者进入这个领域。因此，本文希望通过低成本的硬件来搭建一个机器人研究和教育的平台，以降低相关领域研究的硬件门槛。</p>\n<p>我们选用了 OWI-535 机械臂，因为其：</p>\n<p>非常廉价，只需要 40 美元左右；</p>\n<p>易于获得，在淘宝网或亚马逊上就可以买到；</p>\n<p>非常流行，在 Youtube 上有大量用户上传相关的改装与操作的视频。</p>\n<p>与此同时，其缺点也非常明显：没有任何传感器，因此无法获得反馈信号并对其进行精确控制。但人可以通过观察机械臂，通过遥控器完成一些高级机械臂才能完成的任务, 例如叠筛子。如何用视觉算法像人一样对没有传感器的机械臂进行控制是本文关注的焦点。</p>\n<p>我们选择使用一个外部的 RGB 摄像头作为视觉传感器，实时估计机械臂的三维姿态，并生成反馈控制信号。系统框图如下图所示：</p>\n<p>系统首先读入输入 RGB 视频流中的一帧（图中绿色部分），将其输入到姿态估计网络当中（图中蓝色部分），还原机械臂的三维姿态信息。最后，由强化学习智能体构成的控制器（图中橙色部分）接收三维姿态信息，生成控制信号，控制机械臂的电机运动。</p>\n<p>本文的主要贡献包括：</p>\n<p>设计了一个低成本的、无传感器的机械臂系统的实现方案;</p>\n<p>提出了一种结合几何先验的半监督域适应方法, 实现机械臂位姿估计模块从虚拟到真实的迁移；</p>\n<p>提供了三个带标注的数据集和一个虚拟环境，以促进未来该领域研究的发展。</p>\n<p>下面将分别介绍数据集收集、姿态估计模块和实验结果。</p>\n<p>数据集收集</p>\n<p>因为获取带有精确标注的真实数据代价十分高昂，所以我们构建了一个虚拟环境来自动生成标注数据，用于训练。为了验证模型在真实场景的性能，我们额外收集了两个真实数据集，并进行了人工标注。三个数据集及虚拟环境均开放下载。</p>\n<p>第一个数据集是虚拟数据集（Virtual Dataset）。我们使用了虚幻 4 引擎及其插件 Unrealcv[2] 来进行场景的渲染和数据采集。在生成训练数据时，我们对摄像机的位置、场景光照和背景进行随机化，以增强网络在真实场景中的泛化能力。我们共采集了 5000 张图片作为训练数据。虚拟数据集的标注自动生成，包括三维姿态信息。</p>\n<p>第二个数据集是实验室数据集（Lab Dataset）。我们在实验室环境拍摄了机械臂的图片，标定了相机的内外参数和机械臂的三维姿态。实验室数据集由 500 张左右图片构成，只用于测试。</p>\n<p>第三个数据集是 YouTube 数据集。我们爬取了 YouTube 中 OWI-535 机械臂的相关视频，并进行了手工标注，由于相机内外参数未知，因此我们只标注了二维关键点的位置。YouTube 数据集由 500 张左右图片构成，只用于测试。</p>\n<p>数据集样例图片见下图：</p>\n<p>上两行：虚拟数据；第三行：实验室数据；最后一行：YouTube 数据</p>\n<p>可迁移的三维姿态估计</p>\n<p>机械臂三维姿态估计模块是系统的核心组成部分。其输入是 RGB 图像，输出是机械臂的三维姿态，也即各个转轴的角度。具体而言，其由两个子模块构成：第一个子模块是二维关键点估计神经网络，由输入图像还原出二维关键点坐标；第二个子模块依据二维关键点还原出三维姿态。</p>\n<p>二维关键点估计神经网络使用的是 Stacked Hourglass Network[1]，网络采用全卷积结构。我们预先定义好机械臂上的 17 个关键点，网络的输出是与其对应的 17 个通道的热点图。在预测时，我们取热点图上响应最明显的位置作为预测结果。</p>\n<p>获取了二维姿态后，第二个子模块进行三维还原。我们将机械臂建模为一个 4 个自由度的多刚体模型，因此 17 个关键点的位置满足一定的约束关系。我们通过在线的解一个优化方程，即最小化二维关键点的预测位置和三维模型重投影位置之间的误差，来获得机械臂各转轴角度的最优解。</p>\n<p>此外，我们提出了新的半监督域迁移算法。只使用虚拟数据进行训练的网络，在真实图片上的表现不够好，而采用了我们的算法之后，泛化性能有大幅度提升。下图展示了我们的域迁移算法框图。我们首先使用虚拟图片对神经网络进行预训练。之后，我们将没有标注过的真实图片送入网络，生成初始预测结果。由于域间的差异，初始预测结果可能会产生错误。我们基于初始预测结果进行三维重建，并将此结果投影回二维，就获得了优化后的关键点预测结果。由于在此过程中引入了机械臂刚性结构的强先验信息，所以优化后的预测结果会好于初始预测结果。最后，我们用真实图片及用这种方法生成的虚假标签来对神经网络进行微调。</p>\n<p>我们首先使用虚拟图片对神经网络进行预训练（图中绿色虚线）。然后，我们将没有标注过的真实图片送入网络，生成初始预测结果。接下来，基于初始预测结果进行三维重建，并将此结果投影回二维，获得优化后的关键点预测结果。最后对网络进行微调（图中蓝色部分）。</p>\n<p>实验结果</p>\n<p>二维关键点预测结果</p>\n<p>如下表所示，我们证明了在实验室环境下，我们提出的半监督域迁移算法（最后一行）相比于只使用虚拟数据训练的网络（第一行）性能有很大提升。且此方法优于其他的无监督域迁移算法，包括 CycleGAN[3] 等。参与对比的几种域迁移方法都以 Lab 数据集作为目标域。其在从未见过的 YouTube 数据上的准确率相对其他方法有更大提高，说明网络整体泛化能力获得提升。</p>\n<p>上表为不同迁移方法下得到的模型的二维关键点检测准确率。测试数据分别在虚拟数据集、实验室数据集、YouTube 数据集，其中 YouTube-vis 为只计算可见的关键点的结果。</p>\n<p>三维重建结果</p>\n<p>下图展示了三维重建的定性结果。上图是原始图片，下图是经过三维重建并渲染可视化的图片。可见，系统可以在复杂背景下对机械臂进行三维重建。实验室数据集上的定量结果表明，机械臂转角的重建误差约为 4.8 度。</p>\n<p>机械臂控制结果</p>\n<p>我们使用 DDPG 算法训练强化学习智能体，在虚拟环境中进行交互。智能体的输入是当前状态、目标状态和上一时刻的决策。输出是对 4 个电机马达的控制信号。我们在两个任务上进行了测试。</p>\n<p>第一个任务是 Reach，即让机械臂的前端达到特定目标点的正上方。这是机械臂的「基本功」。通过测量终止位置和目标位置之间的水平距离来评价结果的好坏。上图是我们的实验装置示意图，下方参考板上的 9 个黑色圆点即为目标位置。在这个任务上，我们达到了与人类控制相近的精度。</p>\n<p>在不同的视角、背景下也能很好地工作。</p>\n<p>第二个任务是夹取骰子，现阶段骰子的三维空间位置由人工测量给定。</p>\n<p>参考文献：</p>\n<p>[1] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks for human pose estimation. In European Conference on Computer Vision, 2016.</p>\n<p>[2] Weichao Qiu, Fangwei Zhong, Yi Zhang, Siyuan Qiao, Zihao Xiao, Tae Soo Kim, Yizhou Wang, and Alan Yuille. Unrealcv: Virtual worlds for computer vision. In Proceedings of the 25th ACM International Conference on Multimedia, 2017.</p>\n<p>[3] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A.Efros. Unpaired image-to-image translation using cycleconsistent adversarial networks. In International Conference on Computer Vision, 2017.</p>\n</the>"},{"title":"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图","date":"2019-06-28T16:11:20.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n\n##  Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n### 维诺图\n\n#### 定义\n给定平面中的一组点，所有点不共线，维诺图为每个点（生成元）创建多边形区域，使得每个区域中的点到生成元的距离最近。  \n\n#### 特点 \n* 每个V多边形内有一个生成元； \n* 每个V多边形内点到该生成元距离短于到其它生成元距离； \n* 多边形边界上的点到生成此边界的生成元距离相等（生成元连线的垂直平分线）； \n* 邻接图形的Voronoi多边形界线以原邻接界线作为子集。\n\n### 德罗奈三角剖分\n\n对点集进行结构化的一个重要的方法就是对这些点进行三角剖分。\n#### 定义\nDelaunay三角剖分定义为平面上的点集P是一种三角剖分，使得P中没有点严格处于剖分后中任意一个三角形外接圆的内部。\n\n#### 特点\n* Delaunay三角剖分与Voronoi图是对偶关系。  \n  对于一个维诺图，若任何两个生成元site之间有一条非空边界，那么这两个site之间连接一条边，由此得到的对偶图，就是一个三角剖分。\n* 空圆性  \n  对于Delaunay剖分中的任何一张face的外接圆必然是空的。 \n* 最近邻性  \n  任何一条连接于最近邻之间的边都会被Delaunay剖分所采用，因为这里头会存在一个以这条边为直径（弦）的空圆。\n* 复杂度  \n  在二维平面中，每增加一个点三角形的数目都会大概增加2，边数增加3。可以说在二维上的Delaunay剖分中是一个线性规模的数据结构。但在三维的情况下这两个指标最多会达到平房的量级，更高维的空间的一般结论也会达到2^d量级。\n \n \n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\opencv-delaunay-vornoi-subdiv-example.png\">\n\n\n\n### 维诺图生成方法\n\n首先生成其对偶元Delaunay三角网，再找出三角网每一三角形的外接圆圆心，最后连接相邻三角形的外接圆圆心，形成以每一个三角形顶点为生成元的多边形网。\n\n步骤：  \n（1）离散点自动构建三角网，即构建Delaunay三角网。对离散点和形成的三角形编号，记录每个三角形是由哪三个离散点构成的。   \n（2）计算每个三角形的外接圆圆心，并记录之。   \n（3）遍历三角形链表，寻找与当前三角形pTri三边共边的相邻三角形TriA，TriB和TriC。   \n（4）如果找到，则把寻找到的三角形的外心与pTri的外心连接，存入维诺边链表中。如果找不到，则求出最外边的中垂线射线存入维诺边链表中。   \n（5）遍历结束，所有维诺边被找到，根据边画出维诺图。\n\nDelaunay剖分是一种三角剖分的标准，实现它有多种算法，这里采用Bowyer-Watson算法，算法的基本步骤是：   \n（1）构造一个超级三角形，包含所有散点，放入三角形链表。   \n（2）将点集中的散点依次插入，在三角形链表中找出其外接圆包含插入点的三角形（称为该点的影响三角形），删除影响三角形的公共边，将插入点同影响三角形的全部顶点连接起来，从而完成一个点在Delaunay三角形链表中的插入。   \n（3）根据优化准则对局部新形成的三角形进行优化。将形成的三角形放入Delaunay三角形链表。   \n（4）循环执行上述第2步，直到所有散点插入完毕。\n\n\n\n\n```python\nfrom random import randint, seed\nfrom math import ceil, sqrt, log, floor\n\nimport delaunay as D\n```\n\n\n```python\n# 随机生成20个点\nseed(4)\nn = 10\nxs = [randint(1, 98) for x in range(n)]\nys = [randint(1, 98) for x in range(n)]\nzs = [0 for x in range(n)]\n\nDT = D.Delaunay_Triangulation()\nfor x, y in zip(xs, ys):\n    DT.AddPoint(D.Point(x, y))\n\nXS, YS, TS = DT.export()\n\n# print(XS)\n# print(YS)\n# print(TS)\n\n\"\"\"\nCreating and plotting unstructured triangular grids.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport matplotlib.tri as tri\nimport math\n\n%matplotlib inline\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.plot(xs, ys, 'go')\n\n# Creating a Triangulation without specifying the triangles results in the\n# Delaunay triangulation of the points.\n\n# Create the Triangulation; no triangles so Delaunay triangulation created.\ntriang = tri.Triangulation(xs, ys)\n\n# Plot the triangulation.\nplt.subplot(1,3,2)\nplt.triplot(triang, 'bo-')\n\nplt.subplot(1,3,3)\nplt.triplot(tri.Triangulation(XS, YS, TS), 'ro--')\n\nplt.show()\n\n```\n\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\output_4_0.png\">\n\n\n\n\n### 参考资料\n* 计算几何笔记 - 知乎  \nhttps://zhuanlan.zhihu.com/c_162517931 \n* Delaunay Triangulation - menjiawan的专栏 - CSDN博客  \nhttps://blog.csdn.net/menjiawan/article/details/45073121\n\n### Bowyer-Watson算法\n\n__Bowyer算法__由英国Bath大学的Bowyer在1981年提出。算法首先构造离散点集的的若干离散点的Voronoi图，根据Voronoi领域准则连接临近点，得到初始Delaunay三角剖分，然后逐步加入剖分点，每加入一个点就对已有的Voronoi图进行修改，构造新点集的Voronoi图，直到所有点都插入完毕。\n* Computing Dirichlet tessellations1 | The Computer Journal | Oxford Academic  \nhttps://academic.oup.com/comjnl/article/24/2/162/338193\n\n__Watson算法__由澳大利亚悉尼大学Watson在1981年提出。算法采用空外接圆准则，直接从三角剖分入手。算法从初始三角划分开始，每加入一个离散点，找出所有外接圆包含此点的三角形，删除这些三角形面向该插入点的边，得到包含此点的多边形，将此点与多边形的定点连接就构成新的Delaunay三角剖分，重复此过程直至所有点插入完毕为止。注意，此算法当四点或以上共圆时将产生错误。\n* Computing the n-dimensional Delaunay tessellation with application to Voronoi polytopes1 | The Computer Journal | Oxford Academic  \nhttps://academic.oup.com/comjnl/article/24/2/167/338200\n\n__Bowyer-Watson算法__是根据上述两者算法相互补充改进得到的(貌似跟Watson算法差不多，具体可以参考上述两篇论文)，仍然是一种插点增量算法的一种。算法逻辑如下：\n\n- 1.求解离散点集的凸包，建立点集凸包边界节点的初始三角形划分；\n- 2.选择另外的离散点，插入指定位置，在已有的三角形中找出外接圆包含此点的三角形，并删除公共边，得到一个包含新插入点的多边形；\n- 3.将此点与多边形的其他顶点连接起来，构成新的三角形划分；\n- 4.重复插点知道所有点插入完毕。\n- 5.最后删除超级三角形相关联的三角形即可。\n\n\n### 判断点在三角形内\n\n\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\Trangle.png\">\n\n#### 1. 点P和三顶点夹角和360\n连接点P和三角形的三个顶点得到三条线段PA，PB和PC，求出这三条线段与三角形各边的夹角，如果所有夹角之和为360度，那么点P在三角形内，否则不在，此法直观，但效率低下。\n\n#### 2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧\n当选定线段AB时，点C位于AB的右侧，同理选定BC时，点A位于BC的右侧，最后选定CA时，点B位于CA的右侧，所以当选择某一条边时，我们只需验证点P与该边所对的点在同一侧即可。  \n如何判断两个点在某条线段的同一侧呢？可以通过叉积来实现，连接BP，将BP和BC做叉积，再将BA和BC做叉积，如果两个叉积的结果方向一致，那么两个点在同一侧。  \nBTW，判断两个向量的是否同向可以用点积实现，如果点积大于0，则两向量夹角是锐角，否则是钝角。\n\n#### 3. 利用外积同号和面积关系\n首先利用外积方向判断p在角ABC内：将BA和BC做叉积，连接BP，分别将BA和BP、BP和BC做叉积并判断与BA和BC的叉积同向。\n最后利用外积大小判断p在三角形ABC内：BA和BP、BP和BC的叉积之和，小于BA和BC的叉积。\n\n### 判断点在三角形的外接圆内\n\n#### 1.先求圆心、半径，比较半径和圆心到点P距离\n\n\n由三角形的外心坐标公式计算圆心坐标\n$$\nx=\\frac{\\left|\\begin{array}{lll}{x_{0}^{2}+y_{0}^{2}} & {y_{0}} & {1} \\\\ {x_{1}^{2}+y_{1}^{2}} & {y_{1}} & {1} \\\\ {x_{2}^{2}+y_{2}^{2}} & {y_{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|} , y=\\frac{\\left|\\begin{array}{lll}{x_{0}} & {x_{0}^{2}+y_{0}^{2}} & {1} \\\\ {x_{1}} & {x_{1}^{2}+y_{1}^{2}} & {1} \\\\ {x_{2}} & {x_{2}^{2}+y_{2}^{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|}\n$$\n根据这个外心的坐标公式计算出外接圆的圆心坐标，就能得到圆的半径，从而判断出点P与外接圆的位置关系。\n\n#### 2.利用角度关系\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\P_Trangle.png\">\n\n- step1 计算$∠P_0P_1P_2$和$∠P_0PP_2$的大小，两个角的大小在$[0,π]$范围内。  \n    - step1.1 如果$∠P_0PP_2=0$，则点$P$不在圆内，结束；如果$∠P_0PP_2 = π$,则点$P$在圆内，结束。   \n   \n   \n- setp2 判断点$P$和$P_1$是否在$P_0P_2$同侧。  \n    - step2.1 这里通过判断向量外积 $\\overrightarrow{P_{1} P_{0}} \\times \\overrightarrow{P_{1} P_{2}}$与$\\overrightarrow{P P_{0}} \\times \\overrightarrow{P P_{2}}$ 是否同号，如果同号则在同一侧，否则在两侧。   \n\n\n- step3 如果点$P$和$P_1$是在$P_0P_2$同一侧，若$\\angle P_{0} P_{1} P_{2} \\leq \\angle P_{0} P P_{2}$,则点$P$在圆内，否则在圆外，结束；如果点$P$和$P_1$是在$P_0P_2$不在侧，若$\\angle P_{0} P_{1} P_{2}+\\angle P_{0} P P_{2} \\geq \\pi$，则点$P$在圆内，否则在圆外，结束。\n\n\n### Delaunay Triangulation & Voronoi Diagram in OpenCV\n\n给定一组点，可以使用openCV中的Subdiv2D类计算Delaunay三角剖分或Voronoi图。\n\n步骤：\n- 1.获取关键点列表\n> points = []  \n> points.append((x, y))\n- 2.定义要分区的矩形区间\n> img = cv2.imread(\"image.jpg\");\n> size = img.shape\n> rect = (0, 0, size[1], size[0])\n- 3.创建Subdiv2D类的实例\n> subdiv  = cv2.Subdiv2D(rect)\n- 4.使用subdiv.insert(point)插入点\n> for p in points :\n>     subdiv.insert(p)\n- 5.使用subdiv.getTriangleList方法得到Delaunay三角剖分的三角形列表\n> triangleList = subdiv.getTriangleList();\n> for t in triangleList :\n>     pt1 = (t[0], t[1])\n>     pt2 = (t[2], t[3])\n>     pt3 = (t[4], t[5])\n- 6.使用subdiv.getVoronoiFacetList方法得到Voronoi图形状和中心的列表\n> (facets, centers) = subdiv.getVoronoiFacetList([])\n\n\n\n```python\nimport cv2\nimport numpy as np\nimport random\n\n# Check if a point is inside a rectangle\ndef rect_contains(rect, point) :\n    if point[0] < rect[0] :\n        return False\n    elif point[1] < rect[1] :\n        return False\n    elif point[0] > rect[2] :\n        return False\n    elif point[1] > rect[3] :\n        return False\n    return True\n\n# Draw a point\ndef draw_point(img, p, color ) :\n    cv2.circle( img, p, 2, color, cv2.FILLED, cv2.LINE_AA, 0 )\n\n# Draw delaunay triangles\ndef draw_delaunay(img, subdiv, delaunay_color ) :\n    triangleList = subdiv.getTriangleList();\n    size = img.shape\n    r = (0, 0, size[1], size[0])\n\n    for t in triangleList :\n        pt1 = (t[0], t[1])\n        pt2 = (t[2], t[3])\n        pt3 = (t[4], t[5])\n        \n        if rect_contains(r, pt1) and rect_contains(r, pt2) and rect_contains(r, pt3) :\n            cv2.line(img, pt1, pt2, delaunay_color, 1, cv2.LINE_AA, 0)\n            cv2.line(img, pt2, pt3, delaunay_color, 1, cv2.LINE_AA, 0)\n            cv2.line(img, pt3, pt1, delaunay_color, 1, cv2.LINE_AA, 0)\n\n# Draw voronoi diagram\ndef draw_voronoi(img, subdiv) :\n\n    ( facets, centers) = subdiv.getVoronoiFacetList([])\n\n    for i in range(0,len(facets)) :\n        ifacet_arr = []\n        for f in facets[i] :\n            ifacet_arr.append(f)\n        \n        ifacet = np.array(ifacet_arr, np.int)\n        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n        cv2.fillConvexPoly(img, ifacet, color, cv2.LINE_AA, 0);\n        ifacets = np.array([ifacet])\n        cv2.polylines(img, ifacets, True, (0, 0, 0), 1, cv2.LINE_AA, 0)\n        cv2.circle(img, (centers[i][0], centers[i][1]), 3, (0, 0, 0), cv2.FILLED, cv2.LINE_AA, 0)\n\n\nif __name__ == '__main__':\n\n    # Define window names\n    win_delaunay = \"Delaunay Triangulation\"\n    win_voronoi = \"Voronoi Diagram\"\n\n    # Turn on animation while drawing triangles\n    animate = True\n    \n    # Define colors for drawing.\n    delaunay_color = (255,255,255)\n    points_color = (0, 0, 255)\n\n    # Read in the image.\n    img = cv2.imread(\"./images/obama.jpg\");\n    \n    # Keep a copy around\n    img_orig = img.copy();\n    \n    # Rectangle to be used with Subdiv2D\n    size = img.shape\n    rect = (0, 0, size[1], size[0])\n    \n    # Create an instance of Subdiv2D\n    subdiv = cv2.Subdiv2D(rect);\n\n    # Create an array of points.\n    points = [];\n    \n    # Read in the points from a text file\n    with open(\"./images/obama.txt\") as file :\n        for line in file :\n            x, y = line.split()\n            points.append((int(x), int(y)))\n\n    # Insert points into subdiv\n    for p in points :\n        subdiv.insert(p)\n        \n        # Show animation\n        if animate :\n            img_copy = img_orig.copy()\n            # Draw delaunay triangles\n            draw_delaunay( img_copy, subdiv, (255, 255, 255) );\n            cv2.imshow(win_delaunay, img_copy)\n            cv2.waitKey(100)\n\n    # Draw delaunay triangles\n    draw_delaunay( img, subdiv, (255, 255, 255) );\n\n    # Draw points\n    for p in points :\n        draw_point(img, p, (0,0,255))\n\n    # Allocate space for voronoi Diagram\n    img_voronoi = np.zeros(img.shape, dtype = img.dtype)\n\n    # Draw voronoi diagram\n    draw_voronoi(img_voronoi,subdiv)\n\n    # Show results\n    cv2.imshow(win_delaunay,img)\n    cv2.imshow(win_voronoi,img_voronoi)\n    cv2.waitKey(0)\n\n\n```\n\n### 参考博客\n* Facial Landmark Detection | Learn OpenCV  \nhttps://www.learnopencv.com/facial-landmark-detection/\n* Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python ) | Learn OpenCV  \nhttps://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/\n\n\n","source":"_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图.md","raw":"---\ntitle: 门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\ndate: 2019-06-29 00:11:20\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n\n##  Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n### 维诺图\n\n#### 定义\n给定平面中的一组点，所有点不共线，维诺图为每个点（生成元）创建多边形区域，使得每个区域中的点到生成元的距离最近。  \n\n#### 特点 \n* 每个V多边形内有一个生成元； \n* 每个V多边形内点到该生成元距离短于到其它生成元距离； \n* 多边形边界上的点到生成此边界的生成元距离相等（生成元连线的垂直平分线）； \n* 邻接图形的Voronoi多边形界线以原邻接界线作为子集。\n\n### 德罗奈三角剖分\n\n对点集进行结构化的一个重要的方法就是对这些点进行三角剖分。\n#### 定义\nDelaunay三角剖分定义为平面上的点集P是一种三角剖分，使得P中没有点严格处于剖分后中任意一个三角形外接圆的内部。\n\n#### 特点\n* Delaunay三角剖分与Voronoi图是对偶关系。  \n  对于一个维诺图，若任何两个生成元site之间有一条非空边界，那么这两个site之间连接一条边，由此得到的对偶图，就是一个三角剖分。\n* 空圆性  \n  对于Delaunay剖分中的任何一张face的外接圆必然是空的。 \n* 最近邻性  \n  任何一条连接于最近邻之间的边都会被Delaunay剖分所采用，因为这里头会存在一个以这条边为直径（弦）的空圆。\n* 复杂度  \n  在二维平面中，每增加一个点三角形的数目都会大概增加2，边数增加3。可以说在二维上的Delaunay剖分中是一个线性规模的数据结构。但在三维的情况下这两个指标最多会达到平房的量级，更高维的空间的一般结论也会达到2^d量级。\n \n \n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\opencv-delaunay-vornoi-subdiv-example.png\">\n\n\n\n### 维诺图生成方法\n\n首先生成其对偶元Delaunay三角网，再找出三角网每一三角形的外接圆圆心，最后连接相邻三角形的外接圆圆心，形成以每一个三角形顶点为生成元的多边形网。\n\n步骤：  \n（1）离散点自动构建三角网，即构建Delaunay三角网。对离散点和形成的三角形编号，记录每个三角形是由哪三个离散点构成的。   \n（2）计算每个三角形的外接圆圆心，并记录之。   \n（3）遍历三角形链表，寻找与当前三角形pTri三边共边的相邻三角形TriA，TriB和TriC。   \n（4）如果找到，则把寻找到的三角形的外心与pTri的外心连接，存入维诺边链表中。如果找不到，则求出最外边的中垂线射线存入维诺边链表中。   \n（5）遍历结束，所有维诺边被找到，根据边画出维诺图。\n\nDelaunay剖分是一种三角剖分的标准，实现它有多种算法，这里采用Bowyer-Watson算法，算法的基本步骤是：   \n（1）构造一个超级三角形，包含所有散点，放入三角形链表。   \n（2）将点集中的散点依次插入，在三角形链表中找出其外接圆包含插入点的三角形（称为该点的影响三角形），删除影响三角形的公共边，将插入点同影响三角形的全部顶点连接起来，从而完成一个点在Delaunay三角形链表中的插入。   \n（3）根据优化准则对局部新形成的三角形进行优化。将形成的三角形放入Delaunay三角形链表。   \n（4）循环执行上述第2步，直到所有散点插入完毕。\n\n\n\n\n```python\nfrom random import randint, seed\nfrom math import ceil, sqrt, log, floor\n\nimport delaunay as D\n```\n\n\n```python\n# 随机生成20个点\nseed(4)\nn = 10\nxs = [randint(1, 98) for x in range(n)]\nys = [randint(1, 98) for x in range(n)]\nzs = [0 for x in range(n)]\n\nDT = D.Delaunay_Triangulation()\nfor x, y in zip(xs, ys):\n    DT.AddPoint(D.Point(x, y))\n\nXS, YS, TS = DT.export()\n\n# print(XS)\n# print(YS)\n# print(TS)\n\n\"\"\"\nCreating and plotting unstructured triangular grids.\n\"\"\"\nimport matplotlib.pyplot as plt\nimport matplotlib.tri as tri\nimport math\n\n%matplotlib inline\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.plot(xs, ys, 'go')\n\n# Creating a Triangulation without specifying the triangles results in the\n# Delaunay triangulation of the points.\n\n# Create the Triangulation; no triangles so Delaunay triangulation created.\ntriang = tri.Triangulation(xs, ys)\n\n# Plot the triangulation.\nplt.subplot(1,3,2)\nplt.triplot(triang, 'bo-')\n\nplt.subplot(1,3,3)\nplt.triplot(tri.Triangulation(XS, YS, TS), 'ro--')\n\nplt.show()\n\n```\n\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\output_4_0.png\">\n\n\n\n\n### 参考资料\n* 计算几何笔记 - 知乎  \nhttps://zhuanlan.zhihu.com/c_162517931 \n* Delaunay Triangulation - menjiawan的专栏 - CSDN博客  \nhttps://blog.csdn.net/menjiawan/article/details/45073121\n\n### Bowyer-Watson算法\n\n__Bowyer算法__由英国Bath大学的Bowyer在1981年提出。算法首先构造离散点集的的若干离散点的Voronoi图，根据Voronoi领域准则连接临近点，得到初始Delaunay三角剖分，然后逐步加入剖分点，每加入一个点就对已有的Voronoi图进行修改，构造新点集的Voronoi图，直到所有点都插入完毕。\n* Computing Dirichlet tessellations1 | The Computer Journal | Oxford Academic  \nhttps://academic.oup.com/comjnl/article/24/2/162/338193\n\n__Watson算法__由澳大利亚悉尼大学Watson在1981年提出。算法采用空外接圆准则，直接从三角剖分入手。算法从初始三角划分开始，每加入一个离散点，找出所有外接圆包含此点的三角形，删除这些三角形面向该插入点的边，得到包含此点的多边形，将此点与多边形的定点连接就构成新的Delaunay三角剖分，重复此过程直至所有点插入完毕为止。注意，此算法当四点或以上共圆时将产生错误。\n* Computing the n-dimensional Delaunay tessellation with application to Voronoi polytopes1 | The Computer Journal | Oxford Academic  \nhttps://academic.oup.com/comjnl/article/24/2/167/338200\n\n__Bowyer-Watson算法__是根据上述两者算法相互补充改进得到的(貌似跟Watson算法差不多，具体可以参考上述两篇论文)，仍然是一种插点增量算法的一种。算法逻辑如下：\n\n- 1.求解离散点集的凸包，建立点集凸包边界节点的初始三角形划分；\n- 2.选择另外的离散点，插入指定位置，在已有的三角形中找出外接圆包含此点的三角形，并删除公共边，得到一个包含新插入点的多边形；\n- 3.将此点与多边形的其他顶点连接起来，构成新的三角形划分；\n- 4.重复插点知道所有点插入完毕。\n- 5.最后删除超级三角形相关联的三角形即可。\n\n\n### 判断点在三角形内\n\n\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\Trangle.png\">\n\n#### 1. 点P和三顶点夹角和360\n连接点P和三角形的三个顶点得到三条线段PA，PB和PC，求出这三条线段与三角形各边的夹角，如果所有夹角之和为360度，那么点P在三角形内，否则不在，此法直观，但效率低下。\n\n#### 2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧\n当选定线段AB时，点C位于AB的右侧，同理选定BC时，点A位于BC的右侧，最后选定CA时，点B位于CA的右侧，所以当选择某一条边时，我们只需验证点P与该边所对的点在同一侧即可。  \n如何判断两个点在某条线段的同一侧呢？可以通过叉积来实现，连接BP，将BP和BC做叉积，再将BA和BC做叉积，如果两个叉积的结果方向一致，那么两个点在同一侧。  \nBTW，判断两个向量的是否同向可以用点积实现，如果点积大于0，则两向量夹角是锐角，否则是钝角。\n\n#### 3. 利用外积同号和面积关系\n首先利用外积方向判断p在角ABC内：将BA和BC做叉积，连接BP，分别将BA和BP、BP和BC做叉积并判断与BA和BC的叉积同向。\n最后利用外积大小判断p在三角形ABC内：BA和BP、BP和BC的叉积之和，小于BA和BC的叉积。\n\n### 判断点在三角形的外接圆内\n\n#### 1.先求圆心、半径，比较半径和圆心到点P距离\n\n\n由三角形的外心坐标公式计算圆心坐标\n$$\nx=\\frac{\\left|\\begin{array}{lll}{x_{0}^{2}+y_{0}^{2}} & {y_{0}} & {1} \\\\ {x_{1}^{2}+y_{1}^{2}} & {y_{1}} & {1} \\\\ {x_{2}^{2}+y_{2}^{2}} & {y_{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|} , y=\\frac{\\left|\\begin{array}{lll}{x_{0}} & {x_{0}^{2}+y_{0}^{2}} & {1} \\\\ {x_{1}} & {x_{1}^{2}+y_{1}^{2}} & {1} \\\\ {x_{2}} & {x_{2}^{2}+y_{2}^{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|}\n$$\n根据这个外心的坐标公式计算出外接圆的圆心坐标，就能得到圆的半径，从而判断出点P与外接圆的位置关系。\n\n#### 2.利用角度关系\n<img src=\"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图\\P_Trangle.png\">\n\n- step1 计算$∠P_0P_1P_2$和$∠P_0PP_2$的大小，两个角的大小在$[0,π]$范围内。  \n    - step1.1 如果$∠P_0PP_2=0$，则点$P$不在圆内，结束；如果$∠P_0PP_2 = π$,则点$P$在圆内，结束。   \n   \n   \n- setp2 判断点$P$和$P_1$是否在$P_0P_2$同侧。  \n    - step2.1 这里通过判断向量外积 $\\overrightarrow{P_{1} P_{0}} \\times \\overrightarrow{P_{1} P_{2}}$与$\\overrightarrow{P P_{0}} \\times \\overrightarrow{P P_{2}}$ 是否同号，如果同号则在同一侧，否则在两侧。   \n\n\n- step3 如果点$P$和$P_1$是在$P_0P_2$同一侧，若$\\angle P_{0} P_{1} P_{2} \\leq \\angle P_{0} P P_{2}$,则点$P$在圆内，否则在圆外，结束；如果点$P$和$P_1$是在$P_0P_2$不在侧，若$\\angle P_{0} P_{1} P_{2}+\\angle P_{0} P P_{2} \\geq \\pi$，则点$P$在圆内，否则在圆外，结束。\n\n\n### Delaunay Triangulation & Voronoi Diagram in OpenCV\n\n给定一组点，可以使用openCV中的Subdiv2D类计算Delaunay三角剖分或Voronoi图。\n\n步骤：\n- 1.获取关键点列表\n> points = []  \n> points.append((x, y))\n- 2.定义要分区的矩形区间\n> img = cv2.imread(\"image.jpg\");\n> size = img.shape\n> rect = (0, 0, size[1], size[0])\n- 3.创建Subdiv2D类的实例\n> subdiv  = cv2.Subdiv2D(rect)\n- 4.使用subdiv.insert(point)插入点\n> for p in points :\n>     subdiv.insert(p)\n- 5.使用subdiv.getTriangleList方法得到Delaunay三角剖分的三角形列表\n> triangleList = subdiv.getTriangleList();\n> for t in triangleList :\n>     pt1 = (t[0], t[1])\n>     pt2 = (t[2], t[3])\n>     pt3 = (t[4], t[5])\n- 6.使用subdiv.getVoronoiFacetList方法得到Voronoi图形状和中心的列表\n> (facets, centers) = subdiv.getVoronoiFacetList([])\n\n\n\n```python\nimport cv2\nimport numpy as np\nimport random\n\n# Check if a point is inside a rectangle\ndef rect_contains(rect, point) :\n    if point[0] < rect[0] :\n        return False\n    elif point[1] < rect[1] :\n        return False\n    elif point[0] > rect[2] :\n        return False\n    elif point[1] > rect[3] :\n        return False\n    return True\n\n# Draw a point\ndef draw_point(img, p, color ) :\n    cv2.circle( img, p, 2, color, cv2.FILLED, cv2.LINE_AA, 0 )\n\n# Draw delaunay triangles\ndef draw_delaunay(img, subdiv, delaunay_color ) :\n    triangleList = subdiv.getTriangleList();\n    size = img.shape\n    r = (0, 0, size[1], size[0])\n\n    for t in triangleList :\n        pt1 = (t[0], t[1])\n        pt2 = (t[2], t[3])\n        pt3 = (t[4], t[5])\n        \n        if rect_contains(r, pt1) and rect_contains(r, pt2) and rect_contains(r, pt3) :\n            cv2.line(img, pt1, pt2, delaunay_color, 1, cv2.LINE_AA, 0)\n            cv2.line(img, pt2, pt3, delaunay_color, 1, cv2.LINE_AA, 0)\n            cv2.line(img, pt3, pt1, delaunay_color, 1, cv2.LINE_AA, 0)\n\n# Draw voronoi diagram\ndef draw_voronoi(img, subdiv) :\n\n    ( facets, centers) = subdiv.getVoronoiFacetList([])\n\n    for i in range(0,len(facets)) :\n        ifacet_arr = []\n        for f in facets[i] :\n            ifacet_arr.append(f)\n        \n        ifacet = np.array(ifacet_arr, np.int)\n        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n\n        cv2.fillConvexPoly(img, ifacet, color, cv2.LINE_AA, 0);\n        ifacets = np.array([ifacet])\n        cv2.polylines(img, ifacets, True, (0, 0, 0), 1, cv2.LINE_AA, 0)\n        cv2.circle(img, (centers[i][0], centers[i][1]), 3, (0, 0, 0), cv2.FILLED, cv2.LINE_AA, 0)\n\n\nif __name__ == '__main__':\n\n    # Define window names\n    win_delaunay = \"Delaunay Triangulation\"\n    win_voronoi = \"Voronoi Diagram\"\n\n    # Turn on animation while drawing triangles\n    animate = True\n    \n    # Define colors for drawing.\n    delaunay_color = (255,255,255)\n    points_color = (0, 0, 255)\n\n    # Read in the image.\n    img = cv2.imread(\"./images/obama.jpg\");\n    \n    # Keep a copy around\n    img_orig = img.copy();\n    \n    # Rectangle to be used with Subdiv2D\n    size = img.shape\n    rect = (0, 0, size[1], size[0])\n    \n    # Create an instance of Subdiv2D\n    subdiv = cv2.Subdiv2D(rect);\n\n    # Create an array of points.\n    points = [];\n    \n    # Read in the points from a text file\n    with open(\"./images/obama.txt\") as file :\n        for line in file :\n            x, y = line.split()\n            points.append((int(x), int(y)))\n\n    # Insert points into subdiv\n    for p in points :\n        subdiv.insert(p)\n        \n        # Show animation\n        if animate :\n            img_copy = img_orig.copy()\n            # Draw delaunay triangles\n            draw_delaunay( img_copy, subdiv, (255, 255, 255) );\n            cv2.imshow(win_delaunay, img_copy)\n            cv2.waitKey(100)\n\n    # Draw delaunay triangles\n    draw_delaunay( img, subdiv, (255, 255, 255) );\n\n    # Draw points\n    for p in points :\n        draw_point(img, p, (0,0,255))\n\n    # Allocate space for voronoi Diagram\n    img_voronoi = np.zeros(img.shape, dtype = img.dtype)\n\n    # Draw voronoi diagram\n    draw_voronoi(img_voronoi,subdiv)\n\n    # Show results\n    cv2.imshow(win_delaunay,img)\n    cv2.imshow(win_voronoi,img_voronoi)\n    cv2.waitKey(0)\n\n\n```\n\n### 参考博客\n* Facial Landmark Detection | Learn OpenCV  \nhttps://www.learnopencv.com/facial-landmark-detection/\n* Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python ) | Learn OpenCV  \nhttps://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/\n\n\n","slug":"门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图","published":1,"updated":"2019-07-01T05:48:01.231Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76h0043rsvjgozgk2eo","content":"<p><strong> 门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"Voronoi-diagram-维诺图-和-Delaunay-Triangulation-德罗奈三角剖分\"><a href=\"#Voronoi-diagram-维诺图-和-Delaunay-Triangulation-德罗奈三角剖分\" class=\"headerlink\" title=\"Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分\"></a>Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分</h2><a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n\n<h3 id=\"维诺图\"><a href=\"#维诺图\" class=\"headerlink\" title=\"维诺图\"></a>维诺图</h3><h4 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>给定平面中的一组点，所有点不共线，维诺图为每个点（生成元）创建多边形区域，使得每个区域中的点到生成元的距离最近。  </p>\n<h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>每个V多边形内有一个生成元； </li>\n<li>每个V多边形内点到该生成元距离短于到其它生成元距离； </li>\n<li>多边形边界上的点到生成此边界的生成元距离相等（生成元连线的垂直平分线）； </li>\n<li>邻接图形的Voronoi多边形界线以原邻接界线作为子集。</li>\n</ul>\n<h3 id=\"德罗奈三角剖分\"><a href=\"#德罗奈三角剖分\" class=\"headerlink\" title=\"德罗奈三角剖分\"></a>德罗奈三角剖分</h3><p>对点集进行结构化的一个重要的方法就是对这些点进行三角剖分。</p>\n<h4 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>Delaunay三角剖分定义为平面上的点集P是一种三角剖分，使得P中没有点严格处于剖分后中任意一个三角形外接圆的内部。</p>\n<h4 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>Delaunay三角剖分与Voronoi图是对偶关系。<br>对于一个维诺图，若任何两个生成元site之间有一条非空边界，那么这两个site之间连接一条边，由此得到的对偶图，就是一个三角剖分。</li>\n<li>空圆性<br>对于Delaunay剖分中的任何一张face的外接圆必然是空的。 </li>\n<li>最近邻性<br>任何一条连接于最近邻之间的边都会被Delaunay剖分所采用，因为这里头会存在一个以这条边为直径（弦）的空圆。</li>\n<li>复杂度<br>在二维平面中，每增加一个点三角形的数目都会大概增加2，边数增加3。可以说在二维上的Delaunay剖分中是一个线性规模的数据结构。但在三维的情况下这两个指标最多会达到平房的量级，更高维的空间的一般结论也会达到2^d量级。</li>\n</ul>\n<p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/opencv-delaunay-vornoi-subdiv-example.png\"></p>\n<h3 id=\"维诺图生成方法\"><a href=\"#维诺图生成方法\" class=\"headerlink\" title=\"维诺图生成方法\"></a>维诺图生成方法</h3><p>首先生成其对偶元Delaunay三角网，再找出三角网每一三角形的外接圆圆心，最后连接相邻三角形的外接圆圆心，形成以每一个三角形顶点为生成元的多边形网。</p>\n<p>步骤：<br>（1）离散点自动构建三角网，即构建Delaunay三角网。对离散点和形成的三角形编号，记录每个三角形是由哪三个离散点构成的。<br>（2）计算每个三角形的外接圆圆心，并记录之。<br>（3）遍历三角形链表，寻找与当前三角形pTri三边共边的相邻三角形TriA，TriB和TriC。<br>（4）如果找到，则把寻找到的三角形的外心与pTri的外心连接，存入维诺边链表中。如果找不到，则求出最外边的中垂线射线存入维诺边链表中。<br>（5）遍历结束，所有维诺边被找到，根据边画出维诺图。</p>\n<p>Delaunay剖分是一种三角剖分的标准，实现它有多种算法，这里采用Bowyer-Watson算法，算法的基本步骤是：<br>（1）构造一个超级三角形，包含所有散点，放入三角形链表。<br>（2）将点集中的散点依次插入，在三角形链表中找出其外接圆包含插入点的三角形（称为该点的影响三角形），删除影响三角形的公共边，将插入点同影响三角形的全部顶点连接起来，从而完成一个点在Delaunay三角形链表中的插入。<br>（3）根据优化准则对局部新形成的三角形进行优化。将形成的三角形放入Delaunay三角形链表。<br>（4）循环执行上述第2步，直到所有散点插入完毕。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> random <span class=\"keyword\">import</span> randint, seed</span><br><span class=\"line\"><span class=\"keyword\">from</span> math <span class=\"keyword\">import</span> ceil, sqrt, log, floor</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> delaunay <span class=\"keyword\">as</span> D</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 随机生成20个点</span></span><br><span class=\"line\">seed(<span class=\"number\">4</span>)</span><br><span class=\"line\">n = <span class=\"number\">10</span></span><br><span class=\"line\">xs = [randint(<span class=\"number\">1</span>, <span class=\"number\">98</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">ys = [randint(<span class=\"number\">1</span>, <span class=\"number\">98</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">zs = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\"></span><br><span class=\"line\">DT = D.Delaunay_Triangulation()</span><br><span class=\"line\"><span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> zip(xs, ys):</span><br><span class=\"line\">    DT.AddPoint(D.Point(x, y))</span><br><span class=\"line\"></span><br><span class=\"line\">XS, YS, TS = DT.export()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print(XS)</span></span><br><span class=\"line\"><span class=\"comment\"># print(YS)</span></span><br><span class=\"line\"><span class=\"comment\"># print(TS)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">Creating and plotting unstructured triangular grids.</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.tri <span class=\"keyword\">as</span> tri</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.plot(xs, ys, <span class=\"string\">'go'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Creating a Triangulation without specifying the triangles results in the</span></span><br><span class=\"line\"><span class=\"comment\"># Delaunay triangulation of the points.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create the Triangulation; no triangles so Delaunay triangulation created.</span></span><br><span class=\"line\">triang = tri.Triangulation(xs, ys)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the triangulation.</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.triplot(triang, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.triplot(tri.Triangulation(XS, YS, TS), <span class=\"string\">'ro--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/output_4_0.png\"></p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li>计算几何笔记 - 知乎<br><a href=\"https://zhuanlan.zhihu.com/c_162517931\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/c_162517931</a> </li>\n<li>Delaunay Triangulation - menjiawan的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/menjiawan/article/details/45073121\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/menjiawan/article/details/45073121</a></li>\n</ul>\n<h3 id=\"Bowyer-Watson算法\"><a href=\"#Bowyer-Watson算法\" class=\"headerlink\" title=\"Bowyer-Watson算法\"></a>Bowyer-Watson算法</h3><p><strong>Bowyer算法</strong>由英国Bath大学的Bowyer在1981年提出。算法首先构造离散点集的的若干离散点的Voronoi图，根据Voronoi领域准则连接临近点，得到初始Delaunay三角剖分，然后逐步加入剖分点，每加入一个点就对已有的Voronoi图进行修改，构造新点集的Voronoi图，直到所有点都插入完毕。</p>\n<ul>\n<li>Computing Dirichlet tessellations1 | The Computer Journal | Oxford Academic<br><a href=\"https://academic.oup.com/comjnl/article/24/2/162/338193\" target=\"_blank\" rel=\"noopener\">https://academic.oup.com/comjnl/article/24/2/162/338193</a></li>\n</ul>\n<p><strong>Watson算法</strong>由澳大利亚悉尼大学Watson在1981年提出。算法采用空外接圆准则，直接从三角剖分入手。算法从初始三角划分开始，每加入一个离散点，找出所有外接圆包含此点的三角形，删除这些三角形面向该插入点的边，得到包含此点的多边形，将此点与多边形的定点连接就构成新的Delaunay三角剖分，重复此过程直至所有点插入完毕为止。注意，此算法当四点或以上共圆时将产生错误。</p>\n<ul>\n<li>Computing the n-dimensional Delaunay tessellation with application to Voronoi polytopes1 | The Computer Journal | Oxford Academic<br><a href=\"https://academic.oup.com/comjnl/article/24/2/167/338200\" target=\"_blank\" rel=\"noopener\">https://academic.oup.com/comjnl/article/24/2/167/338200</a></li>\n</ul>\n<p><strong>Bowyer-Watson算法</strong>是根据上述两者算法相互补充改进得到的(貌似跟Watson算法差不多，具体可以参考上述两篇论文)，仍然是一种插点增量算法的一种。算法逻辑如下：</p>\n<ul>\n<li>1.求解离散点集的凸包，建立点集凸包边界节点的初始三角形划分；</li>\n<li>2.选择另外的离散点，插入指定位置，在已有的三角形中找出外接圆包含此点的三角形，并删除公共边，得到一个包含新插入点的多边形；</li>\n<li>3.将此点与多边形的其他顶点连接起来，构成新的三角形划分；</li>\n<li>4.重复插点知道所有点插入完毕。</li>\n<li>5.最后删除超级三角形相关联的三角形即可。</li>\n</ul>\n<h3 id=\"判断点在三角形内\"><a href=\"#判断点在三角形内\" class=\"headerlink\" title=\"判断点在三角形内\"></a>判断点在三角形内</h3><p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/Trangle.png\"></p>\n<h4 id=\"1-点P和三顶点夹角和360\"><a href=\"#1-点P和三顶点夹角和360\" class=\"headerlink\" title=\"1. 点P和三顶点夹角和360\"></a>1. 点P和三顶点夹角和360</h4><p>连接点P和三角形的三个顶点得到三条线段PA，PB和PC，求出这三条线段与三角形各边的夹角，如果所有夹角之和为360度，那么点P在三角形内，否则不在，此法直观，但效率低下。</p>\n<h4 id=\"2-依次选定三边，点P和另一顶点在同一侧-两个外积同号，那么点在一侧\"><a href=\"#2-依次选定三边，点P和另一顶点在同一侧-两个外积同号，那么点在一侧\" class=\"headerlink\" title=\"2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧\"></a>2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧</h4><p>当选定线段AB时，点C位于AB的右侧，同理选定BC时，点A位于BC的右侧，最后选定CA时，点B位于CA的右侧，所以当选择某一条边时，我们只需验证点P与该边所对的点在同一侧即可。<br>如何判断两个点在某条线段的同一侧呢？可以通过叉积来实现，连接BP，将BP和BC做叉积，再将BA和BC做叉积，如果两个叉积的结果方向一致，那么两个点在同一侧。<br>BTW，判断两个向量的是否同向可以用点积实现，如果点积大于0，则两向量夹角是锐角，否则是钝角。</p>\n<h4 id=\"3-利用外积同号和面积关系\"><a href=\"#3-利用外积同号和面积关系\" class=\"headerlink\" title=\"3. 利用外积同号和面积关系\"></a>3. 利用外积同号和面积关系</h4><p>首先利用外积方向判断p在角ABC内：将BA和BC做叉积，连接BP，分别将BA和BP、BP和BC做叉积并判断与BA和BC的叉积同向。<br>最后利用外积大小判断p在三角形ABC内：BA和BP、BP和BC的叉积之和，小于BA和BC的叉积。</p>\n<h3 id=\"判断点在三角形的外接圆内\"><a href=\"#判断点在三角形的外接圆内\" class=\"headerlink\" title=\"判断点在三角形的外接圆内\"></a>判断点在三角形的外接圆内</h3><h4 id=\"1-先求圆心、半径，比较半径和圆心到点P距离\"><a href=\"#1-先求圆心、半径，比较半径和圆心到点P距离\" class=\"headerlink\" title=\"1.先求圆心、半径，比较半径和圆心到点P距离\"></a>1.先求圆心、半径，比较半径和圆心到点P距离</h4><p>由三角形的外心坐标公式计算圆心坐标</p>\n<script type=\"math/tex; mode=display\">\nx=\\frac{\\left|\\begin{array}{lll}{x_{0}^{2}+y_{0}^{2}} & {y_{0}} & {1} \\\\ {x_{1}^{2}+y_{1}^{2}} & {y_{1}} & {1} \\\\ {x_{2}^{2}+y_{2}^{2}} & {y_{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|} , y=\\frac{\\left|\\begin{array}{lll}{x_{0}} & {x_{0}^{2}+y_{0}^{2}} & {1} \\\\ {x_{1}} & {x_{1}^{2}+y_{1}^{2}} & {1} \\\\ {x_{2}} & {x_{2}^{2}+y_{2}^{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|}</script><p>根据这个外心的坐标公式计算出外接圆的圆心坐标，就能得到圆的半径，从而判断出点P与外接圆的位置关系。</p>\n<h4 id=\"2-利用角度关系\"><a href=\"#2-利用角度关系\" class=\"headerlink\" title=\"2.利用角度关系\"></a>2.利用角度关系</h4><p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/P_Trangle.png\"></p>\n<ul>\n<li>step1 计算$∠P_0P_1P_2$和$∠P_0PP_2$的大小，两个角的大小在$[0,π]$范围内。  <ul>\n<li>step1.1 如果$∠P_0PP_2=0$，则点$P$不在圆内，结束；如果$∠P_0PP_2 = π$,则点$P$在圆内，结束。   </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>setp2 判断点$P$和$P_1$是否在$P_0P_2$同侧。  <ul>\n<li>step2.1 这里通过判断向量外积 $\\overrightarrow{P_{1} P_{0}} \\times \\overrightarrow{P_{1} P_{2}}$与$\\overrightarrow{P P_{0}} \\times \\overrightarrow{P P_{2}}$ 是否同号，如果同号则在同一侧，否则在两侧。   </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>step3 如果点$P$和$P_1$是在$P_0P_2$同一侧，若$\\angle P_{0} P_{1} P_{2} \\leq \\angle P_{0} P P_{2}$,则点$P$在圆内，否则在圆外，结束；如果点$P$和$P_1$是在$P_0P_2$不在侧，若$\\angle P_{0} P_{1} P_{2}+\\angle P_{0} P P_{2} \\geq \\pi$，则点$P$在圆内，否则在圆外，结束。</li>\n</ul>\n<h3 id=\"Delaunay-Triangulation-amp-Voronoi-Diagram-in-OpenCV\"><a href=\"#Delaunay-Triangulation-amp-Voronoi-Diagram-in-OpenCV\" class=\"headerlink\" title=\"Delaunay Triangulation &amp; Voronoi Diagram in OpenCV\"></a>Delaunay Triangulation &amp; Voronoi Diagram in OpenCV</h3><p>给定一组点，可以使用openCV中的Subdiv2D类计算Delaunay三角剖分或Voronoi图。</p>\n<p>步骤：</p>\n<ul>\n<li>1.获取关键点列表<blockquote>\n<p>points = []<br>points.append((x, y))</p>\n</blockquote>\n</li>\n<li>2.定义要分区的矩形区间<blockquote>\n<p>img = cv2.imread(“image.jpg”);<br>size = img.shape<br>rect = (0, 0, size[1], size[0])</p>\n</blockquote>\n</li>\n<li>3.创建Subdiv2D类的实例<blockquote>\n<p>subdiv  = cv2.Subdiv2D(rect)</p>\n</blockquote>\n</li>\n<li>4.使用subdiv.insert(point)插入点<blockquote>\n<p>for p in points :</p>\n<pre><code>subdiv.insert(p)\n</code></pre></blockquote>\n</li>\n<li>5.使用subdiv.getTriangleList方法得到Delaunay三角剖分的三角形列表<blockquote>\n<p>triangleList = subdiv.getTriangleList();<br>for t in triangleList :</p>\n<pre><code>pt1 = (t[0], t[1])\npt2 = (t[2], t[3])\npt3 = (t[4], t[5])\n</code></pre></blockquote>\n</li>\n<li>6.使用subdiv.getVoronoiFacetList方法得到Voronoi图形状和中心的列表<blockquote>\n<p>(facets, centers) = subdiv.getVoronoiFacetList([])</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if a point is inside a rectangle</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">rect_contains</span><span class=\"params\">(rect, point)</span> :</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> point[<span class=\"number\">0</span>] &lt; rect[<span class=\"number\">0</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">1</span>] &lt; rect[<span class=\"number\">1</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">0</span>] &gt; rect[<span class=\"number\">2</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">1</span>] &gt; rect[<span class=\"number\">3</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw a point</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_point</span><span class=\"params\">(img, p, color )</span> :</span></span><br><span class=\"line\">    cv2.circle( img, p, <span class=\"number\">2</span>, color, cv2.FILLED, cv2.LINE_AA, <span class=\"number\">0</span> )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_delaunay</span><span class=\"params\">(img, subdiv, delaunay_color )</span> :</span></span><br><span class=\"line\">    triangleList = subdiv.getTriangleList();</span><br><span class=\"line\">    size = img.shape</span><br><span class=\"line\">    r = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, size[<span class=\"number\">1</span>], size[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> triangleList :</span><br><span class=\"line\">        pt1 = (t[<span class=\"number\">0</span>], t[<span class=\"number\">1</span>])</span><br><span class=\"line\">        pt2 = (t[<span class=\"number\">2</span>], t[<span class=\"number\">3</span>])</span><br><span class=\"line\">        pt3 = (t[<span class=\"number\">4</span>], t[<span class=\"number\">5</span>])</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> rect_contains(r, pt1) <span class=\"keyword\">and</span> rect_contains(r, pt2) <span class=\"keyword\">and</span> rect_contains(r, pt3) :</span><br><span class=\"line\">            cv2.line(img, pt1, pt2, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">            cv2.line(img, pt2, pt3, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">            cv2.line(img, pt3, pt1, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw voronoi diagram</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_voronoi</span><span class=\"params\">(img, subdiv)</span> :</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ( facets, centers) = subdiv.getVoronoiFacetList([])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>,len(facets)) :</span><br><span class=\"line\">        ifacet_arr = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> facets[i] :</span><br><span class=\"line\">            ifacet_arr.append(f)</span><br><span class=\"line\">        </span><br><span class=\"line\">        ifacet = np.array(ifacet_arr, np.int)</span><br><span class=\"line\">        color = (random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>), random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>), random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        cv2.fillConvexPoly(img, ifacet, color, cv2.LINE_AA, <span class=\"number\">0</span>);</span><br><span class=\"line\">        ifacets = np.array([ifacet])</span><br><span class=\"line\">        cv2.polylines(img, ifacets, <span class=\"literal\">True</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">        cv2.circle(img, (centers[i][<span class=\"number\">0</span>], centers[i][<span class=\"number\">1</span>]), <span class=\"number\">3</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Define window names</span></span><br><span class=\"line\">    win_delaunay = <span class=\"string\">\"Delaunay Triangulation\"</span></span><br><span class=\"line\">    win_voronoi = <span class=\"string\">\"Voronoi Diagram\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Turn on animation while drawing triangles</span></span><br><span class=\"line\">    animate = <span class=\"literal\">True</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Define colors for drawing.</span></span><br><span class=\"line\">    delaunay_color = (<span class=\"number\">255</span>,<span class=\"number\">255</span>,<span class=\"number\">255</span>)</span><br><span class=\"line\">    points_color = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Read in the image.</span></span><br><span class=\"line\">    img = cv2.imread(<span class=\"string\">\"./images/obama.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Keep a copy around</span></span><br><span class=\"line\">    img_orig = img.copy();</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Rectangle to be used with Subdiv2D</span></span><br><span class=\"line\">    size = img.shape</span><br><span class=\"line\">    rect = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, size[<span class=\"number\">1</span>], size[<span class=\"number\">0</span>])</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Create an instance of Subdiv2D</span></span><br><span class=\"line\">    subdiv = cv2.Subdiv2D(rect);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Create an array of points.</span></span><br><span class=\"line\">    points = [];</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Read in the points from a text file</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(<span class=\"string\">\"./images/obama.txt\"</span>) <span class=\"keyword\">as</span> file :</span><br><span class=\"line\">        <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> file :</span><br><span class=\"line\">            x, y = line.split()</span><br><span class=\"line\">            points.append((int(x), int(y)))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Insert points into subdiv</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> points :</span><br><span class=\"line\">        subdiv.insert(p)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Show animation</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> animate :</span><br><span class=\"line\">            img_copy = img_orig.copy()</span><br><span class=\"line\">            <span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\">            draw_delaunay( img_copy, subdiv, (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>) );</span><br><span class=\"line\">            cv2.imshow(win_delaunay, img_copy)</span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\">    draw_delaunay( img, subdiv, (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>) );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw points</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> points :</span><br><span class=\"line\">        draw_point(img, p, (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Allocate space for voronoi Diagram</span></span><br><span class=\"line\">    img_voronoi = np.zeros(img.shape, dtype = img.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw voronoi diagram</span></span><br><span class=\"line\">    draw_voronoi(img_voronoi,subdiv)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Show results</span></span><br><span class=\"line\">    cv2.imshow(win_delaunay,img)</span><br><span class=\"line\">    cv2.imshow(win_voronoi,img_voronoi)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h3><ul>\n<li>Facial Landmark Detection | Learn OpenCV<br><a href=\"https://www.learnopencv.com/facial-landmark-detection/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/facial-landmark-detection/</a></li>\n<li>Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python ) | Learn OpenCV<br><a href=\"https://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/</a></li>\n</ul>\n</the>","site":{"data":{}},"excerpt":"<p><strong> 门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"Voronoi-diagram-维诺图-和-Delaunay-Triangulation-德罗奈三角剖分\"><a href=\"#Voronoi-diagram-维诺图-和-Delaunay-Triangulation-德罗奈三角剖分\" class=\"headerlink\" title=\"Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分\"></a>Voronoi diagram 维诺图 和 Delaunay Triangulation 德罗奈三角剖分</h2>","more":"<the rest of contents | 余下全文>\n\n\n<h3 id=\"维诺图\"><a href=\"#维诺图\" class=\"headerlink\" title=\"维诺图\"></a>维诺图</h3><h4 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>给定平面中的一组点，所有点不共线，维诺图为每个点（生成元）创建多边形区域，使得每个区域中的点到生成元的距离最近。  </p>\n<h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>每个V多边形内有一个生成元； </li>\n<li>每个V多边形内点到该生成元距离短于到其它生成元距离； </li>\n<li>多边形边界上的点到生成此边界的生成元距离相等（生成元连线的垂直平分线）； </li>\n<li>邻接图形的Voronoi多边形界线以原邻接界线作为子集。</li>\n</ul>\n<h3 id=\"德罗奈三角剖分\"><a href=\"#德罗奈三角剖分\" class=\"headerlink\" title=\"德罗奈三角剖分\"></a>德罗奈三角剖分</h3><p>对点集进行结构化的一个重要的方法就是对这些点进行三角剖分。</p>\n<h4 id=\"定义-1\"><a href=\"#定义-1\" class=\"headerlink\" title=\"定义\"></a>定义</h4><p>Delaunay三角剖分定义为平面上的点集P是一种三角剖分，使得P中没有点严格处于剖分后中任意一个三角形外接圆的内部。</p>\n<h4 id=\"特点-1\"><a href=\"#特点-1\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>Delaunay三角剖分与Voronoi图是对偶关系。<br>对于一个维诺图，若任何两个生成元site之间有一条非空边界，那么这两个site之间连接一条边，由此得到的对偶图，就是一个三角剖分。</li>\n<li>空圆性<br>对于Delaunay剖分中的任何一张face的外接圆必然是空的。 </li>\n<li>最近邻性<br>任何一条连接于最近邻之间的边都会被Delaunay剖分所采用，因为这里头会存在一个以这条边为直径（弦）的空圆。</li>\n<li>复杂度<br>在二维平面中，每增加一个点三角形的数目都会大概增加2，边数增加3。可以说在二维上的Delaunay剖分中是一个线性规模的数据结构。但在三维的情况下这两个指标最多会达到平房的量级，更高维的空间的一般结论也会达到2^d量级。</li>\n</ul>\n<p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/opencv-delaunay-vornoi-subdiv-example.png\"></p>\n<h3 id=\"维诺图生成方法\"><a href=\"#维诺图生成方法\" class=\"headerlink\" title=\"维诺图生成方法\"></a>维诺图生成方法</h3><p>首先生成其对偶元Delaunay三角网，再找出三角网每一三角形的外接圆圆心，最后连接相邻三角形的外接圆圆心，形成以每一个三角形顶点为生成元的多边形网。</p>\n<p>步骤：<br>（1）离散点自动构建三角网，即构建Delaunay三角网。对离散点和形成的三角形编号，记录每个三角形是由哪三个离散点构成的。<br>（2）计算每个三角形的外接圆圆心，并记录之。<br>（3）遍历三角形链表，寻找与当前三角形pTri三边共边的相邻三角形TriA，TriB和TriC。<br>（4）如果找到，则把寻找到的三角形的外心与pTri的外心连接，存入维诺边链表中。如果找不到，则求出最外边的中垂线射线存入维诺边链表中。<br>（5）遍历结束，所有维诺边被找到，根据边画出维诺图。</p>\n<p>Delaunay剖分是一种三角剖分的标准，实现它有多种算法，这里采用Bowyer-Watson算法，算法的基本步骤是：<br>（1）构造一个超级三角形，包含所有散点，放入三角形链表。<br>（2）将点集中的散点依次插入，在三角形链表中找出其外接圆包含插入点的三角形（称为该点的影响三角形），删除影响三角形的公共边，将插入点同影响三角形的全部顶点连接起来，从而完成一个点在Delaunay三角形链表中的插入。<br>（3）根据优化准则对局部新形成的三角形进行优化。将形成的三角形放入Delaunay三角形链表。<br>（4）循环执行上述第2步，直到所有散点插入完毕。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> random <span class=\"keyword\">import</span> randint, seed</span><br><span class=\"line\"><span class=\"keyword\">from</span> math <span class=\"keyword\">import</span> ceil, sqrt, log, floor</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> delaunay <span class=\"keyword\">as</span> D</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 随机生成20个点</span></span><br><span class=\"line\">seed(<span class=\"number\">4</span>)</span><br><span class=\"line\">n = <span class=\"number\">10</span></span><br><span class=\"line\">xs = [randint(<span class=\"number\">1</span>, <span class=\"number\">98</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">ys = [randint(<span class=\"number\">1</span>, <span class=\"number\">98</span>) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\">zs = [<span class=\"number\">0</span> <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> range(n)]</span><br><span class=\"line\"></span><br><span class=\"line\">DT = D.Delaunay_Triangulation()</span><br><span class=\"line\"><span class=\"keyword\">for</span> x, y <span class=\"keyword\">in</span> zip(xs, ys):</span><br><span class=\"line\">    DT.AddPoint(D.Point(x, y))</span><br><span class=\"line\"></span><br><span class=\"line\">XS, YS, TS = DT.export()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># print(XS)</span></span><br><span class=\"line\"><span class=\"comment\"># print(YS)</span></span><br><span class=\"line\"><span class=\"comment\"># print(TS)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">Creating and plotting unstructured triangular grids.</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.tri <span class=\"keyword\">as</span> tri</span><br><span class=\"line\"><span class=\"keyword\">import</span> math</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">15</span>,<span class=\"number\">5</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">1</span>)</span><br><span class=\"line\">plt.plot(xs, ys, <span class=\"string\">'go'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Creating a Triangulation without specifying the triangles results in the</span></span><br><span class=\"line\"><span class=\"comment\"># Delaunay triangulation of the points.</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Create the Triangulation; no triangles so Delaunay triangulation created.</span></span><br><span class=\"line\">triang = tri.Triangulation(xs, ys)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Plot the triangulation.</span></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.triplot(triang, <span class=\"string\">'bo-'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">1</span>,<span class=\"number\">3</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">plt.triplot(tri.Triangulation(XS, YS, TS), <span class=\"string\">'ro--'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/output_4_0.png\"></p>\n<h3 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h3><ul>\n<li>计算几何笔记 - 知乎<br><a href=\"https://zhuanlan.zhihu.com/c_162517931\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/c_162517931</a> </li>\n<li>Delaunay Triangulation - menjiawan的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/menjiawan/article/details/45073121\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/menjiawan/article/details/45073121</a></li>\n</ul>\n<h3 id=\"Bowyer-Watson算法\"><a href=\"#Bowyer-Watson算法\" class=\"headerlink\" title=\"Bowyer-Watson算法\"></a>Bowyer-Watson算法</h3><p><strong>Bowyer算法</strong>由英国Bath大学的Bowyer在1981年提出。算法首先构造离散点集的的若干离散点的Voronoi图，根据Voronoi领域准则连接临近点，得到初始Delaunay三角剖分，然后逐步加入剖分点，每加入一个点就对已有的Voronoi图进行修改，构造新点集的Voronoi图，直到所有点都插入完毕。</p>\n<ul>\n<li>Computing Dirichlet tessellations1 | The Computer Journal | Oxford Academic<br><a href=\"https://academic.oup.com/comjnl/article/24/2/162/338193\" target=\"_blank\" rel=\"noopener\">https://academic.oup.com/comjnl/article/24/2/162/338193</a></li>\n</ul>\n<p><strong>Watson算法</strong>由澳大利亚悉尼大学Watson在1981年提出。算法采用空外接圆准则，直接从三角剖分入手。算法从初始三角划分开始，每加入一个离散点，找出所有外接圆包含此点的三角形，删除这些三角形面向该插入点的边，得到包含此点的多边形，将此点与多边形的定点连接就构成新的Delaunay三角剖分，重复此过程直至所有点插入完毕为止。注意，此算法当四点或以上共圆时将产生错误。</p>\n<ul>\n<li>Computing the n-dimensional Delaunay tessellation with application to Voronoi polytopes1 | The Computer Journal | Oxford Academic<br><a href=\"https://academic.oup.com/comjnl/article/24/2/167/338200\" target=\"_blank\" rel=\"noopener\">https://academic.oup.com/comjnl/article/24/2/167/338200</a></li>\n</ul>\n<p><strong>Bowyer-Watson算法</strong>是根据上述两者算法相互补充改进得到的(貌似跟Watson算法差不多，具体可以参考上述两篇论文)，仍然是一种插点增量算法的一种。算法逻辑如下：</p>\n<ul>\n<li>1.求解离散点集的凸包，建立点集凸包边界节点的初始三角形划分；</li>\n<li>2.选择另外的离散点，插入指定位置，在已有的三角形中找出外接圆包含此点的三角形，并删除公共边，得到一个包含新插入点的多边形；</li>\n<li>3.将此点与多边形的其他顶点连接起来，构成新的三角形划分；</li>\n<li>4.重复插点知道所有点插入完毕。</li>\n<li>5.最后删除超级三角形相关联的三角形即可。</li>\n</ul>\n<h3 id=\"判断点在三角形内\"><a href=\"#判断点在三角形内\" class=\"headerlink\" title=\"判断点在三角形内\"></a>判断点在三角形内</h3><p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/Trangle.png\"></p>\n<h4 id=\"1-点P和三顶点夹角和360\"><a href=\"#1-点P和三顶点夹角和360\" class=\"headerlink\" title=\"1. 点P和三顶点夹角和360\"></a>1. 点P和三顶点夹角和360</h4><p>连接点P和三角形的三个顶点得到三条线段PA，PB和PC，求出这三条线段与三角形各边的夹角，如果所有夹角之和为360度，那么点P在三角形内，否则不在，此法直观，但效率低下。</p>\n<h4 id=\"2-依次选定三边，点P和另一顶点在同一侧-两个外积同号，那么点在一侧\"><a href=\"#2-依次选定三边，点P和另一顶点在同一侧-两个外积同号，那么点在一侧\" class=\"headerlink\" title=\"2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧\"></a>2. 依次选定三边，点P和另一顶点在同一侧:两个外积同号，那么点在一侧</h4><p>当选定线段AB时，点C位于AB的右侧，同理选定BC时，点A位于BC的右侧，最后选定CA时，点B位于CA的右侧，所以当选择某一条边时，我们只需验证点P与该边所对的点在同一侧即可。<br>如何判断两个点在某条线段的同一侧呢？可以通过叉积来实现，连接BP，将BP和BC做叉积，再将BA和BC做叉积，如果两个叉积的结果方向一致，那么两个点在同一侧。<br>BTW，判断两个向量的是否同向可以用点积实现，如果点积大于0，则两向量夹角是锐角，否则是钝角。</p>\n<h4 id=\"3-利用外积同号和面积关系\"><a href=\"#3-利用外积同号和面积关系\" class=\"headerlink\" title=\"3. 利用外积同号和面积关系\"></a>3. 利用外积同号和面积关系</h4><p>首先利用外积方向判断p在角ABC内：将BA和BC做叉积，连接BP，分别将BA和BP、BP和BC做叉积并判断与BA和BC的叉积同向。<br>最后利用外积大小判断p在三角形ABC内：BA和BP、BP和BC的叉积之和，小于BA和BC的叉积。</p>\n<h3 id=\"判断点在三角形的外接圆内\"><a href=\"#判断点在三角形的外接圆内\" class=\"headerlink\" title=\"判断点在三角形的外接圆内\"></a>判断点在三角形的外接圆内</h3><h4 id=\"1-先求圆心、半径，比较半径和圆心到点P距离\"><a href=\"#1-先求圆心、半径，比较半径和圆心到点P距离\" class=\"headerlink\" title=\"1.先求圆心、半径，比较半径和圆心到点P距离\"></a>1.先求圆心、半径，比较半径和圆心到点P距离</h4><p>由三角形的外心坐标公式计算圆心坐标</p>\n<script type=\"math/tex; mode=display\">\nx=\\frac{\\left|\\begin{array}{lll}{x_{0}^{2}+y_{0}^{2}} & {y_{0}} & {1} \\\\ {x_{1}^{2}+y_{1}^{2}} & {y_{1}} & {1} \\\\ {x_{2}^{2}+y_{2}^{2}} & {y_{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|} , y=\\frac{\\left|\\begin{array}{lll}{x_{0}} & {x_{0}^{2}+y_{0}^{2}} & {1} \\\\ {x_{1}} & {x_{1}^{2}+y_{1}^{2}} & {1} \\\\ {x_{2}} & {x_{2}^{2}+y_{2}^{2}} & {1}\\end{array}\\right|}{2\\left|\\begin{array}{ccc}{x_{0}} & {y_{0}} & {1} \\\\ {x_{1}} & {y_{1}} & {1} \\\\ {x_{2}} & {y_{2}} & {1}\\end{array}\\right|}</script><p>根据这个外心的坐标公式计算出外接圆的圆心坐标，就能得到圆的半径，从而判断出点P与外接圆的位置关系。</p>\n<h4 id=\"2-利用角度关系\"><a href=\"#2-利用角度关系\" class=\"headerlink\" title=\"2.利用角度关系\"></a>2.利用角度关系</h4><p><img src=\"/2019/06/29/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/P_Trangle.png\"></p>\n<ul>\n<li>step1 计算$∠P_0P_1P_2$和$∠P_0PP_2$的大小，两个角的大小在$[0,π]$范围内。  <ul>\n<li>step1.1 如果$∠P_0PP_2=0$，则点$P$不在圆内，结束；如果$∠P_0PP_2 = π$,则点$P$在圆内，结束。   </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>setp2 判断点$P$和$P_1$是否在$P_0P_2$同侧。  <ul>\n<li>step2.1 这里通过判断向量外积 $\\overrightarrow{P_{1} P_{0}} \\times \\overrightarrow{P_{1} P_{2}}$与$\\overrightarrow{P P_{0}} \\times \\overrightarrow{P P_{2}}$ 是否同号，如果同号则在同一侧，否则在两侧。   </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>step3 如果点$P$和$P_1$是在$P_0P_2$同一侧，若$\\angle P_{0} P_{1} P_{2} \\leq \\angle P_{0} P P_{2}$,则点$P$在圆内，否则在圆外，结束；如果点$P$和$P_1$是在$P_0P_2$不在侧，若$\\angle P_{0} P_{1} P_{2}+\\angle P_{0} P P_{2} \\geq \\pi$，则点$P$在圆内，否则在圆外，结束。</li>\n</ul>\n<h3 id=\"Delaunay-Triangulation-amp-Voronoi-Diagram-in-OpenCV\"><a href=\"#Delaunay-Triangulation-amp-Voronoi-Diagram-in-OpenCV\" class=\"headerlink\" title=\"Delaunay Triangulation &amp; Voronoi Diagram in OpenCV\"></a>Delaunay Triangulation &amp; Voronoi Diagram in OpenCV</h3><p>给定一组点，可以使用openCV中的Subdiv2D类计算Delaunay三角剖分或Voronoi图。</p>\n<p>步骤：</p>\n<ul>\n<li>1.获取关键点列表<blockquote>\n<p>points = []<br>points.append((x, y))</p>\n</blockquote>\n</li>\n<li>2.定义要分区的矩形区间<blockquote>\n<p>img = cv2.imread(“image.jpg”);<br>size = img.shape<br>rect = (0, 0, size[1], size[0])</p>\n</blockquote>\n</li>\n<li>3.创建Subdiv2D类的实例<blockquote>\n<p>subdiv  = cv2.Subdiv2D(rect)</p>\n</blockquote>\n</li>\n<li>4.使用subdiv.insert(point)插入点<blockquote>\n<p>for p in points :</p>\n<pre><code>subdiv.insert(p)\n</code></pre></blockquote>\n</li>\n<li>5.使用subdiv.getTriangleList方法得到Delaunay三角剖分的三角形列表<blockquote>\n<p>triangleList = subdiv.getTriangleList();<br>for t in triangleList :</p>\n<pre><code>pt1 = (t[0], t[1])\npt2 = (t[2], t[3])\npt3 = (t[4], t[5])\n</code></pre></blockquote>\n</li>\n<li>6.使用subdiv.getVoronoiFacetList方法得到Voronoi图形状和中心的列表<blockquote>\n<p>(facets, centers) = subdiv.getVoronoiFacetList([])</p>\n</blockquote>\n</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> random</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Check if a point is inside a rectangle</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">rect_contains</span><span class=\"params\">(rect, point)</span> :</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> point[<span class=\"number\">0</span>] &lt; rect[<span class=\"number\">0</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">1</span>] &lt; rect[<span class=\"number\">1</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">0</span>] &gt; rect[<span class=\"number\">2</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">elif</span> point[<span class=\"number\">1</span>] &gt; rect[<span class=\"number\">3</span>] :</span><br><span class=\"line\">        <span class=\"keyword\">return</span> <span class=\"literal\">False</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw a point</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_point</span><span class=\"params\">(img, p, color )</span> :</span></span><br><span class=\"line\">    cv2.circle( img, p, <span class=\"number\">2</span>, color, cv2.FILLED, cv2.LINE_AA, <span class=\"number\">0</span> )</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_delaunay</span><span class=\"params\">(img, subdiv, delaunay_color )</span> :</span></span><br><span class=\"line\">    triangleList = subdiv.getTriangleList();</span><br><span class=\"line\">    size = img.shape</span><br><span class=\"line\">    r = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, size[<span class=\"number\">1</span>], size[<span class=\"number\">0</span>])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> t <span class=\"keyword\">in</span> triangleList :</span><br><span class=\"line\">        pt1 = (t[<span class=\"number\">0</span>], t[<span class=\"number\">1</span>])</span><br><span class=\"line\">        pt2 = (t[<span class=\"number\">2</span>], t[<span class=\"number\">3</span>])</span><br><span class=\"line\">        pt3 = (t[<span class=\"number\">4</span>], t[<span class=\"number\">5</span>])</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> rect_contains(r, pt1) <span class=\"keyword\">and</span> rect_contains(r, pt2) <span class=\"keyword\">and</span> rect_contains(r, pt3) :</span><br><span class=\"line\">            cv2.line(img, pt1, pt2, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">            cv2.line(img, pt2, pt3, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">            cv2.line(img, pt3, pt1, delaunay_color, <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Draw voronoi diagram</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">draw_voronoi</span><span class=\"params\">(img, subdiv)</span> :</span></span><br><span class=\"line\"></span><br><span class=\"line\">    ( facets, centers) = subdiv.getVoronoiFacetList([])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">0</span>,len(facets)) :</span><br><span class=\"line\">        ifacet_arr = []</span><br><span class=\"line\">        <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> facets[i] :</span><br><span class=\"line\">            ifacet_arr.append(f)</span><br><span class=\"line\">        </span><br><span class=\"line\">        ifacet = np.array(ifacet_arr, np.int)</span><br><span class=\"line\">        color = (random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>), random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>), random.randint(<span class=\"number\">0</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">        cv2.fillConvexPoly(img, ifacet, color, cv2.LINE_AA, <span class=\"number\">0</span>);</span><br><span class=\"line\">        ifacets = np.array([ifacet])</span><br><span class=\"line\">        cv2.polylines(img, ifacets, <span class=\"literal\">True</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), <span class=\"number\">1</span>, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\">        cv2.circle(img, (centers[i][<span class=\"number\">0</span>], centers[i][<span class=\"number\">1</span>]), <span class=\"number\">3</span>, (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">0</span>), cv2.FILLED, cv2.LINE_AA, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Define window names</span></span><br><span class=\"line\">    win_delaunay = <span class=\"string\">\"Delaunay Triangulation\"</span></span><br><span class=\"line\">    win_voronoi = <span class=\"string\">\"Voronoi Diagram\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Turn on animation while drawing triangles</span></span><br><span class=\"line\">    animate = <span class=\"literal\">True</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Define colors for drawing.</span></span><br><span class=\"line\">    delaunay_color = (<span class=\"number\">255</span>,<span class=\"number\">255</span>,<span class=\"number\">255</span>)</span><br><span class=\"line\">    points_color = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, <span class=\"number\">255</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Read in the image.</span></span><br><span class=\"line\">    img = cv2.imread(<span class=\"string\">\"./images/obama.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Keep a copy around</span></span><br><span class=\"line\">    img_orig = img.copy();</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Rectangle to be used with Subdiv2D</span></span><br><span class=\"line\">    size = img.shape</span><br><span class=\"line\">    rect = (<span class=\"number\">0</span>, <span class=\"number\">0</span>, size[<span class=\"number\">1</span>], size[<span class=\"number\">0</span>])</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Create an instance of Subdiv2D</span></span><br><span class=\"line\">    subdiv = cv2.Subdiv2D(rect);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Create an array of points.</span></span><br><span class=\"line\">    points = [];</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># Read in the points from a text file</span></span><br><span class=\"line\">    <span class=\"keyword\">with</span> open(<span class=\"string\">\"./images/obama.txt\"</span>) <span class=\"keyword\">as</span> file :</span><br><span class=\"line\">        <span class=\"keyword\">for</span> line <span class=\"keyword\">in</span> file :</span><br><span class=\"line\">            x, y = line.split()</span><br><span class=\"line\">            points.append((int(x), int(y)))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Insert points into subdiv</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> points :</span><br><span class=\"line\">        subdiv.insert(p)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\"># Show animation</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> animate :</span><br><span class=\"line\">            img_copy = img_orig.copy()</span><br><span class=\"line\">            <span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\">            draw_delaunay( img_copy, subdiv, (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>) );</span><br><span class=\"line\">            cv2.imshow(win_delaunay, img_copy)</span><br><span class=\"line\">            cv2.waitKey(<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw delaunay triangles</span></span><br><span class=\"line\">    draw_delaunay( img, subdiv, (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>) );</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw points</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> p <span class=\"keyword\">in</span> points :</span><br><span class=\"line\">        draw_point(img, p, (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Allocate space for voronoi Diagram</span></span><br><span class=\"line\">    img_voronoi = np.zeros(img.shape, dtype = img.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Draw voronoi diagram</span></span><br><span class=\"line\">    draw_voronoi(img_voronoi,subdiv)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Show results</span></span><br><span class=\"line\">    cv2.imshow(win_delaunay,img)</span><br><span class=\"line\">    cv2.imshow(win_voronoi,img_voronoi)</span><br><span class=\"line\">    cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<h3 id=\"参考博客\"><a href=\"#参考博客\" class=\"headerlink\" title=\"参考博客\"></a>参考博客</h3><ul>\n<li>Facial Landmark Detection | Learn OpenCV<br><a href=\"https://www.learnopencv.com/facial-landmark-detection/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/facial-landmark-detection/</a></li>\n<li>Delaunay Triangulation and Voronoi Diagram using OpenCV ( C++ / Python ) | Learn OpenCV<br><a href=\"https://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/\" target=\"_blank\" rel=\"noopener\">https://www.learnopencv.com/delaunay-triangulation-and-voronoi-diagram-using-opencv-c-python/</a></li>\n</ul>\n</the>"},{"title":"OpenCV学习笔记三：特征检测和图像检索","date":"2019-06-22T16:08:00.000Z","_content":"** {{ title }}：** <Excerpt in index | 首页摘要>\n## 特征检测算法\n\n* Harris     角点检测\n* Shi-Tomasi 角点检测\n* FAST       角点检测\n* SIFT       斑点（blob）检测\n* SURF       斑点检测\n* BRIEF      斑点检测\n* ORB (Oriented FAST and Rotated BRIEF)\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n### Harris\n\n角点定义：如果某一点在任意方向的一个微小变动都会引起灰度很大的变化，那么这个点就称之为角点。  \nHarris角点检测的核心思想就是用一个局部窗口在图像上进行移动来判断灰度的变化，如果变化大于一个值那么就认为这个点是角点。  \n将窗口向各个方向移动$(u, v)$然后计算所有差异的总和。表达式如下 \n\n$$\nE(u, v)= \\underbrace{w(x, y)}_{\\text { window function }}[\\underbrace{I(x+u, y+v)}_{\\text { shifted intensity }}-\\underbrace{I(x, y)}_{\\text { intensity }}]^{2}\n$$\n\n窗口函数$w(x,y)$可以是正常的矩形窗口也可以是对每一个像素给予不同权重的高斯窗口。  角点检测中要使 $E(u,v)$ 的值最大。  \n使用泰勒展开和二次型，$E(u,v)$可以近似于  \n$$E(u,v) \\approx \\left[ \\begin{matrix}u\\,v\n\\end{matrix}\\right]  M \\left[ \\begin{matrix}\n    u \\\\\n    v \\\\ \n\\end{matrix}\\right]$$\n其中 \n$$M = \\sum_{x, y} w(x, y)\\left[ \\begin{matrix}\n    I_xI_x\\quad I_xI_y \\\\\n    I_xI_y\\quad I_yI_y \\\\ \n\\end{matrix}\\right] $$\n\n这里 $I_x$ 和 $I_y$ 是图像在 $x$ 和 $y$ 方向的导数,可以使用函数 cv2.Sobel()\n计算得到。  \n根据下式中的$R$值判定窗口内是否包含角点\n$$R=det(M)- \\alpha (trace(M))^2 $$\n其中$\\lambda_1$ 和 $\\lambda_2$ 是矩阵 $M$ 的特征值，$\\alpha$是一个经验常数，取值为$[0.04, 0.06]$。  \n根据R值可以判断一个区域是否是角点，边界或者是平面。  \n* 当 $\\lambda_1$ 和 $\\lambda_2$ 都小时，$|R|$ 也小，对应图像中的平滑区域；\n* 当 $\\lambda_1 \\gg \\lambda_2$ 或者 $\\lambda_1 \\ll \\lambda_2$ 时， $R$ 小于0，对应图像中的边缘；\n* 当 $\\lambda_1$ 和 $\\lambda_2$ 都很大时，$R$ 也很大，对应图像中的角点。\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\n%matplotlib inline\n\nimg = cv2.imread('./images/chess_board.png')\nimg_copy = np.copy(img)\nimg_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(10,10))\n\nplt.subplot(221)\nplt.imshow(img)\nplt.subplot(222)\nplt.imshow(img_copy)\n\nimg_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\nimg_gray = np.float32(img_gray)\n# 检测角点，定义串口大小为2，梯度计算的索贝尔核函数大小为3，alpha设置为0.04\nimg_dst = cv2.cornerHarris(img_gray, 2, 3, 0.04)\n# 对图像做膨胀处理，加强角点\nimg_dst = cv2.dilate(img_dst, None)\nplt.subplot(223)\nplt.imshow(img_dst)\n\n# 定义阈值，用于与R相比较\nthresh = 0.7 * img_dst.max()\nimg_corner = np.copy(img)\n# 遍历每一个像素，如果大于阈值，则认为为角点并画在图上\nfor j in range(img_dst.shape[0]):\n    for i in range(img_dst.shape[1]):\n        if img_dst[j, i] > thresh:\n            cv2.circle(img_corner, (i, j), 25, (255,0,0), 1)\nplt.subplot(224)\nplt.imshow(img_corner)\nplt.subplots_adjust(bottom=.01, top=.99, left=.01, right=.99)\n```\n\n<img src='OpenCV学习笔记三：特征检测和图像检索/output_2_0.png' >\n\n\n```python\n%time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\n# filename = './images/blox.jpg'\nfilename = './images/chessboard.png'\nimg = cv2.imread(filename)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ngray = np.float32(gray)\nimg_dst = cv2.cornerHarris(gray, 2, 3, 0.05)\n\n# result is dilated for marking the corners, not important\nimg_dst = cv2.dilate(img_dst, None)\n\n# Threshold for an optimal value, it may vary depending on the image.\n# img[dst>0.07*dst.max()]=[0,0,255]\nthresh = 0.2 * img_dst.max()\n\n# 遍历每一个像素，如果大于阈值，则认为为角点并画在图上\nfor j in range(img_dst.shape[0]):\n    for i in range(img_dst.shape[1]):\n        if img_dst[j, i] > thresh:\n            cv2.circle(img, (i, j), 25, (255,0,0), 1)\n\nimg_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img_show)\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_3_2.png\">\n\n\n### Shi-Tomasi \nHarris角点的打分公式为\n$$R=det(M)- \\alpha (trace(M))^2 $$\nShi-Tomasi 使用的打分公式为\n$$R=min(\\lambda_1, \\lambda_2)$$\n如果打分超过阈值，我们就认为它是一个角点。\n\n\n```python\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/blox.jpg')\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\ncorners = cv2.goodFeaturesToTrack(gray, 50, 0.01, 10)\n# N个最佳角点 = cv2.goodFeaturesToTrack(灰度图, 数量N, 角点质量, 两个角点见最小欧式距离)\ncorners = np.int0(corners)\n\nfor i in corners:\n    x,y = i.ravel()\n    cv2.circle(img, (x,y), 3, 255, -1)\n\nplt.imshow(img)\nplt.show()\n```\n\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_5_0.png\">\n\n\n### FAST\nFAST 算法比其它角点检测算法都快。但是在噪声很高时不够稳定，这是由阈值决定的。  \n原理：FAST特征检测算法来源于corner的定义，这个定义基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。\n$$N = \\sum_{x\\, \\forall \\, circles(p)}|I(x)-I(p)|>\\epsilon_d $$\n步骤：  \n1）在图像中任选一点$p$,假定其像素（亮度）值为$I_p$;  \n2）以$r$为半径画圆，覆盖$p$点周围的$M$个像素,如下图所示: $r=3， M=16$;  \n<img alt=\"FAST\" src=\"OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png\">\n3）设定阈值$t$，如果这周围的16个像素中有连续的$N$个像素的像素值减去$I_p$大于$t$,或者有连续的$N$个像素都大于$I_p+t$,则认为$p$为角点。\n如果$t=0$，那么就可以理解为：有连续N个像素大于或小于$I_p$的灰度值。那么这个点就被判断为角点。  \n\n为了获得更快的结果，还采用了额外的加速办法。  \n如果测试了候选点周围每隔90度角的4个点，应该至少有3个和候选点的灰度值差足够大，否则则不用再计算其他点，直接认为该候选点不是特征点。  \n候选点周围的圆的选取半径是一个很重要的参数，这里为了简单高效，采用半径为3，共有16个周边像素需要比较。为了提高比较的效率，通常只使用N个周边像素来比较，也就是大家经常说的FAST-N，使用比较多的是FAST-9和FAST-12。  \n这个检测器的效率很高，但是它有如下几条缺点：\n* 当 n<12 时它不会丢弃很多候选点 (获得的候选点比较多)。  \n* 像素的选取不是最优的，因为它的效果取决与要解决的问题和角点的分布情况。  \n* 高速测试的结果被抛弃。  \n* 检测到的很多特征点都是连在一起的。  \n前3个问题可以通过机器学习的方法解决，第4问题可以使用非最大值抑制的方法解决。\n\n#### 机器学习的角点检测器\n1. 选择一组训练图片（最好是跟最后应用相关的图片）使用FAST算法找出每幅图像的特征点；\n2. 对每一个特征点，将其周围的 16 个像素存储构成一个向量，对所有图像都这样做构建一个特征向量$P$;\n3. 每一个特征点的16像素点都属于下列三类中的一种\n$$S_{p\\to x}= \\begin{cases}\nd,& \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;I_{p\\to x}\\le I_p - t &(darker)\\\\ \ns,& I_p-t < I_{p\\to x} <  I_p + t  &(similar)\\\\\nb,&I_p+t \\le I_{p\\to x}  &(brighter)\n\\end{cases}\n$$\n根据这些像素点的分类，特征向量$P$也被分为3个子集：$P_d$，$P_s$，$P_b$\n4. 定义一个新的布尔变量$K_p$ ，如果$p$是角点就设置为 Ture，如果不是就设置为 False。\n5. 使用ID3算法（决策树分类器）来查询每一个子集，递归计算所有子集直到熵为0；\n6. 将构建好的决策树运用于其他图像的快速的检测。\n\n\n#### 非极大值抑制\n很可能大部分检测出来的点彼此之间相邻，我们要去除一部分这样的点。为了解决这一问题，可以采用非最大值抑制的算法：  \n假设P，Q两个点相邻，分别计算两个点与其周围的16个像素点之间的差分和为V，去除V值较小的点，即把非最大的角点抑制掉。\n\n\n\n\n```python\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/blox.jpg',0)\n\nfast = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True, type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)#获取FAST角点探测器\nkp = fast.detect(img,None)#描述符\nimg = cv2.drawKeypoints(img, kp, img, color=(255,0,0))#画到img上面\n\nprint (\"Threshold: \", fast.getThreshold())#输出阈值\nprint (\"nonmaxSuppression: \", fast.getNonmaxSuppression())#是否使用非极大值抑制\nprint (\"Total Keypoints with nonmaxSuppression: \", len(kp))#特征点个数\n\n# cv2.imshow('sp',img)\n# cv2.waitKey(0)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n\n```\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_7_1.png\">\n\n\n### SIFT\n角点检测具有旋转不变特性，即即使图片发生了旋转，算法也能找到同样的角点。  \n但是如果对图像进行缩放，角点可能就不再是角点了。  \n尺度不变特征变换（SIFT），利用原始图像与高斯核的卷积来建立尺度空间，并在高斯差分空间金字塔上提取出尺度不变性的特征点。  \n该算法具有一定的仿射不变性，视角不变性，旋转不变性和光照不变性，所以在图像特征提高方面得到了最广泛的应用。  \n\n\n步骤：  \n1）构建高斯差分金字塔  \n通过减少采样来构成一组图像尺寸不同的图像金字塔，然后对这一组图像中的每一张图像使用具有不同方差$σ$的高斯卷积核构建出具有不同分辨率的图像金字塔（不同的尺度空间）,DoG就是这组具有不同分辨率的图像金字塔中相邻的两层之间的差值;  \n<img alt=\"DOG Pyramid\" src = \"OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg\">\n\n2）定位关键点  \n首先在尺度空间和二维平面中检测局部最大值$(x，y，σ)$,这表示在$σ$尺度中点$(x，y)$可能是一个关键点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。   \n<img alt=\"sift_local_extrema\" src=\"OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg\">  \n以上方法检测到的极值点是离散空间的极值点，通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力。\n\n3）关键点描述符  \n为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向，使用图像梯度的方法求取局部结构的稳定方向。  \n选取关键点周围一个 16x16 的邻域，把它分成 16 个 4x4 的小方块，为每个小方块创建一个具有 8 个 bin 的方向直方图。总共加起来有 128 个 bin。由此组成长为 128 的向量就构成了关键点描述符。  \n\n缺点  \nSIFT在图像的不变特征提取方面拥有无与伦比的优势，但并不完美，对模糊的图像和边缘平滑的图像，检测出的特征点过少，对圆更是无能为力。\n1. 实时性不高；  \n2. 有时特征点较少；  \n3. 对边缘光滑的目标无法准确提取特征点。  \n\n参考资料  \n* SIFT算法详解 - zddhub的专栏 - CSDN博客  \nhttps://blog.csdn.net/zddblog/article/details/7521424\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/home.jpg', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsift = cv2.xfeatures2d.SIFT_create()\nkp = sift.detect(gray,None)\n\n# img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n\n```\n\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_9_0.png\">\n\n\n\n``` python\nkp, des = sift.detectAndCompute(gray,None)\n# print(\"kp:\", kp)\nprint(\"des' lenth:\", len(des[0]))\nprint(\"des:\", des)\n```\n\n    des' lenth: 64\n    des: [[ 1.1795463e-02 -1.3453829e-03  1.2853614e-02 ... -6.1970763e-03\n       1.0367702e-02  8.2569038e-03]\n     [-3.7488429e-04 -1.7145486e-03  1.5926192e-03 ...  9.5438212e-03\n       5.8124182e-03  1.0535392e-02]\n     [ 1.8987345e-04 -3.9035594e-04  3.5250295e-04 ... -6.1610942e-03\n       7.9580760e-03  6.6615609e-03]\n     ...\n     [-1.1354305e-02 -2.0890196e-03  1.3535642e-02 ...  5.5240576e-05\n       3.2335313e-03  5.6648249e-04]\n     [ 4.4308142e-03  6.1169025e-03  6.2500047e-03 ...  3.9724767e-04\n       6.5160347e-03  9.4564463e-04]\n     [-7.7680773e-03  2.0684338e-04  7.8980839e-03 ... -2.7418079e-02\n       8.1536770e-03  3.2845538e-02]]\n    \n\n\n``` python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/opencv-logo.png', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsift = cv2.xfeatures2d.SIFT_create()\nkp = sift.detect(gray,None)\n\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_11_0.png\">\n\n### SURF(Speeded-Up Robust Features)\n\n2006年，Bay和Ess等人基于SIFT算法的思路，提出了加速鲁棒特征（SURF）,该算法主要针对于SIFT算法速度太慢，计算量大的缺点，使用了近似Harr小波方法来提取特征点，这种方法就是基于Hessian行列式（DoH）的斑点特征检测方法。通过在不同的尺度上利用积分图像可以有效地计算出近似Harr小波值，简化了二阶微分模板的构建，搞高了尺度空间的特征检测的效率。  \n\n\n``` python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/butterfly.jpg', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsurf = cv2.xfeatures2d.SURF_create(40000)\nkp = surf.detect(gray, None)\n\n# img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_13_0.png\">\n\n### BRIEF\n\nBinary Robust Independent Elementary Features，在特征点附近随机选取若干点对，将这些点对的灰度值的大小， \n组合成一个二进制串，并将这个二进制串作为该特征点的特征描述子（即BRIEF描述子中的每一位是由随机选取的两个像素点做二进制比较得来，BRIEF描述子的所有编码都是二进制数的）   \nBRIEF的优点在于速度，缺点也相当明显：   \n1：不具备旋转不变性    \n2：对噪声敏感   \n3：不具备尺度不变性   \n\nBRIEF 是一种特征描述符，它不提供查找特征的方法。所以我们不得不使用其他特征检测器，比如 SIFT 和 SURF 等。\n\n### ORB (Oriented FAST and Rotated BRIEF)\nORB特征是将FAST特征点的检测方法与BRIEF特征描述子结合起来，并在它们原来的基础上做了改进与优化。\n\nORB特征具有旋转不变性，同时对噪声及透视仿射也具有不变性\n\n``` python\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg=cv2.imread('./images/car.jpg',0)\n\norb=cv2.ORB_create()\n# kp=orb.detect(img,None)\n# kp,des=orb.compute(img,kp)\n\nkp,des=orb.detectAndCompute(img,None)\nimg2=cv2.drawKeypoints(img,kp,None,(0,255,0),flags=0)\nplt.imshow(img2)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_16_0.png\">\n\n``` python\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(12, 12))\n\nimg1 = cv2.imread('./images/manowar_logo.png', 0)\nimg2 = cv2.imread('./images/manowar_single.jpg', 0)\n\norb = cv2.ORB_create()\nkp1, des1 = orb.detectAndCompute(img1,None)\nkp2, des2 = orb.detectAndCompute(img2,None)\n\n# 暴力匹配BFMatcher\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\nmatches = bf.match(des1, des2)\nmatches = sorted(matches, key=lambda x: x.distance)\n\nimg3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:40], img2, flags=2)\nplt.imshow(img3)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_17_0.png\">\n\n``` python\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(12, 12))\n\ntrain=cv2.imread('./images/baboon200_rotated.jpg',0)\nquery=cv2.imread('./images/baboon.jpg',0)\n\nsift=cv2.xfeatures2d.SIFT_create()\nkp1,des1=sift.detectAndCompute(train,None)\nkp2,des2=sift.detectAndCompute(query,None)\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(train,None)\nkp2, des2 = sift.detectAndCompute(query,None)\n\n# FLANN parameters\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks=50) # or pass empty dictionary\n\nflann = cv2.FlannBasedMatcher(index_params,search_params)\n\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# Need to draw only good matches, so create a mask\nmatchesMask = [[0,0] for i in range(len(matches))]\n\n# ratio test as per Lowe's paper\nfor i,(m,n) in enumerate(matches):\n\n    #如果第一个邻近距离比第二个邻近距离的0.7倍小，则保留\n    if m.distance < 0.7*n.distance:\n        matchesMask[i]=[1,0]\n\ndraw_params = dict(matchColor = (0,255,0),\n                   singlePointColor = (255,0,0),\n                   matchesMask = matchesMask,\n                   flags = 0)\n\nimg3 = cv2.drawMatchesKnn(train,kp1,query,kp2,matches,None,**draw_params)\nplt.imshow(img3)\nplt.show()\n\n```\n\n<img src = \"OpenCV学习笔记三：特征检测和图像检索/output_18_0.png\">\n","source":"_posts/OpenCV学习笔记三：特征检测和图像检索.md","raw":"---\ntitle: OpenCV学习笔记三：特征检测和图像检索\ndate: 2019-06-23 00:08:00\ntags:\n  - opencv\n---\n** {{ title }}：** <Excerpt in index | 首页摘要>\n## 特征检测算法\n\n* Harris     角点检测\n* Shi-Tomasi 角点检测\n* FAST       角点检测\n* SIFT       斑点（blob）检测\n* SURF       斑点检测\n* BRIEF      斑点检测\n* ORB (Oriented FAST and Rotated BRIEF)\n\n<!-- more -->\n<The rest of contents | 余下全文>\n\n### Harris\n\n角点定义：如果某一点在任意方向的一个微小变动都会引起灰度很大的变化，那么这个点就称之为角点。  \nHarris角点检测的核心思想就是用一个局部窗口在图像上进行移动来判断灰度的变化，如果变化大于一个值那么就认为这个点是角点。  \n将窗口向各个方向移动$(u, v)$然后计算所有差异的总和。表达式如下 \n\n$$\nE(u, v)= \\underbrace{w(x, y)}_{\\text { window function }}[\\underbrace{I(x+u, y+v)}_{\\text { shifted intensity }}-\\underbrace{I(x, y)}_{\\text { intensity }}]^{2}\n$$\n\n窗口函数$w(x,y)$可以是正常的矩形窗口也可以是对每一个像素给予不同权重的高斯窗口。  角点检测中要使 $E(u,v)$ 的值最大。  \n使用泰勒展开和二次型，$E(u,v)$可以近似于  \n$$E(u,v) \\approx \\left[ \\begin{matrix}u\\,v\n\\end{matrix}\\right]  M \\left[ \\begin{matrix}\n    u \\\\\n    v \\\\ \n\\end{matrix}\\right]$$\n其中 \n$$M = \\sum_{x, y} w(x, y)\\left[ \\begin{matrix}\n    I_xI_x\\quad I_xI_y \\\\\n    I_xI_y\\quad I_yI_y \\\\ \n\\end{matrix}\\right] $$\n\n这里 $I_x$ 和 $I_y$ 是图像在 $x$ 和 $y$ 方向的导数,可以使用函数 cv2.Sobel()\n计算得到。  \n根据下式中的$R$值判定窗口内是否包含角点\n$$R=det(M)- \\alpha (trace(M))^2 $$\n其中$\\lambda_1$ 和 $\\lambda_2$ 是矩阵 $M$ 的特征值，$\\alpha$是一个经验常数，取值为$[0.04, 0.06]$。  \n根据R值可以判断一个区域是否是角点，边界或者是平面。  \n* 当 $\\lambda_1$ 和 $\\lambda_2$ 都小时，$|R|$ 也小，对应图像中的平滑区域；\n* 当 $\\lambda_1 \\gg \\lambda_2$ 或者 $\\lambda_1 \\ll \\lambda_2$ 时， $R$ 小于0，对应图像中的边缘；\n* 当 $\\lambda_1$ 和 $\\lambda_2$ 都很大时，$R$ 也很大，对应图像中的角点。\n\n\n```python\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\n%matplotlib inline\n\nimg = cv2.imread('./images/chess_board.png')\nimg_copy = np.copy(img)\nimg_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)\nplt.figure(figsize=(10,10))\n\nplt.subplot(221)\nplt.imshow(img)\nplt.subplot(222)\nplt.imshow(img_copy)\n\nimg_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\nimg_gray = np.float32(img_gray)\n# 检测角点，定义串口大小为2，梯度计算的索贝尔核函数大小为3，alpha设置为0.04\nimg_dst = cv2.cornerHarris(img_gray, 2, 3, 0.04)\n# 对图像做膨胀处理，加强角点\nimg_dst = cv2.dilate(img_dst, None)\nplt.subplot(223)\nplt.imshow(img_dst)\n\n# 定义阈值，用于与R相比较\nthresh = 0.7 * img_dst.max()\nimg_corner = np.copy(img)\n# 遍历每一个像素，如果大于阈值，则认为为角点并画在图上\nfor j in range(img_dst.shape[0]):\n    for i in range(img_dst.shape[1]):\n        if img_dst[j, i] > thresh:\n            cv2.circle(img_corner, (i, j), 25, (255,0,0), 1)\nplt.subplot(224)\nplt.imshow(img_corner)\nplt.subplots_adjust(bottom=.01, top=.99, left=.01, right=.99)\n```\n\n<img src='OpenCV学习笔记三：特征检测和图像检索/output_2_0.png' >\n\n\n```python\n%time\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\n# filename = './images/blox.jpg'\nfilename = './images/chessboard.png'\nimg = cv2.imread(filename)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ngray = np.float32(gray)\nimg_dst = cv2.cornerHarris(gray, 2, 3, 0.05)\n\n# result is dilated for marking the corners, not important\nimg_dst = cv2.dilate(img_dst, None)\n\n# Threshold for an optimal value, it may vary depending on the image.\n# img[dst>0.07*dst.max()]=[0,0,255]\nthresh = 0.2 * img_dst.max()\n\n# 遍历每一个像素，如果大于阈值，则认为为角点并画在图上\nfor j in range(img_dst.shape[0]):\n    for i in range(img_dst.shape[1]):\n        if img_dst[j, i] > thresh:\n            cv2.circle(img, (i, j), 25, (255,0,0), 1)\n\nimg_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img_show)\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_3_2.png\">\n\n\n### Shi-Tomasi \nHarris角点的打分公式为\n$$R=det(M)- \\alpha (trace(M))^2 $$\nShi-Tomasi 使用的打分公式为\n$$R=min(\\lambda_1, \\lambda_2)$$\n如果打分超过阈值，我们就认为它是一个角点。\n\n\n```python\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/blox.jpg')\ngray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n\ncorners = cv2.goodFeaturesToTrack(gray, 50, 0.01, 10)\n# N个最佳角点 = cv2.goodFeaturesToTrack(灰度图, 数量N, 角点质量, 两个角点见最小欧式距离)\ncorners = np.int0(corners)\n\nfor i in corners:\n    x,y = i.ravel()\n    cv2.circle(img, (x,y), 3, 255, -1)\n\nplt.imshow(img)\nplt.show()\n```\n\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_5_0.png\">\n\n\n### FAST\nFAST 算法比其它角点检测算法都快。但是在噪声很高时不够稳定，这是由阈值决定的。  \n原理：FAST特征检测算法来源于corner的定义，这个定义基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。\n$$N = \\sum_{x\\, \\forall \\, circles(p)}|I(x)-I(p)|>\\epsilon_d $$\n步骤：  \n1）在图像中任选一点$p$,假定其像素（亮度）值为$I_p$;  \n2）以$r$为半径画圆，覆盖$p$点周围的$M$个像素,如下图所示: $r=3， M=16$;  \n<img alt=\"FAST\" src=\"OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png\">\n3）设定阈值$t$，如果这周围的16个像素中有连续的$N$个像素的像素值减去$I_p$大于$t$,或者有连续的$N$个像素都大于$I_p+t$,则认为$p$为角点。\n如果$t=0$，那么就可以理解为：有连续N个像素大于或小于$I_p$的灰度值。那么这个点就被判断为角点。  \n\n为了获得更快的结果，还采用了额外的加速办法。  \n如果测试了候选点周围每隔90度角的4个点，应该至少有3个和候选点的灰度值差足够大，否则则不用再计算其他点，直接认为该候选点不是特征点。  \n候选点周围的圆的选取半径是一个很重要的参数，这里为了简单高效，采用半径为3，共有16个周边像素需要比较。为了提高比较的效率，通常只使用N个周边像素来比较，也就是大家经常说的FAST-N，使用比较多的是FAST-9和FAST-12。  \n这个检测器的效率很高，但是它有如下几条缺点：\n* 当 n<12 时它不会丢弃很多候选点 (获得的候选点比较多)。  \n* 像素的选取不是最优的，因为它的效果取决与要解决的问题和角点的分布情况。  \n* 高速测试的结果被抛弃。  \n* 检测到的很多特征点都是连在一起的。  \n前3个问题可以通过机器学习的方法解决，第4问题可以使用非最大值抑制的方法解决。\n\n#### 机器学习的角点检测器\n1. 选择一组训练图片（最好是跟最后应用相关的图片）使用FAST算法找出每幅图像的特征点；\n2. 对每一个特征点，将其周围的 16 个像素存储构成一个向量，对所有图像都这样做构建一个特征向量$P$;\n3. 每一个特征点的16像素点都属于下列三类中的一种\n$$S_{p\\to x}= \\begin{cases}\nd,& \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;I_{p\\to x}\\le I_p - t &(darker)\\\\ \ns,& I_p-t < I_{p\\to x} <  I_p + t  &(similar)\\\\\nb,&I_p+t \\le I_{p\\to x}  &(brighter)\n\\end{cases}\n$$\n根据这些像素点的分类，特征向量$P$也被分为3个子集：$P_d$，$P_s$，$P_b$\n4. 定义一个新的布尔变量$K_p$ ，如果$p$是角点就设置为 Ture，如果不是就设置为 False。\n5. 使用ID3算法（决策树分类器）来查询每一个子集，递归计算所有子集直到熵为0；\n6. 将构建好的决策树运用于其他图像的快速的检测。\n\n\n#### 非极大值抑制\n很可能大部分检测出来的点彼此之间相邻，我们要去除一部分这样的点。为了解决这一问题，可以采用非最大值抑制的算法：  \n假设P，Q两个点相邻，分别计算两个点与其周围的16个像素点之间的差分和为V，去除V值较小的点，即把非最大的角点抑制掉。\n\n\n\n\n```python\nimport numpy as np\nimport cv2\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/blox.jpg',0)\n\nfast = cv2.FastFeatureDetector_create(threshold=20, nonmaxSuppression=True, type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)#获取FAST角点探测器\nkp = fast.detect(img,None)#描述符\nimg = cv2.drawKeypoints(img, kp, img, color=(255,0,0))#画到img上面\n\nprint (\"Threshold: \", fast.getThreshold())#输出阈值\nprint (\"nonmaxSuppression: \", fast.getNonmaxSuppression())#是否使用非极大值抑制\nprint (\"Total Keypoints with nonmaxSuppression: \", len(kp))#特征点个数\n\n# cv2.imshow('sp',img)\n# cv2.waitKey(0)\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n\n```\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_7_1.png\">\n\n\n### SIFT\n角点检测具有旋转不变特性，即即使图片发生了旋转，算法也能找到同样的角点。  \n但是如果对图像进行缩放，角点可能就不再是角点了。  \n尺度不变特征变换（SIFT），利用原始图像与高斯核的卷积来建立尺度空间，并在高斯差分空间金字塔上提取出尺度不变性的特征点。  \n该算法具有一定的仿射不变性，视角不变性，旋转不变性和光照不变性，所以在图像特征提高方面得到了最广泛的应用。  \n\n\n步骤：  \n1）构建高斯差分金字塔  \n通过减少采样来构成一组图像尺寸不同的图像金字塔，然后对这一组图像中的每一张图像使用具有不同方差$σ$的高斯卷积核构建出具有不同分辨率的图像金字塔（不同的尺度空间）,DoG就是这组具有不同分辨率的图像金字塔中相邻的两层之间的差值;  \n<img alt=\"DOG Pyramid\" src = \"OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg\">\n\n2）定位关键点  \n首先在尺度空间和二维平面中检测局部最大值$(x，y，σ)$,这表示在$σ$尺度中点$(x，y)$可能是一个关键点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。   \n<img alt=\"sift_local_extrema\" src=\"OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg\">  \n以上方法检测到的极值点是离散空间的极值点，通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力。\n\n3）关键点描述符  \n为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向，使用图像梯度的方法求取局部结构的稳定方向。  \n选取关键点周围一个 16x16 的邻域，把它分成 16 个 4x4 的小方块，为每个小方块创建一个具有 8 个 bin 的方向直方图。总共加起来有 128 个 bin。由此组成长为 128 的向量就构成了关键点描述符。  \n\n缺点  \nSIFT在图像的不变特征提取方面拥有无与伦比的优势，但并不完美，对模糊的图像和边缘平滑的图像，检测出的特征点过少，对圆更是无能为力。\n1. 实时性不高；  \n2. 有时特征点较少；  \n3. 对边缘光滑的目标无法准确提取特征点。  \n\n参考资料  \n* SIFT算法详解 - zddhub的专栏 - CSDN博客  \nhttps://blog.csdn.net/zddblog/article/details/7521424\n\n\n\n```python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/home.jpg', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsift = cv2.xfeatures2d.SIFT_create()\nkp = sift.detect(gray,None)\n\n# img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n\n```\n\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_9_0.png\">\n\n\n\n``` python\nkp, des = sift.detectAndCompute(gray,None)\n# print(\"kp:\", kp)\nprint(\"des' lenth:\", len(des[0]))\nprint(\"des:\", des)\n```\n\n    des' lenth: 64\n    des: [[ 1.1795463e-02 -1.3453829e-03  1.2853614e-02 ... -6.1970763e-03\n       1.0367702e-02  8.2569038e-03]\n     [-3.7488429e-04 -1.7145486e-03  1.5926192e-03 ...  9.5438212e-03\n       5.8124182e-03  1.0535392e-02]\n     [ 1.8987345e-04 -3.9035594e-04  3.5250295e-04 ... -6.1610942e-03\n       7.9580760e-03  6.6615609e-03]\n     ...\n     [-1.1354305e-02 -2.0890196e-03  1.3535642e-02 ...  5.5240576e-05\n       3.2335313e-03  5.6648249e-04]\n     [ 4.4308142e-03  6.1169025e-03  6.2500047e-03 ...  3.9724767e-04\n       6.5160347e-03  9.4564463e-04]\n     [-7.7680773e-03  2.0684338e-04  7.8980839e-03 ... -2.7418079e-02\n       8.1536770e-03  3.2845538e-02]]\n    \n\n\n``` python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/opencv-logo.png', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsift = cv2.xfeatures2d.SIFT_create()\nkp = sift.detect(gray,None)\n\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_11_0.png\">\n\n### SURF(Speeded-Up Robust Features)\n\n2006年，Bay和Ess等人基于SIFT算法的思路，提出了加速鲁棒特征（SURF）,该算法主要针对于SIFT算法速度太慢，计算量大的缺点，使用了近似Harr小波方法来提取特征点，这种方法就是基于Hessian行列式（DoH）的斑点特征检测方法。通过在不同的尺度上利用积分图像可以有效地计算出近似Harr小波值，简化了二阶微分模板的构建，搞高了尺度空间的特征检测的效率。  \n\n\n``` python\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg = cv2.imread('./images/butterfly.jpg', 1)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\nsurf = cv2.xfeatures2d.SURF_create(40000)\nkp = surf.detect(gray, None)\n\n# img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))\nimg = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\nimg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_13_0.png\">\n\n### BRIEF\n\nBinary Robust Independent Elementary Features，在特征点附近随机选取若干点对，将这些点对的灰度值的大小， \n组合成一个二进制串，并将这个二进制串作为该特征点的特征描述子（即BRIEF描述子中的每一位是由随机选取的两个像素点做二进制比较得来，BRIEF描述子的所有编码都是二进制数的）   \nBRIEF的优点在于速度，缺点也相当明显：   \n1：不具备旋转不变性    \n2：对噪声敏感   \n3：不具备尺度不变性   \n\nBRIEF 是一种特征描述符，它不提供查找特征的方法。所以我们不得不使用其他特征检测器，比如 SIFT 和 SURF 等。\n\n### ORB (Oriented FAST and Rotated BRIEF)\nORB特征是将FAST特征点的检测方法与BRIEF特征描述子结合起来，并在它们原来的基础上做了改进与优化。\n\nORB特征具有旋转不变性，同时对噪声及透视仿射也具有不变性\n\n``` python\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(8, 8))\n\nimg=cv2.imread('./images/car.jpg',0)\n\norb=cv2.ORB_create()\n# kp=orb.detect(img,None)\n# kp,des=orb.compute(img,kp)\n\nkp,des=orb.detectAndCompute(img,None)\nimg2=cv2.drawKeypoints(img,kp,None,(0,255,0),flags=0)\nplt.imshow(img2)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_16_0.png\">\n\n``` python\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(12, 12))\n\nimg1 = cv2.imread('./images/manowar_logo.png', 0)\nimg2 = cv2.imread('./images/manowar_single.jpg', 0)\n\norb = cv2.ORB_create()\nkp1, des1 = orb.detectAndCompute(img1,None)\nkp2, des2 = orb.detectAndCompute(img2,None)\n\n# 暴力匹配BFMatcher\nbf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\nmatches = bf.match(des1, des2)\nmatches = sorted(matches, key=lambda x: x.distance)\n\nimg3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:40], img2, flags=2)\nplt.imshow(img3)\nplt.show()\n```\n\n<img src=\"OpenCV学习笔记三：特征检测和图像检索/output_17_0.png\">\n\n``` python\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n%matplotlib inline\nplt.figure(figsize=(12, 12))\n\ntrain=cv2.imread('./images/baboon200_rotated.jpg',0)\nquery=cv2.imread('./images/baboon.jpg',0)\n\nsift=cv2.xfeatures2d.SIFT_create()\nkp1,des1=sift.detectAndCompute(train,None)\nkp2,des2=sift.detectAndCompute(query,None)\n\n# find the keypoints and descriptors with SIFT\nkp1, des1 = sift.detectAndCompute(train,None)\nkp2, des2 = sift.detectAndCompute(query,None)\n\n# FLANN parameters\nFLANN_INDEX_KDTREE = 1\nindex_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\nsearch_params = dict(checks=50) # or pass empty dictionary\n\nflann = cv2.FlannBasedMatcher(index_params,search_params)\n\nmatches = flann.knnMatch(des1,des2,k=2)\n\n# Need to draw only good matches, so create a mask\nmatchesMask = [[0,0] for i in range(len(matches))]\n\n# ratio test as per Lowe's paper\nfor i,(m,n) in enumerate(matches):\n\n    #如果第一个邻近距离比第二个邻近距离的0.7倍小，则保留\n    if m.distance < 0.7*n.distance:\n        matchesMask[i]=[1,0]\n\ndraw_params = dict(matchColor = (0,255,0),\n                   singlePointColor = (255,0,0),\n                   matchesMask = matchesMask,\n                   flags = 0)\n\nimg3 = cv2.drawMatchesKnn(train,kp1,query,kp2,matches,None,**draw_params)\nplt.imshow(img3)\nplt.show()\n\n```\n\n<img src = \"OpenCV学习笔记三：特征检测和图像检索/output_18_0.png\">\n","slug":"OpenCV学习笔记三：特征检测和图像检索","published":1,"updated":"2019-06-24T05:47:43.298Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjxqdm76w004arsvj7h4t3rgw","content":"<p><strong> OpenCV学习笔记三：特征检测和图像检索：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"特征检测算法\"><a href=\"#特征检测算法\" class=\"headerlink\" title=\"特征检测算法\"></a>特征检测算法</h2><ul>\n<li>Harris     角点检测</li>\n<li>Shi-Tomasi 角点检测</li>\n<li>FAST       角点检测</li>\n<li>SIFT       斑点（blob）检测</li>\n<li>SURF       斑点检测</li>\n<li>BRIEF      斑点检测</li>\n<li>ORB (Oriented FAST and Rotated BRIEF)</li>\n</ul>\n<a id=\"more\"></a>\n<the rest of contents | 余下全文>\n\n<h3 id=\"Harris\"><a href=\"#Harris\" class=\"headerlink\" title=\"Harris\"></a>Harris</h3><p>角点定义：如果某一点在任意方向的一个微小变动都会引起灰度很大的变化，那么这个点就称之为角点。<br>Harris角点检测的核心思想就是用一个局部窗口在图像上进行移动来判断灰度的变化，如果变化大于一个值那么就认为这个点是角点。<br>将窗口向各个方向移动$(u, v)$然后计算所有差异的总和。表达式如下 </p>\n<script type=\"math/tex; mode=display\">\nE(u, v)= \\underbrace{w(x, y)}_{\\text { window function }}[\\underbrace{I(x+u, y+v)}_{\\text { shifted intensity }}-\\underbrace{I(x, y)}_{\\text { intensity }}]^{2}</script><p>窗口函数$w(x,y)$可以是正常的矩形窗口也可以是对每一个像素给予不同权重的高斯窗口。  角点检测中要使 $E(u,v)$ 的值最大。<br>使用泰勒展开和二次型，$E(u,v)$可以近似于  </p>\n<script type=\"math/tex; mode=display\">E(u,v) \\approx \\left[ \\begin{matrix}u\\,v\n\\end{matrix}\\right]  M \\left[ \\begin{matrix}\n    u \\\\\n    v \\\\ \n\\end{matrix}\\right]</script><p>其中 </p>\n<script type=\"math/tex; mode=display\">M = \\sum_{x, y} w(x, y)\\left[ \\begin{matrix}\n    I_xI_x\\quad I_xI_y \\\\\n    I_xI_y\\quad I_yI_y \\\\ \n\\end{matrix}\\right]</script><p>这里 $I_x$ 和 $I_y$ 是图像在 $x$ 和 $y$ 方向的导数,可以使用函数 cv2.Sobel()<br>计算得到。<br>根据下式中的$R$值判定窗口内是否包含角点</p>\n<script type=\"math/tex; mode=display\">R=det(M)- \\alpha (trace(M))^2</script><p>其中$\\lambda_1$ 和 $\\lambda_2$ 是矩阵 $M$ 的特征值，$\\alpha$是一个经验常数，取值为$[0.04, 0.06]$。<br>根据R值可以判断一个区域是否是角点，边界或者是平面。  </p>\n<ul>\n<li>当 $\\lambda_1$ 和 $\\lambda_2$ 都小时，$|R|$ 也小，对应图像中的平滑区域；</li>\n<li>当 $\\lambda_1 \\gg \\lambda_2$ 或者 $\\lambda_1 \\ll \\lambda_2$ 时， $R$ 小于0，对应图像中的边缘；</li>\n<li>当 $\\lambda_1$ 和 $\\lambda_2$ 都很大时，$R$ 也很大，对应图像中的角点。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/chess_board.png'</span>)</span><br><span class=\"line\">img_copy = np.copy(img)</span><br><span class=\"line\">img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">221</span>)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">222</span>)</span><br><span class=\"line\">plt.imshow(img_copy)</span><br><span class=\"line\"></span><br><span class=\"line\">img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">img_gray = np.float32(img_gray)</span><br><span class=\"line\"><span class=\"comment\"># 检测角点，定义串口大小为2，梯度计算的索贝尔核函数大小为3，alpha设置为0.04</span></span><br><span class=\"line\">img_dst = cv2.cornerHarris(img_gray, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0.04</span>)</span><br><span class=\"line\"><span class=\"comment\"># 对图像做膨胀处理，加强角点</span></span><br><span class=\"line\">img_dst = cv2.dilate(img_dst, <span class=\"literal\">None</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">223</span>)</span><br><span class=\"line\">plt.imshow(img_dst)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义阈值，用于与R相比较</span></span><br><span class=\"line\">thresh = <span class=\"number\">0.7</span> * img_dst.max()</span><br><span class=\"line\">img_corner = np.copy(img)</span><br><span class=\"line\"><span class=\"comment\"># 遍历每一个像素，如果大于阈值，则认为为角点并画在图上</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> img_dst[j, i] &gt; thresh:</span><br><span class=\"line\">            cv2.circle(img_corner, (i, j), <span class=\"number\">25</span>, (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">224</span>)</span><br><span class=\"line\">plt.imshow(img_corner)</span><br><span class=\"line\">plt.subplots_adjust(bottom=<span class=\"number\">.01</span>, top=<span class=\"number\">.99</span>, left=<span class=\"number\">.01</span>, right=<span class=\"number\">.99</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_2_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%time</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># filename = './images/blox.jpg'</span></span><br><span class=\"line\">filename = <span class=\"string\">'./images/chessboard.png'</span></span><br><span class=\"line\">img = cv2.imread(filename)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">gray = np.float32(gray)</span><br><span class=\"line\">img_dst = cv2.cornerHarris(gray, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0.05</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># result is dilated for marking the corners, not important</span></span><br><span class=\"line\">img_dst = cv2.dilate(img_dst, <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Threshold for an optimal value, it may vary depending on the image.</span></span><br><span class=\"line\"><span class=\"comment\"># img[dst&gt;0.07*dst.max()]=[0,0,255]</span></span><br><span class=\"line\">thresh = <span class=\"number\">0.2</span> * img_dst.max()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历每一个像素，如果大于阈值，则认为为角点并画在图上</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> img_dst[j, i] &gt; thresh:</span><br><span class=\"line\">            cv2.circle(img, (i, j), <span class=\"number\">25</span>, (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img_show)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_3_2.png\"></p>\n<h3 id=\"Shi-Tomasi\"><a href=\"#Shi-Tomasi\" class=\"headerlink\" title=\"Shi-Tomasi\"></a>Shi-Tomasi</h3><p>Harris角点的打分公式为</p>\n<script type=\"math/tex; mode=display\">R=det(M)- \\alpha (trace(M))^2</script><p>Shi-Tomasi 使用的打分公式为</p>\n<script type=\"math/tex; mode=display\">R=min(\\lambda_1, \\lambda_2)</script><p>如果打分超过阈值，我们就认为它是一个角点。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/blox.jpg'</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">corners = cv2.goodFeaturesToTrack(gray, <span class=\"number\">50</span>, <span class=\"number\">0.01</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># N个最佳角点 = cv2.goodFeaturesToTrack(灰度图, 数量N, 角点质量, 两个角点见最小欧式距离)</span></span><br><span class=\"line\">corners = np.int0(corners)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> corners:</span><br><span class=\"line\">    x,y = i.ravel()</span><br><span class=\"line\">    cv2.circle(img, (x,y), <span class=\"number\">3</span>, <span class=\"number\">255</span>, <span class=\"number\">-1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_5_0.png\"></p>\n<h3 id=\"FAST\"><a href=\"#FAST\" class=\"headerlink\" title=\"FAST\"></a>FAST</h3><p>FAST 算法比其它角点检测算法都快。但是在噪声很高时不够稳定，这是由阈值决定的。<br>原理：FAST特征检测算法来源于corner的定义，这个定义基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。</p>\n<script type=\"math/tex; mode=display\">N = \\sum_{x\\, \\forall \\, circles(p)}|I(x)-I(p)|>\\epsilon_d</script><p>步骤：<br>1）在图像中任选一点$p$,假定其像素（亮度）值为$I_p$;<br>2）以$r$为半径画圆，覆盖$p$点周围的$M$个像素,如下图所示: $r=3， M=16$;<br><img alt=\"FAST\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png\"><br>3）设定阈值$t$，如果这周围的16个像素中有连续的$N$个像素的像素值减去$I_p$大于$t$,或者有连续的$N$个像素都大于$I_p+t$,则认为$p$为角点。<br>如果$t=0$，那么就可以理解为：有连续N个像素大于或小于$I_p$的灰度值。那么这个点就被判断为角点。  </p>\n<p>为了获得更快的结果，还采用了额外的加速办法。<br>如果测试了候选点周围每隔90度角的4个点，应该至少有3个和候选点的灰度值差足够大，否则则不用再计算其他点，直接认为该候选点不是特征点。<br>候选点周围的圆的选取半径是一个很重要的参数，这里为了简单高效，采用半径为3，共有16个周边像素需要比较。为了提高比较的效率，通常只使用N个周边像素来比较，也就是大家经常说的FAST-N，使用比较多的是FAST-9和FAST-12。<br>这个检测器的效率很高，但是它有如下几条缺点：</p>\n<ul>\n<li>当 n&lt;12 时它不会丢弃很多候选点 (获得的候选点比较多)。  </li>\n<li>像素的选取不是最优的，因为它的效果取决与要解决的问题和角点的分布情况。  </li>\n<li>高速测试的结果被抛弃。  </li>\n<li>检测到的很多特征点都是连在一起的。<br>前3个问题可以通过机器学习的方法解决，第4问题可以使用非最大值抑制的方法解决。</li>\n</ul>\n<h4 id=\"机器学习的角点检测器\"><a href=\"#机器学习的角点检测器\" class=\"headerlink\" title=\"机器学习的角点检测器\"></a>机器学习的角点检测器</h4><ol>\n<li>选择一组训练图片（最好是跟最后应用相关的图片）使用FAST算法找出每幅图像的特征点；</li>\n<li>对每一个特征点，将其周围的 16 个像素存储构成一个向量，对所有图像都这样做构建一个特征向量$P$;</li>\n<li>每一个特征点的16像素点都属于下列三类中的一种<script type=\"math/tex; mode=display\">S_{p\\to x}= \\begin{cases}\nd,& \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;I_{p\\to x}\\le I_p - t &(darker)\\\\ \ns,& I_p-t < I_{p\\to x} <  I_p + t  &(similar)\\\\\nb,&I_p+t \\le I_{p\\to x}  &(brighter)\n\\end{cases}</script>根据这些像素点的分类，特征向量$P$也被分为3个子集：$P_d$，$P_s$，$P_b$</li>\n<li>定义一个新的布尔变量$K_p$ ，如果$p$是角点就设置为 Ture，如果不是就设置为 False。</li>\n<li>使用ID3算法（决策树分类器）来查询每一个子集，递归计算所有子集直到熵为0；</li>\n<li>将构建好的决策树运用于其他图像的快速的检测。</li>\n</ol>\n<h4 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h4><p>很可能大部分检测出来的点彼此之间相邻，我们要去除一部分这样的点。为了解决这一问题，可以采用非最大值抑制的算法：<br>假设P，Q两个点相邻，分别计算两个点与其周围的16个像素点之间的差分和为V，去除V值较小的点，即把非最大的角点抑制掉。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/blox.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fast = cv2.FastFeatureDetector_create(threshold=<span class=\"number\">20</span>, nonmaxSuppression=<span class=\"literal\">True</span>, type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)<span class=\"comment\">#获取FAST角点探测器</span></span><br><span class=\"line\">kp = fast.detect(img,<span class=\"literal\">None</span>)<span class=\"comment\">#描述符</span></span><br><span class=\"line\">img = cv2.drawKeypoints(img, kp, img, color=(<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>))<span class=\"comment\">#画到img上面</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"Threshold: \"</span>, fast.getThreshold())<span class=\"comment\">#输出阈值</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"nonmaxSuppression: \"</span>, fast.getNonmaxSuppression())<span class=\"comment\">#是否使用非极大值抑制</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"Total Keypoints with nonmaxSuppression: \"</span>, len(kp))<span class=\"comment\">#特征点个数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cv2.imshow('sp',img)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.waitKey(0)</span></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_7_1.png\"></p>\n<h3 id=\"SIFT\"><a href=\"#SIFT\" class=\"headerlink\" title=\"SIFT\"></a>SIFT</h3><p>角点检测具有旋转不变特性，即即使图片发生了旋转，算法也能找到同样的角点。<br>但是如果对图像进行缩放，角点可能就不再是角点了。<br>尺度不变特征变换（SIFT），利用原始图像与高斯核的卷积来建立尺度空间，并在高斯差分空间金字塔上提取出尺度不变性的特征点。<br>该算法具有一定的仿射不变性，视角不变性，旋转不变性和光照不变性，所以在图像特征提高方面得到了最广泛的应用。  </p>\n<p>步骤：<br>1）构建高斯差分金字塔<br>通过减少采样来构成一组图像尺寸不同的图像金字塔，然后对这一组图像中的每一张图像使用具有不同方差$σ$的高斯卷积核构建出具有不同分辨率的图像金字塔（不同的尺度空间）,DoG就是这组具有不同分辨率的图像金字塔中相邻的两层之间的差值;<br><img alt=\"DOG Pyramid\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg\"></p>\n<p>2）定位关键点<br>首先在尺度空间和二维平面中检测局部最大值$(x，y，σ)$,这表示在$σ$尺度中点$(x，y)$可能是一个关键点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br><img alt=\"sift_local_extrema\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg\"><br>以上方法检测到的极值点是离散空间的极值点，通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力。</p>\n<p>3）关键点描述符<br>为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向，使用图像梯度的方法求取局部结构的稳定方向。<br>选取关键点周围一个 16x16 的邻域，把它分成 16 个 4x4 的小方块，为每个小方块创建一个具有 8 个 bin 的方向直方图。总共加起来有 128 个 bin。由此组成长为 128 的向量就构成了关键点描述符。  </p>\n<p>缺点<br>SIFT在图像的不变特征提取方面拥有无与伦比的优势，但并不完美，对模糊的图像和边缘平滑的图像，检测出的特征点过少，对圆更是无能为力。</p>\n<ol>\n<li>实时性不高；  </li>\n<li>有时特征点较少；  </li>\n<li>对边缘光滑的目标无法准确提取特征点。  </li>\n</ol>\n<p>参考资料  </p>\n<ul>\n<li>SIFT算法详解 - zddhub的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/zddblog/article/details/7521424\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zddblog/article/details/7521424</a></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/home.jpg'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp = sift.detect(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))</span></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_9_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kp, des = sift.detectAndCompute(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"><span class=\"comment\"># print(\"kp:\", kp)</span></span><br><span class=\"line\">print(<span class=\"string\">\"des' lenth:\"</span>, len(des[<span class=\"number\">0</span>]))</span><br><span class=\"line\">print(<span class=\"string\">\"des:\"</span>, des)</span><br></pre></td></tr></table></figure>\n<pre><code>des&#39; lenth: 64\ndes: [[ 1.1795463e-02 -1.3453829e-03  1.2853614e-02 ... -6.1970763e-03\n   1.0367702e-02  8.2569038e-03]\n [-3.7488429e-04 -1.7145486e-03  1.5926192e-03 ...  9.5438212e-03\n   5.8124182e-03  1.0535392e-02]\n [ 1.8987345e-04 -3.9035594e-04  3.5250295e-04 ... -6.1610942e-03\n   7.9580760e-03  6.6615609e-03]\n ...\n [-1.1354305e-02 -2.0890196e-03  1.3535642e-02 ...  5.5240576e-05\n   3.2335313e-03  5.6648249e-04]\n [ 4.4308142e-03  6.1169025e-03  6.2500047e-03 ...  3.9724767e-04\n   6.5160347e-03  9.4564463e-04]\n [-7.7680773e-03  2.0684338e-04  7.8980839e-03 ... -2.7418079e-02\n   8.1536770e-03  3.2845538e-02]]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp = sift.detect(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_11_0.png\"></p>\n<h3 id=\"SURF-Speeded-Up-Robust-Features\"><a href=\"#SURF-Speeded-Up-Robust-Features\" class=\"headerlink\" title=\"SURF(Speeded-Up Robust Features)\"></a>SURF(Speeded-Up Robust Features)</h3><p>2006年，Bay和Ess等人基于SIFT算法的思路，提出了加速鲁棒特征（SURF）,该算法主要针对于SIFT算法速度太慢，计算量大的缺点，使用了近似Harr小波方法来提取特征点，这种方法就是基于Hessian行列式（DoH）的斑点特征检测方法。通过在不同的尺度上利用积分图像可以有效地计算出近似Harr小波值，简化了二阶微分模板的构建，搞高了尺度空间的特征检测的效率。  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/butterfly.jpg'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">surf = cv2.xfeatures2d.SURF_create(<span class=\"number\">40000</span>)</span><br><span class=\"line\">kp = surf.detect(gray, <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))</span></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_13_0.png\"></p>\n<h3 id=\"BRIEF\"><a href=\"#BRIEF\" class=\"headerlink\" title=\"BRIEF\"></a>BRIEF</h3><p>Binary Robust Independent Elementary Features，在特征点附近随机选取若干点对，将这些点对的灰度值的大小，<br>组合成一个二进制串，并将这个二进制串作为该特征点的特征描述子（即BRIEF描述子中的每一位是由随机选取的两个像素点做二进制比较得来，BRIEF描述子的所有编码都是二进制数的）<br>BRIEF的优点在于速度，缺点也相当明显：<br>1：不具备旋转不变性<br>2：对噪声敏感<br>3：不具备尺度不变性   </p>\n<p>BRIEF 是一种特征描述符，它不提供查找特征的方法。所以我们不得不使用其他特征检测器，比如 SIFT 和 SURF 等。</p>\n<h3 id=\"ORB-Oriented-FAST-and-Rotated-BRIEF\"><a href=\"#ORB-Oriented-FAST-and-Rotated-BRIEF\" class=\"headerlink\" title=\"ORB (Oriented FAST and Rotated BRIEF)\"></a>ORB (Oriented FAST and Rotated BRIEF)</h3><p>ORB特征是将FAST特征点的检测方法与BRIEF特征描述子结合起来，并在它们原来的基础上做了改进与优化。</p>\n<p>ORB特征具有旋转不变性，同时对噪声及透视仿射也具有不变性</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img=cv2.imread(<span class=\"string\">'./images/car.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">orb=cv2.ORB_create()</span><br><span class=\"line\"><span class=\"comment\"># kp=orb.detect(img,None)</span></span><br><span class=\"line\"><span class=\"comment\"># kp,des=orb.compute(img,kp)</span></span><br><span class=\"line\"></span><br><span class=\"line\">kp,des=orb.detectAndCompute(img,<span class=\"literal\">None</span>)</span><br><span class=\"line\">img2=cv2.drawKeypoints(img,kp,<span class=\"literal\">None</span>,(<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>),flags=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.imshow(img2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_16_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">12</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img1 = cv2.imread(<span class=\"string\">'./images/manowar_logo.png'</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">img2 = cv2.imread(<span class=\"string\">'./images/manowar_single.jpg'</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">orb = cv2.ORB_create()</span><br><span class=\"line\">kp1, des1 = orb.detectAndCompute(img1,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2, des2 = orb.detectAndCompute(img2,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 暴力匹配BFMatcher</span></span><br><span class=\"line\">bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=<span class=\"literal\">True</span>)</span><br><span class=\"line\">matches = bf.match(des1, des2)</span><br><span class=\"line\">matches = sorted(matches, key=<span class=\"keyword\">lambda</span> x: x.distance)</span><br><span class=\"line\"></span><br><span class=\"line\">img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:<span class=\"number\">40</span>], img2, flags=<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.imshow(img3)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_17_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">12</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">train=cv2.imread(<span class=\"string\">'./images/baboon200_rotated.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\">query=cv2.imread(<span class=\"string\">'./images/baboon.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sift=cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp1,des1=sift.detectAndCompute(train,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2,des2=sift.detectAndCompute(query,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># find the keypoints and descriptors with SIFT</span></span><br><span class=\"line\">kp1, des1 = sift.detectAndCompute(train,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2, des2 = sift.detectAndCompute(query,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># FLANN parameters</span></span><br><span class=\"line\">FLANN_INDEX_KDTREE = <span class=\"number\">1</span></span><br><span class=\"line\">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = <span class=\"number\">5</span>)</span><br><span class=\"line\">search_params = dict(checks=<span class=\"number\">50</span>) <span class=\"comment\"># or pass empty dictionary</span></span><br><span class=\"line\"></span><br><span class=\"line\">flann = cv2.FlannBasedMatcher(index_params,search_params)</span><br><span class=\"line\"></span><br><span class=\"line\">matches = flann.knnMatch(des1,des2,k=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Need to draw only good matches, so create a mask</span></span><br><span class=\"line\">matchesMask = [[<span class=\"number\">0</span>,<span class=\"number\">0</span>] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(matches))]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ratio test as per Lowe's paper</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i,(m,n) <span class=\"keyword\">in</span> enumerate(matches):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#如果第一个邻近距离比第二个邻近距离的0.7倍小，则保留</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> m.distance &lt; <span class=\"number\">0.7</span>*n.distance:</span><br><span class=\"line\">        matchesMask[i]=[<span class=\"number\">1</span>,<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">draw_params = dict(matchColor = (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>),</span><br><span class=\"line\">                   singlePointColor = (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>),</span><br><span class=\"line\">                   matchesMask = matchesMask,</span><br><span class=\"line\">                   flags = <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img3 = cv2.drawMatchesKnn(train,kp1,query,kp2,matches,<span class=\"literal\">None</span>,**draw_params)</span><br><span class=\"line\">plt.imshow(img3)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_18_0.png\"></p>\n</the>","site":{"data":{}},"excerpt":"<p><strong> OpenCV学习笔记三：特征检测和图像检索：</strong> <excerpt in index | 首页摘要></excerpt></p>\n<h2 id=\"特征检测算法\"><a href=\"#特征检测算法\" class=\"headerlink\" title=\"特征检测算法\"></a>特征检测算法</h2><ul>\n<li>Harris     角点检测</li>\n<li>Shi-Tomasi 角点检测</li>\n<li>FAST       角点检测</li>\n<li>SIFT       斑点（blob）检测</li>\n<li>SURF       斑点检测</li>\n<li>BRIEF      斑点检测</li>\n<li>ORB (Oriented FAST and Rotated BRIEF)</li>\n</ul>","more":"<the rest of contents | 余下全文>\n\n<h3 id=\"Harris\"><a href=\"#Harris\" class=\"headerlink\" title=\"Harris\"></a>Harris</h3><p>角点定义：如果某一点在任意方向的一个微小变动都会引起灰度很大的变化，那么这个点就称之为角点。<br>Harris角点检测的核心思想就是用一个局部窗口在图像上进行移动来判断灰度的变化，如果变化大于一个值那么就认为这个点是角点。<br>将窗口向各个方向移动$(u, v)$然后计算所有差异的总和。表达式如下 </p>\n<script type=\"math/tex; mode=display\">\nE(u, v)= \\underbrace{w(x, y)}_{\\text { window function }}[\\underbrace{I(x+u, y+v)}_{\\text { shifted intensity }}-\\underbrace{I(x, y)}_{\\text { intensity }}]^{2}</script><p>窗口函数$w(x,y)$可以是正常的矩形窗口也可以是对每一个像素给予不同权重的高斯窗口。  角点检测中要使 $E(u,v)$ 的值最大。<br>使用泰勒展开和二次型，$E(u,v)$可以近似于  </p>\n<script type=\"math/tex; mode=display\">E(u,v) \\approx \\left[ \\begin{matrix}u\\,v\n\\end{matrix}\\right]  M \\left[ \\begin{matrix}\n    u \\\\\n    v \\\\ \n\\end{matrix}\\right]</script><p>其中 </p>\n<script type=\"math/tex; mode=display\">M = \\sum_{x, y} w(x, y)\\left[ \\begin{matrix}\n    I_xI_x\\quad I_xI_y \\\\\n    I_xI_y\\quad I_yI_y \\\\ \n\\end{matrix}\\right]</script><p>这里 $I_x$ 和 $I_y$ 是图像在 $x$ 和 $y$ 方向的导数,可以使用函数 cv2.Sobel()<br>计算得到。<br>根据下式中的$R$值判定窗口内是否包含角点</p>\n<script type=\"math/tex; mode=display\">R=det(M)- \\alpha (trace(M))^2</script><p>其中$\\lambda_1$ 和 $\\lambda_2$ 是矩阵 $M$ 的特征值，$\\alpha$是一个经验常数，取值为$[0.04, 0.06]$。<br>根据R值可以判断一个区域是否是角点，边界或者是平面。  </p>\n<ul>\n<li>当 $\\lambda_1$ 和 $\\lambda_2$ 都小时，$|R|$ 也小，对应图像中的平滑区域；</li>\n<li>当 $\\lambda_1 \\gg \\lambda_2$ 或者 $\\lambda_1 \\ll \\lambda_2$ 时， $R$ 小于0，对应图像中的边缘；</li>\n<li>当 $\\lambda_1$ 和 $\\lambda_2$ 都很大时，$R$ 也很大，对应图像中的角点。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/chess_board.png'</span>)</span><br><span class=\"line\">img_copy = np.copy(img)</span><br><span class=\"line\">img_copy = cv2.cvtColor(img_copy, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">10</span>,<span class=\"number\">10</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">plt.subplot(<span class=\"number\">221</span>)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">222</span>)</span><br><span class=\"line\">plt.imshow(img_copy)</span><br><span class=\"line\"></span><br><span class=\"line\">img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">img_gray = np.float32(img_gray)</span><br><span class=\"line\"><span class=\"comment\"># 检测角点，定义串口大小为2，梯度计算的索贝尔核函数大小为3，alpha设置为0.04</span></span><br><span class=\"line\">img_dst = cv2.cornerHarris(img_gray, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0.04</span>)</span><br><span class=\"line\"><span class=\"comment\"># 对图像做膨胀处理，加强角点</span></span><br><span class=\"line\">img_dst = cv2.dilate(img_dst, <span class=\"literal\">None</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">223</span>)</span><br><span class=\"line\">plt.imshow(img_dst)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义阈值，用于与R相比较</span></span><br><span class=\"line\">thresh = <span class=\"number\">0.7</span> * img_dst.max()</span><br><span class=\"line\">img_corner = np.copy(img)</span><br><span class=\"line\"><span class=\"comment\"># 遍历每一个像素，如果大于阈值，则认为为角点并画在图上</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> img_dst[j, i] &gt; thresh:</span><br><span class=\"line\">            cv2.circle(img_corner, (i, j), <span class=\"number\">25</span>, (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\">plt.subplot(<span class=\"number\">224</span>)</span><br><span class=\"line\">plt.imshow(img_corner)</span><br><span class=\"line\">plt.subplots_adjust(bottom=<span class=\"number\">.01</span>, top=<span class=\"number\">.99</span>, left=<span class=\"number\">.01</span>, right=<span class=\"number\">.99</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_2_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">%time</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># filename = './images/blox.jpg'</span></span><br><span class=\"line\">filename = <span class=\"string\">'./images/chessboard.png'</span></span><br><span class=\"line\">img = cv2.imread(filename)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\">gray = np.float32(gray)</span><br><span class=\"line\">img_dst = cv2.cornerHarris(gray, <span class=\"number\">2</span>, <span class=\"number\">3</span>, <span class=\"number\">0.05</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># result is dilated for marking the corners, not important</span></span><br><span class=\"line\">img_dst = cv2.dilate(img_dst, <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Threshold for an optimal value, it may vary depending on the image.</span></span><br><span class=\"line\"><span class=\"comment\"># img[dst&gt;0.07*dst.max()]=[0,0,255]</span></span><br><span class=\"line\">thresh = <span class=\"number\">0.2</span> * img_dst.max()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 遍历每一个像素，如果大于阈值，则认为为角点并画在图上</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">0</span>]):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(img_dst.shape[<span class=\"number\">1</span>]):</span><br><span class=\"line\">        <span class=\"keyword\">if</span> img_dst[j, i] &gt; thresh:</span><br><span class=\"line\">            cv2.circle(img, (i, j), <span class=\"number\">25</span>, (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>), <span class=\"number\">1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img_show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img_show)</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_3_2.png\"></p>\n<h3 id=\"Shi-Tomasi\"><a href=\"#Shi-Tomasi\" class=\"headerlink\" title=\"Shi-Tomasi\"></a>Shi-Tomasi</h3><p>Harris角点的打分公式为</p>\n<script type=\"math/tex; mode=display\">R=det(M)- \\alpha (trace(M))^2</script><p>Shi-Tomasi 使用的打分公式为</p>\n<script type=\"math/tex; mode=display\">R=min(\\lambda_1, \\lambda_2)</script><p>如果打分超过阈值，我们就认为它是一个角点。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/blox.jpg'</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">corners = cv2.goodFeaturesToTrack(gray, <span class=\"number\">50</span>, <span class=\"number\">0.01</span>, <span class=\"number\">10</span>)</span><br><span class=\"line\"><span class=\"comment\"># N个最佳角点 = cv2.goodFeaturesToTrack(灰度图, 数量N, 角点质量, 两个角点见最小欧式距离)</span></span><br><span class=\"line\">corners = np.int0(corners)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> corners:</span><br><span class=\"line\">    x,y = i.ravel()</span><br><span class=\"line\">    cv2.circle(img, (x,y), <span class=\"number\">3</span>, <span class=\"number\">255</span>, <span class=\"number\">-1</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_5_0.png\"></p>\n<h3 id=\"FAST\"><a href=\"#FAST\" class=\"headerlink\" title=\"FAST\"></a>FAST</h3><p>FAST 算法比其它角点检测算法都快。但是在噪声很高时不够稳定，这是由阈值决定的。<br>原理：FAST特征检测算法来源于corner的定义，这个定义基于特征点周围的图像灰度值，检测候选特征点周围一圈的像素值，如果候选点周围领域内有足够多的像素点与该候选点的灰度值差别够大，则认为该候选点为一个特征点。</p>\n<script type=\"math/tex; mode=display\">N = \\sum_{x\\, \\forall \\, circles(p)}|I(x)-I(p)|>\\epsilon_d</script><p>步骤：<br>1）在图像中任选一点$p$,假定其像素（亮度）值为$I_p$;<br>2）以$r$为半径画圆，覆盖$p$点周围的$M$个像素,如下图所示: $r=3， M=16$;<br><img alt=\"FAST\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png\"><br>3）设定阈值$t$，如果这周围的16个像素中有连续的$N$个像素的像素值减去$I_p$大于$t$,或者有连续的$N$个像素都大于$I_p+t$,则认为$p$为角点。<br>如果$t=0$，那么就可以理解为：有连续N个像素大于或小于$I_p$的灰度值。那么这个点就被判断为角点。  </p>\n<p>为了获得更快的结果，还采用了额外的加速办法。<br>如果测试了候选点周围每隔90度角的4个点，应该至少有3个和候选点的灰度值差足够大，否则则不用再计算其他点，直接认为该候选点不是特征点。<br>候选点周围的圆的选取半径是一个很重要的参数，这里为了简单高效，采用半径为3，共有16个周边像素需要比较。为了提高比较的效率，通常只使用N个周边像素来比较，也就是大家经常说的FAST-N，使用比较多的是FAST-9和FAST-12。<br>这个检测器的效率很高，但是它有如下几条缺点：</p>\n<ul>\n<li>当 n&lt;12 时它不会丢弃很多候选点 (获得的候选点比较多)。  </li>\n<li>像素的选取不是最优的，因为它的效果取决与要解决的问题和角点的分布情况。  </li>\n<li>高速测试的结果被抛弃。  </li>\n<li>检测到的很多特征点都是连在一起的。<br>前3个问题可以通过机器学习的方法解决，第4问题可以使用非最大值抑制的方法解决。</li>\n</ul>\n<h4 id=\"机器学习的角点检测器\"><a href=\"#机器学习的角点检测器\" class=\"headerlink\" title=\"机器学习的角点检测器\"></a>机器学习的角点检测器</h4><ol>\n<li>选择一组训练图片（最好是跟最后应用相关的图片）使用FAST算法找出每幅图像的特征点；</li>\n<li>对每一个特征点，将其周围的 16 个像素存储构成一个向量，对所有图像都这样做构建一个特征向量$P$;</li>\n<li>每一个特征点的16像素点都属于下列三类中的一种<script type=\"math/tex; mode=display\">S_{p\\to x}= \\begin{cases}\nd,& \\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;I_{p\\to x}\\le I_p - t &(darker)\\\\ \ns,& I_p-t < I_{p\\to x} <  I_p + t  &(similar)\\\\\nb,&I_p+t \\le I_{p\\to x}  &(brighter)\n\\end{cases}</script>根据这些像素点的分类，特征向量$P$也被分为3个子集：$P_d$，$P_s$，$P_b$</li>\n<li>定义一个新的布尔变量$K_p$ ，如果$p$是角点就设置为 Ture，如果不是就设置为 False。</li>\n<li>使用ID3算法（决策树分类器）来查询每一个子集，递归计算所有子集直到熵为0；</li>\n<li>将构建好的决策树运用于其他图像的快速的检测。</li>\n</ol>\n<h4 id=\"非极大值抑制\"><a href=\"#非极大值抑制\" class=\"headerlink\" title=\"非极大值抑制\"></a>非极大值抑制</h4><p>很可能大部分检测出来的点彼此之间相邻，我们要去除一部分这样的点。为了解决这一问题，可以采用非最大值抑制的算法：<br>假设P，Q两个点相邻，分别计算两个点与其周围的16个像素点之间的差分和为V，去除V值较小的点，即把非最大的角点抑制掉。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/blox.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">fast = cv2.FastFeatureDetector_create(threshold=<span class=\"number\">20</span>, nonmaxSuppression=<span class=\"literal\">True</span>, type=cv2.FAST_FEATURE_DETECTOR_TYPE_9_16)<span class=\"comment\">#获取FAST角点探测器</span></span><br><span class=\"line\">kp = fast.detect(img,<span class=\"literal\">None</span>)<span class=\"comment\">#描述符</span></span><br><span class=\"line\">img = cv2.drawKeypoints(img, kp, img, color=(<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>))<span class=\"comment\">#画到img上面</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"Threshold: \"</span>, fast.getThreshold())<span class=\"comment\">#输出阈值</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"nonmaxSuppression: \"</span>, fast.getNonmaxSuppression())<span class=\"comment\">#是否使用非极大值抑制</span></span><br><span class=\"line\"><span class=\"keyword\">print</span> (<span class=\"string\">\"Total Keypoints with nonmaxSuppression: \"</span>, len(kp))<span class=\"comment\">#特征点个数</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># cv2.imshow('sp',img)</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.waitKey(0)</span></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_7_1.png\"></p>\n<h3 id=\"SIFT\"><a href=\"#SIFT\" class=\"headerlink\" title=\"SIFT\"></a>SIFT</h3><p>角点检测具有旋转不变特性，即即使图片发生了旋转，算法也能找到同样的角点。<br>但是如果对图像进行缩放，角点可能就不再是角点了。<br>尺度不变特征变换（SIFT），利用原始图像与高斯核的卷积来建立尺度空间，并在高斯差分空间金字塔上提取出尺度不变性的特征点。<br>该算法具有一定的仿射不变性，视角不变性，旋转不变性和光照不变性，所以在图像特征提高方面得到了最广泛的应用。  </p>\n<p>步骤：<br>1）构建高斯差分金字塔<br>通过减少采样来构成一组图像尺寸不同的图像金字塔，然后对这一组图像中的每一张图像使用具有不同方差$σ$的高斯卷积核构建出具有不同分辨率的图像金字塔（不同的尺度空间）,DoG就是这组具有不同分辨率的图像金字塔中相邻的两层之间的差值;<br><img alt=\"DOG Pyramid\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg\"></p>\n<p>2）定位关键点<br>首先在尺度空间和二维平面中检测局部最大值$(x，y，σ)$,这表示在$σ$尺度中点$(x，y)$可能是一个关键点。为了寻找DoG函数的极值点，每一个像素点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。<br><img alt=\"sift_local_extrema\" src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg\"><br>以上方法检测到的极值点是离散空间的极值点，通过拟合三维二次函数来精确确定关键点的位置和尺度，同时去除低对比度的关键点和不稳定的边缘响应点(因为DoG算子会产生较强的边缘响应)，以增强匹配稳定性、提高抗噪声能力。</p>\n<p>3）关键点描述符<br>为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个基准方向，使用图像梯度的方法求取局部结构的稳定方向。<br>选取关键点周围一个 16x16 的邻域，把它分成 16 个 4x4 的小方块，为每个小方块创建一个具有 8 个 bin 的方向直方图。总共加起来有 128 个 bin。由此组成长为 128 的向量就构成了关键点描述符。  </p>\n<p>缺点<br>SIFT在图像的不变特征提取方面拥有无与伦比的优势，但并不完美，对模糊的图像和边缘平滑的图像，检测出的特征点过少，对圆更是无能为力。</p>\n<ol>\n<li>实时性不高；  </li>\n<li>有时特征点较少；  </li>\n<li>对边缘光滑的目标无法准确提取特征点。  </li>\n</ol>\n<p>参考资料  </p>\n<ul>\n<li>SIFT算法详解 - zddhub的专栏 - CSDN博客<br><a href=\"https://blog.csdn.net/zddblog/article/details/7521424\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/zddblog/article/details/7521424</a></li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/home.jpg'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp = sift.detect(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))</span></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_9_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">kp, des = sift.detectAndCompute(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"><span class=\"comment\"># print(\"kp:\", kp)</span></span><br><span class=\"line\">print(<span class=\"string\">\"des' lenth:\"</span>, len(des[<span class=\"number\">0</span>]))</span><br><span class=\"line\">print(<span class=\"string\">\"des:\"</span>, des)</span><br></pre></td></tr></table></figure>\n<pre><code>des&#39; lenth: 64\ndes: [[ 1.1795463e-02 -1.3453829e-03  1.2853614e-02 ... -6.1970763e-03\n   1.0367702e-02  8.2569038e-03]\n [-3.7488429e-04 -1.7145486e-03  1.5926192e-03 ...  9.5438212e-03\n   5.8124182e-03  1.0535392e-02]\n [ 1.8987345e-04 -3.9035594e-04  3.5250295e-04 ... -6.1610942e-03\n   7.9580760e-03  6.6615609e-03]\n ...\n [-1.1354305e-02 -2.0890196e-03  1.3535642e-02 ...  5.5240576e-05\n   3.2335313e-03  5.6648249e-04]\n [ 4.4308142e-03  6.1169025e-03  6.2500047e-03 ...  3.9724767e-04\n   6.5160347e-03  9.4564463e-04]\n [-7.7680773e-03  2.0684338e-04  7.8980839e-03 ... -2.7418079e-02\n   8.1536770e-03  3.2845538e-02]]\n</code></pre><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/opencv-logo.png'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">sift = cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp = sift.detect(gray,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_11_0.png\"></p>\n<h3 id=\"SURF-Speeded-Up-Robust-Features\"><a href=\"#SURF-Speeded-Up-Robust-Features\" class=\"headerlink\" title=\"SURF(Speeded-Up Robust Features)\"></a>SURF(Speeded-Up Robust Features)</h3><p>2006年，Bay和Ess等人基于SIFT算法的思路，提出了加速鲁棒特征（SURF）,该算法主要针对于SIFT算法速度太慢，计算量大的缺点，使用了近似Harr小波方法来提取特征点，这种方法就是基于Hessian行列式（DoH）的斑点特征检测方法。通过在不同的尺度上利用积分图像可以有效地计算出近似Harr小波值，简化了二阶微分模板的构建，搞高了尺度空间的特征检测的效率。  </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">from</span> matplotlib <span class=\"keyword\">import</span> pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.imread(<span class=\"string\">'./images/butterfly.jpg'</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)</span><br><span class=\"line\"></span><br><span class=\"line\">surf = cv2.xfeatures2d.SURF_create(<span class=\"number\">40000</span>)</span><br><span class=\"line\">kp = surf.detect(gray, <span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># img = cv2.drawKeypoints(img, kp, img, color=(255,0,0))</span></span><br><span class=\"line\">img = cv2.drawKeypoints(gray, kp, img, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\">img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)</span><br><span class=\"line\">plt.imshow(img)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_13_0.png\"></p>\n<h3 id=\"BRIEF\"><a href=\"#BRIEF\" class=\"headerlink\" title=\"BRIEF\"></a>BRIEF</h3><p>Binary Robust Independent Elementary Features，在特征点附近随机选取若干点对，将这些点对的灰度值的大小，<br>组合成一个二进制串，并将这个二进制串作为该特征点的特征描述子（即BRIEF描述子中的每一位是由随机选取的两个像素点做二进制比较得来，BRIEF描述子的所有编码都是二进制数的）<br>BRIEF的优点在于速度，缺点也相当明显：<br>1：不具备旋转不变性<br>2：对噪声敏感<br>3：不具备尺度不变性   </p>\n<p>BRIEF 是一种特征描述符，它不提供查找特征的方法。所以我们不得不使用其他特征检测器，比如 SIFT 和 SURF 等。</p>\n<h3 id=\"ORB-Oriented-FAST-and-Rotated-BRIEF\"><a href=\"#ORB-Oriented-FAST-and-Rotated-BRIEF\" class=\"headerlink\" title=\"ORB (Oriented FAST and Rotated BRIEF)\"></a>ORB (Oriented FAST and Rotated BRIEF)</h3><p>ORB特征是将FAST特征点的检测方法与BRIEF特征描述子结合起来，并在它们原来的基础上做了改进与优化。</p>\n<p>ORB特征具有旋转不变性，同时对噪声及透视仿射也具有不变性</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">8</span>, <span class=\"number\">8</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img=cv2.imread(<span class=\"string\">'./images/car.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">orb=cv2.ORB_create()</span><br><span class=\"line\"><span class=\"comment\"># kp=orb.detect(img,None)</span></span><br><span class=\"line\"><span class=\"comment\"># kp,des=orb.compute(img,kp)</span></span><br><span class=\"line\"></span><br><span class=\"line\">kp,des=orb.detectAndCompute(img,<span class=\"literal\">None</span>)</span><br><span class=\"line\">img2=cv2.drawKeypoints(img,kp,<span class=\"literal\">None</span>,(<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>),flags=<span class=\"number\">0</span>)</span><br><span class=\"line\">plt.imshow(img2)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_16_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">12</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">img1 = cv2.imread(<span class=\"string\">'./images/manowar_logo.png'</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">img2 = cv2.imread(<span class=\"string\">'./images/manowar_single.jpg'</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">orb = cv2.ORB_create()</span><br><span class=\"line\">kp1, des1 = orb.detectAndCompute(img1,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2, des2 = orb.detectAndCompute(img2,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 暴力匹配BFMatcher</span></span><br><span class=\"line\">bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=<span class=\"literal\">True</span>)</span><br><span class=\"line\">matches = bf.match(des1, des2)</span><br><span class=\"line\">matches = sorted(matches, key=<span class=\"keyword\">lambda</span> x: x.distance)</span><br><span class=\"line\"></span><br><span class=\"line\">img3 = cv2.drawMatches(img1, kp1, img2, kp2, matches[:<span class=\"number\">40</span>], img2, flags=<span class=\"number\">2</span>)</span><br><span class=\"line\">plt.imshow(img3)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_17_0.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"></span><br><span class=\"line\">%matplotlib inline</span><br><span class=\"line\">plt.figure(figsize=(<span class=\"number\">12</span>, <span class=\"number\">12</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">train=cv2.imread(<span class=\"string\">'./images/baboon200_rotated.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\">query=cv2.imread(<span class=\"string\">'./images/baboon.jpg'</span>,<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">sift=cv2.xfeatures2d.SIFT_create()</span><br><span class=\"line\">kp1,des1=sift.detectAndCompute(train,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2,des2=sift.detectAndCompute(query,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># find the keypoints and descriptors with SIFT</span></span><br><span class=\"line\">kp1, des1 = sift.detectAndCompute(train,<span class=\"literal\">None</span>)</span><br><span class=\"line\">kp2, des2 = sift.detectAndCompute(query,<span class=\"literal\">None</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># FLANN parameters</span></span><br><span class=\"line\">FLANN_INDEX_KDTREE = <span class=\"number\">1</span></span><br><span class=\"line\">index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = <span class=\"number\">5</span>)</span><br><span class=\"line\">search_params = dict(checks=<span class=\"number\">50</span>) <span class=\"comment\"># or pass empty dictionary</span></span><br><span class=\"line\"></span><br><span class=\"line\">flann = cv2.FlannBasedMatcher(index_params,search_params)</span><br><span class=\"line\"></span><br><span class=\"line\">matches = flann.knnMatch(des1,des2,k=<span class=\"number\">2</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># Need to draw only good matches, so create a mask</span></span><br><span class=\"line\">matchesMask = [[<span class=\"number\">0</span>,<span class=\"number\">0</span>] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(len(matches))]</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ratio test as per Lowe's paper</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> i,(m,n) <span class=\"keyword\">in</span> enumerate(matches):</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#如果第一个邻近距离比第二个邻近距离的0.7倍小，则保留</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> m.distance &lt; <span class=\"number\">0.7</span>*n.distance:</span><br><span class=\"line\">        matchesMask[i]=[<span class=\"number\">1</span>,<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\">draw_params = dict(matchColor = (<span class=\"number\">0</span>,<span class=\"number\">255</span>,<span class=\"number\">0</span>),</span><br><span class=\"line\">                   singlePointColor = (<span class=\"number\">255</span>,<span class=\"number\">0</span>,<span class=\"number\">0</span>),</span><br><span class=\"line\">                   matchesMask = matchesMask,</span><br><span class=\"line\">                   flags = <span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">img3 = cv2.drawMatchesKnn(train,kp1,query,kp2,matches,<span class=\"literal\">None</span>,**draw_params)</span><br><span class=\"line\">plt.imshow(img3)</span><br><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure>\n<p><img src=\"/2019/06/23/OpenCV学习笔记三：特征检测和图像检索/output_18_0.png\"></p>\n</the>"}],"PostAsset":[{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_13_0.png","slug":"output_13_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","modified":1,"renderable":0},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/output_4_0.png","slug":"output_4_0.png","post":"cjxqdm76d003xrsvjuuaocv3s","modified":1,"renderable":0},{"_id":"source/_posts/Hikey970使用记录/00.png","post":"cjxqdm74i0007rsvjtlr9pz42","slug":"00.png","modified":1,"renderable":1},{"_id":"source/_posts/Jetson-Nano-使用记录/001.png","post":"cjxqdm74l000brsvjf6z7jzbt","slug":"001.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录四：python加载运行OpenCL/001.png","post":"cjxqdm74o000irsvj1q2v70ly","slug":"001.png","modified":1,"renderable":1},{"_id":"source/_posts/Scikit-Learn学习笔记/machine_learning_map.png","slug":"machine_learning_map.png","post":"cjxqdm74u000trsvj6mwbl92u","modified":1,"renderable":0},{"_id":"source/_posts/loomo多服务机器人开发/设计思路-201905.png","slug":"设计思路-201905.png","post":"cjxqdm74v000wrsvj2v9tlitp","modified":1,"renderable":0},{"_id":"source/_posts/tkinter学习笔记/color.png","slug":"color.png","post":"cjxqdm74w000yrsvjusoshyse","modified":1,"renderable":0},{"_id":"source/_posts/桌面冰球机器人/001.gif","slug":"001.gif","post":"cjxqdm752001crsvjo1gqugcd","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人二：透射变换/001.jpg","post":"cjxqdm756001irsvjhqahgogm","slug":"001.jpg","modified":1,"renderable":1},{"_id":"source/_posts/象棋残局机器人五：象棋棋子分类模型/001.jpg","slug":"001.jpg","post":"cjxqdm75b001orsvje3tlnlkk","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人四：策略/001.png","post":"cjxqdm75c001rrsvj2prfmv7n","slug":"001.png","modified":1,"renderable":1},{"_id":"source/_posts/门禁人脸检测和识别/demo.gif","slug":"demo.gif","post":"cjxqdm75g001wrsvjjv7m7b84","modified":1,"renderable":0},{"_id":"source/_posts/简单手势分类器/01.png","post":"cjxqdm751001arsvj79vrqh57","slug":"01.png","modified":1,"renderable":1},{"_id":"source/_posts/简单手势分类器/02.png","slug":"02.png","post":"cjxqdm751001arsvj79vrqh57","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人三：分类模型retrain/001.png","slug":"001.png","post":"cjxqdm758001krsvjn74ah9zz","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人三：分类模型retrain/002.png","slug":"002.png","post":"cjxqdm758001krsvjn74ah9zz","modified":1,"renderable":0},{"_id":"source/_posts/Pixar-Lamp/001.jpg","post":"cjxqdm74p000krsvjjtmr5xfk","slug":"001.jpg","modified":1,"renderable":1},{"_id":"source/_posts/Pixar-Lamp/设计思路-201905.png","slug":"设计思路-201905.png","post":"cjxqdm74p000krsvjjtmr5xfk","modified":1,"renderable":0},{"_id":"source/_posts/Pixar-Lamp/设计思路.png","slug":"设计思路.png","post":"cjxqdm74p000krsvjjtmr5xfk","modified":1,"renderable":0},{"_id":"source/_posts/作业检查机器人/000.jpg","post":"cjxqdm74x0010rsvjd2dvqzp8","slug":"000.jpg","modified":1,"renderable":1},{"_id":"source/_posts/作业检查机器人/001.png","slug":"001.png","post":"cjxqdm74x0010rsvjd2dvqzp8","modified":1,"renderable":0},{"_id":"source/_posts/作业检查机器人/002.png","slug":"002.png","post":"cjxqdm74x0010rsvjd2dvqzp8","modified":1,"renderable":0},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/01.png","post":"cjxqdm7500018rsvj1bhiswl6","slug":"01.png","modified":1,"renderable":1},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/02.png","post":"cjxqdm7500018rsvj1bhiswl6","slug":"02.png","modified":1,"renderable":1},{"_id":"source/_posts/树莓派3b 编译安装OpenCV-4.0.0 for Python3/03.png","post":"cjxqdm7500018rsvj1bhiswl6","slug":"03.png","modified":1,"renderable":1},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/001.jpg","post":"cjxqdm753001ersvjoz9npopo","slug":"001.jpg","modified":1,"renderable":1},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/002.png","slug":"002.png","post":"cjxqdm753001ersvjoz9npopo","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人一：摄像头标定/003.png","slug":"003.png","post":"cjxqdm753001ersvjoz9npopo","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人/demo1.gif","slug":"demo1.gif","post":"cjxqdm755001grsvjff5ukdcm","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人/demo2.gif","slug":"demo2.gif","post":"cjxqdm755001grsvjff5ukdcm","modified":1,"renderable":0},{"_id":"source/_posts/象棋残局机器人/demo3.gif","slug":"demo3.gif","post":"cjxqdm755001grsvjff5ukdcm","modified":1,"renderable":0},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/01.png","post":"cjxqdm74m000drsvjix8msthk","slug":"01.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/02.png","post":"cjxqdm74m000drsvjix8msthk","slug":"02.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/03.png","post":"cjxqdm74m000drsvjix8msthk","slug":"03.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录二：编译安装opencv4-0-0/04.png","post":"cjxqdm74m000drsvjix8msthk","slug":"04.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/01.png","post":"cjxqdm74k000arsvjpbc80pqr","slug":"01.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/02.png","post":"cjxqdm74k000arsvjpbc80pqr","slug":"02.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/03.png","post":"cjxqdm74k000arsvjpbc80pqr","slug":"03.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/04.png","post":"cjxqdm74k000arsvjpbc80pqr","slug":"04.png","modified":1,"renderable":1},{"_id":"source/_posts/Hikey970使用记录三：USB转串口驱动安装/05.png","post":"cjxqdm74k000arsvjpbc80pqr","slug":"05.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_17_0.png","slug":"output_17_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","modified":1,"renderable":0},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_2_0.png","slug":"output_2_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","modified":1,"renderable":0},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/00.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"00.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/01.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"01.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/02.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"02.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/03.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"03.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/04.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"04.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/05.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"05.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/06.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"06.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/07.jpg","slug":"07.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","modified":1,"renderable":0},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/08.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"08.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/09.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"09.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/10.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"10.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/11.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"11.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/12.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"12.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/13.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"13.jpg","modified":1,"renderable":1},{"_id":"source/_posts/FDM3D打印电吉他琴体，制作电吉他/14.jpg","post":"cjxqdm7460003rsvjzzrwqk5g","slug":"14.jpg","modified":1,"renderable":1},{"_id":"source/_posts/天猫精灵，开灯/1.png","post":"cjxqdm76e003zrsvjmn27e3he","slug":"1.png","modified":1,"renderable":1},{"_id":"source/_posts/天猫精灵，开灯/2.png","post":"cjxqdm76e003zrsvjmn27e3he","slug":"2.png","modified":1,"renderable":1},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/P_Trangle.png","post":"cjxqdm76h0043rsvjgozgk2eo","slug":"P_Trangle.png","modified":1,"renderable":1},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/Trangle.png","post":"cjxqdm76h0043rsvjgozgk2eo","slug":"Trangle.png","modified":1,"renderable":1},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/opencv-delaunay-vornoi-subdiv-example.png","slug":"opencv-delaunay-vornoi-subdiv-example.png","post":"cjxqdm76h0043rsvjgozgk2eo","modified":1,"renderable":0},{"_id":"source/_posts/门禁人脸检测和识别三：Delaunay三角剖分和Voronoi图/output_4_0.png","post":"cjxqdm76h0043rsvjgozgk2eo","slug":"output_4_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/Histograms of Oriented Gradients for Human Detection.png","post":"cjxqdm76d003xrsvjuuaocv3s","slug":"Histograms of Oriented Gradients for Human Detection.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/hog01.jpg","post":"cjxqdm76d003xrsvjuuaocv3s","slug":"hog01.jpg","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/hog02.jpg","post":"cjxqdm76d003xrsvjuuaocv3s","slug":"hog02.jpg","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记四：目标检测与识别/output_5_1.png","post":"cjxqdm76d003xrsvjuuaocv3s","slug":"output_5_1.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_10_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_10_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_12_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_12_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_15_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_15_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_17_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_17_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_4_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_4_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_6_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_6_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记二：图像处理/output_8_0.png","post":"cjxqdm76b003wrsvj1c45f9up","slug":"output_8_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/DOG Pyramid.jpg","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"DOG Pyramid.jpg","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/FAST_samples.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"FAST_samples.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_11_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_11_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_16_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_16_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_18_0.png","slug":"output_18_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","modified":1,"renderable":0},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_3_2.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_3_2.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_5_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_5_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_7_1.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_7_1.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/output_9_0.png","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"output_9_0.png","modified":1,"renderable":1},{"_id":"source/_posts/OpenCV学习笔记三：特征检测和图像检索/sift_local_extrema.jpg","post":"cjxqdm76w004arsvj7h4t3rgw","slug":"sift_local_extrema.jpg","modified":1,"renderable":1}],"PostCategory":[],"PostTag":[{"post_id":"cjxqdm73y0000rsvjluj4xcji","tag_id":"cjxqdm7450002rsvjipg2seg9","_id":"cjxqdm74m000ersvj8djt1mgv"},{"post_id":"cjxqdm73y0000rsvjluj4xcji","tag_id":"cjxqdm74g0006rsvj89avap8f","_id":"cjxqdm74n000grsvji70om1l8"},{"post_id":"cjxqdm73y0000rsvjluj4xcji","tag_id":"cjxqdm74k0009rsvj77fegmj4","_id":"cjxqdm74o000jrsvjv4pff1bx"},{"post_id":"cjxqdm7430001rsvjcdfgzynd","tag_id":"cjxqdm74l000crsvjkigopdxn","_id":"cjxqdm74p000lrsvjxcfheh1r"},{"post_id":"cjxqdm7460003rsvjzzrwqk5g","tag_id":"cjxqdm74o000hrsvjsoxoe0mw","_id":"cjxqdm74u000srsvj1ik2vmvl"},{"post_id":"cjxqdm7460003rsvjzzrwqk5g","tag_id":"cjxqdm74q000nrsvj8gyjuu43","_id":"cjxqdm74u000ursvjm24qh7zz"},{"post_id":"cjxqdm7480004rsvji3z4fm2b","tag_id":"cjxqdm74l000crsvjkigopdxn","_id":"cjxqdm74w000xrsvjc9ex3go1"},{"post_id":"cjxqdm74g0005rsvjlpzsuwf4","tag_id":"cjxqdm74l000crsvjkigopdxn","_id":"cjxqdm74x0011rsvjseim0gad"},{"post_id":"cjxqdm74i0007rsvjtlr9pz42","tag_id":"cjxqdm74w000zrsvj0n46kmve","_id":"cjxqdm74z0015rsvj1qijmnw1"},{"post_id":"cjxqdm74j0008rsvjj2ximybt","tag_id":"cjxqdm74w000zrsvj0n46kmve","_id":"cjxqdm7510019rsvjbdfvjscm"},{"post_id":"cjxqdm74k000arsvjpbc80pqr","tag_id":"cjxqdm74w000zrsvj0n46kmve","_id":"cjxqdm753001drsvjpzu19t6e"},{"post_id":"cjxqdm74m000drsvjix8msthk","tag_id":"cjxqdm74w000zrsvj0n46kmve","_id":"cjxqdm756001hrsvjau6hvndk"},{"post_id":"cjxqdm74n000frsvjxb3i5hdb","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm759001lrsvjimm99l1o"},{"post_id":"cjxqdm756001irsvjhqahgogm","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75b001nrsvjuw7323xc"},{"post_id":"cjxqdm74o000irsvj1q2v70ly","tag_id":"cjxqdm757001jrsvj9mlsyyp4","_id":"cjxqdm75c001qrsvj59ucexow"},{"post_id":"cjxqdm74p000krsvjjtmr5xfk","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75g001vrsvjcbhgq39d"},{"post_id":"cjxqdm75f001ursvj8ei9nltn","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75h001yrsvjh0upf089"},{"post_id":"cjxqdm74q000mrsvj1ui1gwll","tag_id":"cjxqdm75e001trsvjh5jaat26","_id":"cjxqdm75i001zrsvjss40z6bm"},{"post_id":"cjxqdm75g001wrsvjjv7m7b84","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75i0020rsvjm6aiddz3"},{"post_id":"cjxqdm75g001wrsvjjv7m7b84","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75i0022rsvjm4y8ejuy"},{"post_id":"cjxqdm74r000orsvjjvawzmes","tag_id":"cjxqdm75h001xrsvjlgm4ps58","_id":"cjxqdm75i0023rsvjkskqxpv3"},{"post_id":"cjxqdm74r000prsvjmscx60bn","tag_id":"cjxqdm75i0021rsvj9lmo6usd","_id":"cjxqdm75n0027rsvjjxh3opp3"},{"post_id":"cjxqdm74r000prsvjmscx60bn","tag_id":"cjxqdm75j0024rsvj6qn4hopr","_id":"cjxqdm75n0028rsvj4yc0bldb"},{"post_id":"cjxqdm74r000prsvjmscx60bn","tag_id":"cjxqdm75j0025rsvj4fuhker2","_id":"cjxqdm75n002arsvj6xbjqw7u"},{"post_id":"cjxqdm74t000rrsvj66lky429","tag_id":"cjxqdm75j0026rsvjdtwk0gyy","_id":"cjxqdm75n002brsvjtxub2iwn"},{"post_id":"cjxqdm74u000trsvj6mwbl92u","tag_id":"cjxqdm75n0029rsvj0l6tlc5j","_id":"cjxqdm75o002drsvj83fpjcxn"},{"post_id":"cjxqdm74v000wrsvj2v9tlitp","tag_id":"cjxqdm75i0021rsvj9lmo6usd","_id":"cjxqdm75p002hrsvjzptvlzdg"},{"post_id":"cjxqdm74v000wrsvj2v9tlitp","tag_id":"cjxqdm75j0024rsvj6qn4hopr","_id":"cjxqdm75p002irsvjnsel78j8"},{"post_id":"cjxqdm74v000wrsvj2v9tlitp","tag_id":"cjxqdm75j0025rsvj4fuhker2","_id":"cjxqdm75p002krsvjo0dauir4"},{"post_id":"cjxqdm74w000yrsvjusoshyse","tag_id":"cjxqdm75p002grsvjsu1ui741","_id":"cjxqdm75q002mrsvjlhoi4cxj"},{"post_id":"cjxqdm74w000yrsvjusoshyse","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75q002nrsvjomwow7h2"},{"post_id":"cjxqdm74x0010rsvjd2dvqzp8","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75r002qrsvjayp2rxyh"},{"post_id":"cjxqdm74x0010rsvjd2dvqzp8","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75r002rrsvj5kdky6qy"},{"post_id":"cjxqdm74x0012rsvjj59io5x8","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75s002ursvjv7ypultx"},{"post_id":"cjxqdm74x0012rsvjj59io5x8","tag_id":"cjxqdm75r002srsvj1cp0b4b0","_id":"cjxqdm75s002vrsvjvgtaj6gw"},{"post_id":"cjxqdm74z0016rsvjv63wlyv3","tag_id":"cjxqdm75s002trsvjgj0urkre","_id":"cjxqdm75t002yrsvjmgb8rf70"},{"post_id":"cjxqdm74z0016rsvjv63wlyv3","tag_id":"cjxqdm75s002wrsvjdxwqb3yy","_id":"cjxqdm75t002zrsvjifa6p4r5"},{"post_id":"cjxqdm7500018rsvj1bhiswl6","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75v0033rsvj6m19b3gp"},{"post_id":"cjxqdm7500018rsvj1bhiswl6","tag_id":"cjxqdm75t0030rsvjei27984u","_id":"cjxqdm75v0034rsvjcxh684bm"},{"post_id":"cjxqdm7500018rsvj1bhiswl6","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75v0036rsvjpe7chzro"},{"post_id":"cjxqdm751001arsvj79vrqh57","tag_id":"cjxqdm75t0030rsvjei27984u","_id":"cjxqdm75x003arsvj7p5dxfos"},{"post_id":"cjxqdm751001arsvj79vrqh57","tag_id":"cjxqdm75v0035rsvjsp2nua92","_id":"cjxqdm75x003brsvj36lo760p"},{"post_id":"cjxqdm751001arsvj79vrqh57","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75y003drsvj26t3bhr6"},{"post_id":"cjxqdm751001arsvj79vrqh57","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm75y003ersvjiahd2qfh"},{"post_id":"cjxqdm752001crsvjo1gqugcd","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75y003grsvj5c2g4q3u"},{"post_id":"cjxqdm752001crsvjo1gqugcd","tag_id":"cjxqdm75x003crsvjbi2i32pd","_id":"cjxqdm75z003hrsvj3rcvro7j"},{"post_id":"cjxqdm753001ersvjoz9npopo","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm75z003jrsvjr4u3ts11"},{"post_id":"cjxqdm755001grsvjff5ukdcm","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm760003mrsvjtr8099xp"},{"post_id":"cjxqdm755001grsvjff5ukdcm","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm760003nrsvjp8n2fdv5"},{"post_id":"cjxqdm755001grsvjff5ukdcm","tag_id":"cjxqdm75z003krsvjtr46hsi9","_id":"cjxqdm761003prsvj6hd4g33o"},{"post_id":"cjxqdm758001krsvjn74ah9zz","tag_id":"cjxqdm75j0026rsvjdtwk0gyy","_id":"cjxqdm761003rrsvj6fsd9t4g"},{"post_id":"cjxqdm758001krsvjn74ah9zz","tag_id":"cjxqdm761003orsvjtz2kg6i6","_id":"cjxqdm762003srsvjdxcpouiq"},{"post_id":"cjxqdm759001mrsvj6ig9i98q","tag_id":"cjxqdm75c001prsvjz5f66i3o","_id":"cjxqdm762003ursvj54009zzn"},{"post_id":"cjxqdm75c001rrsvj2prfmv7n","tag_id":"cjxqdm762003trsvjcvl1797g","_id":"cjxqdm763003vrsvjphtzann1"},{"post_id":"cjxqdm76b003wrsvj1c45f9up","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm76e003yrsvjg10udebu"},{"post_id":"cjxqdm76d003xrsvjuuaocv3s","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm76f0040rsvj77z9zfsn"},{"post_id":"cjxqdm76h0043rsvjgozgk2eo","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm76i0044rsvjcwsif1le"},{"post_id":"cjxqdm76e003zrsvjmn27e3he","tag_id":"cjxqdm75s002trsvjgj0urkre","_id":"cjxqdm76p0046rsvj8x0svr9i"},{"post_id":"cjxqdm76e003zrsvjmn27e3he","tag_id":"cjxqdm75s002wrsvjdxwqb3yy","_id":"cjxqdm76q0047rsvj2qj3xlqv"},{"post_id":"cjxqdm76e003zrsvjmn27e3he","tag_id":"cjxqdm76h0042rsvj69t4in90","_id":"cjxqdm76q0048rsvji9530raw"},{"post_id":"cjxqdm76e003zrsvjmn27e3he","tag_id":"cjxqdm76i0045rsvjfc7lv01q","_id":"cjxqdm76q0049rsvj1o6xh0rj"},{"post_id":"cjxqdm76w004arsvj7h4t3rgw","tag_id":"cjxqdm754001frsvjzp5dhem7","_id":"cjxqdm76y004brsvjr2rqnmys"}],"Tag":[{"name":"lua","_id":"cjxqdm7450002rsvjipg2seg9"},{"name":"neat","_id":"cjxqdm74g0006rsvj89avap8f"},{"name":"Mario","_id":"cjxqdm74k0009rsvj77fegmj4"},{"name":"hexo","_id":"cjxqdm74l000crsvjkigopdxn"},{"name":"3D打印","_id":"cjxqdm74o000hrsvjsoxoe0mw"},{"name":"吉他","_id":"cjxqdm74q000nrsvj8gyjuu43"},{"name":"Hikey970","_id":"cjxqdm74w000zrsvj0n46kmve"},{"name":"opencv","_id":"cjxqdm754001frsvjzp5dhem7"},{"name":"pyopencl","_id":"cjxqdm757001jrsvj9mlsyyp4"},{"name":"python","_id":"cjxqdm75c001prsvjz5f66i3o"},{"name":"RL","_id":"cjxqdm75e001trsvjh5jaat26"},{"name":"go","_id":"cjxqdm75h001xrsvjlgm4ps58"},{"name":"loomo","_id":"cjxqdm75i0021rsvj9lmo6usd"},{"name":"Android","_id":"cjxqdm75j0024rsvj6qn4hopr"},{"name":"机械手","_id":"cjxqdm75j0025rsvj4fuhker2"},{"name":"tensorflow","_id":"cjxqdm75j0026rsvjdtwk0gyy"},{"name":"sklearn","_id":"cjxqdm75n0029rsvj0l6tlc5j"},{"name":"tkinter","_id":"cjxqdm75p002grsvjsu1ui741"},{"name":"jupyter notebook","_id":"cjxqdm75r002srsvj1cp0b4b0"},{"name":"天猫精灵","_id":"cjxqdm75s002trsvjgj0urkre"},{"name":"esp8266","_id":"cjxqdm75s002wrsvjdxwqb3yy"},{"name":"raspberry","_id":"cjxqdm75t0030rsvjei27984u"},{"name":"tf","_id":"cjxqdm75v0035rsvjsp2nua92"},{"name":"arduino","_id":"cjxqdm75x003crsvjbi2i32pd"},{"name":"alphazero","_id":"cjxqdm75z003krsvjtr46hsi9"},{"name":"迁移学习","_id":"cjxqdm761003orsvjtz2kg6i6"},{"name":"AlphaZero","_id":"cjxqdm762003trsvjcvl1797g"},{"name":"php","_id":"cjxqdm76h0042rsvj69t4in90"},{"name":"mysql","_id":"cjxqdm76i0045rsvjfc7lv01q"}]}}