---
title: 元胞自动机与空间演化博弈
date: 2019-11-12 00:51:18
tags:
  - 数模
toc: true
---

<img src="数模：元胞自动机与空间演化博弈\203.gif">  

<!-- more -->
<The rest of contents | 余下全文>

# Cellular Automata & Monte Carlo （元胞自动机及蒙特卡罗方法）
<!-- <img src="数模：元胞自动机\00.png"> -->
<img src="数模：元胞自动机与空间演化博弈\100.png">  

## 概述
* 时间、空间都离散的动力系统
* 不同于数学方程模型，由一系列模型构造的规则构成的方法框架。
* 特点：时间、空间、状态离散。
* 用简单的逻辑规则，给出一种随时间演化的动力学模型，使之能模拟复杂系统。

## 元胞自动机
### 历史
* 20世纪50年代，John von Neumann 最早提出；
* 1970年，John Conway 提出生命游戏 (Conway, J. (1970). In M. Gardner, (Ed.), Scientific American, 223(4), pp. 120-123.)
* 1983年，Stephen Wolfram 初等元胞自动机(Stephen Wolfram. Reviews of Modern Physics,1983, Vol.55)
* 1986年至今，理论及应用

### 一维元胞自动机

一维格子：长为$L$的线段，$L$等份，得$L$个格子，构成一维格子。

格子的状态
* 每个格子有两种状态，且状态是随时间变化的。     
* 将$i$格子在$t$时刻的状态记为 $x_{i}^{t}$ ，规定
$$
x_{i}^{t}=\left\{\begin{array}{l}{0} \\ {1}\end{array}, i=1,2, \cdots \cdots, L\right.
$$

状态的更新机制

$$
x_{i}^{t+1}=f\left(x_{i-1}^{t}, x_{i}^{t}, x_{i+1}^{t}\right), \quad i=1,2, \cdots \cdots, L
$$

采用周期边界


### 时空图
L=100， 初值取$x_{i}^{0}=\left\{\begin{array}{ll}{1} & {i=50} \\ {0} & {i \neq 50}\end{array}\right.$  
用白色表示0状态，用黑色表示1状态。  
对给定规则，演化100时间步，可得如下结构时空图

<!-- <img src="数模：元胞自动机\01.png"> -->
<img src="数模：元胞自动机与空间演化博弈\101.png">  

### 二维元胞自动机

二维格子：将边长为L的正方形，每边L等份得到的L*L个格子。

格子状态：将$(i,j)$格子在$t$时刻的状态记为 $x_{i, j}^{t}$, $(i,j)$ 格子状态的种类由具体问题确定

格子的邻居
* Von Neumann 邻居   
* Moore邻居

状态更新机制：

$$
x_{i, j}^{t+1}=f\left(x_{i-1, j}^{t}, x_{i+1, j}^{t} x_{i, j}^{t}, x_{i, j-1}^{t}, x_{i, j+1}^{t}\right)
$$  
其中 $i, j=1,2, \cdots \cdots, L$

采用周期边界  

元胞自动机方法
* 对每个格子，制定状态改变的局部规则。
* 采用同步更新的方法，进行状态更新。

## 蒙特卡洛方法
随机选定格子
* 对格子及其邻居制定状态改变的局部规则。
* 采用异步更新的方法，进行状态更新。
* Monte-Carlo步与时间步
* Monte-Carlo步：按局部规则完成的一次更新为一个Monte-Carlo步
* 时间步：对 $L*L$ 格子，一般 $L^2$ 个Monte-Carlo步为一个时间步

## 总结
* 在$L*L$格子上，规定每个格子的状态种类数
* 根据具体问题背景，通过制定局部规则，建立格子状态的更新机制，通过计算机模拟研究相应系统的演化规律。
* 局部规则可采用元胞自动机方法或蒙特卡洛方法。
* 元胞自动机方法通过局部规则改变一个格子的状态，且所有格子同步更新。
* 蒙特卡洛方法通过局部规则以随机确定格子的方法，改变该格子及其局部的状态。

## 实验：元胞自动机时空图

CODE
``` python
"""
元胞自动机时空图 Python 实现
"""
%matplotlib inline

import numpy as np
import matplotlib.pyplot as plt
 

class CellularAutomata(object):
 
    def __init__(self, cells_lenth, rules=None):
        """
        Parameters
        ----------
        cells_lenth : 一维元胞自动机长度

        Examples
        --------
        创建一个长度为100的一位格子
        ca =  CellularAutomata(100)

        """

        # 矩阵的四周不参与运算
        self.lenth = cells_lenth
        self.n_iter = 101 # 演化次数
        self.timer = 0    # 当前迭代次数
        if rules:
            self.rules = rules
        else:
            self.rules = {(0,0,0):1, (0,0,1):1, (1,1,0):1, (1,0,1):1,
                          (1,1,1):0, (0,1,0):0, (0,1,1):0, (1,0,0):0} # 定义演化规则
        self.cells = np.zeros((cells_lenth, self.n_iter))
        self.cells[0, int(cells_lenth/2)] = 1 
        
    def update_state(self):
        """更新一次状态"""
        i = self.timer + 1 # 当前要更新的行
        for j in range(self.lenth):
            # 计算该细胞周围的存活细胞数
            (x, y, z) = (self.cells[i-1, (j-1+self.lenth)%self.lenth],
                         self.cells[i-1, j],
                         self.cells[i-1, (j+1+self.lenth)%self.lenth])
            self.cells[i, j] = self.rules[(x,y,z)]
        self.timer += 1
   
    def plot_state(self):
        """画出当前的状态"""
        plt.title('Iter :{}'.format(self.timer))
        plt.imshow(self.cells)
        plt.show()
 
    def update_and_plot(self, n_iter):
        """更新状态并画图
        Parameters
        ----------
        n_iter : 更新的轮数
        """
        plt.ion()
        for _ in range(n_iter):
            plt.title('Iter :{}'.format(self.timer))
            plt.imshow(self.cells)
            self.update_state()
            plt.pause(0.000001)
        plt.ioff()
        
    def update(self, n_iter):
        """更新状态并画图
        Parameters
        ----------
        n_iter : 更新的轮数
        """
        for _ in range(n_iter):
            self.update_state()

if __name__ == '__main__':
    plt.figure(figsize=(16,8))

    rules_list = [
        {(0,0,0):1, (0,0,1):1, (1,1,0):1, (1,0,1):1,
         (1,1,1):0, (0,1,0):0, (0,1,1):0, (1,0,0):0}, 
        {(0,0,0):1, (0,0,1):0, (1,1,0):1, (1,0,1):1,
         (1,1,1):0, (0,1,0):1, (0,1,1):0, (1,0,0):0}, 
        {(0,0,0):0, (0,0,1):1, (1,1,0):0, (1,0,1):0,
         (1,1,1):0, (0,1,0):1, (0,1,1):0, (1,0,0):1}, 
        {(0,0,0):1, (0,0,1):0, (1,1,0):1, (1,0,1):1,
         (1,1,1):0, (0,1,0):0, (0,1,1):1, (1,0,0):0}, 
        {(0,0,0):0, (0,0,1):1, (1,1,0):1, (1,0,1):0,
         (1,1,1):0, (0,1,0):1, (0,1,1):0, (1,0,0):1}, 
        {(0,0,0):0, (0,0,1):0, (1,1,0):1, (1,0,1):1,
         (1,1,1):0, (0,1,0):1, (0,1,1):1, (1,0,0):1}, 
        {(0,0,0):1, (0,0,1):0, (1,1,0):0, (1,0,1):1,
         (1,1,1):1, (0,1,0):1, (0,1,1):0, (1,0,0):1}, 
        {(0,0,0):1, (0,0,1):0, (1,1,0):1, (1,0,1):0,
         (1,1,1):0, (0,1,0):0, (0,1,1):1, (1,0,0):0}, 
    ]
    cas = [CellularAutomata(100, rules) for rules in rules_list]
    for i,ca in enumerate(cas):
        ca.update(99)
        plt.subplot(2,4,i+1)
        plt.imshow(ca.cells)
        plt.axis('off')  #去掉坐标轴
```

结果
<!-- <img src="数模：元胞自动机\02.png"> -->
<img src="数模：元胞自动机与空间演化博弈\102.png">  


# 空间博弈演化 Evolutionary games and spatial chaos

<img src="数模：元胞自动机与空间演化博弈\01.png">  

<!-- more -->
<The rest of contents | 余下全文>

## Prisoner’s dilemma —— 囚徒困境

### 出处
1950年，由就职于兰德公司的梅里尔·弗勒德（Merrill Flood）和梅尔文·德雷希尔（Melvin Dresher）拟定出相关困境的理论。  
后来由顾问艾伯特·塔克（Albert Tucker）以囚徒方式阐述，并命名为“囚徒困境”。

### 描述
两个嫌疑犯作案后被警察抓住，分别关在不同的屋子里接受审讯。  
警察知道两人有罪，但缺乏足够的证据。  
警察告诉每个人：  
如果两人都抵赖，各判刑一年；  
如果两人都坦白，各判八年；  
如果两人中一个坦白而另一个抵赖，坦白的放出去，抵赖的判十年。  
怎么决策？  

### 困境所在
每个囚徒面临两种选择：坦白或抵赖。  
不管同伙如何选择，自己的最优选择是坦白：  
如果同伙抵赖：自己坦白的话放出去，不坦白的话判一年，坦白比不坦白好；  
如果同伙坦白：自己坦白的话判八年，不坦白的话判十年，坦白还是比不坦白好。  
两个嫌疑犯都选择坦白，各判刑八年。  
如果两人都抵赖，各判一年，显然这个结果好。  
囚徒困境反映出的深刻问题：人类的个人理性有时能导致集体的非理性。  

### 行为和策略
个体的行为：
* 坦白
* 抵赖

行为由策略决定：
* 合作：cooperate (C)——抵赖
* 背叛：defect (D)——坦白  

个体间进行博弈，其策略组合对应着收益

### 收益矩阵（Payoff Matrix）
|  | C | D |
| ------ | ------ | ------ |
| C | (-1,-1) | (-10,0) |
| D | (0,-10) | (-8,-8) |


|  | C | D |
| ------ | ------ | ------ |
| C | R | S |
| D | T | P |
* T>R>P>S
* 2R>T+S

Nowak的单参数收益矩阵

|  | C | D |
| ------ | ------ | ------ |
| C | 1 | 0 |
| D | b | 0 |

其中1<b<2，b为背叛诱惑

## Evolution of cooperation behavior

### 策略的变化规则
将个体置于L×L网格上，周期边界  
每个格子一个个体  
初始时每个个体按比例（C、D的比例）赋予具体策略  
每一时刻，每个个体和邻居（4或8）及自身进行博弈，得到每个个体的总收益  
下一时刻个体的策略将以此为基础进行改变  

策略改变的规则： 每个个体选择自身及其邻居中收益值最高的那个个体的策略，作为下一时刻该个体的策略

每个个体策略的更新过程是同步进行的


## Using an efficient computer program

对给定的收益矩阵，及初始时个体的策略，可以通过计算机编程实现上述策略更新过程。  
从而可以知道每一时刻合作者的数量。


## 实验：基于二维元胞自动机的"囚徒困境"模型

### 参数设定及程序思路

* 预处理中，定义格子行数和列数为L，背叛诱惑为B，时间步为Step。  
* 格子策略由二维整型数组a[L][L]记录保存，通过先计算b[L][L]再赋值给a[L][L]保证格子状态同步更新.利用整型变量i j表示格子a[i][j]的位置，i为行数，j为列数。  
* 规则判断中由整型变量count计算邻居中合作者个数，并通过条件判断a[i][j]的策略，计算这一时刻它的收益值保存到二维浮点变量p[i][j]中。通过变量n比较收益大小，通过变量m保存收益大者的策略，并将其赋给t+1时刻个体的策略a[i][j]。
* 整型二维数组c[L][L]用于记录个体每一时刻决策的变化情况，它有四个值：1表示由背叛变为背叛，2表示由背叛变为合作，3表示由合作变为背叛，4表示由合作变为合作。
* 程序将输出策略时空图state.txt文件中，输出收益时空图到payoff.txt文件中，输出策略变化时空图到change.txt文件中。
* 在Matlab中导入change.txt文件转化为矩阵A。通过for循环，使用矩阵B获取矩阵A中表示每一步策略状态时空图的小矩阵。依次绘制B的图像并保存画面到矩阵m中，并利用系统提供的函数movie2avi导出.avi格式文件。

### 程序
数据生成
``` c
#include<stdlib.h>
#include<stdio.h>
#define L 100               //游戏规模
#define step 300            //演化步
#define B 1.93              //背叛诱惑

void main()
{
    int a[L][L],b[L][L];      //策略时空图
    float p[L][L];          //收益时空图
    int c[L][L];            //变化时空图
    float fc=0;            //合作频率
    int tmp_m;           //临时变量用于存放取得最大收益的策略
    float tmp_n;          //临时变量用于存放最大收益值
    int i,j,t,count=0;

    FILE *fp1,*fp2,*fp3,*fp4;
    fp1=fopen("strange.txt","w");
    fp2=fopen("payoff.txt","w");
    fp3=fopen("change.txt","w");
    fp4=fopen("fc.txt","w");

    for(i=0;i<L;i++)         //初始条件：60%合作者随机分布
        for(j=0;j<L;j++)
        {
            switch(rand()%10)
            {
                case 0:case 1:case 2:case 3:
                    a[i][j]=b[i][j]=0;
                    break;
                default:
                    a[i][j]=b[i][j]=1;
            }
        }
    for(t=0;t<step;t++)
    {
        for(i=0;i<L;i++)
        {
            for(j=0;j<L;j++)
            {
                count=0;
                if(a[(i-1+L)%L][(j-1+L)%L]==1) count++;
                if(a[(i-1+L)%L][j]==1) count++;
                if(a[(i-1+L)%L][(j+1+L)%L]==1) count++;
                if(a[i][(j-1+L)%L]==1) count++;
                if(a[i][j]==1) count++;
                if(a[i][(j+1+L)%L]==1) count++;
                if(a[(i+1+L)%L][(j-1+L)%L]==1) count++;
                if(a[(i+1+L)%L][j]==1) count++;
                if(a[(i+1+L)%L][(j+1+L)%L]==1) count++;

                if(a[i][j]==1)
                    p[i][j]=1*count;
                else
                    p[i][j]=B*count;                //计算收益
                fprintf(fp2,"%3.2f ",p[i][j]);
            }
            fprintf(fp2,"\n");
        }
        for(i=0;i<L;i++)
        {
            for(j=0;j<L;j++)
            {
                tmp_m=tmp_n=0;

                if(p[(i-1+L)%L][(j-1+L)%L]>tmp_n)
                    tmp_n=p[(i-1+L)%L][(j-1+L)%L],
                    tmp_m=a[(i-1+L)%L][(j-1+L)%L];
                if(p[(i-1+L)%L][j]>tmp_n)
                    tmp_n=p[(i-1+L)%L][j],tmp_m=a[(i-1+L)%L][j];
                if(p[(i-1+L)%L][(j+1+L)%L]>tmp_n) 
                    tmp_n=p[(i-1+L)%L][(j+1+L)%L], 
                    tmp_m=a[(i-1+L)%L][(j+1+L)%L];
                if(p[i][(j-1+L)%L]>tmp_n) 
                    tmp_n=p[i][(j-1+L)%L],tmp_m=a[i][(j-1+L)%L];
                if(p[i][j]>tmp_n)
                    tmp_n=p[i][j],tmp_m=a[i][j];
                if(p[i][(j+1+L)%L]>tmp_n) 
                    tmp_n=p[i][(j+1+L)%L],tmp_m=a[i][(j+1+L)%L];
                if(p[(i+1+L)%L][(j-1+L)%L]>tmp_n)
                    tmp_n=p[(i+1+L)%L][(j-1+L)%L],
                    tmp_m=a[(i+1+L)%L][(j-1+L)%L];
                if(p[(i+1+L)%L][j]>tmp_n)
                    tmp_n=p[(i+1+L)%L][j],tmp_m=a[(i+1+L)%L][j];
                if(p[(i+1+L)%L][(j+1+L)%L]>tmp_n)
                    tmp_n=p[(i+1+L)%L][(j+1+L)%L],
                    tmp_m=a[(i+1+L)%L][(j+1+L)%L];

                b[i][j]=tmp_m;
            }
        }

        for(i=0;i<L;i++)                       //统计策略变化情况
        {
            for(j=0;j<L;j++)
            {
                if (a[i][j]==0&&b[i][j]==0)
                    c[i][j]=1;
                else if (a[i][j]==0&&b[i][j]==1)
                    c[i][j]=2;
                else if (a[i][j]==1&&b[i][j]==0)
                    c[i][j]=3;
                else if(a[i][j]==1&&b[i][j]==1)
                    c[i][j]=4;
                a[i][j]=b[i][j];

            fprintf(fp1,"%d ",a[i][j]);
            fprintf(fp3,"%d ",c[i][j]);
            }
            fprintf(fp1,"\n");fprintf(fp3,"\n");
        }
        count=0;                    //计算合作频率
        for(i=0;i<L;i++)
            for(j=0;j<L;j++)
                count+=a[i][j];
        fc=(float)count/10000;
        printf("%lf",fc);
        fprintf(fp4,"%lf\n",fc);

        fprintf(fp1,"\n");fprintf(fp2,"\n");fprintf(fp3,"\n");
    }
}

```

使用matlab绘图
``` matlab
>>load change.txt                   %载入文件
>>A = importdata ('change.txt');     %转化为矩阵A
>>m = moviein (100);                 %建立一个100个列向量组成的矩阵
>>for   i = 1:100                    %绘制每一幅策略改变图并保存到矩阵m中
k = 100*i-99;
n = 100*i;
b = A(k:n,1:100);
imagesc(b);
m(:,i)=getframe;
end
>>movie2avi(m,'C:\二维演化.avi','compression','none');    %导出.avi格式文件
```

### 结果

<img src="数模：元胞自动机与空间演化博弈\02.png">  

当 1.8 < b < 2 时，初始分布仅为99×99的网格中央有一个背叛者，上图依次为第30、90、150、200时间步个体策略变化情况。其中棕色代表合作者坚持合作，蓝色代表背叛者坚持背叛，黄色代表合作者选择背叛，青色代表背叛者选择合作。


<img src="数模：元胞自动机与空间演化博弈\03.png">  

当 1.8 < b < 2 时，在60%的合作者的随机初始分布的条件下，合作频率在300个时间步内的变化。

<img src="数模：元胞自动机与空间演化博弈\04.png">   

当 1.8 < b < 2 时，初始条件为90%的合作者随机分布，在200×200的方格中模拟，最终稳定时策略变化图。  

<img src="数模：元胞自动机与空间演化博弈\05.png">   

当 1.75 < b < 1.8 时，初始条件为90%的合作者随机分布，在200×200的方格中模拟，最终稳定时策略变化图。






# 空间博弈与matplotlib绘制gif动图

<!-- <img src="数模：空间博弈与matplotlib绘制gif动图\03.gif"> -->
<img src="数模：元胞自动机与空间演化博弈\203.gif">  

```python
# 独立窗口显示
%matplotlib qt5 
# %matplotlib inline # 取消matplotlib的独立窗口显示
```
<!-- more -->
<The rest of contents | 余下全文>

## Python实现元胞自动机
* 详解Python 实现元胞自动机中的生命游戏(Game of life)_python_脚本之家  
https://www.jb51.net/article/133807.htm

问题重述
* 个体位于L*L网络上，网络无周期边界。  
* 每个格子一个个体，有0或1两种状态，0为死亡，1为存活。  
* 依据Moore邻居的状态决定个体下一时刻的状态：如果相邻方格活着的细胞数量过多，这个细胞会因为资源匮乏而在下一个时刻死去；相反，如果周围活细胞过少，这个细胞会因太孤单而死去。  
* 每个个体的状态更新是同步进行的。


```python
"""
元胞自动机 Python 实现
"""
import numpy as np
import matplotlib.pyplot as plt
 

class GameOfLife(object):
 
    def __init__(self, cells_shape):
        """
        Parameters
        ----------
        cells_shape : 一个元组，表示画布的大小。

        Examples
        --------
        建立一个高20，宽30的画布
        game = GameOfLife((20, 30))

        """

        # 矩阵的四周不参与运算
        self.cells = np.zeros(cells_shape)

        real_width = cells_shape[0] - 2
        real_height = cells_shape[1] - 2

        self.cells[1:-1, 1:-1] = np.random.randint(2, size=(real_width, real_height))
        self.timer = 0
        self.mask = np.ones(9)
        self.mask[4] = 0

    def update_state(self):
        """更新一次状态"""
        buf = np.zeros(self.cells.shape)
        cells = self.cells
        for i in range(1, cells.shape[0] - 1):
            for j in range(1, cells.shape[0] - 1):
                # 计算该细胞周围的存活细胞数
                neighbor = cells[i-1:i+2, j-1:j+2].reshape((-1, ))
                neighbor_num = np.convolve(self.mask, neighbor, 'valid')[0]
                if neighbor_num == 3:
                    buf[i, j] = 1
                elif neighbor_num == 2:
                    buf[i, j] = cells[i, j]
                else:
                    buf[i, j] = 0
        self.cells = buf
        self.timer += 1
   
    def plot_state(self):
        """画出当前的状态"""
        plt.title('Iter :{}'.format(self.timer))
        plt.imshow(self.cells)
        plt.show()
 
    def update_and_plot(self, n_iter):
        """更新状态并画图
        Parameters
        ----------
        n_iter : 更新的轮数
        """
        plt.ion()
        for _ in range(n_iter):
            plt.title('Iter :{}'.format(self.timer))
            plt.imshow(self.cells)
            self.update_state()
            plt.pause(0.2)
        plt.ioff()
           

if __name__ == '__main__':
    game = GameOfLife(cells_shape=(60, 60))
    game.update_and_plot(5)

```
<!-- <img src="数模：空间博弈与matplotlib绘制gif动图\01.png"> -->
<img src="数模：元胞自动机与空间演化博弈\201.png">  

生命游戏中的图形
* Category:Animated images - LifeWiki  
https://www.conwaylife.com/wiki/Category:Animated_images


## 基于元胞自动机的空间博弈

问题重述
* 个体位于L*L网络上，网络无周期边界。  
* 每个格子一个个体，有0或1两种状态，0为背叛，1为合作。  
* 每一时刻，个体和其Moore邻居进行博弈，依据Nowak的单参数收益矩阵，得到每个个体的收益，下一时刻个体的策略以此为基础，即选择自身及邻居中收益值最高的那个个体的策略，作为该个体下一时刻的策略。
* 个体策略更新是同步进行的。

单参数收益矩阵( 1 < b < 2 )
|  | C | D |
| ------ | ------ | ------ |
| C | 1 | 0 |
| D | b | 0 |


```python
"""
基于元胞自动机的空间博弈演化
"""
import numpy as np
import matplotlib.pyplot as plt
 

class GameOfLife(object):
 
    def __init__(self, cells_shape):
        """
        Parameters
        ----------
        cells_shape : 一个元组，表示画布的大小。

        Examples
        --------
        建立一个高20，宽30的画布
        game = GameOfLife((20, 30))

        """

        # 矩阵的四周不参与运算
        self.cells_strategic = np.ones(cells_shape)
        self.cells_benefits = np.zeros(cells_shape)
        self.cells_statechange = np.zeros(cells_shape)
        
        self.state_change = {(1,1):0, (1,0):1, (0,0):2, (0,1):3} 

        real_width = cells_shape[0] - 2
        real_height = cells_shape[1] - 2

        # self.cells_strategic[1:-1, 1:-1] = np.random.randint(2, size=(real_width, real_height)) # 随机策略
        self.cells_strategic[int(real_width/2)+1, int(real_height/2)+1] = 0  # 1：合作  0：背叛
        
        self.B = 1.97 # 背叛诱惑
        self.timer = 0
   
    def update_state(self):
        """更新一次状态"""
        
        buf_b = np.zeros(self.cells_strategic.shape)
        buf_s = np.zeros(self.cells_strategic.shape)
        buf_c = np.zeros(self.cells_strategic.shape)

        cells = self.cells_strategic
        # 更新收益矩阵
        for i in range(1, cells.shape[0] - 1):
            for j in range(1, cells.shape[0] - 1):
                # 计算该细胞周围的合作者数量
                neighbor = cells[i-1:i+2, j-1:j+2]
                neighbor_num = np.sum(neighbor) # 邻居中合作者的数量
                # 计算该细胞收益
                if cells[i, j] == 1: # 计算合作者的收益
                    buf_b[i, j] = neighbor_num * 1.0
                else:
                    buf_b[i, j] = neighbor_num * self.B
        # print(buf_b)
        self.cells_benefits = buf_b
        
        # 更新状态矩阵和状态转移矩阵
        for i in range(1, cells.shape[0] - 1):
            for j in range(1, cells.shape[0] - 1):
                # 找到该细胞及其邻居收益最大值者的策略
                neighbor = self.cells_benefits[i-1:i+2, j-1:j+2]
                index = int(neighbor.argmax())
                # x, y= int(index / 3), index % 3
                (x, y) = np.unravel_index(neighbor.argmax(), neighbor.shape)
                buf_s[i, j] = cells[i-1+x, j-1+y]
                # 更新状态转移矩阵
                last_stratage, new_stratage = cells[i, j], buf_s[i, j] 
                buf_c[i, j] = self.state_change[(last_stratage, new_stratage)]
        # print(buf_s)
        self.cells_strategic = buf_s
        self.cells_statechange = buf_c
        self.timer += 1

    def plot_state(self):
        """画出当前的状态"""
        plt.title('Iter :{}'.format(self.timer))
        plt.imshow(self.cells_strategic)
        plt.show()

    def update_and_plot(self, n_iter):
        """更新状态并画图
        Parameters
        ----------
        n_iter : 更新的轮数
        """
        plt.ion()
        for _ in range(n_iter):
            plt.title('Iter :{}'.format(self.timer))
            # plt.imshow(self.cells_strategic)    # 策略
            plt.imshow(self.cells_statechange)  # 策略变化
            self.update_state()
            plt.pause(0.00001)
        plt.ioff()
           

if __name__ == '__main__':
    game = GameOfLife(cells_shape=(101, 101))
    game.update_and_plot(n_iter=50)
```

## matplotlab绘制动图及保存gif图片
* 如何通过 Matplotlib 绘制动画及保存 GIF 图片？ - frank 的专栏 - CSDN博客  
https://blog.csdn.net/briblue/article/details/84940997

FuncAnimation 的构造方法
``` python
def __init__(self, fig, func, frames=None, init_func=None, fargs=None,
                 save_count=None, **kwargs):
```
* **fig** 自然是 matplotlib 中的 figure 对象。  
* **func** 是每一次更新时所调用的方法,它是回调函数。因此，我们可以在这个方法中更新 figure 当中的 axes 中的 line2d 对象，它是动态更新 figure 的根本。  
* **frames** 代表了整个动画过程中帧的取值范围，而本质上是一个数据发生器。
* **init_func** 是初始函数，用来初始 figure 的画面。  
* **fargs** 是每次附加给 func 回调函数的参数，可以为 None  
* **save_count** 是缓存的数量  
除此之外，还有一些可选的参数，它们分别是  
* **interval** 是每 2 个 frame 发生的时间间隔,单位是 ms，默认值是 200.  
* **repeat_delay**  取值是数值，如果 animation 是重复播放的话，这个值就是每次播放之间的延迟时间，单位是 ms。  
* **repeat**  bool 型可选参数，默认为 True，代表动画是否会重复执行  
* **blit** bool 型可选参数，控制绘制的优化。默认是 False。  

保存
``` python
anim.save('cells_animation.gif',writer='imagemagick')
```


```python
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.animation as animation

fig, ax = plt.subplots()
xdata, ydata = [], []
ln, = plt.plot([], [], 'ro',animated=True)

def init():
    ax.set_xlim(-np.pi,np.pi)
    ax.set_ylim(-1, 1)
    return ln,

def update(frame):
    xdata.append(frame)
    ydata.append(np.sin(frame))
    ln.set_data(xdata, ydata)
    return ln,

def data_gen():
    frame = -np.pi
    step = 2 * np.pi / 90
    while frame < np.pi:
        frame += step
        yield frame

# anim = animation.FuncAnimation(fig, update, frames=np.linspace(-np.pi,np.pi, 360),interval=10,
#                     init_func=init,blit=True)
anim = animation.FuncAnimation(fig, update, frames=data_gen,interval=10,
                    init_func=init,blit=True)

plt.show()
```
<!-- <img src="数模：空间博弈与matplotlib绘制gif动图\02.gif"> -->
<img src="数模：元胞自动机与空间演化博弈\202.gif">  


```python
import matplotlib.pyplot as plt
import matplotlib.animation as animation

"""
基于元胞自动机的空间博弈演化
"""

game = GameOfLife(cells_shape=(101, 101))
data = game.cells_statechange        
fig, ax = plt.subplots()
ax = plt.imshow(data)

def init():
    return ax,

def update(data):
    game.update_state()
    data = game.cells_statechange
    ax = plt.imshow(data)
    return ax,

anim = animation.FuncAnimation(fig=fig, func=update, frames=10, init_func=init, interval=1, blit=True)

plt.show()

# 保存
anim.save('cells_animation.gif',writer='imagemagick')
```

<!-- <img src="数模：空间博弈与matplotlib绘制gif动图\03.gif"> -->
<img src="数模：元胞自动机与空间演化博弈\303.png">  


