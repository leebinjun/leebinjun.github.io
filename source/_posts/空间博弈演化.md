---
title: 空间博弈演化
date: 2019-11-12 00:41:12
toc: true
tags:
  - 数模
---


# Evolutionary games and spatial chaos

<!-- more -->
<The rest of contents | 余下全文>

## Prisoner’s dilemma —— 囚徒困境

### 出处
1950年，由就职于兰德公司的梅里尔·弗勒德（Merrill Flood）和梅尔文·德雷希尔（Melvin Dresher）拟定出相关困境的理论。  
后来由顾问艾伯特·塔克（Albert Tucker）以囚徒方式阐述，并命名为“囚徒困境”。

### 描述
两个嫌疑犯作案后被警察抓住，分别关在不同的屋子里接受审讯。  
警察知道两人有罪，但缺乏足够的证据。  
警察告诉每个人：  
如果两人都抵赖，各判刑一年；  
如果两人都坦白，各判八年；  
如果两人中一个坦白而另一个抵赖，坦白的放出去，抵赖的判十年。  
怎么决策？  

### 困境所在
每个囚徒面临两种选择：坦白或抵赖。  
不管同伙如何选择，自己的最优选择是坦白：  
如果同伙抵赖：自己坦白的话放出去，不坦白的话判一年，坦白比不坦白好；  
如果同伙坦白：自己坦白的话判八年，不坦白的话判十年，坦白还是比不坦白好。  
两个嫌疑犯都选择坦白，各判刑八年。  
如果两人都抵赖，各判一年，显然这个结果好。  
囚徒困境反映出的深刻问题：人类的个人理性有时能导致集体的非理性。  

### 行为和策略
个体的行为：
* 坦白
* 抵赖

行为由策略决定：
* 合作：cooperate (C)——抵赖
* 背叛：defect (D)——坦白  

个体间进行博弈，其策略组合对应着收益

### 收益矩阵（Payoff Matrix）
|  | C | D |
| ------ | ------ | ------ |
| C | (-1,-1) | (-10,0) |
| D | (0,-10) | (-8,-8) |


|  | C | D |
| ------ | ------ | ------ |
| C | R | S |
| D | T | P |
* T>R>P>S
* 2R>T+S

Nowak的单参数收益矩阵

|  | C | D |
| ------ | ------ | ------ |
| C | 1 | 0 |
| D | b | 0 |

其中1<b<2，b为背叛诱惑

## Evolution of cooperation behavior

### 策略的变化规则
将个体置于L×L网格上，周期边界  
每个格子一个个体  
初始时每个个体按比例（C、D的比例）赋予具体策略  
每一时刻，每个个体和邻居（4或8）及自身进行博弈，得到每个个体的总收益  
下一时刻个体的策略将以此为基础进行改变  

策略改变的规则： 每个个体选择自身及其邻居中收益值最高的那个个体的策略，作为下一时刻该个体的策略

每个个体策略的更新过程是同步进行的


## Using an efficient computer program

对给定的收益矩阵，及初始时个体的策略，可以通过计算机编程实现上述策略更新过程。  
从而可以知道每一时刻合作者的数量。


## 实验：基于二维元胞自动机的"囚徒困境"模型

### 参数设定及程序思路

* 预处理中，定义格子行数和列数为L，背叛诱惑为B，时间步为Step。  
* 格子策略由二维整型数组a[L][L]记录保存，通过先计算b[L][L]再赋值给a[L][L]保证格子状态同步更新.利用整型变量i j表示格子a[i][j]的位置，i为行数，j为列数。  
* 规则判断中由整型变量count计算邻居中合作者个数，并通过条件判断a[i][j]的策略，计算这一时刻它的收益值保存到二维浮点变量p[i][j]中。通过变量n比较收益大小，通过变量m保存收益大者的策略，并将其赋给t+1时刻个体的策略a[i][j]。
* 整型二维数组c[L][L]用于记录个体每一时刻决策的变化情况，它有四个值：1表示由背叛变为背叛，2表示由背叛变为合作，3表示由合作变为背叛，4表示由合作变为合作。
* 程序将输出策略时空图state.txt文件中，输出收益时空图到payoff.txt文件中，输出策略变化时空图到change.txt文件中。
* 在Matlab中导入change.txt文件转化为矩阵A。通过for循环，使用矩阵B获取矩阵A中表示每一步策略状态时空图的小矩阵。依次绘制B的图像并保存画面到矩阵m中，并利用系统提供的函数movie2avi导出.avi格式文件。

### 程序
数据生成
``` c
#include<stdlib.h>
#include<stdio.h>
#define L 100               //游戏规模
#define step 300            //演化步
#define B 1.93              //背叛诱惑

void main()
{
    int a[L][L],b[L][L];      //策略时空图
    float p[L][L];          //收益时空图
    int c[L][L];            //变化时空图
    float fc=0;            //合作频率
    int tmp_m;           //临时变量用于存放取得最大收益的策略
    float tmp_n;          //临时变量用于存放最大收益值
    int i,j,t,count=0;

    FILE *fp1,*fp2,*fp3,*fp4;
    fp1=fopen("strange.txt","w");
    fp2=fopen("payoff.txt","w");
    fp3=fopen("change.txt","w");
    fp4=fopen("fc.txt","w");

    for(i=0;i<L;i++)         //初始条件：60%合作者随机分布
        for(j=0;j<L;j++)
        {
            switch(rand()%10)
            {
                case 0:case 1:case 2:case 3:
                    a[i][j]=b[i][j]=0;
                    break;
                default:
                    a[i][j]=b[i][j]=1;
            }
        }
    for(t=0;t<step;t++)
    {
        for(i=0;i<L;i++)
        {
            for(j=0;j<L;j++)
            {
                count=0;
                if(a[(i-1+L)%L][(j-1+L)%L]==1) count++;
                if(a[(i-1+L)%L][j]==1) count++;
                if(a[(i-1+L)%L][(j+1+L)%L]==1) count++;
                if(a[i][(j-1+L)%L]==1) count++;
                if(a[i][j]==1) count++;
                if(a[i][(j+1+L)%L]==1) count++;
                if(a[(i+1+L)%L][(j-1+L)%L]==1) count++;
                if(a[(i+1+L)%L][j]==1) count++;
                if(a[(i+1+L)%L][(j+1+L)%L]==1) count++;

                if(a[i][j]==1)
                    p[i][j]=1*count;
                else
                    p[i][j]=B*count;                //计算收益
                fprintf(fp2,"%3.2f ",p[i][j]);
            }
            fprintf(fp2,"\n");
        }
        for(i=0;i<L;i++)
        {
            for(j=0;j<L;j++)
            {
                tmp_m=tmp_n=0;

                if(p[(i-1+L)%L][(j-1+L)%L]>tmp_n)
                    tmp_n=p[(i-1+L)%L][(j-1+L)%L],
                    tmp_m=a[(i-1+L)%L][(j-1+L)%L];
                if(p[(i-1+L)%L][j]>tmp_n)
                    tmp_n=p[(i-1+L)%L][j],tmp_m=a[(i-1+L)%L][j];
                if(p[(i-1+L)%L][(j+1+L)%L]>tmp_n) 
                    tmp_n=p[(i-1+L)%L][(j+1+L)%L], 
                    tmp_m=a[(i-1+L)%L][(j+1+L)%L];
                if(p[i][(j-1+L)%L]>tmp_n) 
                    tmp_n=p[i][(j-1+L)%L],tmp_m=a[i][(j-1+L)%L];
                if(p[i][j]>tmp_n)
                    tmp_n=p[i][j],tmp_m=a[i][j];
                if(p[i][(j+1+L)%L]>tmp_n) 
                    tmp_n=p[i][(j+1+L)%L],tmp_m=a[i][(j+1+L)%L];
                if(p[(i+1+L)%L][(j-1+L)%L]>tmp_n)
                    tmp_n=p[(i+1+L)%L][(j-1+L)%L],
                    tmp_m=a[(i+1+L)%L][(j-1+L)%L];
                if(p[(i+1+L)%L][j]>tmp_n)
                    tmp_n=p[(i+1+L)%L][j],tmp_m=a[(i+1+L)%L][j];
                if(p[(i+1+L)%L][(j+1+L)%L]>tmp_n)
                    tmp_n=p[(i+1+L)%L][(j+1+L)%L],
                    tmp_m=a[(i+1+L)%L][(j+1+L)%L];

                b[i][j]=tmp_m;
            }
        }

        for(i=0;i<L;i++)                       //统计策略变化情况
        {
            for(j=0;j<L;j++)
            {
                if (a[i][j]==0&&b[i][j]==0)
                    c[i][j]=1;
                else if (a[i][j]==0&&b[i][j]==1)
                    c[i][j]=2;
                else if (a[i][j]==1&&b[i][j]==0)
                    c[i][j]=3;
                else if(a[i][j]==1&&b[i][j]==1)
                    c[i][j]=4;
                a[i][j]=b[i][j];

            fprintf(fp1,"%d ",a[i][j]);
            fprintf(fp3,"%d ",c[i][j]);
            }
            fprintf(fp1,"\n");fprintf(fp3,"\n");
        }
        count=0;                    //计算合作频率
        for(i=0;i<L;i++)
            for(j=0;j<L;j++)
                count+=a[i][j];
        fc=(float)count/10000;
        printf("%lf",fc);
        fprintf(fp4,"%lf\n",fc);

        fprintf(fp1,"\n");fprintf(fp2,"\n");fprintf(fp3,"\n");
    }
}

```

使用matlab绘图
``` matlab
>>load change.txt                   %载入文件
>>A = importdata ('change.txt');     %转化为矩阵A
>>m = moviein (100);                 %建立一个100个列向量组成的矩阵
>>for   i = 1:100                    %绘制每一幅策略改变图并保存到矩阵m中
k = 100*i-99;
n = 100*i;
b = A(k:n,1:100);
imagesc(b);
m(:,i)=getframe;
end
>>movie2avi(m,'C:\二维演化.avi','compression','none');    %导出.avi格式文件
```

### 结果

<img src="空间博弈演化\02.png">  

当 1.8 < b < 2 时，初始分布仅为99×99的网格中央有一个背叛者，上图依次为第30、90、150、200时间步个体策略变化情况。其中棕色代表合作者坚持合作，蓝色代表背叛者坚持背叛，黄色代表合作者选择背叛，青色代表背叛者选择合作。


<img src="空间博弈演化\03.png">  

当 1.8 < b < 2 时，在60%的合作者的随机初始分布的条件下，合作频率在300个时间步内的变化。

<img src="空间博弈演化\04.png">   

当 1.8 < b < 2 时，初始条件为90%的合作者随机分布，在200×200的方格中模拟，最终稳定时策略变化图。  

<img src="空间博弈演化\05.png">   

当 1.75 < b < 1.8 时，初始条件为90%的合作者随机分布，在200×200的方格中模拟，最终稳定时策略变化图。



